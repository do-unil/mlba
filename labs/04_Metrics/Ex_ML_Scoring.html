<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ex_ml_scoring – MLBA - S24 </title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" rel="next">
<link href="../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" rel="prev">
<link href="../../images/logo.dark.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ce80fb680f754bdddd2e33f428b7c2fe.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-a77d94411ef28645364aa138da2dc249.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-96ccf8338fe666a1f86f626509d49180.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-109dea34fb0ab778c1fa5d25b6154e69.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="MLBA - S24">
<meta property="og:description" content="Homepage for Machine Learning in Business Analytics at HEC Lausanne, Spring 2024.">
<meta property="og:site_name" content="MLBA - S24 ">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../labs/04_Metrics/Ex_ML_Scoring.html">Metrics</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../images/logo.light.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main tools-wide">
    <a href="http://moodle2.unil.ch/course/view.php?id=8715" title="Moodle" class="quarto-navigation-tool px-1" aria-label="Moodle"><i class="bi bi-person-rolodex"></i></a>
    <a href="https://github.com/do-unil/mlba" title="GitHub Repo" class="quarto-navigation-tool px-1" aria-label="GitHub Repo"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../schedule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../faq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FAQ</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Lectures</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/01_Introduction/ML_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/02_DataExploration/ML_DataExplo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Exploration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/030_Introduction/ML_Models_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/031_LinearLogisticRegression/ML_LinLogReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/032_Trees/ML_Trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/033_NeuralNetworks/ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/034_SupportVectorMachine/ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/04_Metrics/ML_Metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/05_DataSplitting/ML_DataSplitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/06_Ensembles/ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/07_InterpretableML/ML_Interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/080_Introduction/ML_UnsupIntro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Unsuperised Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/081_Clustering/ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/082_DimensionReduction/ML_DimRed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dimension Reduction</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/00_lab/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/032_Trees/Ex_ML_Tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/033_NeuralNetworks/EX_ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/04_Metrics/Ex_ML_Scoring.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/06_Ensembles/Ex_ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/07_InterpretableML/Ex_ML_VarImp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/081_Clustering/Ex_ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/082_DimensionReduction/Ex_ML_PCA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/083_AutoEncoders/Ex_ML_Autoencoder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Autoencoders</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Assessments</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Exam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exam</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Project</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Project_Directives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Directives</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Report_Guideline.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Report Guidelines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Presentation_Guidelines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Presentation Guidelines</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/beginners_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Beginners in R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/data_acquisition/data_sources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Sources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/data_acquisition/web_scraping_api.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Web Scraping</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/cheatsheets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding Cheatsheets</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#regression-task" id="toc-regression-task" class="nav-link active" data-scroll-target="#regression-task">Regression task</a>
  <ul class="collapse">
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">Data</a></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models">Models</a></li>
  <li><a href="#r-squared" id="toc-r-squared" class="nav-link" data-scroll-target="#r-squared">R-squared</a></li>
  <li><a href="#rmse" id="toc-rmse" class="nav-link" data-scroll-target="#rmse">RMSE</a></li>
  <li><a href="#mae" id="toc-mae" class="nav-link" data-scroll-target="#mae">MAE</a></li>
  <li><a href="#best-model" id="toc-best-model" class="nav-link" data-scroll-target="#best-model">Best model</a></li>
  </ul></li>
  <li><a href="#classification-task" id="toc-classification-task" class="nav-link" data-scroll-target="#classification-task">Classification task</a>
  <ul class="collapse">
  <li><a href="#data-1" id="toc-data-1" class="nav-link" data-scroll-target="#data-1">Data</a></li>
  <li><a href="#models-1" id="toc-models-1" class="nav-link" data-scroll-target="#models-1">Models</a></li>
  <li><a href="#predictions" id="toc-predictions" class="nav-link" data-scroll-target="#predictions">Predictions</a></li>
  <li><a href="#confusion-matrices-prediction-based-measures" id="toc-confusion-matrices-prediction-based-measures" class="nav-link" data-scroll-target="#confusion-matrices-prediction-based-measures">Confusion matrices &amp; prediction-based measures</a></li>
  <li><a href="#probability-based-measures" id="toc-probability-based-measures" class="nav-link" data-scroll-target="#probability-based-measures">Probability-based measures</a></li>
  <li><a href="#roc-curve-prob-threshold-tuning" id="toc-roc-curve-prob-threshold-tuning" class="nav-link" data-scroll-target="#roc-curve-prob-threshold-tuning">ROC curve &amp; prob threshold tuning</a></li>
  </ul></li>
  <li><a href="#your-turn" id="toc-your-turn" class="nav-link" data-scroll-target="#your-turn">Your turn</a>
  <ul class="collapse">
  <li><a href="#classification" id="toc-classification" class="nav-link" data-scroll-target="#classification">Classification</a></li>
  <li><a href="#regression" id="toc-regression" class="nav-link" data-scroll-target="#regression">Regression</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/04_Metrics/Ex_ML_Scoring.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../labs/04_Metrics/Ex_ML_Scoring.html">Metrics</a></li></ol></nav><h1 class="title display-7"></h1></header><div class="quarto-title-block"><div class="quarto-title-tools-only"><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<script type="application/javascript">
// Description: Change image src depending on body class (quarto-light or quarto-dark)
function updateImageSrc() {
  var bodyClass = window.document.body.classList;
  var images = window.document.getElementsByTagName('img');
  for (var i = 0; i < images.length; i++) {
    var image = images[i];
    var src = image.src;
    var newSrc = src;
    if (bodyClass.contains('quarto-light') && src.includes('.dark')) {
      newSrc = src.replace('.dark', '.light');
    } else if (bodyClass.contains('quarto-dark') && src.includes('.light')) {
      newSrc = src.replace('.light', '.dark');
    }
    if (newSrc !== src) {
      image.src = newSrc;
    }
  }
}

var observer = new MutationObserver(function(mutations) {
  mutations.forEach(function(mutation) {
    if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
      updateImageSrc();
    }
  });
});

observer.observe(window.document.body, {
  attributes: true
});

updateImageSrc();
</script>




<p>How can I render the following?— title: “Model scoring”</p>
<hr>
<section id="regression-task" class="level1">
<h1>Regression task</h1>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">Data</h2>
<p>The data set is the one used in the series on linear regressions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/real_estate_data.csv"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then we split the data in a training and a test set (0.8/0.2). For this, we use the <code>createDataPartition</code> function of the <code>caret</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>index_tr <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> real_estate_data<span class="sc">$</span>Price, <span class="at">p=</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>df_tr <span class="ot">&lt;-</span> real_estate_data[index_tr,]</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>df_te <span class="ot">&lt;-</span> real_estate_data[<span class="sc">-</span>index_tr,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="models" class="level2">
<h2 class="anchored" data-anchor-id="models">Models</h2>
<p>We will compare a linear regression, a regression tree and a 3-NN (KNN).</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>est_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span>HouseAge<span class="sc">+</span>Dist<span class="sc">+</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>               NumStores<span class="sc">+</span>Lat<span class="sc">+</span>Long, <span class="at">data=</span>df_tr)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>est_rt <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span>HouseAge<span class="sc">+</span>Dist<span class="sc">+</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>                      NumStores<span class="sc">+</span>Lat<span class="sc">+</span>Long, <span class="at">data=</span>df_tr)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>est_knn <span class="ot">&lt;-</span> <span class="fu">knnreg</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span>HouseAge<span class="sc">+</span>Dist<span class="sc">+</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>                      NumStores<span class="sc">+</span>Lat<span class="sc">+</span>Long, <span class="at">data=</span>df_tr, <span class="at">k =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the course python environment as usual with a r code chunks.</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the models: linear regression, regression tree, and KNN</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define predictors and target variable</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>predictors <span class="op">=</span> [<span class="st">'TransDate'</span>, <span class="st">'HouseAge'</span>, <span class="st">'Dist'</span>, <span class="st">'NumStores'</span>, <span class="st">'Lat'</span>, <span class="st">'Long'</span>]</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">'Price'</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit models</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>est_lm <span class="op">=</span> LinearRegression().fit(r.df_tr[predictors], r.df_tr[target])</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>est_rt <span class="op">=</span> DecisionTreeRegressor(random_state<span class="op">=</span><span class="dv">234</span>).fit(r.df_tr[predictors], r.df_tr[target])</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>est_knn <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">3</span>).fit(r.df_tr[predictors], r.df_tr[target])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="r-squared" class="level2">
<h2 class="anchored" data-anchor-id="r-squared">R-squared</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>We now compute the R2 for each model using the a defined function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">=</span> <span class="cf">function</span>(y_predict, y_actual){</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cor</span>(y_actual,y_predict)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="fu">R2</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">R2</span>(<span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="fu">R2</span>(<span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Just for the exercise, we can compute it by hand (square of the correlation)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)<span class="sc">^</span><span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing as the R code</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Only to demonostrate which argument goes where (different from `caret::R2`)</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(y_true <span class="op">=</span> r.df_te[target], y_pred <span class="op">=</span> est_lm.predict(r.df_te[predictors])))</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Computing it by hand gives us the same result as R</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>np.corrcoef(est_lm.predict(r.df_te[predictors]), r.df_te[target])[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To understand why the results are different in <code>R2</code> from our defined function in R vs.&nbsp;<code>sklearn.metrics.r2_score()</code> in Python, see <a href="https://stats.stackexchange.com/questions/586821/what-is-the-interpretation-of-the-traditional-r2">this post on stackoverflow</a>. If you want to recieve the same results in both, you can try computing the R2 not by correlation but by the formula <span class="math inline">\(1 - \frac{SSR}{SST}\)</span> where <span class="math inline">\(SSR\)</span> is the sum of squared residuals and <span class="math inline">\(SST\)</span> is the total sum of squares.</p>
<p>Additionally, please note that the performance of the tree is highly dependent on the seed, so setting a different seed can lead to different results.</p>
</div>
</div>
</div>
</section>
<section id="rmse" class="level2">
<h2 class="anchored" data-anchor-id="rmse">RMSE</h2>
<p>Now, we compute the RMSE.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE</span>(<span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE</span>(<span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The formula would be:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>((<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te)<span class="sc">-</span>df_te<span class="sc">$</span>Price)<span class="sc">^</span><span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, root_mean_squared_error</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_lm.predict(r.df_te[predictors])))</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># alternatively in the older version of `sklearn`, you had to run the code below</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># print(np.sqrt(mean_squared_error(r.df_te[target], est_lm.predict(r.df_te[predictors]))))</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="mae" class="level2">
<h2 class="anchored" data-anchor-id="mae">MAE</h2>
<p>Now, we compute the MAE.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">MAE</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">MAE</span>(<span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">MAE</span>(<span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The formula would be:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">abs</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te)<span class="sc">-</span>df_te<span class="sc">$</span>Price))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute MAE for each model</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_lm.predict(r.df_te[predictors])))</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="best-model" class="level2">
<h2 class="anchored" data-anchor-id="best-model">Best model</h2>
<p>These three measures agree on the fact that the regression tree is the best model. To inspect further the predictions, we use scatterplots:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(df_te<span class="sc">$</span>Price <span class="sc">~</span> <span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), <span class="at">xlab=</span><span class="st">"Prediction"</span>, </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Observed prices"</span>, <span class="at">main=</span><span class="st">"Lin. Reg."</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(df_te<span class="sc">$</span>Price <span class="sc">~</span> <span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), <span class="at">xlab=</span><span class="st">"Prediction"</span>, </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Observed prices"</span>, <span class="at">main=</span><span class="st">"Lin. Reg."</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(df_te<span class="sc">$</span>Price <span class="sc">~</span> <span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), <span class="at">xlab=</span><span class="st">"Prediction"</span>, </span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Observed prices"</span>, <span class="at">main=</span><span class="st">"Lin. Reg."</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize also in Python</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">221</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_lm.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Lin. Reg."</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">222</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_rt.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Regression Tree"</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">223</span>)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_knn.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"KNN"</span>)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>The scatterplots are in line with the conclusion that KNN is the best, even though it is not easy to declare from a plot. We can in addition see that the regression tree (RT) has made more error on the larger prices.</p>
</section>
</section>
<section id="classification-task" class="level1">
<h1>Classification task</h1>
<section id="data-1" class="level2">
<h2 class="anchored" data-anchor-id="data-1">Data</h2>
<p>The data set is the visit data (already used in previous exercises). For simplicity, we turn the outcome (<code>visits</code>) into factor. Like before, that are also split into a training and a test set.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>DocVis <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/DocVis.csv"</span>))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>DocVis<span class="sc">$</span>visits <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(DocVis<span class="sc">$</span>visits)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">346</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>index_tr <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> DocVis<span class="sc">$</span>visits, <span class="at">p=</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>df_tr <span class="ot">&lt;-</span> DocVis[index_tr,]</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>df_te <span class="ot">&lt;-</span> DocVis[<span class="sc">-</span>index_tr,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="models-1" class="level2">
<h2 class="anchored" data-anchor-id="models-1">Models</h2>
<p>We will compare a logistic regression, a classification tree (pruned) and a SVM with radial basis (cost and gamma tuned).</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<p>Note that the <em>code for tuning the SVM</em> is provided below in comments because of the time it takes to run. The final parameters have been selected accordingly. Also, the SVM fit includes the argument <code>probability=TRUE</code> to allow the calculations of predicted probabilities later.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(adabag)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Logistic regression</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>Doc_lr <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr, <span class="at">family=</span><span class="st">"binomial"</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>Doc_lr <span class="ot">&lt;-</span> <span class="fu">step</span>(Doc_lr)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification tree </span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>Doc_ct <span class="ot">&lt;-</span> <span class="fu">autoprune</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="do">## SVM radial basis</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co"># grid_radial &lt;- expand.grid(sigma = c(0.0001, 0.001, 0.01, 0.1),</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">#                           C = c(0.1, 1, 10, 100, 1000))</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co"># trctrl &lt;- trainControl(method = "cv", number=10)</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co"># set.seed(143)</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Doc_svm &lt;- train(visits ~., data = df_tr, method = "svmRadial",</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co">#                          trControl=trctrl,</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="co">#                          tuneGrid = grid_radial)</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>Doc_svm <span class="ot">&lt;-</span> <span class="fu">svm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr, <span class="at">gamma=</span><span class="fl">0.001</span>, <span class="at">cost=</span><span class="dv">1000</span>, <span class="at">probability=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># We first put the data in a nice format by one-hot encoding the categorical variables</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> pd.get_dummies(r.df_tr.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> r.df_tr[<span class="st">'visits'</span>]</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> pd.get_dummies(r.df_te.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> r.df_te[<span class="st">'visits'</span>]</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>doc_lr <span class="op">=</span> LogisticRegression()</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>doc_lr.fit(X_train, y_train)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>doc_ct <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>doc_ct.fit(X_train, y_train)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>doc_svm <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span><span class="fl">0.001</span>, C<span class="op">=</span><span class="dv">1000</span>, probability<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>doc_svm.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="predictions" class="level2">
<h2 class="anchored" data-anchor-id="predictions">Predictions</h2>
<p>We now compute the predicted probabilities and the predictions of all the models.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<p>Note that, for SVM, we need to extract the <em>attribute</em> “probabilities” from the predicted object. This can be done with the <code>attr</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Logistic regression</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>Doc_lr_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>Doc_lr_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_lr_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification tree </span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>Doc_ct_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_ct, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"prob"</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>Doc_ct_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_ct, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"class"</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="do">## SVM radial basis</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>Doc_svm_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_svm, <span class="at">newdata=</span>df_te, <span class="at">probability=</span><span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> <span class="fu">attr</span>(<span class="st">"probabilities"</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>Doc_svm_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_svm, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"class"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co">## the second column represents the `no` values, to make sure of that, you can run `doc_lr.classes_`</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>doc_lr_prob <span class="op">=</span> doc_lr.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>doc_lr_pred <span class="op">=</span> np.where(doc_lr_prob<span class="op">&gt;</span><span class="fl">0.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>doc_ct_prob <span class="op">=</span> doc_ct.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>doc_ct_pred <span class="op">=</span> doc_ct.predict(X_test)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>doc_svm_prob <span class="op">=</span> doc_svm.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>doc_svm_pred <span class="op">=</span> doc_svm.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="confusion-matrices-prediction-based-measures" class="level2">
<h2 class="anchored" data-anchor-id="confusion-matrices-prediction-based-measures">Confusion matrices &amp; prediction-based measures</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<p>The <code>confusionMatrix</code> function provides all the accuracy measures that we want.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_lr_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_ct_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_svm_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score, balanced_accuracy_score, cohen_kappa_score</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_lr_pred))</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_ct_pred))</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_svm_pred))</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Different results for the tree and CSV due to randomness, but even with that, SVM remains the best model in terms of accuracy.</p>
</div>
</div>
</div>
<p>The conclusion may be different from one measure to another</p>
<ul>
<li>Accuracy: the SVM reaches the highest accuracy</li>
<li>Kappa: the CT is the highest.</li>
<li>Balanced accuracy: the CT is the highest.</li>
<li>etc.</li>
</ul>
<p>Looking at the confusion matrix, we see that the data is highly unbalanced (many more “No” than “Yes”). Therefore, measures like balanced accuracy and kappa are interesting because they take this characteristics into account. This shows that the CT is probably better than the SVM because it reaches a better balance between predicting “Yes” and “No”.</p>
<p>By looking at the sensitivity and specificity (<u>!! here the positive class is “No”</u>), we see that the best model to recover the “No” is the logistic regression (largest sensitivity) and the best model to recover the “Yes” is the classification tree (largest specificity).</p>
</section>
<section id="probability-based-measures" class="level2">
<h2 class="anchored" data-anchor-id="probability-based-measures">Probability-based measures</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-9-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-1" role="tab" aria-controls="tabset-9-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-9-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-2" role="tab" aria-controls="tabset-9-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-9-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-9-1-tab">
<p>To compute the AUC (area under the ROC curve) we can use the <code>caret::twoClassSummary</code> function. The use of this function can be tricky. Its argument should be a data frame with columns (names are fixed):</p>
<ul>
<li>“obs”: the observed classes</li>
<li>“pred”: the predicted classes</li>
<li>two columns with names being the levels of the classes, here “Yes” and “No”, containing the predicted probabilities.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>df_pred_lr <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_te<span class="sc">$</span>visits,</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>                         <span class="at">Yes=</span>Doc_lr_prob,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">No=</span><span class="dv">1</span><span class="sc">-</span>Doc_lr_prob,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>                         <span class="at">pred=</span><span class="fu">as.factor</span>(Doc_lr_pred))</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_pred_lr)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>df_pred_ct <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_te<span class="sc">$</span>visits,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>                         Doc_ct_prob,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>                         <span class="at">pred=</span><span class="fu">as.factor</span>(Doc_ct_pred))</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_pred_ct)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>df_pred_svm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_te<span class="sc">$</span>visits,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>                          Doc_svm_prob,</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>                          <span class="at">pred=</span><span class="fu">as.factor</span>(Doc_svm_pred))</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_pred_svm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then we pass these objects to the function, and levels of the classes to be predicted (for the function to be able to recover them in the data frame). The function compute the AUC by default (under the name ROC_.. not very wise) as well as sensitivity and specificity (that we already have).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">twoClassSummary</span>(df_pred_lr, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">twoClassSummary</span>(df_pred_ct, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">twoClassSummary</span>(df_pred_svm, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This brings us another view: the logistic regression has the highest AUC. This shows that varying the prediction threshold provides a good potential of improving the specificity and the sensitivity (in fine, the balanced accuracy).</p>
<p>Now we compute the entropy using the <code>mnLogLoss</code> function (entropy is also called <em>log-loss</em>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mnLogLoss</span>(df_pred_lr, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mnLogLoss</span>(df_pred_ct, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mnLogLoss</span>(df_pred_svm, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here again, the entropy selects the logistic regression as the best model, though close to classification tree and SVM.</p>
</div>
<div id="tabset-9-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-9-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score, roc_curve</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_lr_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_ct_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_svm_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Now we compute the entropy using the `log_loss` function (entropy is also called *log-loss*).</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> log_loss</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_lr_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_ct_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_svm_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="roc-curve-prob-threshold-tuning" class="level2">
<h2 class="anchored" data-anchor-id="roc-curve-prob-threshold-tuning">ROC curve &amp; prob threshold tuning</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-10-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-1" role="tab" aria-controls="tabset-10-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-10-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-2" role="tab" aria-controls="tabset-10-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-10-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-10-1-tab">
<p>To go deeper in the analysis, we now produce the ROC curve of each model using the <code>roc</code> function of the <code>proc</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>ROC_lr <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_lr)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>ROC_ct <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_ct)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>ROC_svm <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_svm)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_lr, <span class="at">print.thres=</span><span class="st">"best"</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_ct, <span class="at">print.thres=</span><span class="st">"best"</span>, <span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_svm, <span class="at">print.thres=</span><span class="st">"best"</span>, <span class="at">add=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The plotting function provides an “optimal” threshold that reaches the best trade-off between sensitivity and specificity (according to some criterion). We see that there is room to improve this trade-off.</p>
<p>Now, to tune this threshold, we need to do it <em>on the training set</em> to avoid overfitting. To do this, we just repeat the previous calculations (predictions) on the training set. To simplify, we only do this on the logistic regression (note that you can try on the other models; you may find that logistic regression is the best one).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>Doc_lr_prob_tr <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr, <span class="at">newdata=</span>df_tr, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>df_pred_lr_tr <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_tr<span class="sc">$</span>visits,</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>                            <span class="at">Yes=</span>Doc_lr_prob_tr)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>ROC_lr_tr <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_lr_tr)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_lr_tr, <span class="at">print.thres=</span><span class="st">"best"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The best threshold is 0.193. Now let us compute the confusion table with this threshold.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>Doc_lr_pred_opt <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_lr_prob<span class="sc">&gt;</span><span class="fl">0.193</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_lr_pred_opt), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now have a model with an accuracy of circa <span class="math inline">\(70\%\)</span> but with a balanced accuracy of <span class="math inline">\(67\%\)</span>. Far from perfect, this is still an interesting improvement compare to the CT <span class="math inline">\(62\%\)</span>. The specificity and sensitivity are now respectively <span class="math inline">\(62\%\)</span> and <span class="math inline">\(72\%\)</span>. The specificity in particular made a huge improvement (from around <span class="math inline">\(29\%\)</span> at best - by CT - to <span class="math inline">\(62\%\)</span> - by log. reg).</p>
<p>If the aim is to predict both “Yes” and “No”, this last model (log. reg. with tuned threshold) is the best one to use.</p>
</div>
<div id="tabset-10-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-10-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co">## We need to turn back our results into binary values to be plotted</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_lr_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>fpr_lr, tpr_lr, thresholds_lr <span class="op">=</span> roc_curve(y_test_binary, doc_lr_prob)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_lr, tpr_lr, label<span class="op">=</span><span class="st">"Logistic Regression"</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>doc_ct_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_ct_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>fpr_ct, tpr_ct, thresholds_ct <span class="op">=</span> roc_curve(y_test_binary, doc_ct_prob)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_ct, tpr_ct, label<span class="op">=</span><span class="st">"Classification Tree"</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>doc_svm_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_svm_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>fpr_svm, tpr_svm, thresholds_svm <span class="op">=</span> roc_curve(y_test_binary, doc_svm_prob)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Clear the last plot (if any)</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.clf()</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_svm, tpr_svm, label<span class="op">=</span><span class="st">"SVM Radial Basis"</span>)</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the ROC curve</span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>, label<span class="op">=</span><span class="st">"Random Classifier"</span>)</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"ROC Curve"</span>)</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can then plot the results in the similar way to R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_tr <span class="op">=</span> doc_lr.predict_proba(X_train)[:,<span class="dv">1</span>]</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_tr_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>y_train_binary <span class="op">=</span> np.array([doc_lr_prob_tr_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_train])</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>fpr_lr_tr, tpr_lr_tr, thresholds_lr_tr <span class="op">=</span> roc_curve(y_train_binary, doc_lr_prob_tr)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>optimal_idx <span class="op">=</span> np.argmax(tpr_lr_tr <span class="op">-</span> fpr_lr_tr)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>optimal_threshold <span class="op">=</span> thresholds_lr_tr[optimal_idx]</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal threshold: </span><span class="sc">{</span>optimal_threshold<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, we print the confusion matrix again:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>doc_lr_pred_opt <span class="op">=</span> np.where(doc_lr_prob <span class="op">&gt;</span> optimal_threshold, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_lr_pred_opt))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The logistic regression produced with R was better.</p>
</div>
</div>
</div>
</section>
</section>
<section id="your-turn" class="level1">
<h1>Your turn</h1>
<section id="classification" class="level2">
<h2 class="anchored" data-anchor-id="classification">Classification</h2>
<p>Repeat the analysis on the German credit data. Put several models in competition. Tune them and try to optimize their threshold. Select the best one and analyze its performance.</p>
</section>
<section id="regression" class="level2">
<h2 class="anchored" data-anchor-id="regression">Regression</h2>
<p>Repeat the analysis on the nursing cost data. Put several models in competition. Tune them and select the best one. Analyze its performance using a scatterplot.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/do-unil\.github\.io\/mlba");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" class="pagination-link" aria-label="Support Vector Machines">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Support Vector Machines</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="pagination-link" aria-label="Data Splitting">
        <span class="nav-page-text">Data Splitting</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb34" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>How can I render the following?---</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>title: "Model scoring"</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r global_options, include = FALSE}</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::opts_chunk$set(fig.align="center", results = 'hide', fig.show = 'hide')</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="fu"># Regression task</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data</span></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>The data set is the one used in the series on linear regressions.</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/real_estate_data.csv"</span>))</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>Then we split the data in a training and a test set (0.8/0.2). For this, we use the <span class="in">`createDataPartition`</span> function of the <span class="in">`caret`</span> package.</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a>index_tr <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> real_estate_data<span class="sc">$</span>Price, <span class="at">p=</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a>df_tr <span class="ot">&lt;-</span> real_estate_data[index_tr,]</span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a>df_te <span class="ot">&lt;-</span> real_estate_data[<span class="sc">-</span>index_tr,]</span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a><span class="fu">## Models</span></span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a>We will compare a linear regression, a regression tree and a 3-NN (KNN).</span>
<span id="cb34-37"><a href="#cb34-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-38"><a href="#cb34-38" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb34-39"><a href="#cb34-39" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb34-40"><a href="#cb34-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-43"><a href="#cb34-43" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-44"><a href="#cb34-44" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb34-45"><a href="#cb34-45" aria-hidden="true" tabindex="-1"></a>est_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span>HouseAge<span class="sc">+</span>Dist<span class="sc">+</span></span>
<span id="cb34-46"><a href="#cb34-46" aria-hidden="true" tabindex="-1"></a>               NumStores<span class="sc">+</span>Lat<span class="sc">+</span>Long, <span class="at">data=</span>df_tr)</span>
<span id="cb34-47"><a href="#cb34-47" aria-hidden="true" tabindex="-1"></a>est_rt <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span>HouseAge<span class="sc">+</span>Dist<span class="sc">+</span></span>
<span id="cb34-48"><a href="#cb34-48" aria-hidden="true" tabindex="-1"></a>                      NumStores<span class="sc">+</span>Lat<span class="sc">+</span>Long, <span class="at">data=</span>df_tr)</span>
<span id="cb34-49"><a href="#cb34-49" aria-hidden="true" tabindex="-1"></a>est_knn <span class="ot">&lt;-</span> <span class="fu">knnreg</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span>HouseAge<span class="sc">+</span>Dist<span class="sc">+</span></span>
<span id="cb34-50"><a href="#cb34-50" aria-hidden="true" tabindex="-1"></a>                      NumStores<span class="sc">+</span>Lat<span class="sc">+</span>Long, <span class="at">data=</span>df_tr, <span class="at">k =</span> <span class="dv">3</span>)</span>
<span id="cb34-51"><a href="#cb34-51" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-52"><a href="#cb34-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-53"><a href="#cb34-53" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb34-56"><a href="#cb34-56" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-57"><a href="#cb34-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the course python environment as usual with a r code chunks.</span></span>
<span id="cb34-58"><a href="#cb34-58" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb34-59"><a href="#cb34-59" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>)</span>
<span id="cb34-60"><a href="#cb34-60" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-61"><a href="#cb34-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-64"><a href="#cb34-64" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-65"><a href="#cb34-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the models: linear regression, regression tree, and KNN</span></span>
<span id="cb34-66"><a href="#cb34-66" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb34-67"><a href="#cb34-67" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb34-68"><a href="#cb34-68" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb34-69"><a href="#cb34-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-70"><a href="#cb34-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Define predictors and target variable</span></span>
<span id="cb34-71"><a href="#cb34-71" aria-hidden="true" tabindex="-1"></a>predictors <span class="op">=</span> [<span class="st">'TransDate'</span>, <span class="st">'HouseAge'</span>, <span class="st">'Dist'</span>, <span class="st">'NumStores'</span>, <span class="st">'Lat'</span>, <span class="st">'Long'</span>]</span>
<span id="cb34-72"><a href="#cb34-72" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">'Price'</span></span>
<span id="cb34-73"><a href="#cb34-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-74"><a href="#cb34-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit models</span></span>
<span id="cb34-75"><a href="#cb34-75" aria-hidden="true" tabindex="-1"></a>est_lm <span class="op">=</span> LinearRegression().fit(r.df_tr[predictors], r.df_tr[target])</span>
<span id="cb34-76"><a href="#cb34-76" aria-hidden="true" tabindex="-1"></a>est_rt <span class="op">=</span> DecisionTreeRegressor(random_state<span class="op">=</span><span class="dv">234</span>).fit(r.df_tr[predictors], r.df_tr[target])</span>
<span id="cb34-77"><a href="#cb34-77" aria-hidden="true" tabindex="-1"></a>est_knn <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">3</span>).fit(r.df_tr[predictors], r.df_tr[target])</span>
<span id="cb34-78"><a href="#cb34-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-79"><a href="#cb34-79" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-80"><a href="#cb34-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-81"><a href="#cb34-81" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-82"><a href="#cb34-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-83"><a href="#cb34-83" aria-hidden="true" tabindex="-1"></a><span class="fu">## R-squared</span></span>
<span id="cb34-84"><a href="#cb34-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-85"><a href="#cb34-85" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb34-86"><a href="#cb34-86" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb34-87"><a href="#cb34-87" aria-hidden="true" tabindex="-1"></a>We now compute the R2 for each model using the a defined function.</span>
<span id="cb34-88"><a href="#cb34-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-91"><a href="#cb34-91" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-92"><a href="#cb34-92" aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">=</span> <span class="cf">function</span>(y_predict, y_actual){</span>
<span id="cb34-93"><a href="#cb34-93" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cor</span>(y_actual,y_predict)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb34-94"><a href="#cb34-94" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb34-95"><a href="#cb34-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-96"><a href="#cb34-96" aria-hidden="true" tabindex="-1"></a><span class="fu">R2</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb34-97"><a href="#cb34-97" aria-hidden="true" tabindex="-1"></a><span class="fu">R2</span>(<span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb34-98"><a href="#cb34-98" aria-hidden="true" tabindex="-1"></a><span class="fu">R2</span>(<span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb34-99"><a href="#cb34-99" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-100"><a href="#cb34-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-101"><a href="#cb34-101" aria-hidden="true" tabindex="-1"></a>Just for the exercise, we can compute it by hand (square of the correlation)</span>
<span id="cb34-102"><a href="#cb34-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-105"><a href="#cb34-105" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-106"><a href="#cb34-106" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb34-107"><a href="#cb34-107" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-108"><a href="#cb34-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-109"><a href="#cb34-109" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb34-110"><a href="#cb34-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-113"><a href="#cb34-113" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-114"><a href="#cb34-114" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing as the R code</span></span>
<span id="cb34-115"><a href="#cb34-115" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb34-116"><a href="#cb34-116" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb34-117"><a href="#cb34-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-118"><a href="#cb34-118" aria-hidden="true" tabindex="-1"></a><span class="co"># Only to demonostrate which argument goes where (different from `caret::R2`)</span></span>
<span id="cb34-119"><a href="#cb34-119" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(y_true <span class="op">=</span> r.df_te[target], y_pred <span class="op">=</span> est_lm.predict(r.df_te[predictors])))</span>
<span id="cb34-120"><a href="#cb34-120" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb34-121"><a href="#cb34-121" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span>
<span id="cb34-122"><a href="#cb34-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-123"><a href="#cb34-123" aria-hidden="true" tabindex="-1"></a><span class="co"># Computing it by hand gives us the same result as R</span></span>
<span id="cb34-124"><a href="#cb34-124" aria-hidden="true" tabindex="-1"></a>np.corrcoef(est_lm.predict(r.df_te[predictors]), r.df_te[target])[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span></span>
<span id="cb34-125"><a href="#cb34-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-126"><a href="#cb34-126" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-127"><a href="#cb34-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-128"><a href="#cb34-128" aria-hidden="true" tabindex="-1"></a>To understand why the results are different in <span class="in">`R2`</span> from our defined function  in R vs. <span class="in">`sklearn.metrics.r2_score()`</span> in Python, see <span class="co">[</span><span class="ot">this post on stackoverflow</span><span class="co">](https://stats.stackexchange.com/questions/586821/what-is-the-interpretation-of-the-traditional-r2)</span>. If you want to recieve the same results in both, you can try computing the R2 not by correlation but by the formula $1 - \frac{SSR}{SST}$ where $SSR$ is the sum of squared residuals and $SST$ is the total sum of squares.</span>
<span id="cb34-129"><a href="#cb34-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-130"><a href="#cb34-130" aria-hidden="true" tabindex="-1"></a>Additionally, please note that the performance of the tree is highly dependent on the seed, so setting a different seed can lead to different results.</span>
<span id="cb34-131"><a href="#cb34-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-132"><a href="#cb34-132" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-133"><a href="#cb34-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-134"><a href="#cb34-134" aria-hidden="true" tabindex="-1"></a><span class="fu">## RMSE</span></span>
<span id="cb34-135"><a href="#cb34-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-136"><a href="#cb34-136" aria-hidden="true" tabindex="-1"></a>Now, we compute the RMSE.</span>
<span id="cb34-137"><a href="#cb34-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-138"><a href="#cb34-138" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb34-139"><a href="#cb34-139" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb34-140"><a href="#cb34-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-143"><a href="#cb34-143" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-144"><a href="#cb34-144" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb34-145"><a href="#cb34-145" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE</span>(<span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb34-146"><a href="#cb34-146" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE</span>(<span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb34-147"><a href="#cb34-147" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-148"><a href="#cb34-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-149"><a href="#cb34-149" aria-hidden="true" tabindex="-1"></a>The formula would be:</span>
<span id="cb34-150"><a href="#cb34-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-153"><a href="#cb34-153" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-154"><a href="#cb34-154" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>((<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te)<span class="sc">-</span>df_te<span class="sc">$</span>Price)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb34-155"><a href="#cb34-155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-156"><a href="#cb34-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-157"><a href="#cb34-157" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb34-158"><a href="#cb34-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-161"><a href="#cb34-161" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-162"><a href="#cb34-162" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, root_mean_squared_error</span>
<span id="cb34-163"><a href="#cb34-163" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb34-164"><a href="#cb34-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-165"><a href="#cb34-165" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_lm.predict(r.df_te[predictors])))</span>
<span id="cb34-166"><a href="#cb34-166" aria-hidden="true" tabindex="-1"></a><span class="co"># alternatively in the older version of `sklearn`, you had to run the code below</span></span>
<span id="cb34-167"><a href="#cb34-167" aria-hidden="true" tabindex="-1"></a><span class="co"># print(np.sqrt(mean_squared_error(r.df_te[target], est_lm.predict(r.df_te[predictors]))))</span></span>
<span id="cb34-168"><a href="#cb34-168" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb34-169"><a href="#cb34-169" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span>
<span id="cb34-170"><a href="#cb34-170" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-171"><a href="#cb34-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-172"><a href="#cb34-172" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-173"><a href="#cb34-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-174"><a href="#cb34-174" aria-hidden="true" tabindex="-1"></a><span class="fu">## MAE</span></span>
<span id="cb34-175"><a href="#cb34-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-176"><a href="#cb34-176" aria-hidden="true" tabindex="-1"></a>Now, we compute the MAE.</span>
<span id="cb34-177"><a href="#cb34-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-178"><a href="#cb34-178" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb34-179"><a href="#cb34-179" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb34-180"><a href="#cb34-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-183"><a href="#cb34-183" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-184"><a href="#cb34-184" aria-hidden="true" tabindex="-1"></a><span class="fu">MAE</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb34-185"><a href="#cb34-185" aria-hidden="true" tabindex="-1"></a><span class="fu">MAE</span>(<span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb34-186"><a href="#cb34-186" aria-hidden="true" tabindex="-1"></a><span class="fu">MAE</span>(<span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb34-187"><a href="#cb34-187" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-188"><a href="#cb34-188" aria-hidden="true" tabindex="-1"></a>The formula would be:</span>
<span id="cb34-189"><a href="#cb34-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-192"><a href="#cb34-192" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-193"><a href="#cb34-193" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">abs</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te)<span class="sc">-</span>df_te<span class="sc">$</span>Price))</span>
<span id="cb34-194"><a href="#cb34-194" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-195"><a href="#cb34-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-196"><a href="#cb34-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-197"><a href="#cb34-197" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb34-198"><a href="#cb34-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-201"><a href="#cb34-201" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-202"><a href="#cb34-202" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute MAE for each model</span></span>
<span id="cb34-203"><a href="#cb34-203" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error</span>
<span id="cb34-204"><a href="#cb34-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-205"><a href="#cb34-205" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_lm.predict(r.df_te[predictors])))</span>
<span id="cb34-206"><a href="#cb34-206" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb34-207"><a href="#cb34-207" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span>
<span id="cb34-208"><a href="#cb34-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-209"><a href="#cb34-209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-210"><a href="#cb34-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-211"><a href="#cb34-211" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-212"><a href="#cb34-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-213"><a href="#cb34-213" aria-hidden="true" tabindex="-1"></a><span class="fu">## Best model</span></span>
<span id="cb34-214"><a href="#cb34-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-215"><a href="#cb34-215" aria-hidden="true" tabindex="-1"></a>These three measures agree on the fact that the regression tree is the best model. To inspect further the predictions, we use scatterplots:</span>
<span id="cb34-216"><a href="#cb34-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-217"><a href="#cb34-217" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb34-218"><a href="#cb34-218" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb34-219"><a href="#cb34-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-222"><a href="#cb34-222" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-223"><a href="#cb34-223" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb34-224"><a href="#cb34-224" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(df_te<span class="sc">$</span>Price <span class="sc">~</span> <span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), <span class="at">xlab=</span><span class="st">"Prediction"</span>, </span>
<span id="cb34-225"><a href="#cb34-225" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Observed prices"</span>, <span class="at">main=</span><span class="st">"Lin. Reg."</span>)</span>
<span id="cb34-226"><a href="#cb34-226" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb34-227"><a href="#cb34-227" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(df_te<span class="sc">$</span>Price <span class="sc">~</span> <span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), <span class="at">xlab=</span><span class="st">"Prediction"</span>, </span>
<span id="cb34-228"><a href="#cb34-228" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Observed prices"</span>, <span class="at">main=</span><span class="st">"Lin. Reg."</span>)</span>
<span id="cb34-229"><a href="#cb34-229" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb34-230"><a href="#cb34-230" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(df_te<span class="sc">$</span>Price <span class="sc">~</span> <span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), <span class="at">xlab=</span><span class="st">"Prediction"</span>, </span>
<span id="cb34-231"><a href="#cb34-231" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Observed prices"</span>, <span class="at">main=</span><span class="st">"Lin. Reg."</span>)</span>
<span id="cb34-232"><a href="#cb34-232" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb34-233"><a href="#cb34-233" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb34-234"><a href="#cb34-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-235"><a href="#cb34-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-236"><a href="#cb34-236" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb34-239"><a href="#cb34-239" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-240"><a href="#cb34-240" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize also in Python</span></span>
<span id="cb34-241"><a href="#cb34-241" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb34-242"><a href="#cb34-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-243"><a href="#cb34-243" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb34-244"><a href="#cb34-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-245"><a href="#cb34-245" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">221</span>)</span>
<span id="cb34-246"><a href="#cb34-246" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_lm.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb34-247"><a href="#cb34-247" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)</span>
<span id="cb34-248"><a href="#cb34-248" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)</span>
<span id="cb34-249"><a href="#cb34-249" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Lin. Reg."</span>)</span>
<span id="cb34-250"><a href="#cb34-250" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb34-251"><a href="#cb34-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-252"><a href="#cb34-252" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">222</span>)</span>
<span id="cb34-253"><a href="#cb34-253" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_rt.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb34-254"><a href="#cb34-254" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)</span>
<span id="cb34-255"><a href="#cb34-255" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)</span>
<span id="cb34-256"><a href="#cb34-256" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Regression Tree"</span>)</span>
<span id="cb34-257"><a href="#cb34-257" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb34-258"><a href="#cb34-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-259"><a href="#cb34-259" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">223</span>)</span>
<span id="cb34-260"><a href="#cb34-260" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_knn.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb34-261"><a href="#cb34-261" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)</span>
<span id="cb34-262"><a href="#cb34-262" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)</span>
<span id="cb34-263"><a href="#cb34-263" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"KNN"</span>)</span>
<span id="cb34-264"><a href="#cb34-264" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb34-265"><a href="#cb34-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-266"><a href="#cb34-266" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb34-267"><a href="#cb34-267" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-268"><a href="#cb34-268" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-269"><a href="#cb34-269" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-270"><a href="#cb34-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-271"><a href="#cb34-271" aria-hidden="true" tabindex="-1"></a>The scatterplots are in line with the conclusion that KNN is the best, even though it is not easy to declare from a plot. We can in addition see that the regression tree (RT) has made more error on the larger prices.</span>
<span id="cb34-272"><a href="#cb34-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-273"><a href="#cb34-273" aria-hidden="true" tabindex="-1"></a><span class="fu"># Classification task</span></span>
<span id="cb34-274"><a href="#cb34-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-275"><a href="#cb34-275" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data</span></span>
<span id="cb34-276"><a href="#cb34-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-277"><a href="#cb34-277" aria-hidden="true" tabindex="-1"></a>The data set is the visit data (already used in previous exercises). For simplicity, we turn the outcome (<span class="in">`visits`</span>) into factor. Like before, that are also split into a training and a test set.</span>
<span id="cb34-278"><a href="#cb34-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-281"><a href="#cb34-281" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-282"><a href="#cb34-282" aria-hidden="true" tabindex="-1"></a>DocVis <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/DocVis.csv"</span>))</span>
<span id="cb34-283"><a href="#cb34-283" aria-hidden="true" tabindex="-1"></a>DocVis<span class="sc">$</span>visits <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(DocVis<span class="sc">$</span>visits)</span>
<span id="cb34-284"><a href="#cb34-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-285"><a href="#cb34-285" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb34-286"><a href="#cb34-286" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">346</span>)</span>
<span id="cb34-287"><a href="#cb34-287" aria-hidden="true" tabindex="-1"></a>index_tr <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> DocVis<span class="sc">$</span>visits, <span class="at">p=</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb34-288"><a href="#cb34-288" aria-hidden="true" tabindex="-1"></a>df_tr <span class="ot">&lt;-</span> DocVis[index_tr,]</span>
<span id="cb34-289"><a href="#cb34-289" aria-hidden="true" tabindex="-1"></a>df_te <span class="ot">&lt;-</span> DocVis[<span class="sc">-</span>index_tr,]</span>
<span id="cb34-290"><a href="#cb34-290" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-291"><a href="#cb34-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-292"><a href="#cb34-292" aria-hidden="true" tabindex="-1"></a><span class="fu">## Models</span></span>
<span id="cb34-293"><a href="#cb34-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-294"><a href="#cb34-294" aria-hidden="true" tabindex="-1"></a>We will compare a logistic regression, a classification tree (pruned) and a SVM with radial basis (cost and gamma tuned).</span>
<span id="cb34-295"><a href="#cb34-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-296"><a href="#cb34-296" aria-hidden="true" tabindex="-1"></a>:::panel-tabset</span>
<span id="cb34-297"><a href="#cb34-297" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb34-298"><a href="#cb34-298" aria-hidden="true" tabindex="-1"></a>Note that the *code for tuning the SVM* is provided below in comments because of the time it takes to run. The final parameters have been selected accordingly. Also, the SVM fit includes the argument <span class="in">`probability=TRUE`</span> to allow the calculations of predicted probabilities later.</span>
<span id="cb34-299"><a href="#cb34-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-302"><a href="#cb34-302" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-303"><a href="#cb34-303" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb34-304"><a href="#cb34-304" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(adabag)</span>
<span id="cb34-305"><a href="#cb34-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-306"><a href="#cb34-306" aria-hidden="true" tabindex="-1"></a><span class="do">## Logistic regression</span></span>
<span id="cb34-307"><a href="#cb34-307" aria-hidden="true" tabindex="-1"></a>Doc_lr <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr, <span class="at">family=</span><span class="st">"binomial"</span>)</span>
<span id="cb34-308"><a href="#cb34-308" aria-hidden="true" tabindex="-1"></a>Doc_lr <span class="ot">&lt;-</span> <span class="fu">step</span>(Doc_lr)</span>
<span id="cb34-309"><a href="#cb34-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-310"><a href="#cb34-310" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification tree </span></span>
<span id="cb34-311"><a href="#cb34-311" aria-hidden="true" tabindex="-1"></a>Doc_ct <span class="ot">&lt;-</span> <span class="fu">autoprune</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr)</span>
<span id="cb34-312"><a href="#cb34-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-313"><a href="#cb34-313" aria-hidden="true" tabindex="-1"></a><span class="do">## SVM radial basis</span></span>
<span id="cb34-314"><a href="#cb34-314" aria-hidden="true" tabindex="-1"></a><span class="co"># grid_radial &lt;- expand.grid(sigma = c(0.0001, 0.001, 0.01, 0.1),</span></span>
<span id="cb34-315"><a href="#cb34-315" aria-hidden="true" tabindex="-1"></a><span class="co">#                           C = c(0.1, 1, 10, 100, 1000))</span></span>
<span id="cb34-316"><a href="#cb34-316" aria-hidden="true" tabindex="-1"></a><span class="co"># trctrl &lt;- trainControl(method = "cv", number=10)</span></span>
<span id="cb34-317"><a href="#cb34-317" aria-hidden="true" tabindex="-1"></a><span class="co"># set.seed(143)</span></span>
<span id="cb34-318"><a href="#cb34-318" aria-hidden="true" tabindex="-1"></a><span class="co"># Doc_svm &lt;- train(visits ~., data = df_tr, method = "svmRadial",</span></span>
<span id="cb34-319"><a href="#cb34-319" aria-hidden="true" tabindex="-1"></a><span class="co">#                          trControl=trctrl,</span></span>
<span id="cb34-320"><a href="#cb34-320" aria-hidden="true" tabindex="-1"></a><span class="co">#                          tuneGrid = grid_radial)</span></span>
<span id="cb34-321"><a href="#cb34-321" aria-hidden="true" tabindex="-1"></a>Doc_svm <span class="ot">&lt;-</span> <span class="fu">svm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr, <span class="at">gamma=</span><span class="fl">0.001</span>, <span class="at">cost=</span><span class="dv">1000</span>, <span class="at">probability=</span><span class="cn">TRUE</span>)</span>
<span id="cb34-322"><a href="#cb34-322" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-323"><a href="#cb34-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-324"><a href="#cb34-324" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb34-327"><a href="#cb34-327" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-328"><a href="#cb34-328" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb34-329"><a href="#cb34-329" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb34-330"><a href="#cb34-330" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb34-331"><a href="#cb34-331" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb34-332"><a href="#cb34-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-333"><a href="#cb34-333" aria-hidden="true" tabindex="-1"></a><span class="co"># We first put the data in a nice format by one-hot encoding the categorical variables</span></span>
<span id="cb34-334"><a href="#cb34-334" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> pd.get_dummies(r.df_tr.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb34-335"><a href="#cb34-335" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> r.df_tr[<span class="st">'visits'</span>]</span>
<span id="cb34-336"><a href="#cb34-336" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> pd.get_dummies(r.df_te.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb34-337"><a href="#cb34-337" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> r.df_te[<span class="st">'visits'</span>]</span>
<span id="cb34-338"><a href="#cb34-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-339"><a href="#cb34-339" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb34-340"><a href="#cb34-340" aria-hidden="true" tabindex="-1"></a>doc_lr <span class="op">=</span> LogisticRegression()</span>
<span id="cb34-341"><a href="#cb34-341" aria-hidden="true" tabindex="-1"></a>doc_lr.fit(X_train, y_train)</span>
<span id="cb34-342"><a href="#cb34-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-343"><a href="#cb34-343" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb34-344"><a href="#cb34-344" aria-hidden="true" tabindex="-1"></a>doc_ct <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb34-345"><a href="#cb34-345" aria-hidden="true" tabindex="-1"></a>doc_ct.fit(X_train, y_train)</span>
<span id="cb34-346"><a href="#cb34-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-347"><a href="#cb34-347" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb34-348"><a href="#cb34-348" aria-hidden="true" tabindex="-1"></a>doc_svm <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span><span class="fl">0.001</span>, C<span class="op">=</span><span class="dv">1000</span>, probability<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb34-349"><a href="#cb34-349" aria-hidden="true" tabindex="-1"></a>doc_svm.fit(X_train, y_train)</span>
<span id="cb34-350"><a href="#cb34-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-351"><a href="#cb34-351" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-352"><a href="#cb34-352" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-353"><a href="#cb34-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-354"><a href="#cb34-354" aria-hidden="true" tabindex="-1"></a><span class="fu">## Predictions</span></span>
<span id="cb34-355"><a href="#cb34-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-356"><a href="#cb34-356" aria-hidden="true" tabindex="-1"></a>We now compute the predicted probabilities and the predictions of all the models.</span>
<span id="cb34-357"><a href="#cb34-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-358"><a href="#cb34-358" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb34-359"><a href="#cb34-359" aria-hidden="true" tabindex="-1"></a><span class="fu">## R</span></span>
<span id="cb34-360"><a href="#cb34-360" aria-hidden="true" tabindex="-1"></a>Note that, for SVM, we need to extract the *attribute* "probabilities" from the predicted object. This can be done with the <span class="in">`attr`</span> function.</span>
<span id="cb34-361"><a href="#cb34-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-364"><a href="#cb34-364" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-365"><a href="#cb34-365" aria-hidden="true" tabindex="-1"></a><span class="do">## Logistic regression</span></span>
<span id="cb34-366"><a href="#cb34-366" aria-hidden="true" tabindex="-1"></a>Doc_lr_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb34-367"><a href="#cb34-367" aria-hidden="true" tabindex="-1"></a>Doc_lr_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_lr_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb34-368"><a href="#cb34-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-369"><a href="#cb34-369" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification tree </span></span>
<span id="cb34-370"><a href="#cb34-370" aria-hidden="true" tabindex="-1"></a>Doc_ct_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_ct, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"prob"</span>)</span>
<span id="cb34-371"><a href="#cb34-371" aria-hidden="true" tabindex="-1"></a>Doc_ct_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_ct, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"class"</span>)</span>
<span id="cb34-372"><a href="#cb34-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-373"><a href="#cb34-373" aria-hidden="true" tabindex="-1"></a><span class="do">## SVM radial basis</span></span>
<span id="cb34-374"><a href="#cb34-374" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb34-375"><a href="#cb34-375" aria-hidden="true" tabindex="-1"></a>Doc_svm_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_svm, <span class="at">newdata=</span>df_te, <span class="at">probability=</span><span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> <span class="fu">attr</span>(<span class="st">"probabilities"</span>)</span>
<span id="cb34-376"><a href="#cb34-376" aria-hidden="true" tabindex="-1"></a>Doc_svm_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_svm, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"class"</span>)</span>
<span id="cb34-377"><a href="#cb34-377" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-378"><a href="#cb34-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-379"><a href="#cb34-379" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python</span></span>
<span id="cb34-380"><a href="#cb34-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-383"><a href="#cb34-383" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-384"><a href="#cb34-384" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb34-385"><a href="#cb34-385" aria-hidden="true" tabindex="-1"></a><span class="co">## the second column represents the `no` values, to make sure of that, you can run `doc_lr.classes_`</span></span>
<span id="cb34-386"><a href="#cb34-386" aria-hidden="true" tabindex="-1"></a>doc_lr_prob <span class="op">=</span> doc_lr.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb34-387"><a href="#cb34-387" aria-hidden="true" tabindex="-1"></a>doc_lr_pred <span class="op">=</span> np.where(doc_lr_prob<span class="op">&gt;</span><span class="fl">0.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb34-388"><a href="#cb34-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-389"><a href="#cb34-389" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb34-390"><a href="#cb34-390" aria-hidden="true" tabindex="-1"></a>doc_ct_prob <span class="op">=</span> doc_ct.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb34-391"><a href="#cb34-391" aria-hidden="true" tabindex="-1"></a>doc_ct_pred <span class="op">=</span> doc_ct.predict(X_test)</span>
<span id="cb34-392"><a href="#cb34-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-393"><a href="#cb34-393" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb34-394"><a href="#cb34-394" aria-hidden="true" tabindex="-1"></a>doc_svm_prob <span class="op">=</span> doc_svm.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb34-395"><a href="#cb34-395" aria-hidden="true" tabindex="-1"></a>doc_svm_pred <span class="op">=</span> doc_svm.predict(X_test)</span>
<span id="cb34-396"><a href="#cb34-396" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-397"><a href="#cb34-397" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-398"><a href="#cb34-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-399"><a href="#cb34-399" aria-hidden="true" tabindex="-1"></a><span class="fu">## Confusion matrices &amp; prediction-based measures</span></span>
<span id="cb34-400"><a href="#cb34-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-401"><a href="#cb34-401" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb34-402"><a href="#cb34-402" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb34-403"><a href="#cb34-403" aria-hidden="true" tabindex="-1"></a>The <span class="in">`confusionMatrix`</span> function provides all the accuracy measures that we want.</span>
<span id="cb34-404"><a href="#cb34-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-407"><a href="#cb34-407" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-408"><a href="#cb34-408" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_lr_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb34-409"><a href="#cb34-409" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_ct_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb34-410"><a href="#cb34-410" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_svm_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb34-411"><a href="#cb34-411" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-412"><a href="#cb34-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-413"><a href="#cb34-413" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb34-416"><a href="#cb34-416" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-417"><a href="#cb34-417" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score, balanced_accuracy_score, cohen_kappa_score</span>
<span id="cb34-418"><a href="#cb34-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-419"><a href="#cb34-419" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb34-420"><a href="#cb34-420" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_lr_pred))</span>
<span id="cb34-421"><a href="#cb34-421" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-422"><a href="#cb34-422" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-423"><a href="#cb34-423" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-424"><a href="#cb34-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-425"><a href="#cb34-425" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb34-426"><a href="#cb34-426" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_ct_pred))</span>
<span id="cb34-427"><a href="#cb34-427" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-428"><a href="#cb34-428" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-429"><a href="#cb34-429" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-430"><a href="#cb34-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-431"><a href="#cb34-431" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb34-432"><a href="#cb34-432" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_svm_pred))</span>
<span id="cb34-433"><a href="#cb34-433" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-434"><a href="#cb34-434" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-435"><a href="#cb34-435" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-436"><a href="#cb34-436" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-437"><a href="#cb34-437" aria-hidden="true" tabindex="-1"></a>Different results for the tree and CSV due to randomness, but even with that, SVM remains the best model in terms of accuracy.</span>
<span id="cb34-438"><a href="#cb34-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-439"><a href="#cb34-439" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-440"><a href="#cb34-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-441"><a href="#cb34-441" aria-hidden="true" tabindex="-1"></a>The conclusion may be different from one measure to another</span>
<span id="cb34-442"><a href="#cb34-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-443"><a href="#cb34-443" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Accuracy: the SVM reaches the highest accuracy</span>
<span id="cb34-444"><a href="#cb34-444" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Kappa: the CT is the highest.</span>
<span id="cb34-445"><a href="#cb34-445" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Balanced accuracy: the CT is the highest.</span>
<span id="cb34-446"><a href="#cb34-446" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>etc.</span>
<span id="cb34-447"><a href="#cb34-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-448"><a href="#cb34-448" aria-hidden="true" tabindex="-1"></a>Looking at the confusion matrix, we see that the data is highly unbalanced (many more "No" than "Yes"). Therefore, measures like balanced accuracy and kappa are interesting because they take this characteristics into account. This shows that the CT is probably better than the SVM because it reaches a better balance between predicting "Yes" and "No".</span>
<span id="cb34-449"><a href="#cb34-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-450"><a href="#cb34-450" aria-hidden="true" tabindex="-1"></a>By looking at the sensitivity and specificity (<span class="co">[</span><span class="ot">!! here the positive class is "No"</span><span class="co">]</span>{.underline}), we see that the best model to recover the "No" is the logistic regression (largest sensitivity) and the best model to recover the "Yes" is the classification tree (largest specificity).</span>
<span id="cb34-451"><a href="#cb34-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-452"><a href="#cb34-452" aria-hidden="true" tabindex="-1"></a><span class="fu">## Probability-based measures</span></span>
<span id="cb34-453"><a href="#cb34-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-454"><a href="#cb34-454" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb34-455"><a href="#cb34-455" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb34-456"><a href="#cb34-456" aria-hidden="true" tabindex="-1"></a>To compute the AUC (area under the ROC curve) we can use the <span class="in">`caret::twoClassSummary`</span> function. The use of this function can be tricky. Its argument should be a data frame with columns (names are fixed):</span>
<span id="cb34-457"><a href="#cb34-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-458"><a href="#cb34-458" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>"obs": the observed classes</span>
<span id="cb34-459"><a href="#cb34-459" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>"pred": the predicted classes</span>
<span id="cb34-460"><a href="#cb34-460" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>two columns with names being the levels of the classes, here "Yes" and "No", containing the predicted probabilities.</span>
<span id="cb34-461"><a href="#cb34-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-464"><a href="#cb34-464" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-465"><a href="#cb34-465" aria-hidden="true" tabindex="-1"></a>df_pred_lr <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_te<span class="sc">$</span>visits,</span>
<span id="cb34-466"><a href="#cb34-466" aria-hidden="true" tabindex="-1"></a>                         <span class="at">Yes=</span>Doc_lr_prob,</span>
<span id="cb34-467"><a href="#cb34-467" aria-hidden="true" tabindex="-1"></a>                         <span class="at">No=</span><span class="dv">1</span><span class="sc">-</span>Doc_lr_prob,</span>
<span id="cb34-468"><a href="#cb34-468" aria-hidden="true" tabindex="-1"></a>                         <span class="at">pred=</span><span class="fu">as.factor</span>(Doc_lr_pred))</span>
<span id="cb34-469"><a href="#cb34-469" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_pred_lr)</span>
<span id="cb34-470"><a href="#cb34-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-471"><a href="#cb34-471" aria-hidden="true" tabindex="-1"></a>df_pred_ct <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_te<span class="sc">$</span>visits,</span>
<span id="cb34-472"><a href="#cb34-472" aria-hidden="true" tabindex="-1"></a>                         Doc_ct_prob,</span>
<span id="cb34-473"><a href="#cb34-473" aria-hidden="true" tabindex="-1"></a>                         <span class="at">pred=</span><span class="fu">as.factor</span>(Doc_ct_pred))</span>
<span id="cb34-474"><a href="#cb34-474" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_pred_ct)</span>
<span id="cb34-475"><a href="#cb34-475" aria-hidden="true" tabindex="-1"></a>df_pred_svm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_te<span class="sc">$</span>visits,</span>
<span id="cb34-476"><a href="#cb34-476" aria-hidden="true" tabindex="-1"></a>                          Doc_svm_prob,</span>
<span id="cb34-477"><a href="#cb34-477" aria-hidden="true" tabindex="-1"></a>                          <span class="at">pred=</span><span class="fu">as.factor</span>(Doc_svm_pred))</span>
<span id="cb34-478"><a href="#cb34-478" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_pred_svm)</span>
<span id="cb34-479"><a href="#cb34-479" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-480"><a href="#cb34-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-481"><a href="#cb34-481" aria-hidden="true" tabindex="-1"></a>Then we pass these objects to the function, and levels of the classes to be predicted (for the function to be able to recover them in the data frame). The function compute the AUC by default (under the name ROC_.. not very wise) as well as sensitivity and specificity (that we already have).</span>
<span id="cb34-482"><a href="#cb34-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-485"><a href="#cb34-485" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-486"><a href="#cb34-486" aria-hidden="true" tabindex="-1"></a><span class="fu">twoClassSummary</span>(df_pred_lr, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb34-487"><a href="#cb34-487" aria-hidden="true" tabindex="-1"></a><span class="fu">twoClassSummary</span>(df_pred_ct, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb34-488"><a href="#cb34-488" aria-hidden="true" tabindex="-1"></a><span class="fu">twoClassSummary</span>(df_pred_svm, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb34-489"><a href="#cb34-489" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-490"><a href="#cb34-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-491"><a href="#cb34-491" aria-hidden="true" tabindex="-1"></a>This brings us another view: the logistic regression has the highest AUC. This shows that varying the prediction threshold provides a good potential of improving the specificity and the sensitivity (in fine, the balanced accuracy).</span>
<span id="cb34-492"><a href="#cb34-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-493"><a href="#cb34-493" aria-hidden="true" tabindex="-1"></a>Now we compute the entropy using the <span class="in">`mnLogLoss`</span> function (entropy is also called *log-loss*).</span>
<span id="cb34-494"><a href="#cb34-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-497"><a href="#cb34-497" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-498"><a href="#cb34-498" aria-hidden="true" tabindex="-1"></a><span class="fu">mnLogLoss</span>(df_pred_lr, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb34-499"><a href="#cb34-499" aria-hidden="true" tabindex="-1"></a><span class="fu">mnLogLoss</span>(df_pred_ct, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb34-500"><a href="#cb34-500" aria-hidden="true" tabindex="-1"></a><span class="fu">mnLogLoss</span>(df_pred_svm, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb34-501"><a href="#cb34-501" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-502"><a href="#cb34-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-503"><a href="#cb34-503" aria-hidden="true" tabindex="-1"></a>Here again, the entropy selects the logistic regression as the best model, though close to classification tree and SVM.</span>
<span id="cb34-504"><a href="#cb34-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-505"><a href="#cb34-505" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb34-506"><a href="#cb34-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-507"><a href="#cb34-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-510"><a href="#cb34-510" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-511"><a href="#cb34-511" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score, roc_curve</span>
<span id="cb34-512"><a href="#cb34-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-513"><a href="#cb34-513" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb34-514"><a href="#cb34-514" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_lr_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-515"><a href="#cb34-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-516"><a href="#cb34-516" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb34-517"><a href="#cb34-517" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_ct_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-518"><a href="#cb34-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-519"><a href="#cb34-519" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb34-520"><a href="#cb34-520" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_svm_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-521"><a href="#cb34-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-522"><a href="#cb34-522" aria-hidden="true" tabindex="-1"></a><span class="co"># Now we compute the entropy using the `log_loss` function (entropy is also called *log-loss*).</span></span>
<span id="cb34-523"><a href="#cb34-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-524"><a href="#cb34-524" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> log_loss</span>
<span id="cb34-525"><a href="#cb34-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-526"><a href="#cb34-526" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb34-527"><a href="#cb34-527" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_lr_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-528"><a href="#cb34-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-529"><a href="#cb34-529" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb34-530"><a href="#cb34-530" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_ct_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-531"><a href="#cb34-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-532"><a href="#cb34-532" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb34-533"><a href="#cb34-533" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_svm_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-534"><a href="#cb34-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-535"><a href="#cb34-535" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-536"><a href="#cb34-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-537"><a href="#cb34-537" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-538"><a href="#cb34-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-539"><a href="#cb34-539" aria-hidden="true" tabindex="-1"></a><span class="fu">## ROC curve &amp; prob threshold tuning</span></span>
<span id="cb34-540"><a href="#cb34-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-541"><a href="#cb34-541" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb34-542"><a href="#cb34-542" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb34-543"><a href="#cb34-543" aria-hidden="true" tabindex="-1"></a>To go deeper in the analysis, we now produce the ROC curve of each model using the <span class="in">`roc`</span> function of the <span class="in">`proc`</span> package.</span>
<span id="cb34-544"><a href="#cb34-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-547"><a href="#cb34-547" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-548"><a href="#cb34-548" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb34-549"><a href="#cb34-549" aria-hidden="true" tabindex="-1"></a>ROC_lr <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_lr)</span>
<span id="cb34-550"><a href="#cb34-550" aria-hidden="true" tabindex="-1"></a>ROC_ct <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_ct)</span>
<span id="cb34-551"><a href="#cb34-551" aria-hidden="true" tabindex="-1"></a>ROC_svm <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_svm)</span>
<span id="cb34-552"><a href="#cb34-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-553"><a href="#cb34-553" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_lr, <span class="at">print.thres=</span><span class="st">"best"</span>)</span>
<span id="cb34-554"><a href="#cb34-554" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_ct, <span class="at">print.thres=</span><span class="st">"best"</span>, <span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb34-555"><a href="#cb34-555" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_svm, <span class="at">print.thres=</span><span class="st">"best"</span>, <span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb34-556"><a href="#cb34-556" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-557"><a href="#cb34-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-558"><a href="#cb34-558" aria-hidden="true" tabindex="-1"></a>The plotting function provides an "optimal" threshold that reaches the best trade-off between sensitivity and specificity (according to some criterion). We see that there is room to improve this trade-off.</span>
<span id="cb34-559"><a href="#cb34-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-560"><a href="#cb34-560" aria-hidden="true" tabindex="-1"></a>Now, to tune this threshold, we need to do it *on the training set* to avoid overfitting. To do this, we just repeat the previous calculations (predictions) on the training set. To simplify, we only do this on the logistic regression (note that you can try on the other models; you may find that logistic regression is the best one).</span>
<span id="cb34-561"><a href="#cb34-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-564"><a href="#cb34-564" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb34-565"><a href="#cb34-565" aria-hidden="true" tabindex="-1"></a>Doc_lr_prob_tr <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr, <span class="at">newdata=</span>df_tr, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb34-566"><a href="#cb34-566" aria-hidden="true" tabindex="-1"></a>df_pred_lr_tr <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_tr<span class="sc">$</span>visits,</span>
<span id="cb34-567"><a href="#cb34-567" aria-hidden="true" tabindex="-1"></a>                            <span class="at">Yes=</span>Doc_lr_prob_tr)</span>
<span id="cb34-568"><a href="#cb34-568" aria-hidden="true" tabindex="-1"></a>ROC_lr_tr <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_lr_tr)</span>
<span id="cb34-569"><a href="#cb34-569" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_lr_tr, <span class="at">print.thres=</span><span class="st">"best"</span>)</span>
<span id="cb34-570"><a href="#cb34-570" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-571"><a href="#cb34-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-572"><a href="#cb34-572" aria-hidden="true" tabindex="-1"></a>The best threshold is 0.193. Now let us compute the confusion table with this threshold.</span>
<span id="cb34-573"><a href="#cb34-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-574"><a href="#cb34-574" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, results='hide', fig.show='hide'}</span></span>
<span id="cb34-575"><a href="#cb34-575" aria-hidden="true" tabindex="-1"></a><span class="in">Doc_lr_pred_opt &lt;- ifelse(Doc_lr_prob&gt;0.193,"Yes","No")</span></span>
<span id="cb34-576"><a href="#cb34-576" aria-hidden="true" tabindex="-1"></a><span class="in">confusionMatrix(data=as.factor(Doc_lr_pred_opt), reference = df_te$visits)</span></span>
<span id="cb34-577"><a href="#cb34-577" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-578"><a href="#cb34-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-579"><a href="#cb34-579" aria-hidden="true" tabindex="-1"></a>We now have a model with an accuracy of circa $70\%$ but with a balanced accuracy of $67\%$. Far from perfect, this is still an interesting improvement compare to the CT $62\%$. The specificity and sensitivity are now respectively $62\%$ and $72\%$. The specificity in particular made a huge improvement (from around $29\%$ at best - by CT - to $62\%$ - by log. reg).</span>
<span id="cb34-580"><a href="#cb34-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-581"><a href="#cb34-581" aria-hidden="true" tabindex="-1"></a>If the aim is to predict both "Yes" and "No", this last model (log. reg. with tuned threshold) is the best one to use.</span>
<span id="cb34-582"><a href="#cb34-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-583"><a href="#cb34-583" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb34-584"><a href="#cb34-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-587"><a href="#cb34-587" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-588"><a href="#cb34-588" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb34-589"><a href="#cb34-589" aria-hidden="true" tabindex="-1"></a><span class="co">## We need to turn back our results into binary values to be plotted</span></span>
<span id="cb34-590"><a href="#cb34-590" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb34-591"><a href="#cb34-591" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_lr_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb34-592"><a href="#cb34-592" aria-hidden="true" tabindex="-1"></a>fpr_lr, tpr_lr, thresholds_lr <span class="op">=</span> roc_curve(y_test_binary, doc_lr_prob)</span>
<span id="cb34-593"><a href="#cb34-593" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_lr, tpr_lr, label<span class="op">=</span><span class="st">"Logistic Regression"</span>)</span>
<span id="cb34-594"><a href="#cb34-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-595"><a href="#cb34-595" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb34-596"><a href="#cb34-596" aria-hidden="true" tabindex="-1"></a>doc_ct_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb34-597"><a href="#cb34-597" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_ct_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb34-598"><a href="#cb34-598" aria-hidden="true" tabindex="-1"></a>fpr_ct, tpr_ct, thresholds_ct <span class="op">=</span> roc_curve(y_test_binary, doc_ct_prob)</span>
<span id="cb34-599"><a href="#cb34-599" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_ct, tpr_ct, label<span class="op">=</span><span class="st">"Classification Tree"</span>)</span>
<span id="cb34-600"><a href="#cb34-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-601"><a href="#cb34-601" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb34-602"><a href="#cb34-602" aria-hidden="true" tabindex="-1"></a>doc_svm_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb34-603"><a href="#cb34-603" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_svm_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb34-604"><a href="#cb34-604" aria-hidden="true" tabindex="-1"></a>fpr_svm, tpr_svm, thresholds_svm <span class="op">=</span> roc_curve(y_test_binary, doc_svm_prob)</span>
<span id="cb34-605"><a href="#cb34-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-606"><a href="#cb34-606" aria-hidden="true" tabindex="-1"></a><span class="co"># Clear the last plot (if any)</span></span>
<span id="cb34-607"><a href="#cb34-607" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.clf()</span></span>
<span id="cb34-608"><a href="#cb34-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-609"><a href="#cb34-609" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_svm, tpr_svm, label<span class="op">=</span><span class="st">"SVM Radial Basis"</span>)</span>
<span id="cb34-610"><a href="#cb34-610" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the ROC curve</span></span>
<span id="cb34-611"><a href="#cb34-611" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>, label<span class="op">=</span><span class="st">"Random Classifier"</span>)</span>
<span id="cb34-612"><a href="#cb34-612" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)</span>
<span id="cb34-613"><a href="#cb34-613" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)</span>
<span id="cb34-614"><a href="#cb34-614" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"ROC Curve"</span>)</span>
<span id="cb34-615"><a href="#cb34-615" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb34-616"><a href="#cb34-616" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-617"><a href="#cb34-617" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-618"><a href="#cb34-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-619"><a href="#cb34-619" aria-hidden="true" tabindex="-1"></a>We can then plot the results in the similar way to R:</span>
<span id="cb34-620"><a href="#cb34-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-623"><a href="#cb34-623" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-624"><a href="#cb34-624" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_tr <span class="op">=</span> doc_lr.predict_proba(X_train)[:,<span class="dv">1</span>]</span>
<span id="cb34-625"><a href="#cb34-625" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_tr_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb34-626"><a href="#cb34-626" aria-hidden="true" tabindex="-1"></a>y_train_binary <span class="op">=</span> np.array([doc_lr_prob_tr_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_train])</span>
<span id="cb34-627"><a href="#cb34-627" aria-hidden="true" tabindex="-1"></a>fpr_lr_tr, tpr_lr_tr, thresholds_lr_tr <span class="op">=</span> roc_curve(y_train_binary, doc_lr_prob_tr)</span>
<span id="cb34-628"><a href="#cb34-628" aria-hidden="true" tabindex="-1"></a>optimal_idx <span class="op">=</span> np.argmax(tpr_lr_tr <span class="op">-</span> fpr_lr_tr)</span>
<span id="cb34-629"><a href="#cb34-629" aria-hidden="true" tabindex="-1"></a>optimal_threshold <span class="op">=</span> thresholds_lr_tr[optimal_idx]</span>
<span id="cb34-630"><a href="#cb34-630" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal threshold: </span><span class="sc">{</span>optimal_threshold<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-631"><a href="#cb34-631" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-632"><a href="#cb34-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-633"><a href="#cb34-633" aria-hidden="true" tabindex="-1"></a>Finally, we print the confusion matrix again:</span>
<span id="cb34-634"><a href="#cb34-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-637"><a href="#cb34-637" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb34-638"><a href="#cb34-638" aria-hidden="true" tabindex="-1"></a>doc_lr_pred_opt <span class="op">=</span> np.where(doc_lr_prob <span class="op">&gt;</span> optimal_threshold, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb34-639"><a href="#cb34-639" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_lr_pred_opt))</span>
<span id="cb34-640"><a href="#cb34-640" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb34-641"><a href="#cb34-641" aria-hidden="true" tabindex="-1"></a>The logistic regression produced with R was better.</span>
<span id="cb34-642"><a href="#cb34-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-643"><a href="#cb34-643" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb34-644"><a href="#cb34-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-645"><a href="#cb34-645" aria-hidden="true" tabindex="-1"></a><span class="fu"># Your turn</span></span>
<span id="cb34-646"><a href="#cb34-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-647"><a href="#cb34-647" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classification</span></span>
<span id="cb34-648"><a href="#cb34-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-649"><a href="#cb34-649" aria-hidden="true" tabindex="-1"></a>Repeat the analysis on the German credit data. Put several models in competition. Tune them and try to optimize their threshold. Select the best one and analyze its performance.</span>
<span id="cb34-650"><a href="#cb34-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-651"><a href="#cb34-651" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression</span></span>
<span id="cb34-652"><a href="#cb34-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-653"><a href="#cb34-653" aria-hidden="true" tabindex="-1"></a>Repeat the analysis on the nursing cost data. Put several models in competition. Tune them and select the best one. Analyze its performance using a scatterplot.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2024, <a href="https://iliaazizi.com/">Ilia Azizi &amp; Marc-Olivier Boldi</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/04_Metrics/Ex_ML_Scoring.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 🤍 and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>