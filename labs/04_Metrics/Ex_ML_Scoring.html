<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Model scoring – MLBA - S26</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" rel="next">
<link href="../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" rel="prev">
<link href="../../images/logo.dark.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dcd6dad1d9027e0fc018a6aab5a8b21b.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-fc6169d2ff87708b539fd584a3ca0747.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dcd6dad1d9027e0fc018a6aab5a8b21b.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-a6c8c8272570eabf5c1dcd6ee3141b87.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-e4e97402fd8ac5ed68ce08958e14a913.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-a6c8c8272570eabf5c1dcd6ee3141b87.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
<meta property="og:title" content="Model scoring – MLBA - S26">
<meta property="og:image" content="https://do-unil.github.io/mlba/labs/04_Metrics/Ex_ML_Scoring_files/figure-html/unnamed-chunk-15-1.png">
<meta property="og:site_name" content="MLBA - S26">
<meta property="og:image:height" content="960">
<meta property="og:image:width" content="1344">
</head>
<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../labs/04_Metrics/Ex_ML_Scoring.html">Metrics</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../images/logo.light.png" alt="" class="sidebar-logo light-content py-0 d-lg-inline d-none"><img src="../../images/logo.light.png" alt="" class="sidebar-logo dark-content py-0 d-lg-inline d-none"></a>
      <div class="sidebar-tools-main tools-wide">
    <a href="https://moodle.unil.ch/course/view.php?id=36198" title="Moodle" class="quarto-navigation-tool px-1" aria-label="Moodle"><i class="bi bi-person-rolodex"></i></a>
    <a href="https://github.com/do-unil/mlba" title="GitHub Repo" class="quarto-navigation-tool px-1" aria-label="GitHub Repo"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../schedule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../faq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FAQ</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Lectures</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/01_Introduction/ML_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/02_DataExploration/ML_DataExplo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Exploration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/030_Introduction/ML_Models_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/031_LinearLogisticRegression/ML_LinLogReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/032_Trees/ML_Trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/033_NeuralNetworks/ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/034_SupportVectorMachine/ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/04_Metrics/ML_Metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/05_DataSplitting/ML_DataSplitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/06_Ensembles/ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/07_InterpretableML/ML_Interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/080_Introduction/ML_UnsupIntro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Unsuperised Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/081_Clustering/ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/082_DimensionReduction/ML_DimRed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dimension Reduction</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/00_lab/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/032_Trees/Ex_ML_Tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/033_NeuralNetworks/EX_ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/04_Metrics/Ex_ML_Scoring.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/06_Ensembles/Ex_ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/07_InterpretableML/Ex_ML_VarImp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/081_Clustering/Ex_ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/082_DimensionReduction/Ex_ML_PCA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PCA</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Assessments</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Exam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exam</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Project</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Project_Directives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Directives</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Presentation_Guidelines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Presentation Guidelines</span></a>
  </div>
</li>
      </ul>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/beginners_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Beginners in R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/data_acquisition/data_sources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Sources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/data_acquisition/web_scraping_api.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Web Scraping</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/cheatsheets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding Cheatsheets</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">On this page</h2>
   
  <ul>
<li>
<a href="#regression-task" id="toc-regression-task" class="nav-link active" data-scroll-target="#regression-task">Regression task</a>
  <ul class="collapse">
<li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">Data</a></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models">Models</a></li>
  <li><a href="#r-squared" id="toc-r-squared" class="nav-link" data-scroll-target="#r-squared">R-squared</a></li>
  <li><a href="#rmse" id="toc-rmse" class="nav-link" data-scroll-target="#rmse">RMSE</a></li>
  <li><a href="#mae" id="toc-mae" class="nav-link" data-scroll-target="#mae">MAE</a></li>
  <li><a href="#best-model" id="toc-best-model" class="nav-link" data-scroll-target="#best-model">Best model</a></li>
  </ul>
</li>
  <li>
<a href="#classification-task" id="toc-classification-task" class="nav-link" data-scroll-target="#classification-task">Classification task</a>
  <ul class="collapse">
<li><a href="#data-1" id="toc-data-1" class="nav-link" data-scroll-target="#data-1">Data</a></li>
  <li><a href="#models-1" id="toc-models-1" class="nav-link" data-scroll-target="#models-1">Models</a></li>
  <li><a href="#predictions" id="toc-predictions" class="nav-link" data-scroll-target="#predictions">Predictions</a></li>
  <li><a href="#confusion-matrices-prediction-based-measures" id="toc-confusion-matrices-prediction-based-measures" class="nav-link" data-scroll-target="#confusion-matrices-prediction-based-measures">Confusion matrices &amp; prediction-based measures</a></li>
  <li><a href="#probability-based-measures" id="toc-probability-based-measures" class="nav-link" data-scroll-target="#probability-based-measures">Probability-based measures</a></li>
  <li><a href="#roc-curve-prob-threshold-tuning" id="toc-roc-curve-prob-threshold-tuning" class="nav-link" data-scroll-target="#roc-curve-prob-threshold-tuning">ROC curve &amp; prob threshold tuning</a></li>
  </ul>
</li>
  <li>
<a href="#your-turn" id="toc-your-turn" class="nav-link" data-scroll-target="#your-turn">Your turn</a>
  <ul class="collapse">
<li><a href="#classification" id="toc-classification" class="nav-link" data-scroll-target="#classification">Classification</a></li>
  <li><a href="#regression" id="toc-regression" class="nav-link" data-scroll-target="#regression">Regression</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/04_Metrics/Ex_ML_Scoring.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><script type="application/javascript">
// Description: Change image src depending on body class (quarto-light or quarto-dark)
function updateImageSrc() {
  var bodyClass = window.document.body.classList;
  var images = window.document.getElementsByTagName('img');
  for (var i = 0; i < images.length; i++) {
    var image = images[i];
    var src = image.src;
    var newSrc = src;
    if (bodyClass.contains('quarto-light') && src.includes('.dark')) {
      newSrc = src.replace('.dark', '.light');
    } else if (bodyClass.contains('quarto-dark') && src.includes('.light')) {
      newSrc = src.replace('.light', '.dark');
    }
    if (newSrc !== src) {
      image.src = newSrc;
    }
  }
}

var observer = new MutationObserver(function(mutations) {
  mutations.forEach(function(mutation) {
    if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
      updateImageSrc();
    }
  });
});

observer.observe(window.document.body, {
  attributes: true
});

updateImageSrc();
</script><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../labs/04_Metrics/Ex_ML_Scoring.html">Metrics</a></li></ol></nav><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Model scoring</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><section id="regression-task" class="level1"><h1>Regression task</h1>
<section id="data" class="level2"><h2 class="anchored" data-anchor-id="data">Data</h2>
<p>The data set is the one used in the series on linear regressions.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://readr.tidyverse.org">readr</a></span><span class="op">)</span></span>
<span><span class="va">real_estate_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org/reference/here.html">here</a></span><span class="op">(</span><span class="st">"labs/data/real_estate_data.csv"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Then we split the data in a training and a test set (0.8/0.2). For this, we use the <code>createDataPartition</code> function of the <code>caret</code> package.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/caret/">caret</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">234</span><span class="op">)</span></span>
<span><span class="va">index_tr</span> <span class="op">&lt;-</span> <span class="fu">createDataPartition</span><span class="op">(</span>y <span class="op">=</span> <span class="va">real_estate_data</span><span class="op">$</span><span class="va">Price</span>, p<span class="op">=</span> <span class="fl">0.8</span>, list <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">df_tr</span> <span class="op">&lt;-</span> <span class="va">real_estate_data</span><span class="op">[</span><span class="va">index_tr</span>,<span class="op">]</span></span>
<span><span class="va">df_te</span> <span class="op">&lt;-</span> <span class="va">real_estate_data</span><span class="op">[</span><span class="op">-</span><span class="va">index_tr</span>,<span class="op">]</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section><section id="models" class="level2"><h2 class="anchored" data-anchor-id="models">Models</h2>
<p>We will compare a linear regression, a regression tree and a 3-NN (KNN).</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" href="" aria-current="page">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/bethatkinson/rpart">rpart</a></span><span class="op">)</span></span>
<span><span class="va">est_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Price</span><span class="op">~</span><span class="va">TransDate</span><span class="op">+</span><span class="va">HouseAge</span><span class="op">+</span><span class="va">Dist</span><span class="op">+</span></span>
<span>               <span class="va">NumStores</span><span class="op">+</span><span class="va">Lat</span><span class="op">+</span><span class="va">Long</span>, data<span class="op">=</span><span class="va">df_tr</span><span class="op">)</span></span>
<span><span class="va">est_rt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart</a></span><span class="op">(</span><span class="va">Price</span><span class="op">~</span><span class="va">TransDate</span><span class="op">+</span><span class="va">HouseAge</span><span class="op">+</span><span class="va">Dist</span><span class="op">+</span></span>
<span>                      <span class="va">NumStores</span><span class="op">+</span><span class="va">Lat</span><span class="op">+</span><span class="va">Long</span>, data<span class="op">=</span><span class="va">df_tr</span><span class="op">)</span></span>
<span><span class="va">est_knn</span> <span class="op">&lt;-</span> <span class="fu">knnreg</span><span class="op">(</span><span class="va">Price</span><span class="op">~</span><span class="va">TransDate</span><span class="op">+</span><span class="va">HouseAge</span><span class="op">+</span><span class="va">Dist</span><span class="op">+</span></span>
<span>                      <span class="va">NumStores</span><span class="op">+</span><span class="va">Lat</span><span class="op">+</span><span class="va">Long</span>, data<span class="op">=</span><span class="va">df_tr</span>, k <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load the course python environment as usual with a r code chunks.</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rstudio.github.io/reticulate/">reticulate</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/use_python.html">use_condaenv</a></span><span class="op">(</span><span class="st">"MLBA"</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the models: linear regression, regression tree, and KNN</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define predictors and target variable</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>predictors <span class="op">=</span> [<span class="st">'TransDate'</span>, <span class="st">'HouseAge'</span>, <span class="st">'Dist'</span>, <span class="st">'NumStores'</span>, <span class="st">'Lat'</span>, <span class="st">'Long'</span>]</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">'Price'</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit models</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>est_lm <span class="op">=</span> LinearRegression().fit(r.df_tr[predictors], r.df_tr[target])</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>est_rt <span class="op">=</span> DecisionTreeRegressor(random_state<span class="op">=</span><span class="dv">234</span>).fit(r.df_tr[predictors], r.df_tr[target])</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>est_knn <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">3</span>).fit(r.df_tr[predictors], r.df_tr[target])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</div>
</section><section id="r-squared" class="level2"><h2 class="anchored" data-anchor-id="r-squared">R-squared</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>We now compute the R2 for each model using the a defined function.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">R2</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">y_predict</span>, <span class="va">y_actual</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">y_actual</span>,<span class="va">y_predict</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu">R2</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_lm</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, <span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span>
<span><span class="fu">R2</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_rt</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, <span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span>
<span><span class="fu">R2</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_knn</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, <span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6562361
[1] 0.7719796
[1] 0.8079045</code></pre>
</div>
</div>
<p>Just for the exercise, we can compute it by hand (square of the correlation)</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_lm</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, <span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6562361</code></pre>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing as the R code</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Only to demonostrate which argument goes where (different from `caret::R2`)</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(y_true <span class="op">=</span> r.df_te[target], y_pred <span class="op">=</span> est_lm.predict(r.df_te[predictors])))</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Computing it by hand gives us the same result as R</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>np.corrcoef(est_lm.predict(r.df_te[predictors]), r.df_te[target])[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.6424009640449693
0.7018428459476751
0.7971133712172433
np.float64(0.6562360670242778)</code></pre>
</div>
</div>
<p>To understand why the results are different in <code>R2</code> from our defined function in R vs.&nbsp;<code>sklearn.metrics.r2_score()</code> in Python, see <a href="https://stats.stackexchange.com/questions/586821/what-is-the-interpretation-of-the-traditional-r2">this post on stackoverflow</a>. If you want to recieve the same results in both, you can try computing the R2 not by correlation but by the formula <span class="math inline">\(1 - \frac{SSR}{SST}\)</span> where <span class="math inline">\(SSR\)</span> is the sum of squared residuals and <span class="math inline">\(SST\)</span> is the total sum of squares.</p>
<p>Additionally, please note that the performance of the tree is highly dependent on the seed, so setting a different seed can lead to different results.</p>
</div>
</div>
</div>
</section><section id="rmse" class="level2"><h2 class="anchored" data-anchor-id="rmse">RMSE</h2>
<p>Now, we compute the RMSE.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">RMSE</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_lm</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, <span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span>
<span><span class="fu">RMSE</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_rt</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, <span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span>
<span><span class="fu">RMSE</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_knn</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, <span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7.498671
[1] 6.088373
[1] 5.659951</code></pre>
</div>
</div>
<p>The formula would be:</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_lm</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span><span class="op">-</span><span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7.498671</code></pre>
</div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, root_mean_squared_error</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_lm.predict(r.df_te[predictors])))</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># alternatively in the older version of `sklearn`, you had to run the code below</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># print(np.sqrt(mean_squared_error(r.df_te[target], est_lm.predict(r.df_te[predictors]))))</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>7.498671398473088
6.84713310132913
5.648236408450452</code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section id="mae" class="level2"><h2 class="anchored" data-anchor-id="mae">MAE</h2>
<p>Now, we compute the MAE.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">MAE</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_lm</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, <span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span>
<span><span class="fu">MAE</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_rt</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, <span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span>
<span><span class="fu">MAE</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_knn</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, <span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.803592
[1] 4.599811
[1] 4.461789</code></pre>
</div>
</div>
<p>The formula would be:</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_lm</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span><span class="op">-</span><span class="va">df_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.803592</code></pre>
</div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute MAE for each model</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_lm.predict(r.df_te[predictors])))</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.80359171132348
4.726829268292682
4.4349593495934965</code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section id="best-model" class="level2"><h2 class="anchored" data-anchor-id="best-model">Best model</h2>
<p>These three measures agree on the fact that the regression tree is the best model. To inspect further the predictions, we use scatterplots:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">df_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_lm</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, xlab<span class="op">=</span><span class="st">"Prediction"</span>, </span>
<span>     ylab<span class="op">=</span><span class="st">"Observed prices"</span>, main<span class="op">=</span><span class="st">"Lin. Reg."</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">df_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_rt</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, xlab<span class="op">=</span><span class="st">"Prediction"</span>, </span>
<span>     ylab<span class="op">=</span><span class="st">"Observed prices"</span>, main<span class="op">=</span><span class="st">"Lin. Reg."</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">df_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">est_knn</span>, newdata <span class="op">=</span> <span class="va">df_te</span><span class="op">)</span>, xlab<span class="op">=</span><span class="st">"Prediction"</span>, </span>
<span>     ylab<span class="op">=</span><span class="st">"Observed prices"</span>, main<span class="op">=</span><span class="st">"Lin. Reg."</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="Ex_ML_Scoring_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize also in Python</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">221</span>)<span class="op">;</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_lm.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)<span class="op">;</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)<span class="op">;</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Lin. Reg."</span>)<span class="op">;</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)<span class="op">;</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">222</span>)<span class="op">;</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_rt.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)<span class="op">;</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)<span class="op">;</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Regression Tree"</span>)<span class="op">;</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)<span class="op">;</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">223</span>)<span class="op">;</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_knn.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)<span class="op">;</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)<span class="op">;</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"KNN"</span>)<span class="op">;</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)<span class="op">;</span></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="Ex_ML_Scoring_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<p>The scatterplots are in line with the conclusion that KNN is the best, even though it is not easy to declare from a plot. We can in addition see that the regression tree (RT) has made more error on the larger prices.</p>
</section></section><section id="classification-task" class="level1"><h1>Classification task</h1>
<section id="data-1" class="level2"><h2 class="anchored" data-anchor-id="data-1">Data</h2>
<p>The data set is the visit data (already used in previous exercises). For simplicity, we turn the outcome (<code>visits</code>) into factor. Like before, that are also split into a training and a test set.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">DocVis</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org/reference/here.html">here</a></span><span class="op">(</span><span class="st">"labs/data/DocVis.csv"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">DocVis</span><span class="op">$</span><span class="va">visits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">DocVis</span><span class="op">$</span><span class="va">visits</span><span class="op">)</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/caret/">caret</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">346</span><span class="op">)</span></span>
<span><span class="va">index_tr</span> <span class="op">&lt;-</span> <span class="fu">createDataPartition</span><span class="op">(</span>y <span class="op">=</span> <span class="va">DocVis</span><span class="op">$</span><span class="va">visits</span>, p<span class="op">=</span> <span class="fl">0.8</span>, list <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">df_tr</span> <span class="op">&lt;-</span> <span class="va">DocVis</span><span class="op">[</span><span class="va">index_tr</span>,<span class="op">]</span></span>
<span><span class="va">df_te</span> <span class="op">&lt;-</span> <span class="va">DocVis</span><span class="op">[</span><span class="op">-</span><span class="va">index_tr</span>,<span class="op">]</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section><section id="models-1" class="level2"><h2 class="anchored" data-anchor-id="models-1">Models</h2>
<p>We will compare a logistic regression, a classification tree (pruned) and a SVM with radial basis (cost and gamma tuned).</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<p>Note that the <em>code for tuning the SVM</em> is provided below in comments because of the time it takes to run. The final parameters have been selected accordingly. Also, the SVM fit includes the argument <code>probability=TRUE</code> to allow the calculations of predicted probabilities later.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">e1071</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">adabag</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Logistic regression</span></span>
<span><span class="va">Doc_lr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">visits</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">df_tr</span>, family<span class="op">=</span><span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="va">Doc_lr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/step.html">step</a></span><span class="op">(</span><span class="va">Doc_lr</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Classification tree </span></span>
<span><span class="va">Doc_ct</span> <span class="op">&lt;-</span> <span class="fu">autoprune</span><span class="op">(</span><span class="va">visits</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">df_tr</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## SVM radial basis</span></span>
<span><span class="co"># grid_radial &lt;- expand.grid(sigma = c(0.0001, 0.001, 0.01, 0.1),</span></span>
<span><span class="co">#                           C = c(0.1, 1, 10, 100, 1000))</span></span>
<span><span class="co"># trctrl &lt;- trainControl(method = "cv", number=10)</span></span>
<span><span class="co"># set.seed(143)</span></span>
<span><span class="co"># Doc_svm &lt;- train(visits ~., data = df_tr, method = "svmRadial",</span></span>
<span><span class="co">#                          trControl=trctrl,</span></span>
<span><span class="co">#                          tuneGrid = grid_radial)</span></span>
<span><span class="va">Doc_svm</span> <span class="op">&lt;-</span> <span class="fu">svm</span><span class="op">(</span><span class="va">visits</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">df_tr</span>, gamma<span class="op">=</span><span class="fl">0.001</span>, cost<span class="op">=</span><span class="fl">1000</span>, probability<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Start:  AIC=3652.59
visits ~ gender + age + income + illness + reduced + health + 
    private + freepoor + freerepat + nchronic + lchronic

            Df Deviance    AIC
- nchronic   1   3629.0 3651.0
- income     1   3630.4 3652.4
&lt;none&gt;           3628.6 3652.6
- lchronic   1   3632.0 3654.0
- freerepat  1   3633.3 3655.3
- private    1   3633.9 3655.9
- age        1   3635.0 3657.0
- gender     1   3636.8 3658.8
- freepoor   1   3637.1 3659.1
- health     1   3637.7 3659.7
- illness    1   3703.2 3725.2
- reduced    1   3779.4 3801.4

Step:  AIC=3651.02
visits ~ gender + age + income + illness + reduced + health + 
    private + freepoor + freerepat + lchronic

            Df Deviance    AIC
- income     1   3630.8 3650.8
&lt;none&gt;           3629.0 3651.0
- lchronic   1   3632.1 3652.1
- freerepat  1   3633.8 3653.8
- private    1   3634.5 3654.5
- age        1   3636.6 3656.6
- freepoor   1   3637.4 3657.4
- gender     1   3637.5 3657.5
- health     1   3638.2 3658.2
- illness    1   3712.9 3732.9
- reduced    1   3779.9 3799.9

Step:  AIC=3650.8
visits ~ gender + age + illness + reduced + health + private + 
    freepoor + freerepat + lchronic

            Df Deviance    AIC
&lt;none&gt;           3630.8 3650.8
- lchronic   1   3633.8 3651.8
- private    1   3635.6 3653.6
- freerepat  1   3636.8 3654.8
- freepoor   1   3638.2 3656.2
- age        1   3639.4 3657.4
- health     1   3640.4 3658.4
- gender     1   3641.4 3659.4
- illness    1   3715.8 3733.8
- reduced    1   3781.1 3799.1</code></pre>
</div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co"># We first put the data in a nice format by one-hot encoding the categorical variables</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> pd.get_dummies(r.df_tr.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> r.df_tr[<span class="st">'visits'</span>]</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> pd.get_dummies(r.df_te.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> r.df_te[<span class="st">'visits'</span>]</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>doc_lr <span class="op">=</span> LogisticRegression()</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>doc_lr.fit(X_train, y_train)<span class="op">;</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>doc_ct <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>doc_ct.fit(X_train, y_train)<span class="op">;</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>doc_svm <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span><span class="fl">0.001</span>, C<span class="op">=</span><span class="dv">1000</span>, probability<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>doc_svm.fit(X_train, y_train)<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</div>
</section><section id="predictions" class="level2"><h2 class="anchored" data-anchor-id="predictions">Predictions</h2>
<p>We now compute the predicted probabilities and the predictions of all the models.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<p>Note that, for SVM, we need to extract the <em>attribute</em> “probabilities” from the predicted object. This can be done with the <code>attr</code> function.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Logistic regression</span></span>
<span><span class="va">Doc_lr_prob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">Doc_lr</span>, newdata<span class="op">=</span><span class="va">df_te</span>, type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span></span>
<span><span class="va">Doc_lr_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">Doc_lr_prob</span><span class="op">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Classification tree </span></span>
<span><span class="va">Doc_ct_prob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">Doc_ct</span>, newdata<span class="op">=</span><span class="va">df_te</span>, type<span class="op">=</span><span class="st">"prob"</span><span class="op">)</span></span>
<span><span class="va">Doc_ct_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">Doc_ct</span>, newdata<span class="op">=</span><span class="va">df_te</span>, type<span class="op">=</span><span class="st">"class"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## SVM radial basis</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="va">Doc_svm_prob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">Doc_svm</span>, newdata<span class="op">=</span><span class="va">df_te</span>, probability<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html">attr</a></span><span class="op">(</span><span class="st">"probabilities"</span><span class="op">)</span></span>
<span><span class="va">Doc_svm_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">Doc_svm</span>, newdata<span class="op">=</span><span class="va">df_te</span>, type<span class="op">=</span><span class="st">"class"</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co">## the second column represents the `no` values, to make sure of that, you can run `doc_lr.classes_`</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>doc_lr_prob <span class="op">=</span> doc_lr.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>doc_lr_pred <span class="op">=</span> np.where(doc_lr_prob<span class="op">&gt;</span><span class="fl">0.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>doc_ct_prob <span class="op">=</span> doc_ct.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>doc_ct_pred <span class="op">=</span> doc_ct.predict(X_test)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>doc_svm_prob <span class="op">=</span> doc_svm.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>doc_svm_pred <span class="op">=</span> doc_svm.predict(X_test)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</div>
</section><section id="confusion-matrices-prediction-based-measures" class="level2"><h2 class="anchored" data-anchor-id="confusion-matrices-prediction-based-measures">Confusion matrices &amp; prediction-based measures</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<p>The <code>confusionMatrix</code> function provides all the accuracy measures that we want.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">confusionMatrix</span><span class="op">(</span>data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Doc_lr_pred</span><span class="op">)</span>, reference <span class="op">=</span> <span class="va">df_te</span><span class="op">$</span><span class="va">visits</span><span class="op">)</span></span>
<span><span class="fu">confusionMatrix</span><span class="op">(</span>data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Doc_ct_pred</span><span class="op">)</span>, reference <span class="op">=</span> <span class="va">df_te</span><span class="op">$</span><span class="va">visits</span><span class="op">)</span></span>
<span><span class="fu">confusionMatrix</span><span class="op">(</span>data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Doc_svm_pred</span><span class="op">)</span>, reference <span class="op">=</span> <span class="va">df_te</span><span class="op">$</span><span class="va">visits</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  No Yes
       No  809 179
       Yes  19  30
                                          
               Accuracy : 0.8091          
                 95% CI : (0.7838, 0.8326)
    No Information Rate : 0.7985          
    P-Value [Acc &gt; NIR] : 0.2089          
                                          
                  Kappa : 0.1689          
                                          
 Mcnemar's Test P-Value : &lt;2e-16          
                                          
            Sensitivity : 0.9771          
            Specificity : 0.1435          
         Pos Pred Value : 0.8188          
         Neg Pred Value : 0.6122          
             Prevalence : 0.7985          
         Detection Rate : 0.7801          
   Detection Prevalence : 0.9527          
      Balanced Accuracy : 0.5603          
                                          
       'Positive' Class : No              
                                          
Confusion Matrix and Statistics

          Reference
Prediction  No Yes
       No  791 149
       Yes  37  60
                                          
               Accuracy : 0.8206          
                 95% CI : (0.7959, 0.8435)
    No Information Rate : 0.7985          
    P-Value [Acc &gt; NIR] : 0.03934         
                                          
                  Kappa : 0.3031          
                                          
 Mcnemar's Test P-Value : 3.988e-16       
                                          
            Sensitivity : 0.9553          
            Specificity : 0.2871          
         Pos Pred Value : 0.8415          
         Neg Pred Value : 0.6186          
             Prevalence : 0.7985          
         Detection Rate : 0.7628          
   Detection Prevalence : 0.9065          
      Balanced Accuracy : 0.6212          
                                          
       'Positive' Class : No              
                                          
Confusion Matrix and Statistics

          Reference
Prediction  No Yes
       No  802 159
       Yes  26  50
                                          
               Accuracy : 0.8216          
                 95% CI : (0.7969, 0.8444)
    No Information Rate : 0.7985          
    P-Value [Acc &gt; NIR] : 0.03302         
                                          
                  Kappa : 0.2727          
                                          
 Mcnemar's Test P-Value : &lt; 2e-16         
                                          
            Sensitivity : 0.9686          
            Specificity : 0.2392          
         Pos Pred Value : 0.8345          
         Neg Pred Value : 0.6579          
             Prevalence : 0.7985          
         Detection Rate : 0.7734          
   Detection Prevalence : 0.9267          
      Balanced Accuracy : 0.6039          
                                          
       'Positive' Class : No              
                                          </code></pre>
</div>
</div>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score, balanced_accuracy_score, cohen_kappa_score</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_lr_pred))</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_ct_pred))</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_svm_pred))</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[809  19]
 [179  30]]
Accuracy: 0.809
Kappa: 0.169
Balanced accuracy: 0.560
[[724 104]
 [145  64]]
Accuracy: 0.760
Kappa: 0.195
Balanced accuracy: 0.590
[[808  20]
 [169  40]]
Accuracy: 0.818
Kappa: 0.228
Balanced accuracy: 0.584</code></pre>
</div>
</div>
<p>Different results for the tree and CSV due to randomness, but even with that, SVM remains the best model in terms of accuracy.</p>
</div>
</div>
</div>
<p>The conclusion may be different from one measure to another</p>
<ul>
<li>Accuracy: the SVM reaches the highest accuracy</li>
<li>Kappa: the CT is the highest.</li>
<li>Balanced accuracy: the CT is the highest.</li>
<li>etc.</li>
</ul>
<p>Looking at the confusion matrix, we see that the data is highly unbalanced (many more “No” than “Yes”). Therefore, measures like balanced accuracy and kappa are interesting because they take this characteristics into account. This shows that the CT is probably better than the SVM because it reaches a better balance between predicting “Yes” and “No”.</p>
<p>By looking at the sensitivity and specificity (<u>!! here the positive class is “No”</u>), we see that the best model to recover the “No” is the logistic regression (largest sensitivity) and the best model to recover the “Yes” is the classification tree (largest specificity).</p>
</section><section id="probability-based-measures" class="level2"><h2 class="anchored" data-anchor-id="probability-based-measures">Probability-based measures</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-9-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-1" role="tab" aria-controls="tabset-9-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-9-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-2" role="tab" aria-controls="tabset-9-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-9-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-9-1-tab">
<p>To compute the AUC (area under the ROC curve) we can use the <code>caret::twoClassSummary</code> function. The use of this function can be tricky. Its argument should be a data frame with columns (names are fixed):</p>
<ul>
<li>“obs”: the observed classes</li>
<li>“pred”: the predicted classes</li>
<li>two columns with names being the levels of the classes, here “Yes” and “No”, containing the predicted probabilities.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">df_pred_lr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>obs<span class="op">=</span><span class="va">df_te</span><span class="op">$</span><span class="va">visits</span>,</span>
<span>                         Yes<span class="op">=</span><span class="va">Doc_lr_prob</span>,</span>
<span>                         No<span class="op">=</span><span class="fl">1</span><span class="op">-</span><span class="va">Doc_lr_prob</span>,</span>
<span>                         pred<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Doc_lr_pred</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">df_pred_lr</span><span class="op">)</span></span>
<span></span>
<span><span class="va">df_pred_ct</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>obs<span class="op">=</span><span class="va">df_te</span><span class="op">$</span><span class="va">visits</span>,</span>
<span>                         <span class="va">Doc_ct_prob</span>,</span>
<span>                         pred<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Doc_ct_pred</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">df_pred_ct</span><span class="op">)</span></span>
<span><span class="va">df_pred_svm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>obs<span class="op">=</span><span class="va">df_te</span><span class="op">$</span><span class="va">visits</span>,</span>
<span>                          <span class="va">Doc_svm_prob</span>,</span>
<span>                          pred<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Doc_svm_pred</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">df_pred_svm</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>   obs        Yes        No pred
6  Yes 0.43567107 0.5643289   No
11 Yes 0.08350891 0.9164911   No
12 Yes 0.16600203 0.8339980   No
13 Yes 0.55658181 0.4434182  Yes
14 Yes 0.47463795 0.5253620   No
15 Yes 0.19414583 0.8058542   No
   obs        No       Yes pred
6  Yes 0.8437079 0.1562921   No
11 Yes 0.8437079 0.1562921   No
12 Yes 0.8437079 0.1562921   No
13 Yes 0.3785311 0.6214689  Yes
14 Yes 0.3785311 0.6214689  Yes
15 Yes 0.8437079 0.1562921   No
   obs       Yes        No pred
6  Yes 0.2263059 0.7736941   No
11 Yes 0.1619207 0.8380793   No
12 Yes 0.1622321 0.8377679   No
13 Yes 0.7072647 0.2927353  Yes
14 Yes 0.6285501 0.3714499  Yes
15 Yes 0.2273475 0.7726525   No</code></pre>
</div>
</div>
<p>Then we pass these objects to the function, and levels of the classes to be predicted (for the function to be able to recover them in the data frame). The function compute the AUC by default (under the name ROC_.. not very wise) as well as sensitivity and specificity (that we already have).</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">twoClassSummary</span><span class="op">(</span><span class="va">df_pred_lr</span>, lev <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">df_pred_lr</span><span class="op">$</span><span class="va">obs</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">twoClassSummary</span><span class="op">(</span><span class="va">df_pred_ct</span>, lev <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">df_pred_lr</span><span class="op">$</span><span class="va">obs</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">twoClassSummary</span><span class="op">(</span><span class="va">df_pred_svm</span>, lev <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">df_pred_lr</span><span class="op">$</span><span class="va">obs</span><span class="op">)</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>      ROC      Sens      Spec 
0.7320170 0.9770531 0.1435407 
      ROC      Sens      Spec 
0.6261673 0.9553140 0.2870813 
      ROC      Sens      Spec 
0.7189631 0.9685990 0.2392344 </code></pre>
</div>
</div>
<p>This brings us another view: the logistic regression has the highest AUC. This shows that varying the prediction threshold provides a good potential of improving the specificity and the sensitivity (in fine, the balanced accuracy).</p>
<p>Now we compute the entropy using the <code>mnLogLoss</code> function (entropy is also called <em>log-loss</em>).</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">mnLogLoss</span><span class="op">(</span><span class="va">df_pred_lr</span>, lev <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">df_pred_lr</span><span class="op">$</span><span class="va">obs</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">mnLogLoss</span><span class="op">(</span><span class="va">df_pred_ct</span>, lev <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">df_pred_lr</span><span class="op">$</span><span class="va">obs</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">mnLogLoss</span><span class="op">(</span><span class="va">df_pred_svm</span>, lev <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">df_pred_lr</span><span class="op">$</span><span class="va">obs</span><span class="op">)</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  logLoss 
0.4492389 
  logLoss 
0.4596595 
  logLoss 
0.4545877 </code></pre>
</div>
</div>
<p>Here again, the entropy selects the logistic regression as the best model, though close to classification tree and SVM.</p>
</div>
<div id="tabset-9-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-9-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score, roc_curve</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_lr_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_ct_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_svm_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Now we compute the entropy using the `log_loss` function (entropy is also called *log-loss*).</span></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> log_loss</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_lr_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_ct_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_svm_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>AUC: 0.729
AUC: 0.602
AUC: 0.732
Log-loss: 0.450
Log-loss: 7.688
Log-loss: 0.462</code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section id="roc-curve-prob-threshold-tuning" class="level2"><h2 class="anchored" data-anchor-id="roc-curve-prob-threshold-tuning">ROC curve &amp; prob threshold tuning</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-10-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-1" role="tab" aria-controls="tabset-10-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-10-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-2" role="tab" aria-controls="tabset-10-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-10-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-10-1-tab">
<p>To go deeper in the analysis, we now produce the ROC curve of each model using the <code>roc</code> function of the <code>proc</code> package.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://xrobin.github.io/pROC/">pROC</a></span><span class="op">)</span></span>
<span><span class="va">ROC_lr</span> <span class="op">&lt;-</span> <span class="fu">roc</span><span class="op">(</span><span class="va">obs</span> <span class="op">~</span> <span class="va">Yes</span>, data<span class="op">=</span><span class="va">df_pred_lr</span><span class="op">)</span></span>
<span><span class="va">ROC_ct</span> <span class="op">&lt;-</span> <span class="fu">roc</span><span class="op">(</span><span class="va">obs</span> <span class="op">~</span> <span class="va">Yes</span>, data<span class="op">=</span><span class="va">df_pred_ct</span><span class="op">)</span></span>
<span><span class="va">ROC_svm</span> <span class="op">&lt;-</span> <span class="fu">roc</span><span class="op">(</span><span class="va">obs</span> <span class="op">~</span> <span class="va">Yes</span>, data<span class="op">=</span><span class="va">df_pred_svm</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">ROC_lr</span>, print.thres<span class="op">=</span><span class="st">"best"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">ROC_ct</span>, print.thres<span class="op">=</span><span class="st">"best"</span>, add<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">ROC_svm</span>, print.thres<span class="op">=</span><span class="st">"best"</span>, add<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="Ex_ML_Scoring_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The plotting function provides an “optimal” threshold that reaches the best trade-off between sensitivity and specificity (according to some criterion). We see that there is room to improve this trade-off.</p>
<p>Now, to tune this threshold, we need to do it <em>on the training set</em> to avoid overfitting. To do this, we just repeat the previous calculations (predictions) on the training set. To simplify, we only do this on the logistic regression (note that you can try on the other models; you may find that logistic regression is the best one).</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Doc_lr_prob_tr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">Doc_lr</span>, newdata<span class="op">=</span><span class="va">df_tr</span>, type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span></span>
<span><span class="va">df_pred_lr_tr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>obs<span class="op">=</span><span class="va">df_tr</span><span class="op">$</span><span class="va">visits</span>,</span>
<span>                            Yes<span class="op">=</span><span class="va">Doc_lr_prob_tr</span><span class="op">)</span></span>
<span><span class="va">ROC_lr_tr</span> <span class="op">&lt;-</span> <span class="fu">roc</span><span class="op">(</span><span class="va">obs</span> <span class="op">~</span> <span class="va">Yes</span>, data<span class="op">=</span><span class="va">df_pred_lr_tr</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">ROC_lr_tr</span>, print.thres<span class="op">=</span><span class="st">"best"</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="Ex_ML_Scoring_files/figure-html/unnamed-chunk-29-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The best threshold is 0.193. Now let us compute the confusion table with this threshold.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Doc_lr_pred_opt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">Doc_lr_prob</span><span class="op">&gt;</span><span class="fl">0.193</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span><span class="op">)</span></span>
<span><span class="fu">confusionMatrix</span><span class="op">(</span>data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Doc_lr_pred_opt</span><span class="op">)</span>, reference <span class="op">=</span> <span class="va">df_te</span><span class="op">$</span><span class="va">visits</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  No Yes
       No  595  79
       Yes 233 130
                                          
               Accuracy : 0.6991          
                 95% CI : (0.6702, 0.7269)
    No Information Rate : 0.7985          
    P-Value [Acc &gt; NIR] : 1               
                                          
                  Kappa : 0.2671          
                                          
 Mcnemar's Test P-Value : &lt;2e-16          
                                          
            Sensitivity : 0.7186          
            Specificity : 0.6220          
         Pos Pred Value : 0.8828          
         Neg Pred Value : 0.3581          
             Prevalence : 0.7985          
         Detection Rate : 0.5738          
   Detection Prevalence : 0.6500          
      Balanced Accuracy : 0.6703          
                                          
       'Positive' Class : No              
                                          </code></pre>
</div>
</div>
<p>We now have a model with an accuracy of circa <span class="math inline">\(70\%\)</span> but with a balanced accuracy of <span class="math inline">\(67\%\)</span>. Far from perfect, this is still an interesting improvement compare to the CT <span class="math inline">\(62\%\)</span>. The specificity and sensitivity are now respectively <span class="math inline">\(62\%\)</span> and <span class="math inline">\(72\%\)</span>. The specificity in particular made a huge improvement (from around <span class="math inline">\(29\%\)</span> at best - by CT - to <span class="math inline">\(62\%\)</span> - by log. reg).</p>
<p>If the aim is to predict both “Yes” and “No”, this last model (log. reg. with tuned threshold) is the best one to use.</p>
</div>
<div id="tabset-10-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-10-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="co">## We need to turn back our results into binary values to be plotted</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_lr_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>fpr_lr, tpr_lr, thresholds_lr <span class="op">=</span> roc_curve(y_test_binary, doc_lr_prob)</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_lr, tpr_lr, label<span class="op">=</span><span class="st">"Logistic Regression"</span>)<span class="op">;</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>doc_ct_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_ct_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>fpr_ct, tpr_ct, thresholds_ct <span class="op">=</span> roc_curve(y_test_binary, doc_ct_prob)</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_ct, tpr_ct, label<span class="op">=</span><span class="st">"Classification Tree"</span>)<span class="op">;</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>doc_svm_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_svm_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>fpr_svm, tpr_svm, thresholds_svm <span class="op">=</span> roc_curve(y_test_binary, doc_svm_prob)</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Clear the last plot (if any)</span></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.clf()</span></span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_svm, tpr_svm, label<span class="op">=</span><span class="st">"SVM Radial Basis"</span>)<span class="op">;</span></span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the ROC curve</span></span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>, label<span class="op">=</span><span class="st">"Random Classifier"</span>)<span class="op">;</span></span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)<span class="op">;</span></span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)<span class="op">;</span></span>
<span id="cb48-27"><a href="#cb48-27" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"ROC Curve"</span>)<span class="op">;</span></span>
<span id="cb48-28"><a href="#cb48-28" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span>
<span id="cb48-29"><a href="#cb48-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="Ex_ML_Scoring_files/figure-html/unnamed-chunk-31-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>We can then plot the results in the similar way to R:</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_tr <span class="op">=</span> doc_lr.predict_proba(X_train)[:,<span class="dv">1</span>]</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_tr_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>y_train_binary <span class="op">=</span> np.array([doc_lr_prob_tr_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_train])</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>fpr_lr_tr, tpr_lr_tr, thresholds_lr_tr <span class="op">=</span> roc_curve(y_train_binary, doc_lr_prob_tr)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>optimal_idx <span class="op">=</span> np.argmax(tpr_lr_tr <span class="op">-</span> fpr_lr_tr)</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>optimal_threshold <span class="op">=</span> thresholds_lr_tr[optimal_idx]</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal threshold: </span><span class="sc">{</span>optimal_threshold<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimal threshold: 0.188</code></pre>
</div>
</div>
<p>Finally, we print the confusion matrix again:</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>doc_lr_pred_opt <span class="op">=</span> np.where(doc_lr_prob <span class="op">&gt;</span> optimal_threshold, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_lr_pred_opt))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[578 250]
 [ 80 129]]</code></pre>
</div>
</div>
<p>The logistic regression produced with R was better.</p>
</div>
</div>
</div>
</section></section><section id="your-turn" class="level1"><h1>Your turn</h1>
<section id="classification" class="level2"><h2 class="anchored" data-anchor-id="classification">Classification</h2>
<p>Repeat the analysis on the German credit data. Put several models in competition. Tune them and try to optimize their threshold. Select the best one and analyze its performance.</p>
</section><section id="regression" class="level2"><h2 class="anchored" data-anchor-id="regression">Regression</h2>
<p>Repeat the analysis on the nursing cost data. Put several models in competition. Tune them and select the best one. Analyze its performance using a scatterplot.</p>


<!-- -->

</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/do-unil\.github\.io\/mlba");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" class="pagination-link" aria-label="Support Vector Machines">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Support Vector Machines</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="pagination-link" aria-label="Data Splitting">
        <span class="nav-page-text">Data Splitting</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb53" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Model scoring"</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r global_options, include = FALSE}</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">fig.align=</span><span class="st">"center"</span>, <span class="at">results =</span> <span class="st">'hold'</span>, <span class="at">fig.show =</span> <span class="st">'show'</span>, <span class="at">warning =</span> <span class="cn">FALSE</span>, <span class="at">message =</span> <span class="cn">FALSE</span>)</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="fu"># Regression task</span></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>The data set is the one used in the series on linear regressions.</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/real_estate_data.csv"</span>))</span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a>Then we split the data in a training and a test set (0.8/0.2). For this, we use the <span class="in">`createDataPartition`</span> function of the <span class="in">`caret`</span> package.</span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-27"><a href="#cb53-27" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb53-28"><a href="#cb53-28" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb53-29"><a href="#cb53-29" aria-hidden="true" tabindex="-1"></a>index_tr <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> real_estate_data<span class="sc">$</span>Price, <span class="at">p=</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb53-30"><a href="#cb53-30" aria-hidden="true" tabindex="-1"></a>df_tr <span class="ot">&lt;-</span> real_estate_data[index_tr,]</span>
<span id="cb53-31"><a href="#cb53-31" aria-hidden="true" tabindex="-1"></a>df_te <span class="ot">&lt;-</span> real_estate_data[<span class="sc">-</span>index_tr,]</span>
<span id="cb53-32"><a href="#cb53-32" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-33"><a href="#cb53-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-34"><a href="#cb53-34" aria-hidden="true" tabindex="-1"></a><span class="fu">## Models</span></span>
<span id="cb53-35"><a href="#cb53-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-36"><a href="#cb53-36" aria-hidden="true" tabindex="-1"></a>We will compare a linear regression, a regression tree and a 3-NN (KNN).</span>
<span id="cb53-37"><a href="#cb53-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-38"><a href="#cb53-38" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb53-39"><a href="#cb53-39" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb53-40"><a href="#cb53-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-43"><a href="#cb53-43" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-44"><a href="#cb53-44" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb53-45"><a href="#cb53-45" aria-hidden="true" tabindex="-1"></a>est_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span>HouseAge<span class="sc">+</span>Dist<span class="sc">+</span></span>
<span id="cb53-46"><a href="#cb53-46" aria-hidden="true" tabindex="-1"></a>               NumStores<span class="sc">+</span>Lat<span class="sc">+</span>Long, <span class="at">data=</span>df_tr)</span>
<span id="cb53-47"><a href="#cb53-47" aria-hidden="true" tabindex="-1"></a>est_rt <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span>HouseAge<span class="sc">+</span>Dist<span class="sc">+</span></span>
<span id="cb53-48"><a href="#cb53-48" aria-hidden="true" tabindex="-1"></a>                      NumStores<span class="sc">+</span>Lat<span class="sc">+</span>Long, <span class="at">data=</span>df_tr)</span>
<span id="cb53-49"><a href="#cb53-49" aria-hidden="true" tabindex="-1"></a>est_knn <span class="ot">&lt;-</span> <span class="fu">knnreg</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span>HouseAge<span class="sc">+</span>Dist<span class="sc">+</span></span>
<span id="cb53-50"><a href="#cb53-50" aria-hidden="true" tabindex="-1"></a>                      NumStores<span class="sc">+</span>Lat<span class="sc">+</span>Long, <span class="at">data=</span>df_tr, <span class="at">k =</span> <span class="dv">3</span>)</span>
<span id="cb53-51"><a href="#cb53-51" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-52"><a href="#cb53-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-53"><a href="#cb53-53" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb53-56"><a href="#cb53-56" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-57"><a href="#cb53-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the course python environment as usual with a r code chunks.</span></span>
<span id="cb53-58"><a href="#cb53-58" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb53-59"><a href="#cb53-59" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>)</span>
<span id="cb53-60"><a href="#cb53-60" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-61"><a href="#cb53-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-64"><a href="#cb53-64" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-65"><a href="#cb53-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the models: linear regression, regression tree, and KNN</span></span>
<span id="cb53-66"><a href="#cb53-66" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb53-67"><a href="#cb53-67" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb53-68"><a href="#cb53-68" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb53-69"><a href="#cb53-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-70"><a href="#cb53-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Define predictors and target variable</span></span>
<span id="cb53-71"><a href="#cb53-71" aria-hidden="true" tabindex="-1"></a>predictors <span class="op">=</span> [<span class="st">'TransDate'</span>, <span class="st">'HouseAge'</span>, <span class="st">'Dist'</span>, <span class="st">'NumStores'</span>, <span class="st">'Lat'</span>, <span class="st">'Long'</span>]</span>
<span id="cb53-72"><a href="#cb53-72" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">'Price'</span></span>
<span id="cb53-73"><a href="#cb53-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-74"><a href="#cb53-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit models</span></span>
<span id="cb53-75"><a href="#cb53-75" aria-hidden="true" tabindex="-1"></a>est_lm <span class="op">=</span> LinearRegression().fit(r.df_tr[predictors], r.df_tr[target])</span>
<span id="cb53-76"><a href="#cb53-76" aria-hidden="true" tabindex="-1"></a>est_rt <span class="op">=</span> DecisionTreeRegressor(random_state<span class="op">=</span><span class="dv">234</span>).fit(r.df_tr[predictors], r.df_tr[target])</span>
<span id="cb53-77"><a href="#cb53-77" aria-hidden="true" tabindex="-1"></a>est_knn <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">3</span>).fit(r.df_tr[predictors], r.df_tr[target])</span>
<span id="cb53-78"><a href="#cb53-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-79"><a href="#cb53-79" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-80"><a href="#cb53-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-81"><a href="#cb53-81" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb53-82"><a href="#cb53-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-83"><a href="#cb53-83" aria-hidden="true" tabindex="-1"></a><span class="fu">## R-squared</span></span>
<span id="cb53-84"><a href="#cb53-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-85"><a href="#cb53-85" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb53-86"><a href="#cb53-86" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb53-87"><a href="#cb53-87" aria-hidden="true" tabindex="-1"></a>We now compute the R2 for each model using the a defined function.</span>
<span id="cb53-88"><a href="#cb53-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-91"><a href="#cb53-91" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-92"><a href="#cb53-92" aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">=</span> <span class="cf">function</span>(y_predict, y_actual){</span>
<span id="cb53-93"><a href="#cb53-93" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cor</span>(y_actual,y_predict)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb53-94"><a href="#cb53-94" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb53-95"><a href="#cb53-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-96"><a href="#cb53-96" aria-hidden="true" tabindex="-1"></a><span class="fu">R2</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb53-97"><a href="#cb53-97" aria-hidden="true" tabindex="-1"></a><span class="fu">R2</span>(<span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb53-98"><a href="#cb53-98" aria-hidden="true" tabindex="-1"></a><span class="fu">R2</span>(<span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb53-99"><a href="#cb53-99" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-100"><a href="#cb53-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-101"><a href="#cb53-101" aria-hidden="true" tabindex="-1"></a>Just for the exercise, we can compute it by hand (square of the correlation)</span>
<span id="cb53-102"><a href="#cb53-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-105"><a href="#cb53-105" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-106"><a href="#cb53-106" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb53-107"><a href="#cb53-107" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-108"><a href="#cb53-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-109"><a href="#cb53-109" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb53-110"><a href="#cb53-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-113"><a href="#cb53-113" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-114"><a href="#cb53-114" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing as the R code</span></span>
<span id="cb53-115"><a href="#cb53-115" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb53-116"><a href="#cb53-116" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb53-117"><a href="#cb53-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-118"><a href="#cb53-118" aria-hidden="true" tabindex="-1"></a><span class="co"># Only to demonostrate which argument goes where (different from `caret::R2`)</span></span>
<span id="cb53-119"><a href="#cb53-119" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(y_true <span class="op">=</span> r.df_te[target], y_pred <span class="op">=</span> est_lm.predict(r.df_te[predictors])))</span>
<span id="cb53-120"><a href="#cb53-120" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb53-121"><a href="#cb53-121" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r2_score(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span>
<span id="cb53-122"><a href="#cb53-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-123"><a href="#cb53-123" aria-hidden="true" tabindex="-1"></a><span class="co"># Computing it by hand gives us the same result as R</span></span>
<span id="cb53-124"><a href="#cb53-124" aria-hidden="true" tabindex="-1"></a>np.corrcoef(est_lm.predict(r.df_te[predictors]), r.df_te[target])[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span></span>
<span id="cb53-125"><a href="#cb53-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-126"><a href="#cb53-126" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-127"><a href="#cb53-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-128"><a href="#cb53-128" aria-hidden="true" tabindex="-1"></a>To understand why the results are different in <span class="in">`R2`</span> from our defined function  in R vs. <span class="in">`sklearn.metrics.r2_score()`</span> in Python, see <span class="co">[</span><span class="ot">this post on stackoverflow</span><span class="co">](https://stats.stackexchange.com/questions/586821/what-is-the-interpretation-of-the-traditional-r2)</span>. If you want to recieve the same results in both, you can try computing the R2 not by correlation but by the formula $1 - \frac{SSR}{SST}$ where $SSR$ is the sum of squared residuals and $SST$ is the total sum of squares.</span>
<span id="cb53-129"><a href="#cb53-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-130"><a href="#cb53-130" aria-hidden="true" tabindex="-1"></a>Additionally, please note that the performance of the tree is highly dependent on the seed, so setting a different seed can lead to different results.</span>
<span id="cb53-131"><a href="#cb53-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-132"><a href="#cb53-132" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb53-133"><a href="#cb53-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-134"><a href="#cb53-134" aria-hidden="true" tabindex="-1"></a><span class="fu">## RMSE</span></span>
<span id="cb53-135"><a href="#cb53-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-136"><a href="#cb53-136" aria-hidden="true" tabindex="-1"></a>Now, we compute the RMSE.</span>
<span id="cb53-137"><a href="#cb53-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-138"><a href="#cb53-138" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb53-139"><a href="#cb53-139" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb53-140"><a href="#cb53-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-143"><a href="#cb53-143" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-144"><a href="#cb53-144" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb53-145"><a href="#cb53-145" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE</span>(<span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb53-146"><a href="#cb53-146" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE</span>(<span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb53-147"><a href="#cb53-147" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-148"><a href="#cb53-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-149"><a href="#cb53-149" aria-hidden="true" tabindex="-1"></a>The formula would be:</span>
<span id="cb53-150"><a href="#cb53-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-153"><a href="#cb53-153" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-154"><a href="#cb53-154" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>((<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te)<span class="sc">-</span>df_te<span class="sc">$</span>Price)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb53-155"><a href="#cb53-155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-156"><a href="#cb53-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-157"><a href="#cb53-157" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb53-158"><a href="#cb53-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-161"><a href="#cb53-161" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-162"><a href="#cb53-162" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, root_mean_squared_error</span>
<span id="cb53-163"><a href="#cb53-163" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb53-164"><a href="#cb53-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-165"><a href="#cb53-165" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_lm.predict(r.df_te[predictors])))</span>
<span id="cb53-166"><a href="#cb53-166" aria-hidden="true" tabindex="-1"></a><span class="co"># alternatively in the older version of `sklearn`, you had to run the code below</span></span>
<span id="cb53-167"><a href="#cb53-167" aria-hidden="true" tabindex="-1"></a><span class="co"># print(np.sqrt(mean_squared_error(r.df_te[target], est_lm.predict(r.df_te[predictors]))))</span></span>
<span id="cb53-168"><a href="#cb53-168" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb53-169"><a href="#cb53-169" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(root_mean_squared_error(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span>
<span id="cb53-170"><a href="#cb53-170" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-171"><a href="#cb53-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-172"><a href="#cb53-172" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb53-173"><a href="#cb53-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-174"><a href="#cb53-174" aria-hidden="true" tabindex="-1"></a><span class="fu">## MAE</span></span>
<span id="cb53-175"><a href="#cb53-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-176"><a href="#cb53-176" aria-hidden="true" tabindex="-1"></a>Now, we compute the MAE.</span>
<span id="cb53-177"><a href="#cb53-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-178"><a href="#cb53-178" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb53-179"><a href="#cb53-179" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb53-180"><a href="#cb53-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-183"><a href="#cb53-183" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-184"><a href="#cb53-184" aria-hidden="true" tabindex="-1"></a><span class="fu">MAE</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb53-185"><a href="#cb53-185" aria-hidden="true" tabindex="-1"></a><span class="fu">MAE</span>(<span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb53-186"><a href="#cb53-186" aria-hidden="true" tabindex="-1"></a><span class="fu">MAE</span>(<span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), df_te<span class="sc">$</span>Price)</span>
<span id="cb53-187"><a href="#cb53-187" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-188"><a href="#cb53-188" aria-hidden="true" tabindex="-1"></a>The formula would be:</span>
<span id="cb53-189"><a href="#cb53-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-192"><a href="#cb53-192" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-193"><a href="#cb53-193" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">abs</span>(<span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te)<span class="sc">-</span>df_te<span class="sc">$</span>Price))</span>
<span id="cb53-194"><a href="#cb53-194" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-195"><a href="#cb53-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-196"><a href="#cb53-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-197"><a href="#cb53-197" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb53-198"><a href="#cb53-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-201"><a href="#cb53-201" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-202"><a href="#cb53-202" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute MAE for each model</span></span>
<span id="cb53-203"><a href="#cb53-203" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error</span>
<span id="cb53-204"><a href="#cb53-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-205"><a href="#cb53-205" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_lm.predict(r.df_te[predictors])))</span>
<span id="cb53-206"><a href="#cb53-206" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_rt.predict(r.df_te[predictors])))</span>
<span id="cb53-207"><a href="#cb53-207" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(r.df_te[target], est_knn.predict(r.df_te[predictors])))</span>
<span id="cb53-208"><a href="#cb53-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-209"><a href="#cb53-209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-210"><a href="#cb53-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-211"><a href="#cb53-211" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb53-212"><a href="#cb53-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-213"><a href="#cb53-213" aria-hidden="true" tabindex="-1"></a><span class="fu">## Best model</span></span>
<span id="cb53-214"><a href="#cb53-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-215"><a href="#cb53-215" aria-hidden="true" tabindex="-1"></a>These three measures agree on the fact that the regression tree is the best model. To inspect further the predictions, we use scatterplots:</span>
<span id="cb53-216"><a href="#cb53-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-217"><a href="#cb53-217" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb53-218"><a href="#cb53-218" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb53-219"><a href="#cb53-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-222"><a href="#cb53-222" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-223"><a href="#cb53-223" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb53-224"><a href="#cb53-224" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(df_te<span class="sc">$</span>Price <span class="sc">~</span> <span class="fu">predict</span>(est_lm, <span class="at">newdata =</span> df_te), <span class="at">xlab=</span><span class="st">"Prediction"</span>, </span>
<span id="cb53-225"><a href="#cb53-225" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Observed prices"</span>, <span class="at">main=</span><span class="st">"Lin. Reg."</span>)</span>
<span id="cb53-226"><a href="#cb53-226" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb53-227"><a href="#cb53-227" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(df_te<span class="sc">$</span>Price <span class="sc">~</span> <span class="fu">predict</span>(est_rt, <span class="at">newdata =</span> df_te), <span class="at">xlab=</span><span class="st">"Prediction"</span>, </span>
<span id="cb53-228"><a href="#cb53-228" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Observed prices"</span>, <span class="at">main=</span><span class="st">"Lin. Reg."</span>)</span>
<span id="cb53-229"><a href="#cb53-229" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb53-230"><a href="#cb53-230" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(df_te<span class="sc">$</span>Price <span class="sc">~</span> <span class="fu">predict</span>(est_knn, <span class="at">newdata =</span> df_te), <span class="at">xlab=</span><span class="st">"Prediction"</span>, </span>
<span id="cb53-231"><a href="#cb53-231" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Observed prices"</span>, <span class="at">main=</span><span class="st">"Lin. Reg."</span>)</span>
<span id="cb53-232"><a href="#cb53-232" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb53-233"><a href="#cb53-233" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb53-234"><a href="#cb53-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-235"><a href="#cb53-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-236"><a href="#cb53-236" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb53-239"><a href="#cb53-239" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-240"><a href="#cb53-240" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize also in Python</span></span>
<span id="cb53-241"><a href="#cb53-241" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb53-242"><a href="#cb53-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-243"><a href="#cb53-243" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb53-244"><a href="#cb53-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-245"><a href="#cb53-245" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">221</span>)<span class="op">;</span></span>
<span id="cb53-246"><a href="#cb53-246" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_lm.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span>
<span id="cb53-247"><a href="#cb53-247" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)<span class="op">;</span></span>
<span id="cb53-248"><a href="#cb53-248" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)<span class="op">;</span></span>
<span id="cb53-249"><a href="#cb53-249" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Lin. Reg."</span>)<span class="op">;</span></span>
<span id="cb53-250"><a href="#cb53-250" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)<span class="op">;</span></span>
<span id="cb53-251"><a href="#cb53-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-252"><a href="#cb53-252" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">222</span>)<span class="op">;</span></span>
<span id="cb53-253"><a href="#cb53-253" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_rt.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span>
<span id="cb53-254"><a href="#cb53-254" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)<span class="op">;</span></span>
<span id="cb53-255"><a href="#cb53-255" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)<span class="op">;</span></span>
<span id="cb53-256"><a href="#cb53-256" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Regression Tree"</span>)<span class="op">;</span></span>
<span id="cb53-257"><a href="#cb53-257" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)<span class="op">;</span></span>
<span id="cb53-258"><a href="#cb53-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-259"><a href="#cb53-259" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">223</span>)<span class="op">;</span></span>
<span id="cb53-260"><a href="#cb53-260" aria-hidden="true" tabindex="-1"></a>plt.scatter(est_knn.predict(r.df_te[predictors]), r.df_te[target], alpha<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span>
<span id="cb53-261"><a href="#cb53-261" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)<span class="op">;</span></span>
<span id="cb53-262"><a href="#cb53-262" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Observed prices"</span>)<span class="op">;</span></span>
<span id="cb53-263"><a href="#cb53-263" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"KNN"</span>)<span class="op">;</span></span>
<span id="cb53-264"><a href="#cb53-264" aria-hidden="true" tabindex="-1"></a>plt.plot(r.df_te[target], r.df_te[target], color<span class="op">=</span><span class="st">'red'</span>)<span class="op">;</span></span>
<span id="cb53-265"><a href="#cb53-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-266"><a href="#cb53-266" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span></span>
<span id="cb53-267"><a href="#cb53-267" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb53-268"><a href="#cb53-268" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-269"><a href="#cb53-269" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb53-270"><a href="#cb53-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-271"><a href="#cb53-271" aria-hidden="true" tabindex="-1"></a>The scatterplots are in line with the conclusion that KNN is the best, even though it is not easy to declare from a plot. We can in addition see that the regression tree (RT) has made more error on the larger prices.</span>
<span id="cb53-272"><a href="#cb53-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-273"><a href="#cb53-273" aria-hidden="true" tabindex="-1"></a><span class="fu"># Classification task</span></span>
<span id="cb53-274"><a href="#cb53-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-275"><a href="#cb53-275" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data</span></span>
<span id="cb53-276"><a href="#cb53-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-277"><a href="#cb53-277" aria-hidden="true" tabindex="-1"></a>The data set is the visit data (already used in previous exercises). For simplicity, we turn the outcome (<span class="in">`visits`</span>) into factor. Like before, that are also split into a training and a test set.</span>
<span id="cb53-278"><a href="#cb53-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-281"><a href="#cb53-281" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-282"><a href="#cb53-282" aria-hidden="true" tabindex="-1"></a>DocVis <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/DocVis.csv"</span>))</span>
<span id="cb53-283"><a href="#cb53-283" aria-hidden="true" tabindex="-1"></a>DocVis<span class="sc">$</span>visits <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(DocVis<span class="sc">$</span>visits)</span>
<span id="cb53-284"><a href="#cb53-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-285"><a href="#cb53-285" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb53-286"><a href="#cb53-286" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">346</span>)</span>
<span id="cb53-287"><a href="#cb53-287" aria-hidden="true" tabindex="-1"></a>index_tr <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> DocVis<span class="sc">$</span>visits, <span class="at">p=</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb53-288"><a href="#cb53-288" aria-hidden="true" tabindex="-1"></a>df_tr <span class="ot">&lt;-</span> DocVis[index_tr,]</span>
<span id="cb53-289"><a href="#cb53-289" aria-hidden="true" tabindex="-1"></a>df_te <span class="ot">&lt;-</span> DocVis[<span class="sc">-</span>index_tr,]</span>
<span id="cb53-290"><a href="#cb53-290" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-291"><a href="#cb53-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-292"><a href="#cb53-292" aria-hidden="true" tabindex="-1"></a><span class="fu">## Models</span></span>
<span id="cb53-293"><a href="#cb53-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-294"><a href="#cb53-294" aria-hidden="true" tabindex="-1"></a>We will compare a logistic regression, a classification tree (pruned) and a SVM with radial basis (cost and gamma tuned).</span>
<span id="cb53-295"><a href="#cb53-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-296"><a href="#cb53-296" aria-hidden="true" tabindex="-1"></a>:::panel-tabset</span>
<span id="cb53-297"><a href="#cb53-297" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb53-298"><a href="#cb53-298" aria-hidden="true" tabindex="-1"></a>Note that the *code for tuning the SVM* is provided below in comments because of the time it takes to run. The final parameters have been selected accordingly. Also, the SVM fit includes the argument <span class="in">`probability=TRUE`</span> to allow the calculations of predicted probabilities later.</span>
<span id="cb53-299"><a href="#cb53-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-302"><a href="#cb53-302" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-303"><a href="#cb53-303" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb53-304"><a href="#cb53-304" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(adabag)</span>
<span id="cb53-305"><a href="#cb53-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-306"><a href="#cb53-306" aria-hidden="true" tabindex="-1"></a><span class="do">## Logistic regression</span></span>
<span id="cb53-307"><a href="#cb53-307" aria-hidden="true" tabindex="-1"></a>Doc_lr <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr, <span class="at">family=</span><span class="st">"binomial"</span>)</span>
<span id="cb53-308"><a href="#cb53-308" aria-hidden="true" tabindex="-1"></a>Doc_lr <span class="ot">&lt;-</span> <span class="fu">step</span>(Doc_lr)</span>
<span id="cb53-309"><a href="#cb53-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-310"><a href="#cb53-310" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification tree </span></span>
<span id="cb53-311"><a href="#cb53-311" aria-hidden="true" tabindex="-1"></a>Doc_ct <span class="ot">&lt;-</span> <span class="fu">autoprune</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr)</span>
<span id="cb53-312"><a href="#cb53-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-313"><a href="#cb53-313" aria-hidden="true" tabindex="-1"></a><span class="do">## SVM radial basis</span></span>
<span id="cb53-314"><a href="#cb53-314" aria-hidden="true" tabindex="-1"></a><span class="co"># grid_radial &lt;- expand.grid(sigma = c(0.0001, 0.001, 0.01, 0.1),</span></span>
<span id="cb53-315"><a href="#cb53-315" aria-hidden="true" tabindex="-1"></a><span class="co">#                           C = c(0.1, 1, 10, 100, 1000))</span></span>
<span id="cb53-316"><a href="#cb53-316" aria-hidden="true" tabindex="-1"></a><span class="co"># trctrl &lt;- trainControl(method = "cv", number=10)</span></span>
<span id="cb53-317"><a href="#cb53-317" aria-hidden="true" tabindex="-1"></a><span class="co"># set.seed(143)</span></span>
<span id="cb53-318"><a href="#cb53-318" aria-hidden="true" tabindex="-1"></a><span class="co"># Doc_svm &lt;- train(visits ~., data = df_tr, method = "svmRadial",</span></span>
<span id="cb53-319"><a href="#cb53-319" aria-hidden="true" tabindex="-1"></a><span class="co">#                          trControl=trctrl,</span></span>
<span id="cb53-320"><a href="#cb53-320" aria-hidden="true" tabindex="-1"></a><span class="co">#                          tuneGrid = grid_radial)</span></span>
<span id="cb53-321"><a href="#cb53-321" aria-hidden="true" tabindex="-1"></a>Doc_svm <span class="ot">&lt;-</span> <span class="fu">svm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr, <span class="at">gamma=</span><span class="fl">0.001</span>, <span class="at">cost=</span><span class="dv">1000</span>, <span class="at">probability=</span><span class="cn">TRUE</span>)</span>
<span id="cb53-322"><a href="#cb53-322" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-323"><a href="#cb53-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-324"><a href="#cb53-324" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb53-327"><a href="#cb53-327" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-328"><a href="#cb53-328" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb53-329"><a href="#cb53-329" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb53-330"><a href="#cb53-330" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb53-331"><a href="#cb53-331" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb53-332"><a href="#cb53-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-333"><a href="#cb53-333" aria-hidden="true" tabindex="-1"></a><span class="co"># We first put the data in a nice format by one-hot encoding the categorical variables</span></span>
<span id="cb53-334"><a href="#cb53-334" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> pd.get_dummies(r.df_tr.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb53-335"><a href="#cb53-335" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> r.df_tr[<span class="st">'visits'</span>]</span>
<span id="cb53-336"><a href="#cb53-336" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> pd.get_dummies(r.df_te.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb53-337"><a href="#cb53-337" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> r.df_te[<span class="st">'visits'</span>]</span>
<span id="cb53-338"><a href="#cb53-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-339"><a href="#cb53-339" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb53-340"><a href="#cb53-340" aria-hidden="true" tabindex="-1"></a>doc_lr <span class="op">=</span> LogisticRegression()</span>
<span id="cb53-341"><a href="#cb53-341" aria-hidden="true" tabindex="-1"></a>doc_lr.fit(X_train, y_train)<span class="op">;</span></span>
<span id="cb53-342"><a href="#cb53-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-343"><a href="#cb53-343" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb53-344"><a href="#cb53-344" aria-hidden="true" tabindex="-1"></a>doc_ct <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb53-345"><a href="#cb53-345" aria-hidden="true" tabindex="-1"></a>doc_ct.fit(X_train, y_train)<span class="op">;</span></span>
<span id="cb53-346"><a href="#cb53-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-347"><a href="#cb53-347" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb53-348"><a href="#cb53-348" aria-hidden="true" tabindex="-1"></a>doc_svm <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span><span class="fl">0.001</span>, C<span class="op">=</span><span class="dv">1000</span>, probability<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb53-349"><a href="#cb53-349" aria-hidden="true" tabindex="-1"></a>doc_svm.fit(X_train, y_train)<span class="op">;</span></span>
<span id="cb53-350"><a href="#cb53-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-351"><a href="#cb53-351" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-352"><a href="#cb53-352" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb53-353"><a href="#cb53-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-354"><a href="#cb53-354" aria-hidden="true" tabindex="-1"></a><span class="fu">## Predictions</span></span>
<span id="cb53-355"><a href="#cb53-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-356"><a href="#cb53-356" aria-hidden="true" tabindex="-1"></a>We now compute the predicted probabilities and the predictions of all the models.</span>
<span id="cb53-357"><a href="#cb53-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-358"><a href="#cb53-358" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb53-359"><a href="#cb53-359" aria-hidden="true" tabindex="-1"></a><span class="fu">## R</span></span>
<span id="cb53-360"><a href="#cb53-360" aria-hidden="true" tabindex="-1"></a>Note that, for SVM, we need to extract the *attribute* "probabilities" from the predicted object. This can be done with the <span class="in">`attr`</span> function.</span>
<span id="cb53-361"><a href="#cb53-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-364"><a href="#cb53-364" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-365"><a href="#cb53-365" aria-hidden="true" tabindex="-1"></a><span class="do">## Logistic regression</span></span>
<span id="cb53-366"><a href="#cb53-366" aria-hidden="true" tabindex="-1"></a>Doc_lr_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb53-367"><a href="#cb53-367" aria-hidden="true" tabindex="-1"></a>Doc_lr_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_lr_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb53-368"><a href="#cb53-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-369"><a href="#cb53-369" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification tree </span></span>
<span id="cb53-370"><a href="#cb53-370" aria-hidden="true" tabindex="-1"></a>Doc_ct_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_ct, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"prob"</span>)</span>
<span id="cb53-371"><a href="#cb53-371" aria-hidden="true" tabindex="-1"></a>Doc_ct_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_ct, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"class"</span>)</span>
<span id="cb53-372"><a href="#cb53-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-373"><a href="#cb53-373" aria-hidden="true" tabindex="-1"></a><span class="do">## SVM radial basis</span></span>
<span id="cb53-374"><a href="#cb53-374" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb53-375"><a href="#cb53-375" aria-hidden="true" tabindex="-1"></a>Doc_svm_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_svm, <span class="at">newdata=</span>df_te, <span class="at">probability=</span><span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> <span class="fu">attr</span>(<span class="st">"probabilities"</span>)</span>
<span id="cb53-376"><a href="#cb53-376" aria-hidden="true" tabindex="-1"></a>Doc_svm_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_svm, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"class"</span>)</span>
<span id="cb53-377"><a href="#cb53-377" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-378"><a href="#cb53-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-379"><a href="#cb53-379" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python</span></span>
<span id="cb53-380"><a href="#cb53-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-383"><a href="#cb53-383" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-384"><a href="#cb53-384" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb53-385"><a href="#cb53-385" aria-hidden="true" tabindex="-1"></a><span class="co">## the second column represents the `no` values, to make sure of that, you can run `doc_lr.classes_`</span></span>
<span id="cb53-386"><a href="#cb53-386" aria-hidden="true" tabindex="-1"></a>doc_lr_prob <span class="op">=</span> doc_lr.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb53-387"><a href="#cb53-387" aria-hidden="true" tabindex="-1"></a>doc_lr_pred <span class="op">=</span> np.where(doc_lr_prob<span class="op">&gt;</span><span class="fl">0.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb53-388"><a href="#cb53-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-389"><a href="#cb53-389" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb53-390"><a href="#cb53-390" aria-hidden="true" tabindex="-1"></a>doc_ct_prob <span class="op">=</span> doc_ct.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb53-391"><a href="#cb53-391" aria-hidden="true" tabindex="-1"></a>doc_ct_pred <span class="op">=</span> doc_ct.predict(X_test)</span>
<span id="cb53-392"><a href="#cb53-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-393"><a href="#cb53-393" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb53-394"><a href="#cb53-394" aria-hidden="true" tabindex="-1"></a>doc_svm_prob <span class="op">=</span> doc_svm.predict_proba(X_test)[:,<span class="dv">1</span>]</span>
<span id="cb53-395"><a href="#cb53-395" aria-hidden="true" tabindex="-1"></a>doc_svm_pred <span class="op">=</span> doc_svm.predict(X_test)</span>
<span id="cb53-396"><a href="#cb53-396" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-397"><a href="#cb53-397" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb53-398"><a href="#cb53-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-399"><a href="#cb53-399" aria-hidden="true" tabindex="-1"></a><span class="fu">## Confusion matrices &amp; prediction-based measures</span></span>
<span id="cb53-400"><a href="#cb53-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-401"><a href="#cb53-401" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb53-402"><a href="#cb53-402" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb53-403"><a href="#cb53-403" aria-hidden="true" tabindex="-1"></a>The <span class="in">`confusionMatrix`</span> function provides all the accuracy measures that we want.</span>
<span id="cb53-404"><a href="#cb53-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-407"><a href="#cb53-407" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-408"><a href="#cb53-408" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_lr_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb53-409"><a href="#cb53-409" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_ct_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb53-410"><a href="#cb53-410" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_svm_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb53-411"><a href="#cb53-411" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-412"><a href="#cb53-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-413"><a href="#cb53-413" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb53-416"><a href="#cb53-416" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-417"><a href="#cb53-417" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score, balanced_accuracy_score, cohen_kappa_score</span>
<span id="cb53-418"><a href="#cb53-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-419"><a href="#cb53-419" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb53-420"><a href="#cb53-420" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_lr_pred))</span>
<span id="cb53-421"><a href="#cb53-421" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-422"><a href="#cb53-422" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-423"><a href="#cb53-423" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_lr_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-424"><a href="#cb53-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-425"><a href="#cb53-425" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb53-426"><a href="#cb53-426" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_ct_pred))</span>
<span id="cb53-427"><a href="#cb53-427" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-428"><a href="#cb53-428" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-429"><a href="#cb53-429" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_ct_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-430"><a href="#cb53-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-431"><a href="#cb53-431" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb53-432"><a href="#cb53-432" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_svm_pred))</span>
<span id="cb53-433"><a href="#cb53-433" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-434"><a href="#cb53-434" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Kappa: </span><span class="sc">{</span>cohen_kappa_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-435"><a href="#cb53-435" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced accuracy: </span><span class="sc">{</span>balanced_accuracy_score(y_test, doc_svm_pred)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-436"><a href="#cb53-436" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-437"><a href="#cb53-437" aria-hidden="true" tabindex="-1"></a>Different results for the tree and CSV due to randomness, but even with that, SVM remains the best model in terms of accuracy.</span>
<span id="cb53-438"><a href="#cb53-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-439"><a href="#cb53-439" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb53-440"><a href="#cb53-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-441"><a href="#cb53-441" aria-hidden="true" tabindex="-1"></a>The conclusion may be different from one measure to another</span>
<span id="cb53-442"><a href="#cb53-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-443"><a href="#cb53-443" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Accuracy: the SVM reaches the highest accuracy</span>
<span id="cb53-444"><a href="#cb53-444" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Kappa: the CT is the highest.</span>
<span id="cb53-445"><a href="#cb53-445" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Balanced accuracy: the CT is the highest.</span>
<span id="cb53-446"><a href="#cb53-446" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>etc.</span>
<span id="cb53-447"><a href="#cb53-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-448"><a href="#cb53-448" aria-hidden="true" tabindex="-1"></a>Looking at the confusion matrix, we see that the data is highly unbalanced (many more "No" than "Yes"). Therefore, measures like balanced accuracy and kappa are interesting because they take this characteristics into account. This shows that the CT is probably better than the SVM because it reaches a better balance between predicting "Yes" and "No".</span>
<span id="cb53-449"><a href="#cb53-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-450"><a href="#cb53-450" aria-hidden="true" tabindex="-1"></a>By looking at the sensitivity and specificity (<span class="co">[</span><span class="ot">!! here the positive class is "No"</span><span class="co">]</span>{.underline}), we see that the best model to recover the "No" is the logistic regression (largest sensitivity) and the best model to recover the "Yes" is the classification tree (largest specificity).</span>
<span id="cb53-451"><a href="#cb53-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-452"><a href="#cb53-452" aria-hidden="true" tabindex="-1"></a><span class="fu">## Probability-based measures</span></span>
<span id="cb53-453"><a href="#cb53-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-454"><a href="#cb53-454" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb53-455"><a href="#cb53-455" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb53-456"><a href="#cb53-456" aria-hidden="true" tabindex="-1"></a>To compute the AUC (area under the ROC curve) we can use the <span class="in">`caret::twoClassSummary`</span> function. The use of this function can be tricky. Its argument should be a data frame with columns (names are fixed):</span>
<span id="cb53-457"><a href="#cb53-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-458"><a href="#cb53-458" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>"obs": the observed classes</span>
<span id="cb53-459"><a href="#cb53-459" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>"pred": the predicted classes</span>
<span id="cb53-460"><a href="#cb53-460" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>two columns with names being the levels of the classes, here "Yes" and "No", containing the predicted probabilities.</span>
<span id="cb53-461"><a href="#cb53-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-464"><a href="#cb53-464" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-465"><a href="#cb53-465" aria-hidden="true" tabindex="-1"></a>df_pred_lr <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_te<span class="sc">$</span>visits,</span>
<span id="cb53-466"><a href="#cb53-466" aria-hidden="true" tabindex="-1"></a>                         <span class="at">Yes=</span>Doc_lr_prob,</span>
<span id="cb53-467"><a href="#cb53-467" aria-hidden="true" tabindex="-1"></a>                         <span class="at">No=</span><span class="dv">1</span><span class="sc">-</span>Doc_lr_prob,</span>
<span id="cb53-468"><a href="#cb53-468" aria-hidden="true" tabindex="-1"></a>                         <span class="at">pred=</span><span class="fu">as.factor</span>(Doc_lr_pred))</span>
<span id="cb53-469"><a href="#cb53-469" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_pred_lr)</span>
<span id="cb53-470"><a href="#cb53-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-471"><a href="#cb53-471" aria-hidden="true" tabindex="-1"></a>df_pred_ct <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_te<span class="sc">$</span>visits,</span>
<span id="cb53-472"><a href="#cb53-472" aria-hidden="true" tabindex="-1"></a>                         Doc_ct_prob,</span>
<span id="cb53-473"><a href="#cb53-473" aria-hidden="true" tabindex="-1"></a>                         <span class="at">pred=</span><span class="fu">as.factor</span>(Doc_ct_pred))</span>
<span id="cb53-474"><a href="#cb53-474" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_pred_ct)</span>
<span id="cb53-475"><a href="#cb53-475" aria-hidden="true" tabindex="-1"></a>df_pred_svm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_te<span class="sc">$</span>visits,</span>
<span id="cb53-476"><a href="#cb53-476" aria-hidden="true" tabindex="-1"></a>                          Doc_svm_prob,</span>
<span id="cb53-477"><a href="#cb53-477" aria-hidden="true" tabindex="-1"></a>                          <span class="at">pred=</span><span class="fu">as.factor</span>(Doc_svm_pred))</span>
<span id="cb53-478"><a href="#cb53-478" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df_pred_svm)</span>
<span id="cb53-479"><a href="#cb53-479" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-480"><a href="#cb53-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-481"><a href="#cb53-481" aria-hidden="true" tabindex="-1"></a>Then we pass these objects to the function, and levels of the classes to be predicted (for the function to be able to recover them in the data frame). The function compute the AUC by default (under the name ROC_.. not very wise) as well as sensitivity and specificity (that we already have).</span>
<span id="cb53-482"><a href="#cb53-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-485"><a href="#cb53-485" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-486"><a href="#cb53-486" aria-hidden="true" tabindex="-1"></a><span class="fu">twoClassSummary</span>(df_pred_lr, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb53-487"><a href="#cb53-487" aria-hidden="true" tabindex="-1"></a><span class="fu">twoClassSummary</span>(df_pred_ct, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb53-488"><a href="#cb53-488" aria-hidden="true" tabindex="-1"></a><span class="fu">twoClassSummary</span>(df_pred_svm, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb53-489"><a href="#cb53-489" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-490"><a href="#cb53-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-491"><a href="#cb53-491" aria-hidden="true" tabindex="-1"></a>This brings us another view: the logistic regression has the highest AUC. This shows that varying the prediction threshold provides a good potential of improving the specificity and the sensitivity (in fine, the balanced accuracy).</span>
<span id="cb53-492"><a href="#cb53-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-493"><a href="#cb53-493" aria-hidden="true" tabindex="-1"></a>Now we compute the entropy using the <span class="in">`mnLogLoss`</span> function (entropy is also called *log-loss*).</span>
<span id="cb53-494"><a href="#cb53-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-497"><a href="#cb53-497" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-498"><a href="#cb53-498" aria-hidden="true" tabindex="-1"></a><span class="fu">mnLogLoss</span>(df_pred_lr, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb53-499"><a href="#cb53-499" aria-hidden="true" tabindex="-1"></a><span class="fu">mnLogLoss</span>(df_pred_ct, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb53-500"><a href="#cb53-500" aria-hidden="true" tabindex="-1"></a><span class="fu">mnLogLoss</span>(df_pred_svm, <span class="at">lev =</span> <span class="fu">levels</span>(df_pred_lr<span class="sc">$</span>obs))</span>
<span id="cb53-501"><a href="#cb53-501" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-502"><a href="#cb53-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-503"><a href="#cb53-503" aria-hidden="true" tabindex="-1"></a>Here again, the entropy selects the logistic regression as the best model, though close to classification tree and SVM.</span>
<span id="cb53-504"><a href="#cb53-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-505"><a href="#cb53-505" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb53-506"><a href="#cb53-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-507"><a href="#cb53-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-510"><a href="#cb53-510" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-511"><a href="#cb53-511" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score, roc_curve</span>
<span id="cb53-512"><a href="#cb53-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-513"><a href="#cb53-513" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb53-514"><a href="#cb53-514" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_lr_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-515"><a href="#cb53-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-516"><a href="#cb53-516" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb53-517"><a href="#cb53-517" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_ct_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-518"><a href="#cb53-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-519"><a href="#cb53-519" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb53-520"><a href="#cb53-520" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AUC: </span><span class="sc">{</span>roc_auc_score(y_test, doc_svm_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-521"><a href="#cb53-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-522"><a href="#cb53-522" aria-hidden="true" tabindex="-1"></a><span class="co"># Now we compute the entropy using the `log_loss` function (entropy is also called *log-loss*).</span></span>
<span id="cb53-523"><a href="#cb53-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-524"><a href="#cb53-524" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> log_loss</span>
<span id="cb53-525"><a href="#cb53-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-526"><a href="#cb53-526" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb53-527"><a href="#cb53-527" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_lr_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-528"><a href="#cb53-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-529"><a href="#cb53-529" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb53-530"><a href="#cb53-530" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_ct_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-531"><a href="#cb53-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-532"><a href="#cb53-532" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb53-533"><a href="#cb53-533" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Log-loss: </span><span class="sc">{</span>log_loss(y_test, doc_svm_prob)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-534"><a href="#cb53-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-535"><a href="#cb53-535" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-536"><a href="#cb53-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-537"><a href="#cb53-537" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb53-538"><a href="#cb53-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-539"><a href="#cb53-539" aria-hidden="true" tabindex="-1"></a><span class="fu">## ROC curve &amp; prob threshold tuning</span></span>
<span id="cb53-540"><a href="#cb53-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-541"><a href="#cb53-541" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb53-542"><a href="#cb53-542" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb53-543"><a href="#cb53-543" aria-hidden="true" tabindex="-1"></a>To go deeper in the analysis, we now produce the ROC curve of each model using the <span class="in">`roc`</span> function of the <span class="in">`proc`</span> package.</span>
<span id="cb53-544"><a href="#cb53-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-547"><a href="#cb53-547" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-548"><a href="#cb53-548" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb53-549"><a href="#cb53-549" aria-hidden="true" tabindex="-1"></a>ROC_lr <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_lr)</span>
<span id="cb53-550"><a href="#cb53-550" aria-hidden="true" tabindex="-1"></a>ROC_ct <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_ct)</span>
<span id="cb53-551"><a href="#cb53-551" aria-hidden="true" tabindex="-1"></a>ROC_svm <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_svm)</span>
<span id="cb53-552"><a href="#cb53-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-553"><a href="#cb53-553" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_lr, <span class="at">print.thres=</span><span class="st">"best"</span>)</span>
<span id="cb53-554"><a href="#cb53-554" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_ct, <span class="at">print.thres=</span><span class="st">"best"</span>, <span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb53-555"><a href="#cb53-555" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_svm, <span class="at">print.thres=</span><span class="st">"best"</span>, <span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb53-556"><a href="#cb53-556" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-557"><a href="#cb53-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-558"><a href="#cb53-558" aria-hidden="true" tabindex="-1"></a>The plotting function provides an "optimal" threshold that reaches the best trade-off between sensitivity and specificity (according to some criterion). We see that there is room to improve this trade-off.</span>
<span id="cb53-559"><a href="#cb53-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-560"><a href="#cb53-560" aria-hidden="true" tabindex="-1"></a>Now, to tune this threshold, we need to do it *on the training set* to avoid overfitting. To do this, we just repeat the previous calculations (predictions) on the training set. To simplify, we only do this on the logistic regression (note that you can try on the other models; you may find that logistic regression is the best one).</span>
<span id="cb53-561"><a href="#cb53-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-564"><a href="#cb53-564" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-565"><a href="#cb53-565" aria-hidden="true" tabindex="-1"></a>Doc_lr_prob_tr <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr, <span class="at">newdata=</span>df_tr, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb53-566"><a href="#cb53-566" aria-hidden="true" tabindex="-1"></a>df_pred_lr_tr <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">obs=</span>df_tr<span class="sc">$</span>visits,</span>
<span id="cb53-567"><a href="#cb53-567" aria-hidden="true" tabindex="-1"></a>                            <span class="at">Yes=</span>Doc_lr_prob_tr)</span>
<span id="cb53-568"><a href="#cb53-568" aria-hidden="true" tabindex="-1"></a>ROC_lr_tr <span class="ot">&lt;-</span> <span class="fu">roc</span>(obs <span class="sc">~</span> Yes, <span class="at">data=</span>df_pred_lr_tr)</span>
<span id="cb53-569"><a href="#cb53-569" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ROC_lr_tr, <span class="at">print.thres=</span><span class="st">"best"</span>)</span>
<span id="cb53-570"><a href="#cb53-570" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-571"><a href="#cb53-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-572"><a href="#cb53-572" aria-hidden="true" tabindex="-1"></a>The best threshold is 0.193. Now let us compute the confusion table with this threshold.</span>
<span id="cb53-573"><a href="#cb53-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-576"><a href="#cb53-576" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-577"><a href="#cb53-577" aria-hidden="true" tabindex="-1"></a>Doc_lr_pred_opt <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_lr_prob<span class="sc">&gt;</span><span class="fl">0.193</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb53-578"><a href="#cb53-578" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_lr_pred_opt), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb53-579"><a href="#cb53-579" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-580"><a href="#cb53-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-581"><a href="#cb53-581" aria-hidden="true" tabindex="-1"></a>We now have a model with an accuracy of circa $70\%$ but with a balanced accuracy of $67\%$. Far from perfect, this is still an interesting improvement compare to the CT $62\%$. The specificity and sensitivity are now respectively $62\%$ and $72\%$. The specificity in particular made a huge improvement (from around $29\%$ at best - by CT - to $62\%$ - by log. reg).</span>
<span id="cb53-582"><a href="#cb53-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-583"><a href="#cb53-583" aria-hidden="true" tabindex="-1"></a>If the aim is to predict both "Yes" and "No", this last model (log. reg. with tuned threshold) is the best one to use.</span>
<span id="cb53-584"><a href="#cb53-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-585"><a href="#cb53-585" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb53-586"><a href="#cb53-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-589"><a href="#cb53-589" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-590"><a href="#cb53-590" aria-hidden="true" tabindex="-1"></a><span class="co">## Logistic regression</span></span>
<span id="cb53-591"><a href="#cb53-591" aria-hidden="true" tabindex="-1"></a><span class="co">## We need to turn back our results into binary values to be plotted</span></span>
<span id="cb53-592"><a href="#cb53-592" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb53-593"><a href="#cb53-593" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_lr_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb53-594"><a href="#cb53-594" aria-hidden="true" tabindex="-1"></a>fpr_lr, tpr_lr, thresholds_lr <span class="op">=</span> roc_curve(y_test_binary, doc_lr_prob)</span>
<span id="cb53-595"><a href="#cb53-595" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_lr, tpr_lr, label<span class="op">=</span><span class="st">"Logistic Regression"</span>)<span class="op">;</span></span>
<span id="cb53-596"><a href="#cb53-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-597"><a href="#cb53-597" aria-hidden="true" tabindex="-1"></a><span class="co">## Classification tree</span></span>
<span id="cb53-598"><a href="#cb53-598" aria-hidden="true" tabindex="-1"></a>doc_ct_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb53-599"><a href="#cb53-599" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_ct_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb53-600"><a href="#cb53-600" aria-hidden="true" tabindex="-1"></a>fpr_ct, tpr_ct, thresholds_ct <span class="op">=</span> roc_curve(y_test_binary, doc_ct_prob)</span>
<span id="cb53-601"><a href="#cb53-601" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_ct, tpr_ct, label<span class="op">=</span><span class="st">"Classification Tree"</span>)<span class="op">;</span></span>
<span id="cb53-602"><a href="#cb53-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-603"><a href="#cb53-603" aria-hidden="true" tabindex="-1"></a><span class="co">## SVM radial basis</span></span>
<span id="cb53-604"><a href="#cb53-604" aria-hidden="true" tabindex="-1"></a>doc_svm_prob_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb53-605"><a href="#cb53-605" aria-hidden="true" tabindex="-1"></a>y_test_binary <span class="op">=</span> np.array([doc_svm_prob_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_test])</span>
<span id="cb53-606"><a href="#cb53-606" aria-hidden="true" tabindex="-1"></a>fpr_svm, tpr_svm, thresholds_svm <span class="op">=</span> roc_curve(y_test_binary, doc_svm_prob)</span>
<span id="cb53-607"><a href="#cb53-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-608"><a href="#cb53-608" aria-hidden="true" tabindex="-1"></a><span class="co"># Clear the last plot (if any)</span></span>
<span id="cb53-609"><a href="#cb53-609" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.clf()</span></span>
<span id="cb53-610"><a href="#cb53-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-611"><a href="#cb53-611" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr_svm, tpr_svm, label<span class="op">=</span><span class="st">"SVM Radial Basis"</span>)<span class="op">;</span></span>
<span id="cb53-612"><a href="#cb53-612" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the ROC curve</span></span>
<span id="cb53-613"><a href="#cb53-613" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>, label<span class="op">=</span><span class="st">"Random Classifier"</span>)<span class="op">;</span></span>
<span id="cb53-614"><a href="#cb53-614" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)<span class="op">;</span></span>
<span id="cb53-615"><a href="#cb53-615" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)<span class="op">;</span></span>
<span id="cb53-616"><a href="#cb53-616" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"ROC Curve"</span>)<span class="op">;</span></span>
<span id="cb53-617"><a href="#cb53-617" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span>
<span id="cb53-618"><a href="#cb53-618" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb53-619"><a href="#cb53-619" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-620"><a href="#cb53-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-621"><a href="#cb53-621" aria-hidden="true" tabindex="-1"></a>We can then plot the results in the similar way to R:</span>
<span id="cb53-622"><a href="#cb53-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-625"><a href="#cb53-625" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-626"><a href="#cb53-626" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_tr <span class="op">=</span> doc_lr.predict_proba(X_train)[:,<span class="dv">1</span>]</span>
<span id="cb53-627"><a href="#cb53-627" aria-hidden="true" tabindex="-1"></a>doc_lr_prob_tr_dict <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="dv">1</span>, <span class="st">'No'</span>: <span class="dv">0</span>}</span>
<span id="cb53-628"><a href="#cb53-628" aria-hidden="true" tabindex="-1"></a>y_train_binary <span class="op">=</span> np.array([doc_lr_prob_tr_dict[x] <span class="cf">for</span> x <span class="kw">in</span> y_train])</span>
<span id="cb53-629"><a href="#cb53-629" aria-hidden="true" tabindex="-1"></a>fpr_lr_tr, tpr_lr_tr, thresholds_lr_tr <span class="op">=</span> roc_curve(y_train_binary, doc_lr_prob_tr)</span>
<span id="cb53-630"><a href="#cb53-630" aria-hidden="true" tabindex="-1"></a>optimal_idx <span class="op">=</span> np.argmax(tpr_lr_tr <span class="op">-</span> fpr_lr_tr)</span>
<span id="cb53-631"><a href="#cb53-631" aria-hidden="true" tabindex="-1"></a>optimal_threshold <span class="op">=</span> thresholds_lr_tr[optimal_idx]</span>
<span id="cb53-632"><a href="#cb53-632" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal threshold: </span><span class="sc">{</span>optimal_threshold<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb53-633"><a href="#cb53-633" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-634"><a href="#cb53-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-635"><a href="#cb53-635" aria-hidden="true" tabindex="-1"></a>Finally, we print the confusion matrix again:</span>
<span id="cb53-636"><a href="#cb53-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-639"><a href="#cb53-639" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb53-640"><a href="#cb53-640" aria-hidden="true" tabindex="-1"></a>doc_lr_pred_opt <span class="op">=</span> np.where(doc_lr_prob <span class="op">&gt;</span> optimal_threshold, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb53-641"><a href="#cb53-641" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y_test, doc_lr_pred_opt))</span>
<span id="cb53-642"><a href="#cb53-642" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-643"><a href="#cb53-643" aria-hidden="true" tabindex="-1"></a>The logistic regression produced with R was better.</span>
<span id="cb53-644"><a href="#cb53-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-645"><a href="#cb53-645" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb53-646"><a href="#cb53-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-647"><a href="#cb53-647" aria-hidden="true" tabindex="-1"></a><span class="fu"># Your turn</span></span>
<span id="cb53-648"><a href="#cb53-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-649"><a href="#cb53-649" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classification</span></span>
<span id="cb53-650"><a href="#cb53-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-651"><a href="#cb53-651" aria-hidden="true" tabindex="-1"></a>Repeat the analysis on the German credit data. Put several models in competition. Tune them and try to optimize their threshold. Select the best one and analyze its performance.</span>
<span id="cb53-652"><a href="#cb53-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-653"><a href="#cb53-653" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression</span></span>
<span id="cb53-654"><a href="#cb53-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-655"><a href="#cb53-655" aria-hidden="true" tabindex="-1"></a>Repeat the analysis on the nursing cost data. Put several models in competition. Tune them and select the best one. Analyze its performance using a scatterplot.</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2026, <a href="https://iliaazizi.com/">Ilia Azizi</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/04_Metrics/Ex_ML_Scoring.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 🤍 and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>