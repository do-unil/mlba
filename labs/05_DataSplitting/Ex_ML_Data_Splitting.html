<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data splitting – MLBA - S24</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../labs/06_Ensembles/Ex_ML_Ensemble.html" rel="next">
<link href="../../labs/04_Metrics/Ex_ML_Scoring.html" rel="prev">
<link href="../../images/logo.dark.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ce80fb680f754bdddd2e33f428b7c2fe.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-a77d94411ef28645364aa138da2dc249.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-96ccf8338fe666a1f86f626509d49180.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-109dea34fb0ab778c1fa5d25b6154e69.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<meta property="og:title" content="Data splitting – MLBA - S24">
<meta property="og:description" content="Homepage for Machine Learning in Business Analytics at HEC Lausanne, Spring 2024.">
<meta property="og:site_name" content="MLBA - S24 ">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html">Data Splitting</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../images/logo.light.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main tools-wide">
    <a href="https://moodle.unil.ch/course/view.php?id=33387" title="Moodle" class="quarto-navigation-tool px-1" aria-label="Moodle"><i class="bi bi-person-rolodex"></i></a>
    <a href="https://github.com/do-unil/mlba" title="GitHub Repo" class="quarto-navigation-tool px-1" aria-label="GitHub Repo"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../schedule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../faq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FAQ</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Lectures</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/01_Introduction/ML_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/02_DataExploration/ML_DataExplo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Exploration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/030_Introduction/ML_Models_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/031_LinearLogisticRegression/ML_LinLogReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/032_Trees/ML_Trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/033_NeuralNetworks/ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/034_SupportVectorMachine/ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/04_Metrics/ML_Metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/05_DataSplitting/ML_DataSplitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/06_Ensembles/ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/07_InterpretableML/ML_Interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/080_Introduction/ML_UnsupIntro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Unsuperised Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/081_Clustering/ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/082_DimensionReduction/ML_DimRed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dimension Reduction</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/00_lab/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/032_Trees/Ex_ML_Tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/033_NeuralNetworks/EX_ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/04_Metrics/Ex_ML_Scoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/06_Ensembles/Ex_ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/07_InterpretableML/Ex_ML_VarImp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/081_Clustering/Ex_ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/082_DimensionReduction/Ex_ML_PCA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/083_AutoEncoders/Ex_ML_Autoencoder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Autoencoders</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Assessments</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Exam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exam</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Project</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Project_Directives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Directives</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Presentation_Guidelines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Presentation Guidelines</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/beginners_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Beginners in R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/data_acquisition/data_sources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Sources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/data_acquisition/web_scraping_api.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Web Scraping</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/cheatsheets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding Cheatsheets</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#data-preparation" id="toc-data-preparation" class="nav-link active" data-scroll-target="#data-preparation">Data preparation</a></li>
  <li><a href="#fold-cross-validation" id="toc-fold-cross-validation" class="nav-link" data-scroll-target="#fold-cross-validation">10-fold Cross-validation</a>
  <ul class="collapse">
  <li><a href="#first-fold" id="toc-first-fold" class="nav-link" data-scroll-target="#first-fold">First fold</a></li>
  <li><a href="#loop-on-the-10-folds" id="toc-loop-on-the-10-folds" class="nav-link" data-scroll-target="#loop-on-the-10-folds">Loop on the 10 folds</a></li>
  <li><a href="#automated-approach" id="toc-automated-approach" class="nav-link" data-scroll-target="#automated-approach">Automated approach</a></li>
  </ul></li>
  <li><a href="#bootstrap-with-100-replicates" id="toc-bootstrap-with-100-replicates" class="nav-link" data-scroll-target="#bootstrap-with-100-replicates">Bootstrap with 100 replicates</a>
  <ul class="collapse">
  <li><a href="#first-sample" id="toc-first-sample" class="nav-link" data-scroll-target="#first-sample">First sample</a></li>
  <li><a href="#loop-on-the-100-sample" id="toc-loop-on-the-100-sample" class="nav-link" data-scroll-target="#loop-on-the-100-sample">Loop on the 100 sample</a></li>
  <li><a href="#automated-approach-1" id="toc-automated-approach-1" class="nav-link" data-scroll-target="#automated-approach-1">Automated approach</a></li>
  </ul></li>
  <li><a href="#balancing-data" id="toc-balancing-data" class="nav-link" data-scroll-target="#balancing-data">Balancing data</a>
  <ul class="collapse">
  <li><a href="#sub-sampling" id="toc-sub-sampling" class="nav-link" data-scroll-target="#sub-sampling">Sub-sampling</a></li>
  <li><a href="#resampling" id="toc-resampling" class="nav-link" data-scroll-target="#resampling">Resampling</a></li>
  </ul></li>
  <li><a href="#your-turn" id="toc-your-turn" class="nav-link" data-scroll-target="#your-turn">Your turn</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/05_DataSplitting/Ex_ML_Data_Splitting.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<script type="application/javascript">
// Description: Change image src depending on body class (quarto-light or quarto-dark)
function updateImageSrc() {
  var bodyClass = window.document.body.classList;
  var images = window.document.getElementsByTagName('img');
  for (var i = 0; i < images.length; i++) {
    var image = images[i];
    var src = image.src;
    var newSrc = src;
    if (bodyClass.contains('quarto-light') && src.includes('.dark')) {
      newSrc = src.replace('.dark', '.light');
    } else if (bodyClass.contains('quarto-dark') && src.includes('.light')) {
      newSrc = src.replace('.light', '.dark');
    }
    if (newSrc !== src) {
      image.src = newSrc;
    }
  }
}

var observer = new MutationObserver(function(mutations) {
  mutations.forEach(function(mutation) {
    if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
      updateImageSrc();
    }
  });
});

observer.observe(window.document.body, {
  attributes: true
});

updateImageSrc();
</script>

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html">Data Splitting</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Data splitting</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="data-preparation" class="level1">
<h1>Data preparation</h1>
<p>In this series, we practice the data splitting strategies seen in class. The data are the doctor visits, already used in previous applications: cross-validation, bootstrap, and balancing.</p>
<p>We’ll be using the <code>DocVis</code> dataset for this lab session.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>DocVis <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/DocVis.csv"</span>))</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>DocVis<span class="sc">$</span>visits <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(DocVis<span class="sc">$</span>visits) <span class="do">## make sure that visits is a factor</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We need to set aside a test set. This will be used after to check that there was no overfitting during the training of the model and to ensure that the score we have obtained generalizes outside the training data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">346</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>index_tr <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> DocVis<span class="sc">$</span>visits, <span class="at">p=</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>df_tr <span class="ot">&lt;-</span> DocVis[index_tr,]</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>df_te <span class="ot">&lt;-</span> DocVis[<span class="sc">-</span>index_tr,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that the splitting techniques used are applied <code>on the training set</code> only.</p>
</section>
<section id="fold-cross-validation" class="level1">
<h1>10-fold Cross-validation</h1>
<p>In this part, we practice the cross-validation by first building it “by hand” then in an automatic way using <code>caret</code>. A 10-fold cross-validation is prepared.</p>
<section id="first-fold" class="level2">
<h2 class="anchored" data-anchor-id="first-fold">First fold</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>First, we create the folds by using the <code>createFolds</code> function of <code>caret</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>index_CV <span class="ot">&lt;-</span> <span class="fu">createFolds</span>(<span class="at">y =</span> df_tr<span class="sc">$</span>visits, <span class="at">k=</span><span class="dv">10</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>index_CV[[<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As seen before, the <code>index_CV</code> object is a list of row indices. The first element of the list <code>index_CV[[1]]</code> corresponds to the first fold. It is the vector of row indices of the validation set for the first fold (i.e., the validation is made of the rows of the training set that are in this vector). All the indices that are not in <code>index_CV[[1]]</code> will be in the training set (for this fold).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df_cv_tr <span class="ot">&lt;-</span> df_tr[<span class="sc">-</span>index_CV[[<span class="dv">1</span>]],]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>df_cv_val <span class="ot">&lt;-</span> df_tr[index_CV[[<span class="dv">1</span>]],]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For this fold, <code>df_cv_tr</code> is the training set (it contains 9/10 of the original training set <code>df_tr</code>) and <code>df_cv_val</code> is the validation set (it contains 1/10 of the original training set <code>df_tr</code>). These two sets are disjoints.</p>
<p>Now, we simply fit the model with the training set and compute its accuracy on the validation set. For this exercise, we use a logistic regression with AIC-based variable selection.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>Doc_cv <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_cv_tr, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>Doc_cv_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_cv, <span class="at">newdata=</span>df_cv_val, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>Doc_cv_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_cv_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_cv_pred), <span class="at">reference =</span> df_cv_val<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the course python environment as usual with a r code chunks.</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>, <span class="at">required =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will one-hot encode the categorical variables using <code>pd.get_dummies()</code> and then divide the data into <code>X_train</code>, <code>y_train</code>, <code>X_test</code> and <code>y_test</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encoding the categorical columns</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> pd.get_dummies(r.df_tr.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> r.df_tr[<span class="st">'visits'</span>]</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> pd.get_dummies(r.df_te.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> r.df_te[<span class="st">'visits'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, we create the folds by using the <code>KFold</code> function of <code>scikit-learn</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We setup the 10-k fold</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">346</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>fold_indices <span class="op">=</span> <span class="bu">list</span>(kf.split(X_train, y_train))</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>first_fold_train, first_fold_val <span class="op">=</span> fold_indices[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As seen before, the <code>fold_indices</code> object is a list of tuple pairs. The first element of the list <code>fold_indices[0]</code> corresponds to the first fold. It is the tuple of row indices of the training set and the validation set for the first fold. All the indices that are not in <code>first_fold_val</code> will be in the training set (for this fold).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>X_cv_tr <span class="op">=</span> X_train.iloc[first_fold_train, :]</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>y_cv_tr <span class="op">=</span> y_train.iloc[first_fold_train]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>X_cv_val <span class="op">=</span> X_train.iloc[first_fold_val, :]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>y_cv_val <span class="op">=</span> y_train.iloc[first_fold_val]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This part, will be slightly different from the R approach. Here, we fit the model with the training set and compute its accuracy on the validation set. For the python approach, we use a logistic regression with recursive feature elimination to select the best number of features.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, confusion_matrix</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> RFE</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>rfe <span class="op">=</span> RFE(model)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>rfe.fit(X_cv_tr, y_cv_tr)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>pred_probs <span class="op">=</span> rfe.predict_proba(X_cv_val)[:, <span class="dv">1</span>]</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>Doc_cv_pred <span class="op">=</span> np.where(pred_probs <span class="op">&gt;</span> <span class="fl">0.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> accuracy_score(y_cv_val, Doc_cv_pred)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>acc</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co"># alternatively, you could use `cross_val_score`</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.model_selection import cross_val_score</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co"># cv_scores = cross_val_score(rfe, X_cv_tr, y_cv_tr, cv=kf, scoring="accuracy")</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co"># cv_scores</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="loop-on-the-10-folds" class="level2">
<h2 class="anchored" data-anchor-id="loop-on-the-10-folds">Loop on the 10 folds</h2>
<p>Now we repeat the previous steps for all the folds.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>In order to track the 10 accuracy measures obtained, we store them into a vector (<code>acc_vec</code>). Note also that the option <code>trace=0</code> was set in the function <code>step</code> to avoid all the print outs of the AIC selections.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>acc_vec <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">10</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>){</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  df_cv_tr <span class="ot">&lt;-</span> df_tr[<span class="sc">-</span>index_CV[[i]],]</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  df_cv_val <span class="ot">&lt;-</span> df_tr[index_CV[[i]],]</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  Doc_cv <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_cv_tr, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>(<span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>  Doc_cv_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_cv, <span class="at">newdata=</span>df_cv_val, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  Doc_cv_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_cv_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  acc_vec[i] <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_cv_pred), <span class="at">reference =</span> df_cv_val<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>acc_vec</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>By definition of the CV, all the 10 validations sets in this loop are disjoints. Thus, these 10 accuracy measures are in a way representative of what can be expected on the test set, except if we are very unlucky when we created the test set.</p>
<p>Now we can estimate the expected accuracy (i.e., the mean) and its variation (below we use the standard deviation).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(acc_vec)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(acc_vec)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The small SD shows that the results are reliable and that we have good chance that the model, trained on the whole training set, will have this accuracy on the test set.</p>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>For python, in order to track the 10 accuracy measures obtained, we store them into a list (<code>acc_list</code>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>acc_list <span class="op">=</span> []</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> train_idx, val_idx <span class="kw">in</span> kf.split(X_train, y_train):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    X_cv_tr, y_cv_tr <span class="op">=</span> X_train.iloc[train_idx, :], y_train.iloc[train_idx]</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    X_cv_val, y_cv_val <span class="op">=</span> X_train.iloc[val_idx, :], y_train.iloc[val_idx]</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    rfe.fit(X_cv_tr, y_cv_tr)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    pred_probs <span class="op">=</span> rfe.predict_proba(X_cv_val)[:, <span class="dv">1</span>]</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    Doc_cv_pred <span class="op">=</span> np.where(pred_probs <span class="op">&gt;</span> <span class="fl">0.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> accuracy_score(y_cv_val, Doc_cv_pred)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    acc_list.append(acc)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>acc_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Once again, we can estimate the expected accuracy and its variation.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>mean_acc <span class="op">=</span> np.mean(acc_list)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>std_acc <span class="op">=</span> np.std(acc_list)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>mean_acc, std_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we fit the final model using the whole training set and evaluate its performance on the test set.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>rfe.fit(X_train, y_train)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> rfe.predict(X_test)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="op">=</span> accuracy_score(y_test, y_test_pred)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>test_cm <span class="op">=</span> confusion_matrix(y_test, y_test_pred)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>test_accuracy, test_cm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="automated-approach" class="level2">
<h2 class="anchored" data-anchor-id="automated-approach">Automated approach</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">R - <code>caret</code></a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Python - <code>sklearn</code></a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<p>The 10-CV can be easily obtained from <code>caret</code>. First, set up the splitting data method using the <code>trainControl</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>trctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then pass this method to the <code>train</code> function (from <code>caret</code>). In addition, we use the model (below unhappily called “method” also) <code>glmStepAIC</code> which, combined with the <code>binomial</code> family, applies a logistic regression and a AIC-based variable selection (backward; exactly like the <code>step</code> function used above). Of course, we also provide the model formula.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">346</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>Doc_cv <span class="ot">&lt;-</span> <span class="fu">train</span>(visits <span class="sc">~</span>., <span class="at">data =</span> df_tr, <span class="at">method =</span> <span class="st">"glmStepAIC"</span>, <span class="at">family=</span><span class="st">"binomial"</span>,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">trControl=</span>trctrl, <span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>Doc_cv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that the function “only” provides the expected accuracy and the expected kappa. It does not provides their standard deviations.</p>
<p>The final model (i.e., the model trained on the whole training set <code>df_tr</code>) is stored in <code>Doc_cv$finalModel</code>. It can be used to compute the accuracy on the test set.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>Doc_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_cv, <span class="at">newdata =</span> df_te)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>Doc_pred, <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>In python, a similar approach demonstrated in <code>caret</code> would be using <code>GridSearchCV</code> from <code>scikit-learn</code>. We use the same 10-CV <code>kf</code> object created earlier. Then pass this method to the <code>GridSearchCV</code> function with <code>LogisticRegression</code> model with <code>RFE</code> for feature selection with the grid of parameters we would like to search for (in this case the number of features). Then, we output the (hyper-)parameters with the best performance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>rfe <span class="op">=</span> RFE(model)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'n_features_to_select'</span>: <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, X_train.shape[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">1</span>))}</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(rfe, param_grid, scoring<span class="op">=</span><span class="st">'accuracy'</span>, cv<span class="op">=</span>kf)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(grid_search.best_score_, grid_search.best_params_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The final model (i.e., the model trained on the whole training set <code>X_train</code>) is stored in <code>grid_search.best_estimator_</code>. It can be used to compute the accuracy on the test set.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> grid_search.best_estimator_.predict(X_test)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="op">=</span> accuracy_score(y_test, y_test_pred)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>test_cm <span class="op">=</span> confusion_matrix(y_test, y_test_pred)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_accuracy, test_cm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Our results did improve compared to the last python model.</p>
</div>
</div>
</div>
</section>
</section>
<section id="bootstrap-with-100-replicates" class="level1">
<h1>Bootstrap with 100 replicates</h1>
<p>We now apply the bootstrap with 100 replicates. Like for CV, we first make it by hand and then we use some kind of automated approach like <code>caret</code>.</p>
<section id="first-sample" class="level2">
<h2 class="anchored" data-anchor-id="first-sample">First sample</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<p>We need to first create the replicates using the <code>caret</code> function <code>createResample</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">897</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>index_boot <span class="ot">&lt;-</span> <span class="fu">createResample</span>(<span class="at">y=</span>df_tr<span class="sc">$</span>visits, <span class="at">times=</span><span class="dv">100</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>index_boot[[<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Again, it creates a list of indices. The first element of the list, <code>index_boot[[1]]</code>, contains the row indices that will be in the training set. Note that, it is of length 4,153. In other words, the training set during this first replicate is of the same dimension as the whole training set <code>df_tr</code>. Note also that, in <code>index_boot[[1]]</code>, there are indices that are replicated. This is the bootstrap sampling process. Some rows will be replicated in the training set. This also means that some rows of <code>df_tr</code> will not be in <code>index_boot[[1]]</code>. These rows are said to be <code>out-of-bag</code> and form the validation set. See below the dimensions of the data frames.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>df_boot_tr <span class="ot">&lt;-</span> df_tr[index_boot[[<span class="dv">1</span>]],]</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(df_boot_tr)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>df_boot_val <span class="ot">&lt;-</span> df_tr[<span class="sc">-</span>index_boot[[<span class="dv">1</span>]],]</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(df_boot_val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now fit the data to this first sample training set.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>Doc_boot <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_boot_tr, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The accuracy is then computed with the 632-rule: first, the apparent accuracy is computed (accuracy on the sample training set), then the out-of-bag accuracy (the accuracy on the validation set), then the final accuracy estimate is the 0.368/0.632-combination of the two.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>Doc_boot_prob_val <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_boot, <span class="at">newdata=</span>df_boot_val, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>Doc_boot_pred_val <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_boot_prob_val<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>oob_acc <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_boot_pred_val), <span class="at">reference =</span> df_boot_val<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>Doc_boot_prob_tr <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_boot, <span class="at">newdata=</span>df_boot_tr, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>Doc_boot_pred_tr <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_boot_prob_tr<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>app_acc <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_boot_pred_tr), <span class="at">reference =</span> df_boot_tr<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>oob_acc <span class="do">## out-of-bag accuracy</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>app_acc <span class="do">## apparent accuracy</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="fl">0.368</span><span class="sc">*</span>app_acc <span class="sc">+</span> <span class="fl">0.632</span><span class="sc">*</span>oob_acc <span class="do">## accuracy estimate</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<p>First, we create the replicates using the <code>resample</code> function from <code>sklearn.utils</code>. Please note that unlike <code>caret::createResample()</code>, in <code>sklearn</code> (to the best of our knowledge), there’s no method that returns a list of the samples, so with <code>resample</code>, we get one set of resampled data points. This doesn’t matter for now, but in the following sub-section, we will write a function to do the same thing in python.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils <span class="im">import</span> resample</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">897</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>df_boot_tr <span class="op">=</span> resample(r.df_tr, n_samples<span class="op">=</span><span class="bu">len</span>(r.df_tr), random_state<span class="op">=</span><span class="dv">897</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>resample</code> function returns a new data frames with the same number of samples as the original <code>r.df_tr</code>, but some rows will be replicated. This also means that some rows of <code>r.df_tr</code> will not be in the bootstrapped data frames These rows are said to be <code>out-of-bag</code> and form the validation set. See below the dimensions of the data frames.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>df_boot_tr.shape</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>oob_mask <span class="op">=</span> <span class="op">~</span>r.df_tr.index.isin(df_boot_tr.index.values)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>df_boot_val <span class="op">=</span> r.df_tr[oob_mask]</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>df_boot_val.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>There’s a difference between the shape of <code>df_boot_val</code> because of the difference in random generators between R &amp; python. If you change the number for the random generator in python (i.e., <code>np.random.seed(897)</code>) or in R (i.e., <code>set.seed(897)</code>), you’ll see that the results will be slightly different.</p>
</div>
</div>
</div>
</section>
<section id="loop-on-the-100-sample" class="level2">
<h2 class="anchored" data-anchor-id="loop-on-the-100-sample">Loop on the 100 sample</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<p>The previous code is looped. The accuracy measures are stored in vectors. The code can be quite long to run.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>oob_acc_vec <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>app_acc_vec <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>acc_vec <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>  df_boot_tr <span class="ot">&lt;-</span> df_tr[index_boot[[i]],]</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>  df_boot_val <span class="ot">&lt;-</span> df_tr[<span class="sc">-</span>index_boot[[i]],]</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>  Doc_boot <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_boot_tr, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>(<span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>  Doc_boot_prob_val <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_boot, <span class="at">newdata=</span>df_boot_val, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>  Doc_boot_pred_val <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_boot_prob_val<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>  oob_acc_vec[i] <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_boot_pred_val), <span class="at">reference =</span> df_boot_val<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>  Doc_boot_prob_tr <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_boot, <span class="at">newdata=</span>df_boot_tr, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>  Doc_boot_pred_tr <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_boot_prob_tr<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>  app_acc_vec[i] <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_boot_pred_tr), <span class="at">reference =</span> df_boot_tr<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>  acc_vec[i] <span class="ot">&lt;-</span> <span class="fl">0.368</span><span class="sc">*</span>app_acc_vec[i] <span class="sc">+</span> <span class="fl">0.632</span><span class="sc">*</span>oob_acc_vec[i]</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>acc_vec</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Like for the CV, we can estimate the expected accuracy and its dispersion.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(acc_vec)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(acc_vec)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<p>In this part of the code, we perform the bootstrap procedure with 100 samples. To that, we will implement our own function to create the index n-times for a given dataset. This ensures that we get a similar output to <code>caret::createResample()</code>. In this case, we apply this function to our main training dataframe 100 times.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_resample(data, times<span class="op">=</span><span class="dv">100</span>, random_seed<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If you're not familiar with the documentation below, they are called</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># `docstrings` and whenever you ask help for a function or see it's documentation,</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># they are generated from that</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate bootstrap sample indices for data.</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - data (array-like): The data to bootstrap.</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - times (int): The number of bootstrap samples to generate.</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co">    - random_seed (int): The random seed to use for reproducibility.</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co">    - samples (list of arrays): A list of times bootstrap sample indices.</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>    np.random.seed(random_seed)</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    n_samples <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> []</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(times):</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> np.random.choice(n_samples, n_samples, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>        samples.append(indices)</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> samples</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="co"># apply the new created function</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>index_boot <span class="op">=</span> create_resample(r.df_tr, times<span class="op">=</span><span class="dv">100</span>, random_seed <span class="op">=</span> <span class="dv">123</span>)</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a><span class="co"># we can see if we successfully replicated the sampling process 100 times</span></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(index_boot))</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a><span class="co"># check if we have the correct number of rows (e.g. for the first element)</span></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(index_boot[<span class="dv">0</span>]))</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a><span class="co"># alternatively to see this information, you can uncomment &amp; run the code below</span></span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a><span class="co"># np.asarray(index_boot).shape</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>One thing to note is that we could have used the <code>sklearn.utils.resample</code> introduced earlier to directly get a list of dataframes with the randomly chosen indices. The issue here would be rather a computational one, as we have to extract the rows many times from the dataset and then hold all this data in memory, which is redundant. So although this may not be a problem for 100 replications, it can quickly start to become an issue if you want to replicated many more times (e.g., 100,000 times). The best approach is to get the indices, and then subset the rows only when needed.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils <span class="im">import</span> resample</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_n_resamples(data, times, random_seed<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate n_bootstraps bootstrap samples of data.</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - data (array-like): The data to bootstrap.</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - n_bootstraps (int): The number of bootstrap samples to generate.</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="co">    - random_seed (int): The random seed to use for reproducibility.</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co">    - bootstrap_samples (list of lists): A list of n_bootstraps bootstrap samples.</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    np.random.seed(random_seed)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    bootstrap_samples <span class="op">=</span> []</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(times):</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>        sample <span class="op">=</span> resample(data)</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>        bootstrap_samples.append(sample)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> bootstrap_samples</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>dfs_boot <span class="op">=</span> create_n_resamples(r.df_tr, times<span class="op">=</span><span class="dv">100</span>, random_seed <span class="op">=</span> <span class="dv">123</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p>For each sample, we calculate the out-of-bag accuracy, the apparent accuracy, and the final accuracy estimate using the 0.368/0.632 rule. This is done using a loop that iterates 100 times, once for each bootstrap sample. The steps that the code follows are similar to R, and are outlined below:</p>
<ol type="1">
<li>We set up three arrays to store the out-of-bag accuracy, the apparent accuracy, and the final accuracy estimate for each of the 100 bootstrap samples.</li>
<li>In the loop, we perform the following steps for each bootstrap sample:
<ol type="a">
<li>Use the generate a random list of indices with replacement, which forms the bootstrap training set.</li>
<li>Create a mask to extract the out-of-bag (validation) set from the original training set.</li>
<li>Train the logistic regression model with RFE on the bootstrap training set.</li>
<li>Compute the out-of-bag accuracy by predicting on the validation set and comparing the predicted labels to the true labels.</li>
<li>Compute the apparent accuracy by predicting on the bootstrap training set and comparing the predicted labels to the true labels.</li>
<li>Calculate the final accuracy estimate for the current bootstrap sample using the 0.368/0.632 rule.</li>
</ol></li>
<li>Once the loop is complete, the <code>acc_vec</code> array will contain the final accuracy estimates for all 100 bootstrap samples. We can then calculate the mean and standard deviation of these accuracy estimates to get an overall understanding of the model’s performance.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># we one-hote encode the categorical variables</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co">## notice that we didn't use the argument `drop_first` before, since this is like</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co">## making dummy variable m - 1 where m is the number of variables you have</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>r.df_tr_encoded <span class="op">=</span> pd.get_dummies(r.df_tr, drop_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>oob_acc_vec <span class="op">=</span> np.zeros(<span class="dv">100</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>app_acc_vec <span class="op">=</span> np.zeros(<span class="dv">100</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>acc_vec <span class="op">=</span> np.zeros(<span class="dv">100</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    df_boot_tr <span class="op">=</span> r.df_tr_encoded.iloc[index_boot[i]]</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    y_boot_tr <span class="op">=</span> df_boot_tr[<span class="st">"visits_Yes"</span>].astype(<span class="bu">int</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    X_boot_tr <span class="op">=</span> df_boot_tr.drop(<span class="st">"visits_Yes"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    oob_mask <span class="op">=</span> <span class="op">~</span>r.df_tr_encoded.index.isin(df_boot_tr.index.values)</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>    df_boot_val <span class="op">=</span> r.df_tr_encoded[oob_mask]</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    y_boot_val <span class="op">=</span> df_boot_val[<span class="st">"visits_Yes"</span>].astype(<span class="bu">int</span>)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    X_boot_val <span class="op">=</span> df_boot_val.drop(<span class="st">"visits_Yes"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>    rfe <span class="op">=</span> RFE(model)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    rfe.fit(X_boot_tr, y_boot_tr)</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    pred_probs_val <span class="op">=</span> rfe.predict_proba(X_boot_val)[:, <span class="dv">1</span>]</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>    Doc_boot_pred_val <span class="op">=</span> (pred_probs_val <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>    oob_acc <span class="op">=</span> accuracy_score(y_boot_val, Doc_boot_pred_val)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>    oob_acc_vec[i] <span class="op">=</span> oob_acc</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>    pred_probs_tr <span class="op">=</span> rfe.predict_proba(X_boot_tr)[:, <span class="dv">1</span>]</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>    Doc_boot_pred_tr <span class="op">=</span> (pred_probs_tr <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>    app_acc <span class="op">=</span> accuracy_score(y_boot_tr, Doc_boot_pred_tr)</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>    app_acc_vec[i] <span class="op">=</span> app_acc</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>    acc_vec[i] <span class="op">=</span> <span class="fl">0.368</span> <span class="op">*</span> app_acc <span class="op">+</span> <span class="fl">0.632</span> <span class="op">*</span> oob_acc</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(acc_vec)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="automated-approach-1" class="level2">
<h2 class="anchored" data-anchor-id="automated-approach-1">Automated approach</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">R - <code>caret</code></a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Python - <code>sklearn</code> &amp; <code>mlxtend</code></a></li></ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<p>We only need to change the method in the <code>trainControl</code> function. The corresponding method is “boot632”.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">346</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>trctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"boot632"</span>, <span class="at">number=</span><span class="dv">100</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>Doc_boot <span class="ot">&lt;-</span> <span class="fu">train</span>(visits <span class="sc">~</span>., <span class="at">data =</span> df_tr, <span class="at">method =</span> <span class="st">"glmStepAIC"</span>, <span class="at">family=</span><span class="st">"binomial"</span>,</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">trControl=</span>trctrl, <span class="at">trace =</span> <span class="dv">0</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>Doc_boot</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<p>As <code>sklearn</code> does not offer bootstrap with the 0.632 rule, we use <code>bootstrap_point632_score</code> function from the <code>mlxtend</code> library to perform bootstrapping with the 0.632 rule for our Logistic Regression model. We will use <code>mlxtend</code> with R for bootstrapping with the 0.632 rule.</p>
<p>Please note for this part, we don’t make any step-wise feature selection here as in the case of <code>caret</code> (i.e., <code>glmStepAIC</code>), but similar feature selections such as <code>sklearn.feature_selection.RFE</code> can be implemented since, as mentioned in the <code>Ex_ML_LinLogReg</code> exercises, there are no exact implementations of step-wise AIC regression with the libraries of interest in python.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlxtend.evaluate <span class="im">import</span> bootstrap_point632_score</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">346</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the logistic regression model</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute bootstrap point 632 scores</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> bootstrap_point632_score(estimator<span class="op">=</span>model, X<span class="op">=</span>X_train, y<span class="op">=</span>y_train, n_splits<span class="op">=</span><span class="dv">100</span>, random_seed<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the mean accuracy and standard deviation</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean accuracy:"</span>, np.mean(scores))</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Standard deviation:"</span>, np.std(scores))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The results are now very close to our model in <code>caret</code>.</p>
</div>
</div>
</div>
</section>
</section>
<section id="balancing-data" class="level1">
<h1>Balancing data</h1>
<p>In this part, we apply the balancing data technique in order to improve the prediction of “yes” with the doctor visit data. The table below reveals the unbalance problem.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Statistics on the training set</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df_tr<span class="sc">$</span>visits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Since there are many more “No” than “Yes”, any model favors the prediction of the “No”. It results a good accuracy but the specificity (or the sensitivity depending on the choice of the positive class) is low, as well as the balanced accuracy.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>Doc_lr <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>(<span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>Doc_lr_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>Doc_lr_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_lr_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_lr_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>r.df_tr[<span class="st">'visits'</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>lr.fit(X_train, y_train)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>lr_pred <span class="op">=</span> lr.predict(X_test)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>lr_cf <span class="op">=</span> confusion_matrix(y_test, lr_pred)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(lr_cf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To calculate all the other scores aside from the confusion matrix, we actually have to compute them manually:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> balanced_accuracy_score, recall_score</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>tn, fp, fn, tp <span class="op">=</span> lr_cf.ravel()</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>specificity <span class="op">=</span> tn <span class="op">/</span> (tn <span class="op">+</span> fp)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>sensitivity <span class="op">=</span> recall_score(y_test, lr_pred, pos_label<span class="op">=</span><span class="st">'Yes'</span>)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>balanced_acc <span class="op">=</span> balanced_accuracy_score(y_test, lr_pred)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, lr_pred)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced Accuracy: </span><span class="sc">{</span>balanced_acc<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Specificity: </span><span class="sc">{</span>specificity<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sensitivity: </span><span class="sc">{</span>sensitivity<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Please note that <code>Specificity</code> and <code>Sensitivity</code> have the reverse values compared to R, and that’s because the confusion matrix in R first takes the predicted values and then the true values. In contrast, it is the confusion matrix from <code>sklearn</code>, the true values are given before the predicted ones. The interpretation does not change, and it’s only about which class you consider as your positive class.</p>
</div>
</div>
</div>
<section id="sub-sampling" class="level2">
<h2 class="anchored" data-anchor-id="sub-sampling">Sub-sampling</h2>
<p>Balancing using sub-sampling consists of taking all the cases in the smallest class (i.e., <code>Yes</code>) and extract at random the same amount of cases in the largest category (i.e., <code>No</code>).</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>n_yes <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="fu">table</span>(df_tr<span class="sc">$</span>visits)) <span class="do">## 840</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>df_tr_no <span class="ot">&lt;-</span> <span class="fu">filter</span>(df_tr, visits<span class="sc">==</span><span class="st">"No"</span>) <span class="do">## the "No" cases</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>df_tr_yes <span class="ot">&lt;-</span> <span class="fu">filter</span>(df_tr, visits<span class="sc">==</span><span class="st">"Yes"</span>) <span class="do">## The "Yes" cases</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>index_no <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">size=</span>n_yes, <span class="at">x=</span><span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(df_tr_no), <span class="at">replace=</span><span class="cn">FALSE</span>) <span class="do">## sub-sample 840 instances from the "No"</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>df_tr_subs <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">rbind</span>(df_tr_yes, df_tr_no[index_no,])) <span class="do">## Bind all the "Yes" and the sub-sampled "No"</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df_tr_subs<span class="sc">$</span>visits) <span class="do">## The cases are balanced</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let us see the result on the accuracy measures.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>Doc_lr_subs <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr_subs, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>(<span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>Doc_lr_subs_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr_subs, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>Doc_lr_subs_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_lr_subs_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_lr_subs_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>n_yes <span class="op">=</span> <span class="bu">min</span>(r.df_tr[<span class="st">'visits'</span>].value_counts()) <span class="co">## 840</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>df_tr_no <span class="op">=</span> r.df_tr[r.df_tr[<span class="st">'visits'</span>] <span class="op">==</span> <span class="st">"No"</span>] <span class="co">## the "No" cases</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>df_tr_yes <span class="op">=</span> r.df_tr[r.df_tr[<span class="st">'visits'</span>] <span class="op">==</span> <span class="st">"Yes"</span>] <span class="co">## The "Yes" cases</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>index_no <span class="op">=</span> np.random.choice(df_tr_no.index, size<span class="op">=</span>n_yes, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>df_tr_subs <span class="op">=</span> pd.concat([df_tr_yes, df_tr_no.loc[index_no]])</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>df_tr_subs[<span class="st">'visits'</span>].value_counts() <span class="co">## The cases like R are balanced</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now to the calculating the scores again:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>X_train_subs <span class="op">=</span> pd.get_dummies(df_tr_subs.drop(columns<span class="op">=</span>[<span class="st">'visits'</span>]))</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>y_train_subs <span class="op">=</span> df_tr_subs[<span class="st">'visits'</span>]</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>lr_subs <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>lr_subs.fit(X_train_subs, y_train_subs)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>lr_subs_pred <span class="op">=</span> lr_subs.predict(X_test)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>lr_subs_cf <span class="op">=</span> confusion_matrix(y_test, lr_subs_pred)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>tn_subs, fp_subs, fn_subs, tp_subs <span class="op">=</span> lr_subs_cf.ravel()</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>specificity_subs <span class="op">=</span> tn_subs <span class="op">/</span> (tn_subs <span class="op">+</span> fp_subs)</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>sensitivity_subs <span class="op">=</span> recall_score(y_test, lr_subs_pred, pos_label<span class="op">=</span><span class="st">'Yes'</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>balanced_acc_subs <span class="op">=</span> balanced_accuracy_score(y_test, lr_subs_pred)</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>accuracy_subs <span class="op">=</span> accuracy_score(y_test, lr_subs_pred)</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(lr_subs_cf)</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_subs<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced Accuracy: </span><span class="sc">{</span>balanced_acc_subs<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Specificity: </span><span class="sc">{</span>specificity_subs<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sensitivity: </span><span class="sc">{</span>sensitivity_subs<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Same conclusion as R (albeit with slightly different values).</p>
</div>
</div>
</div>
<p>As expected, the accuracy has decreased but the balanced accuracy has increased. Depending on the aim of the prediction, this model may be much better to use than the one trained on the unbalanced data.</p>
</section>
<section id="resampling" class="level2">
<h2 class="anchored" data-anchor-id="resampling">Resampling</h2>
<p>Balancing by resampling follows the same aim. The difference with sub-sampling is that the resampling increases the number of cases in the smallest class by resampling at random from them. The codes below are explicit:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-9-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-1" role="tab" aria-controls="tabset-9-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-9-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-2" role="tab" aria-controls="tabset-9-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-9-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-9-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>n_no <span class="ot">&lt;-</span> <span class="fu">max</span>(<span class="fu">table</span>(df_tr<span class="sc">$</span>visits)) <span class="do">## 3313</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>df_tr_no <span class="ot">&lt;-</span> <span class="fu">filter</span>(df_tr, visits<span class="sc">==</span><span class="st">"No"</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>df_tr_yes <span class="ot">&lt;-</span> <span class="fu">filter</span>(df_tr, visits<span class="sc">==</span><span class="st">"Yes"</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>index_yes <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">size=</span>n_no, <span class="at">x=</span><span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(df_tr_yes), <span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>df_tr_res <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">rbind</span>(df_tr_no, df_tr_yes[index_yes,]))</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df_tr_res<span class="sc">$</span>visits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we have a balanced data set where each class has the same amount as the largest class (i.e., “No”) in the original training set. The effect on the model fit is very similar to the subsampling:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>Doc_lr_res <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr_res, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>(<span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>Doc_lr_res_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr_res, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>Doc_lr_res_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_lr_res_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_lr_res_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-9-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-9-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>n_no <span class="op">=</span> <span class="bu">max</span>(r.df_tr[<span class="st">'visits'</span>].value_counts()) <span class="co">## 3313</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>df_tr_no <span class="op">=</span> r.df_tr[r.df_tr[<span class="st">'visits'</span>] <span class="op">==</span> <span class="st">"No"</span>]</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>df_tr_yes <span class="op">=</span> r.df_tr[r.df_tr[<span class="st">'visits'</span>] <span class="op">==</span> <span class="st">"Yes"</span>]</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>index_yes <span class="op">=</span> np.random.choice(df_tr_yes.index, size<span class="op">=</span>n_no, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>df_tr_res <span class="op">=</span> pd.concat([df_tr_no, df_tr_yes.loc[index_yes]])</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>df_tr_res[<span class="st">'visits'</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can model again with the resampled data</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>X_train_res <span class="op">=</span> pd.get_dummies(df_tr_res.drop(columns<span class="op">=</span>[<span class="st">'visits'</span>]))</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>y_train_res <span class="op">=</span> df_tr_res[<span class="st">'visits'</span>]</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>lr_res <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>lr_res.fit(X_train_res, y_train_res)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>lr_res_pred <span class="op">=</span> lr_res.predict(X_test)</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>lr_res_cf <span class="op">=</span> confusion_matrix(y_test, lr_res_pred)</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>tn_res, fp_res, fn_res, tp_res <span class="op">=</span> lr_res_cf.ravel()</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>specificity_res <span class="op">=</span> tn_res <span class="op">/</span> (tn_res <span class="op">+</span> fp_res)</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>sensitivity_res <span class="op">=</span> recall_score(y_test, lr_res_pred, pos_label<span class="op">=</span><span class="st">'Yes'</span>)</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>balanced_acc_res <span class="op">=</span> balanced_accuracy_score(y_test, lr_res_pred)</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>accuracy_res <span class="op">=</span> accuracy_score(y_test, lr_res_pred)</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(lr_res_cf)</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_res<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced Accuracy: </span><span class="sc">{</span>balanced_acc_res<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Specificity: </span><span class="sc">{</span>specificity_res<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sensitivity: </span><span class="sc">{</span>sensitivity_res<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>Whether one should prefer sub-sampling or resampling depends on the amount and the richness of the data.</p>
</section>
</section>
<section id="your-turn" class="level1">
<h1>Your turn</h1>
<p>Repeat the analysis on the German credit data. Balance the data using either method. Then, using <code>caret</code> (R) or <code>sklearn</code> (python) and either CV or Bootstrap, put several models in competition. Select the best one according to your choice of score. Finally, use the test set to see if the best model does not overfit the training set.</p>
<p>Doing this will have achieved a complete supervised learning task from A to Z.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/do-unil\.github\.io\/mlba");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../labs/04_Metrics/Ex_ML_Scoring.html" class="pagination-link" aria-label="Metrics">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Metrics</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../labs/06_Ensembles/Ex_ML_Ensemble.html" class="pagination-link" aria-label="Ensemble Methods">
        <span class="nav-page-text">Ensemble Methods</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb47" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Data splitting"</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r global_options, include = FALSE}</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::opts_chunk$set(fig.align="center", results = 'hide', fig.show = 'hide')</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="fu"># Data preparation</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>In this series, we practice the data splitting strategies seen in class. The data are the doctor visits, already used in previous applications: cross-validation, bootstrap, and balancing.</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>We'll be using the <span class="in">`DocVis`</span> dataset for this lab session.</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>DocVis <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/DocVis.csv"</span>))</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>DocVis<span class="sc">$</span>visits <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(DocVis<span class="sc">$</span>visits) <span class="do">## make sure that visits is a factor</span></span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a>We need to set aside a test set. This will be used after to check that there was no overfitting during the training of the model and to ensure that the score we have obtained generalizes outside the training data.</span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb47-29"><a href="#cb47-29" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">346</span>)</span>
<span id="cb47-30"><a href="#cb47-30" aria-hidden="true" tabindex="-1"></a>index_tr <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> DocVis<span class="sc">$</span>visits, <span class="at">p=</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb47-31"><a href="#cb47-31" aria-hidden="true" tabindex="-1"></a>df_tr <span class="ot">&lt;-</span> DocVis[index_tr,]</span>
<span id="cb47-32"><a href="#cb47-32" aria-hidden="true" tabindex="-1"></a>df_te <span class="ot">&lt;-</span> DocVis[<span class="sc">-</span>index_tr,]</span>
<span id="cb47-33"><a href="#cb47-33" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-34"><a href="#cb47-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-35"><a href="#cb47-35" aria-hidden="true" tabindex="-1"></a>Note that the splitting techniques used are applied <span class="in">`on the training set`</span> only.</span>
<span id="cb47-36"><a href="#cb47-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-37"><a href="#cb47-37" aria-hidden="true" tabindex="-1"></a><span class="fu"># 10-fold Cross-validation</span></span>
<span id="cb47-38"><a href="#cb47-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-39"><a href="#cb47-39" aria-hidden="true" tabindex="-1"></a>In this part, we practice the cross-validation by first building it "by hand" then in an automatic way using <span class="in">`caret`</span>. A 10-fold cross-validation is prepared.</span>
<span id="cb47-40"><a href="#cb47-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-41"><a href="#cb47-41" aria-hidden="true" tabindex="-1"></a><span class="fu">## First fold</span></span>
<span id="cb47-42"><a href="#cb47-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-43"><a href="#cb47-43" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb47-44"><a href="#cb47-44" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb47-45"><a href="#cb47-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-46"><a href="#cb47-46" aria-hidden="true" tabindex="-1"></a>First, we create the folds by using the <span class="in">`createFolds`</span> function of <span class="in">`caret`</span>.</span>
<span id="cb47-47"><a href="#cb47-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-50"><a href="#cb47-50" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-51"><a href="#cb47-51" aria-hidden="true" tabindex="-1"></a>index_CV <span class="ot">&lt;-</span> <span class="fu">createFolds</span>(<span class="at">y =</span> df_tr<span class="sc">$</span>visits, <span class="at">k=</span><span class="dv">10</span>)</span>
<span id="cb47-52"><a href="#cb47-52" aria-hidden="true" tabindex="-1"></a>index_CV[[<span class="dv">1</span>]]</span>
<span id="cb47-53"><a href="#cb47-53" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-54"><a href="#cb47-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-55"><a href="#cb47-55" aria-hidden="true" tabindex="-1"></a>As seen before, the <span class="in">`index_CV`</span> object is a list of row indices. The first element of the list <span class="in">`index_CV[[1]]`</span> corresponds to the first fold. It is the vector of row indices of the validation set for the first fold (i.e., the validation is made of the rows of the training set that are in this vector). All the indices that are not in <span class="in">`index_CV[[1]]`</span> will be in the training set (for this fold).</span>
<span id="cb47-56"><a href="#cb47-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-59"><a href="#cb47-59" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-60"><a href="#cb47-60" aria-hidden="true" tabindex="-1"></a>df_cv_tr <span class="ot">&lt;-</span> df_tr[<span class="sc">-</span>index_CV[[<span class="dv">1</span>]],]</span>
<span id="cb47-61"><a href="#cb47-61" aria-hidden="true" tabindex="-1"></a>df_cv_val <span class="ot">&lt;-</span> df_tr[index_CV[[<span class="dv">1</span>]],]</span>
<span id="cb47-62"><a href="#cb47-62" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-63"><a href="#cb47-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-64"><a href="#cb47-64" aria-hidden="true" tabindex="-1"></a>For this fold, <span class="in">`df_cv_tr`</span> is the training set (it contains 9/10 of the original training set <span class="in">`df_tr`</span>) and <span class="in">`df_cv_val`</span> is the validation set (it contains 1/10 of the original training set <span class="in">`df_tr`</span>). These two sets are disjoints.</span>
<span id="cb47-65"><a href="#cb47-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-66"><a href="#cb47-66" aria-hidden="true" tabindex="-1"></a>Now, we simply fit the model with the training set and compute its accuracy on the validation set. For this exercise, we use a logistic regression with AIC-based variable selection.</span>
<span id="cb47-67"><a href="#cb47-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-70"><a href="#cb47-70" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-71"><a href="#cb47-71" aria-hidden="true" tabindex="-1"></a>Doc_cv <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_cv_tr, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>()</span>
<span id="cb47-72"><a href="#cb47-72" aria-hidden="true" tabindex="-1"></a>Doc_cv_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_cv, <span class="at">newdata=</span>df_cv_val, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb47-73"><a href="#cb47-73" aria-hidden="true" tabindex="-1"></a>Doc_cv_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_cv_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb47-74"><a href="#cb47-74" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_cv_pred), <span class="at">reference =</span> df_cv_val<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span>
<span id="cb47-75"><a href="#cb47-75" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-76"><a href="#cb47-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-77"><a href="#cb47-77" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb47-78"><a href="#cb47-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-81"><a href="#cb47-81" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-82"><a href="#cb47-82" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the course python environment as usual with a r code chunks.</span></span>
<span id="cb47-83"><a href="#cb47-83" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb47-84"><a href="#cb47-84" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>, <span class="at">required =</span> <span class="cn">TRUE</span>)</span>
<span id="cb47-85"><a href="#cb47-85" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-86"><a href="#cb47-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-87"><a href="#cb47-87" aria-hidden="true" tabindex="-1"></a>We will one-hot encode the categorical variables using <span class="in">`pd.get_dummies()`</span> and then divide the data into <span class="in">`X_train`</span>, <span class="in">`y_train`</span>, <span class="in">`X_test`</span> and <span class="in">`y_test`</span>.</span>
<span id="cb47-88"><a href="#cb47-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-91"><a href="#cb47-91" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-92"><a href="#cb47-92" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb47-93"><a href="#cb47-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-94"><a href="#cb47-94" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encoding the categorical columns</span></span>
<span id="cb47-95"><a href="#cb47-95" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> pd.get_dummies(r.df_tr.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb47-96"><a href="#cb47-96" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> r.df_tr[<span class="st">'visits'</span>]</span>
<span id="cb47-97"><a href="#cb47-97" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> pd.get_dummies(r.df_te.drop(<span class="st">'visits'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb47-98"><a href="#cb47-98" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> r.df_te[<span class="st">'visits'</span>]</span>
<span id="cb47-99"><a href="#cb47-99" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-100"><a href="#cb47-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-101"><a href="#cb47-101" aria-hidden="true" tabindex="-1"></a>Then, we create the folds by using the <span class="in">`KFold`</span> function of <span class="in">`scikit-learn`</span>.</span>
<span id="cb47-102"><a href="#cb47-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-105"><a href="#cb47-105" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-106"><a href="#cb47-106" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb47-107"><a href="#cb47-107" aria-hidden="true" tabindex="-1"></a><span class="co"># We setup the 10-k fold</span></span>
<span id="cb47-108"><a href="#cb47-108" aria-hidden="true" tabindex="-1"></a>kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">346</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb47-109"><a href="#cb47-109" aria-hidden="true" tabindex="-1"></a>fold_indices <span class="op">=</span> <span class="bu">list</span>(kf.split(X_train, y_train))</span>
<span id="cb47-110"><a href="#cb47-110" aria-hidden="true" tabindex="-1"></a>first_fold_train, first_fold_val <span class="op">=</span> fold_indices[<span class="dv">0</span>]</span>
<span id="cb47-111"><a href="#cb47-111" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-112"><a href="#cb47-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-113"><a href="#cb47-113" aria-hidden="true" tabindex="-1"></a>As seen before, the <span class="in">`fold_indices`</span> object is a list of tuple pairs. The first element of the list <span class="in">`fold_indices[0]`</span> corresponds to the first fold. It is the tuple of row indices of the training set and the validation set for the first fold. All the indices that are not in <span class="in">`first_fold_val`</span> will be in the training set (for this fold).</span>
<span id="cb47-114"><a href="#cb47-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-117"><a href="#cb47-117" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-118"><a href="#cb47-118" aria-hidden="true" tabindex="-1"></a>X_cv_tr <span class="op">=</span> X_train.iloc[first_fold_train, :]</span>
<span id="cb47-119"><a href="#cb47-119" aria-hidden="true" tabindex="-1"></a>y_cv_tr <span class="op">=</span> y_train.iloc[first_fold_train]</span>
<span id="cb47-120"><a href="#cb47-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-121"><a href="#cb47-121" aria-hidden="true" tabindex="-1"></a>X_cv_val <span class="op">=</span> X_train.iloc[first_fold_val, :]</span>
<span id="cb47-122"><a href="#cb47-122" aria-hidden="true" tabindex="-1"></a>y_cv_val <span class="op">=</span> y_train.iloc[first_fold_val]</span>
<span id="cb47-123"><a href="#cb47-123" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-124"><a href="#cb47-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-125"><a href="#cb47-125" aria-hidden="true" tabindex="-1"></a>This part, will be slightly different from the R approach. Here, we fit the model with the training set and compute its accuracy on the validation set. For the python approach, we use a logistic regression with recursive feature elimination to select the best number of features.</span>
<span id="cb47-126"><a href="#cb47-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-129"><a href="#cb47-129" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-130"><a href="#cb47-130" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb47-131"><a href="#cb47-131" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, confusion_matrix</span>
<span id="cb47-132"><a href="#cb47-132" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> RFE</span>
<span id="cb47-133"><a href="#cb47-133" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb47-134"><a href="#cb47-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-135"><a href="#cb47-135" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb47-136"><a href="#cb47-136" aria-hidden="true" tabindex="-1"></a>rfe <span class="op">=</span> RFE(model)</span>
<span id="cb47-137"><a href="#cb47-137" aria-hidden="true" tabindex="-1"></a>rfe.fit(X_cv_tr, y_cv_tr)</span>
<span id="cb47-138"><a href="#cb47-138" aria-hidden="true" tabindex="-1"></a>pred_probs <span class="op">=</span> rfe.predict_proba(X_cv_val)[:, <span class="dv">1</span>]</span>
<span id="cb47-139"><a href="#cb47-139" aria-hidden="true" tabindex="-1"></a>Doc_cv_pred <span class="op">=</span> np.where(pred_probs <span class="op">&gt;</span> <span class="fl">0.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb47-140"><a href="#cb47-140" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> accuracy_score(y_cv_val, Doc_cv_pred)</span>
<span id="cb47-141"><a href="#cb47-141" aria-hidden="true" tabindex="-1"></a>acc</span>
<span id="cb47-142"><a href="#cb47-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-143"><a href="#cb47-143" aria-hidden="true" tabindex="-1"></a><span class="co"># alternatively, you could use `cross_val_score`</span></span>
<span id="cb47-144"><a href="#cb47-144" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.model_selection import cross_val_score</span></span>
<span id="cb47-145"><a href="#cb47-145" aria-hidden="true" tabindex="-1"></a><span class="co"># cv_scores = cross_val_score(rfe, X_cv_tr, y_cv_tr, cv=kf, scoring="accuracy")</span></span>
<span id="cb47-146"><a href="#cb47-146" aria-hidden="true" tabindex="-1"></a><span class="co"># cv_scores</span></span>
<span id="cb47-147"><a href="#cb47-147" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-148"><a href="#cb47-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-149"><a href="#cb47-149" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb47-150"><a href="#cb47-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-151"><a href="#cb47-151" aria-hidden="true" tabindex="-1"></a><span class="fu">## Loop on the 10 folds</span></span>
<span id="cb47-152"><a href="#cb47-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-153"><a href="#cb47-153" aria-hidden="true" tabindex="-1"></a>Now we repeat the previous steps for all the folds.</span>
<span id="cb47-154"><a href="#cb47-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-155"><a href="#cb47-155" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb47-156"><a href="#cb47-156" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb47-157"><a href="#cb47-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-158"><a href="#cb47-158" aria-hidden="true" tabindex="-1"></a>In order to track the 10 accuracy measures obtained, we store them into a vector (<span class="in">`acc_vec`</span>). Note also that the option <span class="in">`trace=0`</span> was set in the function <span class="in">`step`</span> to avoid all the print outs of the AIC selections.</span>
<span id="cb47-159"><a href="#cb47-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-162"><a href="#cb47-162" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-163"><a href="#cb47-163" aria-hidden="true" tabindex="-1"></a>acc_vec <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">10</span>)</span>
<span id="cb47-164"><a href="#cb47-164" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>){</span>
<span id="cb47-165"><a href="#cb47-165" aria-hidden="true" tabindex="-1"></a>  df_cv_tr <span class="ot">&lt;-</span> df_tr[<span class="sc">-</span>index_CV[[i]],]</span>
<span id="cb47-166"><a href="#cb47-166" aria-hidden="true" tabindex="-1"></a>  df_cv_val <span class="ot">&lt;-</span> df_tr[index_CV[[i]],]</span>
<span id="cb47-167"><a href="#cb47-167" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-168"><a href="#cb47-168" aria-hidden="true" tabindex="-1"></a>  Doc_cv <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_cv_tr, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>(<span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb47-169"><a href="#cb47-169" aria-hidden="true" tabindex="-1"></a>  Doc_cv_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_cv, <span class="at">newdata=</span>df_cv_val, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb47-170"><a href="#cb47-170" aria-hidden="true" tabindex="-1"></a>  Doc_cv_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_cv_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb47-171"><a href="#cb47-171" aria-hidden="true" tabindex="-1"></a>  acc_vec[i] <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_cv_pred), <span class="at">reference =</span> df_cv_val<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span>
<span id="cb47-172"><a href="#cb47-172" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb47-173"><a href="#cb47-173" aria-hidden="true" tabindex="-1"></a>acc_vec</span>
<span id="cb47-174"><a href="#cb47-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-175"><a href="#cb47-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-176"><a href="#cb47-176" aria-hidden="true" tabindex="-1"></a>By definition of the CV, all the 10 validations sets in this loop are disjoints. Thus, these 10 accuracy measures are in a way representative of what can be expected on the test set, except if we are very unlucky when we created the test set.</span>
<span id="cb47-177"><a href="#cb47-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-178"><a href="#cb47-178" aria-hidden="true" tabindex="-1"></a>Now we can estimate the expected accuracy (i.e., the mean) and its variation (below we use the standard deviation).</span>
<span id="cb47-179"><a href="#cb47-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-182"><a href="#cb47-182" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-183"><a href="#cb47-183" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(acc_vec)</span>
<span id="cb47-184"><a href="#cb47-184" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(acc_vec)</span>
<span id="cb47-185"><a href="#cb47-185" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-186"><a href="#cb47-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-187"><a href="#cb47-187" aria-hidden="true" tabindex="-1"></a>The small SD shows that the results are reliable and that we have good chance that the model, trained on the whole training set, will have this accuracy on the test set.</span>
<span id="cb47-188"><a href="#cb47-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-189"><a href="#cb47-189" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb47-190"><a href="#cb47-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-191"><a href="#cb47-191" aria-hidden="true" tabindex="-1"></a>For python, in order to track the 10 accuracy measures obtained, we store them into a list (<span class="in">`acc_list`</span>).</span>
<span id="cb47-192"><a href="#cb47-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-195"><a href="#cb47-195" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-196"><a href="#cb47-196" aria-hidden="true" tabindex="-1"></a>acc_list <span class="op">=</span> []</span>
<span id="cb47-197"><a href="#cb47-197" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> train_idx, val_idx <span class="kw">in</span> kf.split(X_train, y_train):</span>
<span id="cb47-198"><a href="#cb47-198" aria-hidden="true" tabindex="-1"></a>    X_cv_tr, y_cv_tr <span class="op">=</span> X_train.iloc[train_idx, :], y_train.iloc[train_idx]</span>
<span id="cb47-199"><a href="#cb47-199" aria-hidden="true" tabindex="-1"></a>    X_cv_val, y_cv_val <span class="op">=</span> X_train.iloc[val_idx, :], y_train.iloc[val_idx]</span>
<span id="cb47-200"><a href="#cb47-200" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb47-201"><a href="#cb47-201" aria-hidden="true" tabindex="-1"></a>    rfe.fit(X_cv_tr, y_cv_tr)</span>
<span id="cb47-202"><a href="#cb47-202" aria-hidden="true" tabindex="-1"></a>    pred_probs <span class="op">=</span> rfe.predict_proba(X_cv_val)[:, <span class="dv">1</span>]</span>
<span id="cb47-203"><a href="#cb47-203" aria-hidden="true" tabindex="-1"></a>    Doc_cv_pred <span class="op">=</span> np.where(pred_probs <span class="op">&gt;</span> <span class="fl">0.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>)</span>
<span id="cb47-204"><a href="#cb47-204" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> accuracy_score(y_cv_val, Doc_cv_pred)</span>
<span id="cb47-205"><a href="#cb47-205" aria-hidden="true" tabindex="-1"></a>    acc_list.append(acc)</span>
<span id="cb47-206"><a href="#cb47-206" aria-hidden="true" tabindex="-1"></a>acc_list</span>
<span id="cb47-207"><a href="#cb47-207" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-208"><a href="#cb47-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-209"><a href="#cb47-209" aria-hidden="true" tabindex="-1"></a>Once again, we can estimate the expected accuracy and its variation.</span>
<span id="cb47-210"><a href="#cb47-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-213"><a href="#cb47-213" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-214"><a href="#cb47-214" aria-hidden="true" tabindex="-1"></a>mean_acc <span class="op">=</span> np.mean(acc_list)</span>
<span id="cb47-215"><a href="#cb47-215" aria-hidden="true" tabindex="-1"></a>std_acc <span class="op">=</span> np.std(acc_list)</span>
<span id="cb47-216"><a href="#cb47-216" aria-hidden="true" tabindex="-1"></a>mean_acc, std_acc</span>
<span id="cb47-217"><a href="#cb47-217" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-218"><a href="#cb47-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-219"><a href="#cb47-219" aria-hidden="true" tabindex="-1"></a>Now, we fit the final model using the whole training set and evaluate its performance on the test set.</span>
<span id="cb47-220"><a href="#cb47-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-223"><a href="#cb47-223" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-224"><a href="#cb47-224" aria-hidden="true" tabindex="-1"></a>rfe.fit(X_train, y_train)</span>
<span id="cb47-225"><a href="#cb47-225" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> rfe.predict(X_test)</span>
<span id="cb47-226"><a href="#cb47-226" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="op">=</span> accuracy_score(y_test, y_test_pred)</span>
<span id="cb47-227"><a href="#cb47-227" aria-hidden="true" tabindex="-1"></a>test_cm <span class="op">=</span> confusion_matrix(y_test, y_test_pred)</span>
<span id="cb47-228"><a href="#cb47-228" aria-hidden="true" tabindex="-1"></a>test_accuracy, test_cm</span>
<span id="cb47-229"><a href="#cb47-229" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-230"><a href="#cb47-230" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb47-231"><a href="#cb47-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-232"><a href="#cb47-232" aria-hidden="true" tabindex="-1"></a><span class="fu">## Automated approach</span></span>
<span id="cb47-233"><a href="#cb47-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-234"><a href="#cb47-234" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb47-235"><a href="#cb47-235" aria-hidden="true" tabindex="-1"></a><span class="fu">### R - `caret`</span></span>
<span id="cb47-236"><a href="#cb47-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-237"><a href="#cb47-237" aria-hidden="true" tabindex="-1"></a>The 10-CV can be easily obtained from <span class="in">`caret`</span>. First, set up the splitting data method using the <span class="in">`trainControl`</span> function.</span>
<span id="cb47-238"><a href="#cb47-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-241"><a href="#cb47-241" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-242"><a href="#cb47-242" aria-hidden="true" tabindex="-1"></a>trctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number=</span><span class="dv">10</span>)</span>
<span id="cb47-243"><a href="#cb47-243" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-244"><a href="#cb47-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-245"><a href="#cb47-245" aria-hidden="true" tabindex="-1"></a>Then pass this method to the <span class="in">`train`</span> function (from <span class="in">`caret`</span>). In addition, we use the model (below unhappily called "method" also) <span class="in">`glmStepAIC`</span> which, combined with the <span class="in">`binomial`</span> family, applies a logistic regression and a AIC-based variable selection (backward; exactly like the <span class="in">`step`</span> function used above). Of course, we also provide the model formula.</span>
<span id="cb47-246"><a href="#cb47-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-249"><a href="#cb47-249" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-250"><a href="#cb47-250" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">346</span>)</span>
<span id="cb47-251"><a href="#cb47-251" aria-hidden="true" tabindex="-1"></a>Doc_cv <span class="ot">&lt;-</span> <span class="fu">train</span>(visits <span class="sc">~</span>., <span class="at">data =</span> df_tr, <span class="at">method =</span> <span class="st">"glmStepAIC"</span>, <span class="at">family=</span><span class="st">"binomial"</span>,</span>
<span id="cb47-252"><a href="#cb47-252" aria-hidden="true" tabindex="-1"></a>                    <span class="at">trControl=</span>trctrl, <span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb47-253"><a href="#cb47-253" aria-hidden="true" tabindex="-1"></a>Doc_cv</span>
<span id="cb47-254"><a href="#cb47-254" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-255"><a href="#cb47-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-256"><a href="#cb47-256" aria-hidden="true" tabindex="-1"></a>Note that the function "only" provides the expected accuracy and the expected kappa. It does not provides their standard deviations.</span>
<span id="cb47-257"><a href="#cb47-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-258"><a href="#cb47-258" aria-hidden="true" tabindex="-1"></a>The final model (i.e., the model trained on the whole training set <span class="in">`df_tr`</span>) is stored in <span class="in">`Doc_cv$finalModel`</span>. It can be used to compute the accuracy on the test set.</span>
<span id="cb47-259"><a href="#cb47-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-262"><a href="#cb47-262" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-263"><a href="#cb47-263" aria-hidden="true" tabindex="-1"></a>Doc_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_cv, <span class="at">newdata =</span> df_te)</span>
<span id="cb47-264"><a href="#cb47-264" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>Doc_pred, <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb47-265"><a href="#cb47-265" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-266"><a href="#cb47-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-267"><a href="#cb47-267" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python - `sklearn`</span></span>
<span id="cb47-268"><a href="#cb47-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-269"><a href="#cb47-269" aria-hidden="true" tabindex="-1"></a>In python, a similar approach demonstrated in <span class="in">`caret`</span> would be using <span class="in">`GridSearchCV`</span> from <span class="in">`scikit-learn`</span>. We use the same 10-CV <span class="in">`kf`</span> object created earlier. Then pass this method to the <span class="in">`GridSearchCV`</span> function with <span class="in">`LogisticRegression`</span> model with <span class="in">`RFE`</span> for feature selection with the grid of parameters we would like to search for (in this case the number of features). Then, we output the (hyper-)parameters with the best performance.</span>
<span id="cb47-270"><a href="#cb47-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-273"><a href="#cb47-273" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-274"><a href="#cb47-274" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb47-275"><a href="#cb47-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-276"><a href="#cb47-276" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb47-277"><a href="#cb47-277" aria-hidden="true" tabindex="-1"></a>rfe <span class="op">=</span> RFE(model)</span>
<span id="cb47-278"><a href="#cb47-278" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'n_features_to_select'</span>: <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, X_train.shape[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">1</span>))}</span>
<span id="cb47-279"><a href="#cb47-279" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(rfe, param_grid, scoring<span class="op">=</span><span class="st">'accuracy'</span>, cv<span class="op">=</span>kf)</span>
<span id="cb47-280"><a href="#cb47-280" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span>
<span id="cb47-281"><a href="#cb47-281" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(grid_search.best_score_, grid_search.best_params_)</span>
<span id="cb47-282"><a href="#cb47-282" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-283"><a href="#cb47-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-284"><a href="#cb47-284" aria-hidden="true" tabindex="-1"></a>The final model (i.e., the model trained on the whole training set <span class="in">`X_train`</span>) is stored in <span class="in">`grid_search.best_estimator_`</span>. It can be used to compute the accuracy on the test set.</span>
<span id="cb47-285"><a href="#cb47-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-288"><a href="#cb47-288" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-289"><a href="#cb47-289" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> grid_search.best_estimator_.predict(X_test)</span>
<span id="cb47-290"><a href="#cb47-290" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="op">=</span> accuracy_score(y_test, y_test_pred)</span>
<span id="cb47-291"><a href="#cb47-291" aria-hidden="true" tabindex="-1"></a>test_cm <span class="op">=</span> confusion_matrix(y_test, y_test_pred)</span>
<span id="cb47-292"><a href="#cb47-292" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_accuracy, test_cm)</span>
<span id="cb47-293"><a href="#cb47-293" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-294"><a href="#cb47-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-295"><a href="#cb47-295" aria-hidden="true" tabindex="-1"></a>Our results did improve compared to the last python model.</span>
<span id="cb47-296"><a href="#cb47-296" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb47-297"><a href="#cb47-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-298"><a href="#cb47-298" aria-hidden="true" tabindex="-1"></a><span class="fu"># Bootstrap with 100 replicates</span></span>
<span id="cb47-299"><a href="#cb47-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-300"><a href="#cb47-300" aria-hidden="true" tabindex="-1"></a>We now apply the bootstrap with 100 replicates. Like for CV, we first make it by hand and then we use some kind of automated approach like <span class="in">`caret`</span>.</span>
<span id="cb47-301"><a href="#cb47-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-302"><a href="#cb47-302" aria-hidden="true" tabindex="-1"></a><span class="fu">## First sample</span></span>
<span id="cb47-303"><a href="#cb47-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-304"><a href="#cb47-304" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb47-305"><a href="#cb47-305" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb47-306"><a href="#cb47-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-307"><a href="#cb47-307" aria-hidden="true" tabindex="-1"></a>We need to first create the replicates using the <span class="in">`caret`</span> function <span class="in">`createResample`</span>.</span>
<span id="cb47-308"><a href="#cb47-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-311"><a href="#cb47-311" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-312"><a href="#cb47-312" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">897</span>)</span>
<span id="cb47-313"><a href="#cb47-313" aria-hidden="true" tabindex="-1"></a>index_boot <span class="ot">&lt;-</span> <span class="fu">createResample</span>(<span class="at">y=</span>df_tr<span class="sc">$</span>visits, <span class="at">times=</span><span class="dv">100</span>)</span>
<span id="cb47-314"><a href="#cb47-314" aria-hidden="true" tabindex="-1"></a>index_boot[[<span class="dv">1</span>]]</span>
<span id="cb47-315"><a href="#cb47-315" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-316"><a href="#cb47-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-317"><a href="#cb47-317" aria-hidden="true" tabindex="-1"></a>Again, it creates a list of indices. The first element of the list, <span class="in">`index_boot[[1]]`</span>, contains the row indices that will be in the training set. Note that, it is of length 4,153. In other words, the training set during this first replicate is of the same dimension as the whole training set <span class="in">`df_tr`</span>. Note also that, in <span class="in">`index_boot[[1]]`</span>, there are indices that are replicated. This is the bootstrap sampling process. Some rows will be replicated in the training set. This also means that some rows of <span class="in">`df_tr`</span> will not be in <span class="in">`index_boot[[1]]`</span>. These rows are said to be <span class="in">`out-of-bag`</span> and form the validation set. See below the dimensions of the data frames.</span>
<span id="cb47-318"><a href="#cb47-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-321"><a href="#cb47-321" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-322"><a href="#cb47-322" aria-hidden="true" tabindex="-1"></a>df_boot_tr <span class="ot">&lt;-</span> df_tr[index_boot[[<span class="dv">1</span>]],]</span>
<span id="cb47-323"><a href="#cb47-323" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(df_boot_tr)</span>
<span id="cb47-324"><a href="#cb47-324" aria-hidden="true" tabindex="-1"></a>df_boot_val <span class="ot">&lt;-</span> df_tr[<span class="sc">-</span>index_boot[[<span class="dv">1</span>]],]</span>
<span id="cb47-325"><a href="#cb47-325" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(df_boot_val)</span>
<span id="cb47-326"><a href="#cb47-326" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-327"><a href="#cb47-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-328"><a href="#cb47-328" aria-hidden="true" tabindex="-1"></a>We now fit the data to this first sample training set.</span>
<span id="cb47-329"><a href="#cb47-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-332"><a href="#cb47-332" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-333"><a href="#cb47-333" aria-hidden="true" tabindex="-1"></a>Doc_boot <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_boot_tr, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>()</span>
<span id="cb47-334"><a href="#cb47-334" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-335"><a href="#cb47-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-336"><a href="#cb47-336" aria-hidden="true" tabindex="-1"></a>The accuracy is then computed with the 632-rule: first, the apparent accuracy is computed (accuracy on the sample training set), then the out-of-bag accuracy (the accuracy on the validation set), then the final accuracy estimate is the 0.368/0.632-combination of the two.</span>
<span id="cb47-337"><a href="#cb47-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-340"><a href="#cb47-340" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-341"><a href="#cb47-341" aria-hidden="true" tabindex="-1"></a>Doc_boot_prob_val <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_boot, <span class="at">newdata=</span>df_boot_val, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb47-342"><a href="#cb47-342" aria-hidden="true" tabindex="-1"></a>Doc_boot_pred_val <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_boot_prob_val<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb47-343"><a href="#cb47-343" aria-hidden="true" tabindex="-1"></a>oob_acc <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_boot_pred_val), <span class="at">reference =</span> df_boot_val<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span>
<span id="cb47-344"><a href="#cb47-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-345"><a href="#cb47-345" aria-hidden="true" tabindex="-1"></a>Doc_boot_prob_tr <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_boot, <span class="at">newdata=</span>df_boot_tr, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb47-346"><a href="#cb47-346" aria-hidden="true" tabindex="-1"></a>Doc_boot_pred_tr <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_boot_prob_tr<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb47-347"><a href="#cb47-347" aria-hidden="true" tabindex="-1"></a>app_acc <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_boot_pred_tr), <span class="at">reference =</span> df_boot_tr<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span>
<span id="cb47-348"><a href="#cb47-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-349"><a href="#cb47-349" aria-hidden="true" tabindex="-1"></a>oob_acc <span class="do">## out-of-bag accuracy</span></span>
<span id="cb47-350"><a href="#cb47-350" aria-hidden="true" tabindex="-1"></a>app_acc <span class="do">## apparent accuracy</span></span>
<span id="cb47-351"><a href="#cb47-351" aria-hidden="true" tabindex="-1"></a><span class="fl">0.368</span><span class="sc">*</span>app_acc <span class="sc">+</span> <span class="fl">0.632</span><span class="sc">*</span>oob_acc <span class="do">## accuracy estimate</span></span>
<span id="cb47-352"><a href="#cb47-352" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-353"><a href="#cb47-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-354"><a href="#cb47-354" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb47-355"><a href="#cb47-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-356"><a href="#cb47-356" aria-hidden="true" tabindex="-1"></a>First, we create the replicates using the <span class="in">`resample`</span> function from <span class="in">`sklearn.utils`</span>. Please note that unlike <span class="in">`caret::createResample()`</span>, in <span class="in">`sklearn`</span> (to the best of our knowledge), there's no method that returns a list of the samples, so with <span class="in">`resample`</span>, we get one set of resampled data points. This doesn't matter for now, but in the following sub-section, we will write a function to do the same thing in python.</span>
<span id="cb47-357"><a href="#cb47-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-360"><a href="#cb47-360" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-361"><a href="#cb47-361" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils <span class="im">import</span> resample</span>
<span id="cb47-362"><a href="#cb47-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-363"><a href="#cb47-363" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">897</span>)</span>
<span id="cb47-364"><a href="#cb47-364" aria-hidden="true" tabindex="-1"></a>df_boot_tr <span class="op">=</span> resample(r.df_tr, n_samples<span class="op">=</span><span class="bu">len</span>(r.df_tr), random_state<span class="op">=</span><span class="dv">897</span>)</span>
<span id="cb47-365"><a href="#cb47-365" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-366"><a href="#cb47-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-367"><a href="#cb47-367" aria-hidden="true" tabindex="-1"></a>The <span class="in">`resample`</span> function returns a new data frames with the same number of samples as the original <span class="in">`r.df_tr`</span>, but some rows will be replicated. This also means that some rows of <span class="in">`r.df_tr`</span> will not be in the bootstrapped data frames These rows are said to be <span class="in">`out-of-bag`</span> and form the validation set. See below the dimensions of the data frames.</span>
<span id="cb47-368"><a href="#cb47-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-371"><a href="#cb47-371" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-372"><a href="#cb47-372" aria-hidden="true" tabindex="-1"></a>df_boot_tr.shape</span>
<span id="cb47-373"><a href="#cb47-373" aria-hidden="true" tabindex="-1"></a>oob_mask <span class="op">=</span> <span class="op">~</span>r.df_tr.index.isin(df_boot_tr.index.values)</span>
<span id="cb47-374"><a href="#cb47-374" aria-hidden="true" tabindex="-1"></a>df_boot_val <span class="op">=</span> r.df_tr[oob_mask]</span>
<span id="cb47-375"><a href="#cb47-375" aria-hidden="true" tabindex="-1"></a>df_boot_val.shape</span>
<span id="cb47-376"><a href="#cb47-376" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-377"><a href="#cb47-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-378"><a href="#cb47-378" aria-hidden="true" tabindex="-1"></a>There's a difference between the shape of <span class="in">`df_boot_val`</span> because of the difference in random generators between R &amp; python. If you change the number for the random generator in python (i.e., <span class="in">`np.random.seed(897)`</span>) or in R (i.e., <span class="in">`set.seed(897)`</span>), you'll see that the results will be slightly different.</span>
<span id="cb47-379"><a href="#cb47-379" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb47-380"><a href="#cb47-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-381"><a href="#cb47-381" aria-hidden="true" tabindex="-1"></a><span class="fu">## Loop on the 100 sample</span></span>
<span id="cb47-382"><a href="#cb47-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-383"><a href="#cb47-383" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb47-384"><a href="#cb47-384" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb47-385"><a href="#cb47-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-386"><a href="#cb47-386" aria-hidden="true" tabindex="-1"></a>The previous code is looped. The accuracy measures are stored in vectors. The code can be quite long to run.</span>
<span id="cb47-387"><a href="#cb47-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-390"><a href="#cb47-390" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-391"><a href="#cb47-391" aria-hidden="true" tabindex="-1"></a>oob_acc_vec <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb47-392"><a href="#cb47-392" aria-hidden="true" tabindex="-1"></a>app_acc_vec <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb47-393"><a href="#cb47-393" aria-hidden="true" tabindex="-1"></a>acc_vec <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">100</span>)</span>
<span id="cb47-394"><a href="#cb47-394" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb47-395"><a href="#cb47-395" aria-hidden="true" tabindex="-1"></a>  df_boot_tr <span class="ot">&lt;-</span> df_tr[index_boot[[i]],]</span>
<span id="cb47-396"><a href="#cb47-396" aria-hidden="true" tabindex="-1"></a>  df_boot_val <span class="ot">&lt;-</span> df_tr[<span class="sc">-</span>index_boot[[i]],]</span>
<span id="cb47-397"><a href="#cb47-397" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-398"><a href="#cb47-398" aria-hidden="true" tabindex="-1"></a>  Doc_boot <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_boot_tr, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>(<span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb47-399"><a href="#cb47-399" aria-hidden="true" tabindex="-1"></a>  Doc_boot_prob_val <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_boot, <span class="at">newdata=</span>df_boot_val, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb47-400"><a href="#cb47-400" aria-hidden="true" tabindex="-1"></a>  Doc_boot_pred_val <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_boot_prob_val<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb47-401"><a href="#cb47-401" aria-hidden="true" tabindex="-1"></a>  oob_acc_vec[i] <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_boot_pred_val), <span class="at">reference =</span> df_boot_val<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span>
<span id="cb47-402"><a href="#cb47-402" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-403"><a href="#cb47-403" aria-hidden="true" tabindex="-1"></a>  Doc_boot_prob_tr <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_boot, <span class="at">newdata=</span>df_boot_tr, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb47-404"><a href="#cb47-404" aria-hidden="true" tabindex="-1"></a>  Doc_boot_pred_tr <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_boot_prob_tr<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb47-405"><a href="#cb47-405" aria-hidden="true" tabindex="-1"></a>  app_acc_vec[i] <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_boot_pred_tr), <span class="at">reference =</span> df_boot_tr<span class="sc">$</span>visits)<span class="sc">$</span>overall[<span class="dv">1</span>]</span>
<span id="cb47-406"><a href="#cb47-406" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-407"><a href="#cb47-407" aria-hidden="true" tabindex="-1"></a>  acc_vec[i] <span class="ot">&lt;-</span> <span class="fl">0.368</span><span class="sc">*</span>app_acc_vec[i] <span class="sc">+</span> <span class="fl">0.632</span><span class="sc">*</span>oob_acc_vec[i]</span>
<span id="cb47-408"><a href="#cb47-408" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb47-409"><a href="#cb47-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-410"><a href="#cb47-410" aria-hidden="true" tabindex="-1"></a>acc_vec</span>
<span id="cb47-411"><a href="#cb47-411" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-412"><a href="#cb47-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-413"><a href="#cb47-413" aria-hidden="true" tabindex="-1"></a>Like for the CV, we can estimate the expected accuracy and its dispersion.</span>
<span id="cb47-414"><a href="#cb47-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-417"><a href="#cb47-417" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-418"><a href="#cb47-418" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(acc_vec)</span>
<span id="cb47-419"><a href="#cb47-419" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(acc_vec)</span>
<span id="cb47-420"><a href="#cb47-420" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-421"><a href="#cb47-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-422"><a href="#cb47-422" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb47-423"><a href="#cb47-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-424"><a href="#cb47-424" aria-hidden="true" tabindex="-1"></a>In this part of the code, we perform the bootstrap procedure with 100 samples. To that, we will implement our own function to create the index n-times for a given dataset. This ensures that we get a similar output to <span class="in">`caret::createResample()`</span>. In this case, we apply this function to our main training dataframe 100 times.</span>
<span id="cb47-425"><a href="#cb47-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-428"><a href="#cb47-428" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-429"><a href="#cb47-429" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_resample(data, times<span class="op">=</span><span class="dv">100</span>, random_seed<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb47-430"><a href="#cb47-430" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If you're not familiar with the documentation below, they are called</span></span>
<span id="cb47-431"><a href="#cb47-431" aria-hidden="true" tabindex="-1"></a>    <span class="co"># `docstrings` and whenever you ask help for a function or see it's documentation,</span></span>
<span id="cb47-432"><a href="#cb47-432" aria-hidden="true" tabindex="-1"></a>    <span class="co"># they are generated from that</span></span>
<span id="cb47-433"><a href="#cb47-433" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb47-434"><a href="#cb47-434" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate bootstrap sample indices for data.</span></span>
<span id="cb47-435"><a href="#cb47-435" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb47-436"><a href="#cb47-436" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb47-437"><a href="#cb47-437" aria-hidden="true" tabindex="-1"></a><span class="co">    - data (array-like): The data to bootstrap.</span></span>
<span id="cb47-438"><a href="#cb47-438" aria-hidden="true" tabindex="-1"></a><span class="co">    - times (int): The number of bootstrap samples to generate.</span></span>
<span id="cb47-439"><a href="#cb47-439" aria-hidden="true" tabindex="-1"></a><span class="co">    - random_seed (int): The random seed to use for reproducibility.</span></span>
<span id="cb47-440"><a href="#cb47-440" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb47-441"><a href="#cb47-441" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb47-442"><a href="#cb47-442" aria-hidden="true" tabindex="-1"></a><span class="co">    - samples (list of arrays): A list of times bootstrap sample indices.</span></span>
<span id="cb47-443"><a href="#cb47-443" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb47-444"><a href="#cb47-444" aria-hidden="true" tabindex="-1"></a>    np.random.seed(random_seed)</span>
<span id="cb47-445"><a href="#cb47-445" aria-hidden="true" tabindex="-1"></a>    n_samples <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb47-446"><a href="#cb47-446" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> []</span>
<span id="cb47-447"><a href="#cb47-447" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(times):</span>
<span id="cb47-448"><a href="#cb47-448" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> np.random.choice(n_samples, n_samples, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb47-449"><a href="#cb47-449" aria-hidden="true" tabindex="-1"></a>        samples.append(indices)</span>
<span id="cb47-450"><a href="#cb47-450" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> samples</span>
<span id="cb47-451"><a href="#cb47-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-452"><a href="#cb47-452" aria-hidden="true" tabindex="-1"></a><span class="co"># apply the new created function</span></span>
<span id="cb47-453"><a href="#cb47-453" aria-hidden="true" tabindex="-1"></a>index_boot <span class="op">=</span> create_resample(r.df_tr, times<span class="op">=</span><span class="dv">100</span>, random_seed <span class="op">=</span> <span class="dv">123</span>)</span>
<span id="cb47-454"><a href="#cb47-454" aria-hidden="true" tabindex="-1"></a><span class="co"># we can see if we successfully replicated the sampling process 100 times</span></span>
<span id="cb47-455"><a href="#cb47-455" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(index_boot))</span>
<span id="cb47-456"><a href="#cb47-456" aria-hidden="true" tabindex="-1"></a><span class="co"># check if we have the correct number of rows (e.g. for the first element)</span></span>
<span id="cb47-457"><a href="#cb47-457" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(index_boot[<span class="dv">0</span>]))</span>
<span id="cb47-458"><a href="#cb47-458" aria-hidden="true" tabindex="-1"></a><span class="co"># alternatively to see this information, you can uncomment &amp; run the code below</span></span>
<span id="cb47-459"><a href="#cb47-459" aria-hidden="true" tabindex="-1"></a><span class="co"># np.asarray(index_boot).shape</span></span>
<span id="cb47-460"><a href="#cb47-460" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-461"><a href="#cb47-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-462"><a href="#cb47-462" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb47-463"><a href="#cb47-463" aria-hidden="true" tabindex="-1"></a>One thing to note is that we could have used the <span class="in">`sklearn.utils.resample`</span> introduced earlier to directly get a list of dataframes with the randomly chosen indices. The issue here would be rather a computational one, as we have to extract the rows many times from the dataset and then hold all this data in memory, which is redundant. So although this may not be a problem for 100 replications, it can quickly start to become an issue if you want to replicated many more times (e.g., 100,000 times). The best approach is to get the indices, and then subset the rows only when needed.</span>
<span id="cb47-464"><a href="#cb47-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-465"><a href="#cb47-465" aria-hidden="true" tabindex="-1"></a><span class="in">```{python, eval = F}</span></span>
<span id="cb47-466"><a href="#cb47-466" aria-hidden="true" tabindex="-1"></a><span class="in">import numpy as np</span></span>
<span id="cb47-467"><a href="#cb47-467" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.utils import resample</span></span>
<span id="cb47-468"><a href="#cb47-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-469"><a href="#cb47-469" aria-hidden="true" tabindex="-1"></a><span class="in">def create_n_resamples(data, times, random_seed=None):</span></span>
<span id="cb47-470"><a href="#cb47-470" aria-hidden="true" tabindex="-1"></a><span class="in">    """</span></span>
<span id="cb47-471"><a href="#cb47-471" aria-hidden="true" tabindex="-1"></a><span class="in">    Generate n_bootstraps bootstrap samples of data.</span></span>
<span id="cb47-472"><a href="#cb47-472" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb47-473"><a href="#cb47-473" aria-hidden="true" tabindex="-1"></a><span class="in">    Args:</span></span>
<span id="cb47-474"><a href="#cb47-474" aria-hidden="true" tabindex="-1"></a><span class="in">    - data (array-like): The data to bootstrap.</span></span>
<span id="cb47-475"><a href="#cb47-475" aria-hidden="true" tabindex="-1"></a><span class="in">    - n_bootstraps (int): The number of bootstrap samples to generate.</span></span>
<span id="cb47-476"><a href="#cb47-476" aria-hidden="true" tabindex="-1"></a><span class="in">    - random_seed (int): The random seed to use for reproducibility.</span></span>
<span id="cb47-477"><a href="#cb47-477" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb47-478"><a href="#cb47-478" aria-hidden="true" tabindex="-1"></a><span class="in">    Returns:</span></span>
<span id="cb47-479"><a href="#cb47-479" aria-hidden="true" tabindex="-1"></a><span class="in">    - bootstrap_samples (list of lists): A list of n_bootstraps bootstrap samples.</span></span>
<span id="cb47-480"><a href="#cb47-480" aria-hidden="true" tabindex="-1"></a><span class="in">    """</span></span>
<span id="cb47-481"><a href="#cb47-481" aria-hidden="true" tabindex="-1"></a><span class="in">    np.random.seed(random_seed)</span></span>
<span id="cb47-482"><a href="#cb47-482" aria-hidden="true" tabindex="-1"></a><span class="in">    bootstrap_samples = []</span></span>
<span id="cb47-483"><a href="#cb47-483" aria-hidden="true" tabindex="-1"></a><span class="in">    for i in range(times):</span></span>
<span id="cb47-484"><a href="#cb47-484" aria-hidden="true" tabindex="-1"></a><span class="in">        sample = resample(data)</span></span>
<span id="cb47-485"><a href="#cb47-485" aria-hidden="true" tabindex="-1"></a><span class="in">        bootstrap_samples.append(sample)</span></span>
<span id="cb47-486"><a href="#cb47-486" aria-hidden="true" tabindex="-1"></a><span class="in">    return bootstrap_samples</span></span>
<span id="cb47-487"><a href="#cb47-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-488"><a href="#cb47-488" aria-hidden="true" tabindex="-1"></a><span class="in">dfs_boot = create_n_resamples(r.df_tr, times=100, random_seed = 123) </span></span>
<span id="cb47-489"><a href="#cb47-489" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-490"><a href="#cb47-490" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb47-491"><a href="#cb47-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-492"><a href="#cb47-492" aria-hidden="true" tabindex="-1"></a>For each sample, we calculate the out-of-bag accuracy, the apparent accuracy, and the final accuracy estimate using the 0.368/0.632 rule. This is done using a loop that iterates 100 times, once for each bootstrap sample. The steps that the code follows are similar to R, and are outlined below:</span>
<span id="cb47-493"><a href="#cb47-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-494"><a href="#cb47-494" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>We set up three arrays to store the out-of-bag accuracy, the apparent accuracy, and the final accuracy estimate for each of the 100 bootstrap samples.</span>
<span id="cb47-495"><a href="#cb47-495" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>In the loop, we perform the following steps for each bootstrap sample:</span>
<span id="cb47-496"><a href="#cb47-496" aria-hidden="true" tabindex="-1"></a>    a.  Use the generate a random list of indices with replacement, which forms the bootstrap training set.</span>
<span id="cb47-497"><a href="#cb47-497" aria-hidden="true" tabindex="-1"></a>    b.  Create a mask to extract the out-of-bag (validation) set from the original training set.</span>
<span id="cb47-498"><a href="#cb47-498" aria-hidden="true" tabindex="-1"></a>    c.  Train the logistic regression model with RFE on the bootstrap training set.</span>
<span id="cb47-499"><a href="#cb47-499" aria-hidden="true" tabindex="-1"></a>    d.  Compute the out-of-bag accuracy by predicting on the validation set and comparing the predicted labels to the true labels.</span>
<span id="cb47-500"><a href="#cb47-500" aria-hidden="true" tabindex="-1"></a>    e.  Compute the apparent accuracy by predicting on the bootstrap training set and comparing the predicted labels to the true labels.</span>
<span id="cb47-501"><a href="#cb47-501" aria-hidden="true" tabindex="-1"></a>    f.  Calculate the final accuracy estimate for the current bootstrap sample using the 0.368/0.632 rule.</span>
<span id="cb47-502"><a href="#cb47-502" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Once the loop is complete, the <span class="in">`acc_vec`</span> array will contain the final accuracy estimates for all 100 bootstrap samples. We can then calculate the mean and standard deviation of these accuracy estimates to get an overall understanding of the model's performance.</span>
<span id="cb47-503"><a href="#cb47-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-506"><a href="#cb47-506" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-507"><a href="#cb47-507" aria-hidden="true" tabindex="-1"></a><span class="co"># we one-hote encode the categorical variables</span></span>
<span id="cb47-508"><a href="#cb47-508" aria-hidden="true" tabindex="-1"></a><span class="co">## notice that we didn't use the argument `drop_first` before, since this is like</span></span>
<span id="cb47-509"><a href="#cb47-509" aria-hidden="true" tabindex="-1"></a><span class="co">## making dummy variable m - 1 where m is the number of variables you have</span></span>
<span id="cb47-510"><a href="#cb47-510" aria-hidden="true" tabindex="-1"></a>r.df_tr_encoded <span class="op">=</span> pd.get_dummies(r.df_tr, drop_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb47-511"><a href="#cb47-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-512"><a href="#cb47-512" aria-hidden="true" tabindex="-1"></a>oob_acc_vec <span class="op">=</span> np.zeros(<span class="dv">100</span>)</span>
<span id="cb47-513"><a href="#cb47-513" aria-hidden="true" tabindex="-1"></a>app_acc_vec <span class="op">=</span> np.zeros(<span class="dv">100</span>)</span>
<span id="cb47-514"><a href="#cb47-514" aria-hidden="true" tabindex="-1"></a>acc_vec <span class="op">=</span> np.zeros(<span class="dv">100</span>)</span>
<span id="cb47-515"><a href="#cb47-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-516"><a href="#cb47-516" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb47-517"><a href="#cb47-517" aria-hidden="true" tabindex="-1"></a>    df_boot_tr <span class="op">=</span> r.df_tr_encoded.iloc[index_boot[i]]</span>
<span id="cb47-518"><a href="#cb47-518" aria-hidden="true" tabindex="-1"></a>    y_boot_tr <span class="op">=</span> df_boot_tr[<span class="st">"visits_Yes"</span>].astype(<span class="bu">int</span>)</span>
<span id="cb47-519"><a href="#cb47-519" aria-hidden="true" tabindex="-1"></a>    X_boot_tr <span class="op">=</span> df_boot_tr.drop(<span class="st">"visits_Yes"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb47-520"><a href="#cb47-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-521"><a href="#cb47-521" aria-hidden="true" tabindex="-1"></a>    oob_mask <span class="op">=</span> <span class="op">~</span>r.df_tr_encoded.index.isin(df_boot_tr.index.values)</span>
<span id="cb47-522"><a href="#cb47-522" aria-hidden="true" tabindex="-1"></a>    df_boot_val <span class="op">=</span> r.df_tr_encoded[oob_mask]</span>
<span id="cb47-523"><a href="#cb47-523" aria-hidden="true" tabindex="-1"></a>    y_boot_val <span class="op">=</span> df_boot_val[<span class="st">"visits_Yes"</span>].astype(<span class="bu">int</span>)</span>
<span id="cb47-524"><a href="#cb47-524" aria-hidden="true" tabindex="-1"></a>    X_boot_val <span class="op">=</span> df_boot_val.drop(<span class="st">"visits_Yes"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb47-525"><a href="#cb47-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-526"><a href="#cb47-526" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb47-527"><a href="#cb47-527" aria-hidden="true" tabindex="-1"></a>    rfe <span class="op">=</span> RFE(model)</span>
<span id="cb47-528"><a href="#cb47-528" aria-hidden="true" tabindex="-1"></a>    rfe.fit(X_boot_tr, y_boot_tr)</span>
<span id="cb47-529"><a href="#cb47-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-530"><a href="#cb47-530" aria-hidden="true" tabindex="-1"></a>    pred_probs_val <span class="op">=</span> rfe.predict_proba(X_boot_val)[:, <span class="dv">1</span>]</span>
<span id="cb47-531"><a href="#cb47-531" aria-hidden="true" tabindex="-1"></a>    Doc_boot_pred_val <span class="op">=</span> (pred_probs_val <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span>
<span id="cb47-532"><a href="#cb47-532" aria-hidden="true" tabindex="-1"></a>    oob_acc <span class="op">=</span> accuracy_score(y_boot_val, Doc_boot_pred_val)</span>
<span id="cb47-533"><a href="#cb47-533" aria-hidden="true" tabindex="-1"></a>    oob_acc_vec[i] <span class="op">=</span> oob_acc</span>
<span id="cb47-534"><a href="#cb47-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-535"><a href="#cb47-535" aria-hidden="true" tabindex="-1"></a>    pred_probs_tr <span class="op">=</span> rfe.predict_proba(X_boot_tr)[:, <span class="dv">1</span>]</span>
<span id="cb47-536"><a href="#cb47-536" aria-hidden="true" tabindex="-1"></a>    Doc_boot_pred_tr <span class="op">=</span> (pred_probs_tr <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span>
<span id="cb47-537"><a href="#cb47-537" aria-hidden="true" tabindex="-1"></a>    app_acc <span class="op">=</span> accuracy_score(y_boot_tr, Doc_boot_pred_tr)</span>
<span id="cb47-538"><a href="#cb47-538" aria-hidden="true" tabindex="-1"></a>    app_acc_vec[i] <span class="op">=</span> app_acc</span>
<span id="cb47-539"><a href="#cb47-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-540"><a href="#cb47-540" aria-hidden="true" tabindex="-1"></a>    acc_vec[i] <span class="op">=</span> <span class="fl">0.368</span> <span class="op">*</span> app_acc <span class="op">+</span> <span class="fl">0.632</span> <span class="op">*</span> oob_acc</span>
<span id="cb47-541"><a href="#cb47-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-542"><a href="#cb47-542" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(acc_vec)</span>
<span id="cb47-543"><a href="#cb47-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-544"><a href="#cb47-544" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-545"><a href="#cb47-545" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb47-546"><a href="#cb47-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-547"><a href="#cb47-547" aria-hidden="true" tabindex="-1"></a><span class="fu">## Automated approach</span></span>
<span id="cb47-548"><a href="#cb47-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-549"><a href="#cb47-549" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb47-550"><a href="#cb47-550" aria-hidden="true" tabindex="-1"></a><span class="fu">### R - `caret`</span></span>
<span id="cb47-551"><a href="#cb47-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-552"><a href="#cb47-552" aria-hidden="true" tabindex="-1"></a>We only need to change the method in the <span class="in">`trainControl`</span> function. The corresponding method is "boot632".</span>
<span id="cb47-553"><a href="#cb47-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-556"><a href="#cb47-556" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-557"><a href="#cb47-557" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">346</span>)</span>
<span id="cb47-558"><a href="#cb47-558" aria-hidden="true" tabindex="-1"></a>trctrl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"boot632"</span>, <span class="at">number=</span><span class="dv">100</span>)</span>
<span id="cb47-559"><a href="#cb47-559" aria-hidden="true" tabindex="-1"></a>Doc_boot <span class="ot">&lt;-</span> <span class="fu">train</span>(visits <span class="sc">~</span>., <span class="at">data =</span> df_tr, <span class="at">method =</span> <span class="st">"glmStepAIC"</span>, <span class="at">family=</span><span class="st">"binomial"</span>,</span>
<span id="cb47-560"><a href="#cb47-560" aria-hidden="true" tabindex="-1"></a>                   <span class="at">trControl=</span>trctrl, <span class="at">trace =</span> <span class="dv">0</span>)</span>
<span id="cb47-561"><a href="#cb47-561" aria-hidden="true" tabindex="-1"></a>Doc_boot</span>
<span id="cb47-562"><a href="#cb47-562" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-563"><a href="#cb47-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-564"><a href="#cb47-564" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python - `sklearn` &amp; `mlxtend`</span></span>
<span id="cb47-565"><a href="#cb47-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-566"><a href="#cb47-566" aria-hidden="true" tabindex="-1"></a>As <span class="in">`sklearn`</span> does not offer bootstrap with the 0.632 rule, we use <span class="in">`bootstrap_point632_score`</span> function from the <span class="in">`mlxtend`</span> library to perform bootstrapping with the 0.632 rule for our Logistic Regression model. We will use <span class="in">`mlxtend`</span> with R for bootstrapping with the 0.632 rule.</span>
<span id="cb47-567"><a href="#cb47-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-568"><a href="#cb47-568" aria-hidden="true" tabindex="-1"></a>Please note for this part, we don't make any step-wise feature selection here as in the case of <span class="in">`caret`</span> (i.e., <span class="in">`glmStepAIC`</span>), but similar feature selections such as <span class="in">`sklearn.feature_selection.RFE`</span> can be implemented since, as mentioned in the <span class="in">`Ex_ML_LinLogReg`</span> exercises, there are no exact implementations of step-wise AIC regression with the libraries of interest in python.</span>
<span id="cb47-569"><a href="#cb47-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-572"><a href="#cb47-572" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-573"><a href="#cb47-573" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlxtend.evaluate <span class="im">import</span> bootstrap_point632_score</span>
<span id="cb47-574"><a href="#cb47-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-575"><a href="#cb47-575" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">346</span>)</span>
<span id="cb47-576"><a href="#cb47-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-577"><a href="#cb47-577" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the logistic regression model</span></span>
<span id="cb47-578"><a href="#cb47-578" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb47-579"><a href="#cb47-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-580"><a href="#cb47-580" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute bootstrap point 632 scores</span></span>
<span id="cb47-581"><a href="#cb47-581" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> bootstrap_point632_score(estimator<span class="op">=</span>model, X<span class="op">=</span>X_train, y<span class="op">=</span>y_train, n_splits<span class="op">=</span><span class="dv">100</span>, random_seed<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb47-582"><a href="#cb47-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-583"><a href="#cb47-583" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the mean accuracy and standard deviation</span></span>
<span id="cb47-584"><a href="#cb47-584" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean accuracy:"</span>, np.mean(scores))</span>
<span id="cb47-585"><a href="#cb47-585" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Standard deviation:"</span>, np.std(scores))</span>
<span id="cb47-586"><a href="#cb47-586" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-587"><a href="#cb47-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-588"><a href="#cb47-588" aria-hidden="true" tabindex="-1"></a>The results are now very close to our model in <span class="in">`caret`</span>.</span>
<span id="cb47-589"><a href="#cb47-589" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb47-590"><a href="#cb47-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-591"><a href="#cb47-591" aria-hidden="true" tabindex="-1"></a><span class="fu"># Balancing data</span></span>
<span id="cb47-592"><a href="#cb47-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-593"><a href="#cb47-593" aria-hidden="true" tabindex="-1"></a>In this part, we apply the balancing data technique in order to improve the prediction of "yes" with the doctor visit data. The table below reveals the unbalance problem.</span>
<span id="cb47-594"><a href="#cb47-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-595"><a href="#cb47-595" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb47-596"><a href="#cb47-596" aria-hidden="true" tabindex="-1"></a><span class="fu">## R</span></span>
<span id="cb47-597"><a href="#cb47-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-600"><a href="#cb47-600" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-601"><a href="#cb47-601" aria-hidden="true" tabindex="-1"></a><span class="do">## Statistics on the training set</span></span>
<span id="cb47-602"><a href="#cb47-602" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df_tr<span class="sc">$</span>visits)</span>
<span id="cb47-603"><a href="#cb47-603" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-604"><a href="#cb47-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-605"><a href="#cb47-605" aria-hidden="true" tabindex="-1"></a>Since there are many more "No" than "Yes", any model favors the prediction of the "No". It results a good accuracy but the specificity (or the sensitivity depending on the choice of the positive class) is low, as well as the balanced accuracy.</span>
<span id="cb47-606"><a href="#cb47-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-609"><a href="#cb47-609" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-610"><a href="#cb47-610" aria-hidden="true" tabindex="-1"></a>Doc_lr <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>(<span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb47-611"><a href="#cb47-611" aria-hidden="true" tabindex="-1"></a>Doc_lr_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb47-612"><a href="#cb47-612" aria-hidden="true" tabindex="-1"></a>Doc_lr_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_lr_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb47-613"><a href="#cb47-613" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_lr_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb47-614"><a href="#cb47-614" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-615"><a href="#cb47-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-616"><a href="#cb47-616" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python</span></span>
<span id="cb47-617"><a href="#cb47-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-620"><a href="#cb47-620" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-621"><a href="#cb47-621" aria-hidden="true" tabindex="-1"></a>r.df_tr[<span class="st">'visits'</span>].value_counts()</span>
<span id="cb47-622"><a href="#cb47-622" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-623"><a href="#cb47-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-626"><a href="#cb47-626" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-627"><a href="#cb47-627" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb47-628"><a href="#cb47-628" aria-hidden="true" tabindex="-1"></a>lr.fit(X_train, y_train)</span>
<span id="cb47-629"><a href="#cb47-629" aria-hidden="true" tabindex="-1"></a>lr_pred <span class="op">=</span> lr.predict(X_test)</span>
<span id="cb47-630"><a href="#cb47-630" aria-hidden="true" tabindex="-1"></a>lr_cf <span class="op">=</span> confusion_matrix(y_test, lr_pred)</span>
<span id="cb47-631"><a href="#cb47-631" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(lr_cf)</span>
<span id="cb47-632"><a href="#cb47-632" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-633"><a href="#cb47-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-634"><a href="#cb47-634" aria-hidden="true" tabindex="-1"></a>To calculate all the other scores aside from the confusion matrix, we actually have to compute them manually:</span>
<span id="cb47-635"><a href="#cb47-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-638"><a href="#cb47-638" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-639"><a href="#cb47-639" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> balanced_accuracy_score, recall_score</span>
<span id="cb47-640"><a href="#cb47-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-641"><a href="#cb47-641" aria-hidden="true" tabindex="-1"></a>tn, fp, fn, tp <span class="op">=</span> lr_cf.ravel()</span>
<span id="cb47-642"><a href="#cb47-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-643"><a href="#cb47-643" aria-hidden="true" tabindex="-1"></a>specificity <span class="op">=</span> tn <span class="op">/</span> (tn <span class="op">+</span> fp)</span>
<span id="cb47-644"><a href="#cb47-644" aria-hidden="true" tabindex="-1"></a>sensitivity <span class="op">=</span> recall_score(y_test, lr_pred, pos_label<span class="op">=</span><span class="st">'Yes'</span>)</span>
<span id="cb47-645"><a href="#cb47-645" aria-hidden="true" tabindex="-1"></a>balanced_acc <span class="op">=</span> balanced_accuracy_score(y_test, lr_pred)</span>
<span id="cb47-646"><a href="#cb47-646" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, lr_pred)</span>
<span id="cb47-647"><a href="#cb47-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-648"><a href="#cb47-648" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-649"><a href="#cb47-649" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced Accuracy: </span><span class="sc">{</span>balanced_acc<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-650"><a href="#cb47-650" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Specificity: </span><span class="sc">{</span>specificity<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-651"><a href="#cb47-651" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sensitivity: </span><span class="sc">{</span>sensitivity<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-652"><a href="#cb47-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-653"><a href="#cb47-653" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-654"><a href="#cb47-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-655"><a href="#cb47-655" aria-hidden="true" tabindex="-1"></a>Please note that <span class="in">`Specificity`</span> and <span class="in">`Sensitivity`</span> have the reverse values compared to R, and that's because the confusion matrix in R first takes the predicted values and then the true values. In contrast, it is the confusion matrix from <span class="in">`sklearn`</span>, the true values are given before the predicted ones. The interpretation does not change, and it's only about which class you consider as your positive class.</span>
<span id="cb47-656"><a href="#cb47-656" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb47-657"><a href="#cb47-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-658"><a href="#cb47-658" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sub-sampling</span></span>
<span id="cb47-659"><a href="#cb47-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-660"><a href="#cb47-660" aria-hidden="true" tabindex="-1"></a>Balancing using sub-sampling consists of taking all the cases in the smallest class (i.e., <span class="in">`Yes`</span>) and extract at random the same amount of cases in the largest category (i.e., <span class="in">`No`</span>).</span>
<span id="cb47-661"><a href="#cb47-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-662"><a href="#cb47-662" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb47-663"><a href="#cb47-663" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb47-664"><a href="#cb47-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-667"><a href="#cb47-667" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-668"><a href="#cb47-668" aria-hidden="true" tabindex="-1"></a>n_yes <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="fu">table</span>(df_tr<span class="sc">$</span>visits)) <span class="do">## 840</span></span>
<span id="cb47-669"><a href="#cb47-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-670"><a href="#cb47-670" aria-hidden="true" tabindex="-1"></a>df_tr_no <span class="ot">&lt;-</span> <span class="fu">filter</span>(df_tr, visits<span class="sc">==</span><span class="st">"No"</span>) <span class="do">## the "No" cases</span></span>
<span id="cb47-671"><a href="#cb47-671" aria-hidden="true" tabindex="-1"></a>df_tr_yes <span class="ot">&lt;-</span> <span class="fu">filter</span>(df_tr, visits<span class="sc">==</span><span class="st">"Yes"</span>) <span class="do">## The "Yes" cases</span></span>
<span id="cb47-672"><a href="#cb47-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-673"><a href="#cb47-673" aria-hidden="true" tabindex="-1"></a>index_no <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">size=</span>n_yes, <span class="at">x=</span><span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(df_tr_no), <span class="at">replace=</span><span class="cn">FALSE</span>) <span class="do">## sub-sample 840 instances from the "No"</span></span>
<span id="cb47-674"><a href="#cb47-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-675"><a href="#cb47-675" aria-hidden="true" tabindex="-1"></a>df_tr_subs <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">rbind</span>(df_tr_yes, df_tr_no[index_no,])) <span class="do">## Bind all the "Yes" and the sub-sampled "No"</span></span>
<span id="cb47-676"><a href="#cb47-676" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df_tr_subs<span class="sc">$</span>visits) <span class="do">## The cases are balanced</span></span>
<span id="cb47-677"><a href="#cb47-677" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-678"><a href="#cb47-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-679"><a href="#cb47-679" aria-hidden="true" tabindex="-1"></a>Now let us see the result on the accuracy measures.</span>
<span id="cb47-680"><a href="#cb47-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-683"><a href="#cb47-683" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-684"><a href="#cb47-684" aria-hidden="true" tabindex="-1"></a>Doc_lr_subs <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr_subs, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>(<span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb47-685"><a href="#cb47-685" aria-hidden="true" tabindex="-1"></a>Doc_lr_subs_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr_subs, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb47-686"><a href="#cb47-686" aria-hidden="true" tabindex="-1"></a>Doc_lr_subs_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_lr_subs_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb47-687"><a href="#cb47-687" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_lr_subs_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb47-688"><a href="#cb47-688" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-689"><a href="#cb47-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-690"><a href="#cb47-690" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb47-691"><a href="#cb47-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-694"><a href="#cb47-694" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-695"><a href="#cb47-695" aria-hidden="true" tabindex="-1"></a>n_yes <span class="op">=</span> <span class="bu">min</span>(r.df_tr[<span class="st">'visits'</span>].value_counts()) <span class="co">## 840</span></span>
<span id="cb47-696"><a href="#cb47-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-697"><a href="#cb47-697" aria-hidden="true" tabindex="-1"></a>df_tr_no <span class="op">=</span> r.df_tr[r.df_tr[<span class="st">'visits'</span>] <span class="op">==</span> <span class="st">"No"</span>] <span class="co">## the "No" cases</span></span>
<span id="cb47-698"><a href="#cb47-698" aria-hidden="true" tabindex="-1"></a>df_tr_yes <span class="op">=</span> r.df_tr[r.df_tr[<span class="st">'visits'</span>] <span class="op">==</span> <span class="st">"Yes"</span>] <span class="co">## The "Yes" cases</span></span>
<span id="cb47-699"><a href="#cb47-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-700"><a href="#cb47-700" aria-hidden="true" tabindex="-1"></a>index_no <span class="op">=</span> np.random.choice(df_tr_no.index, size<span class="op">=</span>n_yes, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb47-701"><a href="#cb47-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-702"><a href="#cb47-702" aria-hidden="true" tabindex="-1"></a>df_tr_subs <span class="op">=</span> pd.concat([df_tr_yes, df_tr_no.loc[index_no]])</span>
<span id="cb47-703"><a href="#cb47-703" aria-hidden="true" tabindex="-1"></a>df_tr_subs[<span class="st">'visits'</span>].value_counts() <span class="co">## The cases like R are balanced</span></span>
<span id="cb47-704"><a href="#cb47-704" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-705"><a href="#cb47-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-706"><a href="#cb47-706" aria-hidden="true" tabindex="-1"></a>Now to the calculating the scores again:</span>
<span id="cb47-707"><a href="#cb47-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-710"><a href="#cb47-710" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-711"><a href="#cb47-711" aria-hidden="true" tabindex="-1"></a>X_train_subs <span class="op">=</span> pd.get_dummies(df_tr_subs.drop(columns<span class="op">=</span>[<span class="st">'visits'</span>]))</span>
<span id="cb47-712"><a href="#cb47-712" aria-hidden="true" tabindex="-1"></a>y_train_subs <span class="op">=</span> df_tr_subs[<span class="st">'visits'</span>]</span>
<span id="cb47-713"><a href="#cb47-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-714"><a href="#cb47-714" aria-hidden="true" tabindex="-1"></a>lr_subs <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb47-715"><a href="#cb47-715" aria-hidden="true" tabindex="-1"></a>lr_subs.fit(X_train_subs, y_train_subs)</span>
<span id="cb47-716"><a href="#cb47-716" aria-hidden="true" tabindex="-1"></a>lr_subs_pred <span class="op">=</span> lr_subs.predict(X_test)</span>
<span id="cb47-717"><a href="#cb47-717" aria-hidden="true" tabindex="-1"></a>lr_subs_cf <span class="op">=</span> confusion_matrix(y_test, lr_subs_pred)</span>
<span id="cb47-718"><a href="#cb47-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-719"><a href="#cb47-719" aria-hidden="true" tabindex="-1"></a>tn_subs, fp_subs, fn_subs, tp_subs <span class="op">=</span> lr_subs_cf.ravel()</span>
<span id="cb47-720"><a href="#cb47-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-721"><a href="#cb47-721" aria-hidden="true" tabindex="-1"></a>specificity_subs <span class="op">=</span> tn_subs <span class="op">/</span> (tn_subs <span class="op">+</span> fp_subs)</span>
<span id="cb47-722"><a href="#cb47-722" aria-hidden="true" tabindex="-1"></a>sensitivity_subs <span class="op">=</span> recall_score(y_test, lr_subs_pred, pos_label<span class="op">=</span><span class="st">'Yes'</span>)</span>
<span id="cb47-723"><a href="#cb47-723" aria-hidden="true" tabindex="-1"></a>balanced_acc_subs <span class="op">=</span> balanced_accuracy_score(y_test, lr_subs_pred)</span>
<span id="cb47-724"><a href="#cb47-724" aria-hidden="true" tabindex="-1"></a>accuracy_subs <span class="op">=</span> accuracy_score(y_test, lr_subs_pred)</span>
<span id="cb47-725"><a href="#cb47-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-726"><a href="#cb47-726" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(lr_subs_cf)</span>
<span id="cb47-727"><a href="#cb47-727" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_subs<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-728"><a href="#cb47-728" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced Accuracy: </span><span class="sc">{</span>balanced_acc_subs<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-729"><a href="#cb47-729" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Specificity: </span><span class="sc">{</span>specificity_subs<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-730"><a href="#cb47-730" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sensitivity: </span><span class="sc">{</span>sensitivity_subs<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-731"><a href="#cb47-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-732"><a href="#cb47-732" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-733"><a href="#cb47-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-734"><a href="#cb47-734" aria-hidden="true" tabindex="-1"></a>Same conclusion as R (albeit with slightly different values).</span>
<span id="cb47-735"><a href="#cb47-735" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb47-736"><a href="#cb47-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-737"><a href="#cb47-737" aria-hidden="true" tabindex="-1"></a>As expected, the accuracy has decreased but the balanced accuracy has increased. Depending on the aim of the prediction, this model may be much better to use than the one trained on the unbalanced data.</span>
<span id="cb47-738"><a href="#cb47-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-739"><a href="#cb47-739" aria-hidden="true" tabindex="-1"></a><span class="fu">## Resampling</span></span>
<span id="cb47-740"><a href="#cb47-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-741"><a href="#cb47-741" aria-hidden="true" tabindex="-1"></a>Balancing by resampling follows the same aim. The difference with sub-sampling is that the resampling increases the number of cases in the smallest class by resampling at random from them. The codes below are explicit:</span>
<span id="cb47-742"><a href="#cb47-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-743"><a href="#cb47-743" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb47-744"><a href="#cb47-744" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb47-745"><a href="#cb47-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-748"><a href="#cb47-748" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-749"><a href="#cb47-749" aria-hidden="true" tabindex="-1"></a>n_no <span class="ot">&lt;-</span> <span class="fu">max</span>(<span class="fu">table</span>(df_tr<span class="sc">$</span>visits)) <span class="do">## 3313</span></span>
<span id="cb47-750"><a href="#cb47-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-751"><a href="#cb47-751" aria-hidden="true" tabindex="-1"></a>df_tr_no <span class="ot">&lt;-</span> <span class="fu">filter</span>(df_tr, visits<span class="sc">==</span><span class="st">"No"</span>)</span>
<span id="cb47-752"><a href="#cb47-752" aria-hidden="true" tabindex="-1"></a>df_tr_yes <span class="ot">&lt;-</span> <span class="fu">filter</span>(df_tr, visits<span class="sc">==</span><span class="st">"Yes"</span>)</span>
<span id="cb47-753"><a href="#cb47-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-754"><a href="#cb47-754" aria-hidden="true" tabindex="-1"></a>index_yes <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">size=</span>n_no, <span class="at">x=</span><span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(df_tr_yes), <span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb47-755"><a href="#cb47-755" aria-hidden="true" tabindex="-1"></a>df_tr_res <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">rbind</span>(df_tr_no, df_tr_yes[index_yes,]))</span>
<span id="cb47-756"><a href="#cb47-756" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(df_tr_res<span class="sc">$</span>visits)</span>
<span id="cb47-757"><a href="#cb47-757" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-758"><a href="#cb47-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-759"><a href="#cb47-759" aria-hidden="true" tabindex="-1"></a>Now, we have a balanced data set where each class has the same amount as the largest class (i.e., "No") in the original training set. The effect on the model fit is very similar to the subsampling:</span>
<span id="cb47-760"><a href="#cb47-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-763"><a href="#cb47-763" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb47-764"><a href="#cb47-764" aria-hidden="true" tabindex="-1"></a>Doc_lr_res <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>df_tr_res, <span class="at">family=</span><span class="st">"binomial"</span>) <span class="sc">%&gt;%</span> <span class="fu">step</span>(<span class="at">trace=</span><span class="dv">0</span>)</span>
<span id="cb47-765"><a href="#cb47-765" aria-hidden="true" tabindex="-1"></a>Doc_lr_res_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(Doc_lr_res, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb47-766"><a href="#cb47-766" aria-hidden="true" tabindex="-1"></a>Doc_lr_res_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Doc_lr_res_prob<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="st">"Yes"</span>,<span class="st">"No"</span>)</span>
<span id="cb47-767"><a href="#cb47-767" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(Doc_lr_res_pred), <span class="at">reference =</span> df_te<span class="sc">$</span>visits)</span>
<span id="cb47-768"><a href="#cb47-768" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-769"><a href="#cb47-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-770"><a href="#cb47-770" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb47-771"><a href="#cb47-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-774"><a href="#cb47-774" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-775"><a href="#cb47-775" aria-hidden="true" tabindex="-1"></a>n_no <span class="op">=</span> <span class="bu">max</span>(r.df_tr[<span class="st">'visits'</span>].value_counts()) <span class="co">## 3313</span></span>
<span id="cb47-776"><a href="#cb47-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-777"><a href="#cb47-777" aria-hidden="true" tabindex="-1"></a>df_tr_no <span class="op">=</span> r.df_tr[r.df_tr[<span class="st">'visits'</span>] <span class="op">==</span> <span class="st">"No"</span>]</span>
<span id="cb47-778"><a href="#cb47-778" aria-hidden="true" tabindex="-1"></a>df_tr_yes <span class="op">=</span> r.df_tr[r.df_tr[<span class="st">'visits'</span>] <span class="op">==</span> <span class="st">"Yes"</span>]</span>
<span id="cb47-779"><a href="#cb47-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-780"><a href="#cb47-780" aria-hidden="true" tabindex="-1"></a>index_yes <span class="op">=</span> np.random.choice(df_tr_yes.index, size<span class="op">=</span>n_no, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb47-781"><a href="#cb47-781" aria-hidden="true" tabindex="-1"></a>df_tr_res <span class="op">=</span> pd.concat([df_tr_no, df_tr_yes.loc[index_yes]])</span>
<span id="cb47-782"><a href="#cb47-782" aria-hidden="true" tabindex="-1"></a>df_tr_res[<span class="st">'visits'</span>].value_counts()</span>
<span id="cb47-783"><a href="#cb47-783" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-784"><a href="#cb47-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-785"><a href="#cb47-785" aria-hidden="true" tabindex="-1"></a>Now we can model again with the resampled data</span>
<span id="cb47-786"><a href="#cb47-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-789"><a href="#cb47-789" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb47-790"><a href="#cb47-790" aria-hidden="true" tabindex="-1"></a>X_train_res <span class="op">=</span> pd.get_dummies(df_tr_res.drop(columns<span class="op">=</span>[<span class="st">'visits'</span>]))</span>
<span id="cb47-791"><a href="#cb47-791" aria-hidden="true" tabindex="-1"></a>y_train_res <span class="op">=</span> df_tr_res[<span class="st">'visits'</span>]</span>
<span id="cb47-792"><a href="#cb47-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-793"><a href="#cb47-793" aria-hidden="true" tabindex="-1"></a>lr_res <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb47-794"><a href="#cb47-794" aria-hidden="true" tabindex="-1"></a>lr_res.fit(X_train_res, y_train_res)</span>
<span id="cb47-795"><a href="#cb47-795" aria-hidden="true" tabindex="-1"></a>lr_res_pred <span class="op">=</span> lr_res.predict(X_test)</span>
<span id="cb47-796"><a href="#cb47-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-797"><a href="#cb47-797" aria-hidden="true" tabindex="-1"></a>lr_res_cf <span class="op">=</span> confusion_matrix(y_test, lr_res_pred)</span>
<span id="cb47-798"><a href="#cb47-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-799"><a href="#cb47-799" aria-hidden="true" tabindex="-1"></a>tn_res, fp_res, fn_res, tp_res <span class="op">=</span> lr_res_cf.ravel()</span>
<span id="cb47-800"><a href="#cb47-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-801"><a href="#cb47-801" aria-hidden="true" tabindex="-1"></a>specificity_res <span class="op">=</span> tn_res <span class="op">/</span> (tn_res <span class="op">+</span> fp_res)</span>
<span id="cb47-802"><a href="#cb47-802" aria-hidden="true" tabindex="-1"></a>sensitivity_res <span class="op">=</span> recall_score(y_test, lr_res_pred, pos_label<span class="op">=</span><span class="st">'Yes'</span>)</span>
<span id="cb47-803"><a href="#cb47-803" aria-hidden="true" tabindex="-1"></a>balanced_acc_res <span class="op">=</span> balanced_accuracy_score(y_test, lr_res_pred)</span>
<span id="cb47-804"><a href="#cb47-804" aria-hidden="true" tabindex="-1"></a>accuracy_res <span class="op">=</span> accuracy_score(y_test, lr_res_pred)</span>
<span id="cb47-805"><a href="#cb47-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-806"><a href="#cb47-806" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(lr_res_cf)</span>
<span id="cb47-807"><a href="#cb47-807" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_res<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-808"><a href="#cb47-808" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Balanced Accuracy: </span><span class="sc">{</span>balanced_acc_res<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-809"><a href="#cb47-809" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Specificity: </span><span class="sc">{</span>specificity_res<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-810"><a href="#cb47-810" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sensitivity: </span><span class="sc">{</span>sensitivity_res<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-811"><a href="#cb47-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-812"><a href="#cb47-812" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb47-813"><a href="#cb47-813" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb47-814"><a href="#cb47-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-815"><a href="#cb47-815" aria-hidden="true" tabindex="-1"></a>Whether one should prefer sub-sampling or resampling depends on the amount and the richness of the data.</span>
<span id="cb47-816"><a href="#cb47-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-817"><a href="#cb47-817" aria-hidden="true" tabindex="-1"></a><span class="fu"># Your turn</span></span>
<span id="cb47-818"><a href="#cb47-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-819"><a href="#cb47-819" aria-hidden="true" tabindex="-1"></a>Repeat the analysis on the German credit data. Balance the data using either method. Then, using <span class="in">`caret`</span> (R) or <span class="in">`sklearn`</span> (python) and either CV or Bootstrap, put several models in competition. Select the best one according to your choice of score. Finally, use the test set to see if the best model does not overfit the training set.</span>
<span id="cb47-820"><a href="#cb47-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-821"><a href="#cb47-821" aria-hidden="true" tabindex="-1"></a>Doing this will have achieved a complete supervised learning task from A to Z.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2024, <a href="https://iliaazizi.com/">Ilia Azizi &amp; Marc-Olivier Boldi</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/05_DataSplitting/Ex_ML_Data_Splitting.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 🤍 and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>