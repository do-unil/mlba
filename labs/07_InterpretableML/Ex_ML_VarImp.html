<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Variable Importance – MLBA - S24</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../labs/08_UnsupervisedLearning/081_Clustering/Ex_ML_Clustering.html" rel="next">
<link href="../../labs/06_Ensembles/Ex_ML_Ensemble.html" rel="prev">
<link href="../../images/logo.dark.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dcd6dad1d9027e0fc018a6aab5a8b21b.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-fc6169d2ff87708b539fd584a3ca0747.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dcd6dad1d9027e0fc018a6aab5a8b21b.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-00fd0552d18edc0374d7cfd5272f6da8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-6e850ac48b8f6b646df9660bb1f4cae3.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-00fd0552d18edc0374d7cfd5272f6da8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<meta property="og:title" content="Variable Importance – MLBA - S24">
<meta property="og:description" content="Homepage for Machine Learning in Business Analytics at HEC Lausanne, Spring 2024.">
<meta property="og:site_name" content="MLBA - S24 ">
</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../labs/07_InterpretableML/Ex_ML_VarImp.html">Interpretable ML</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../images/logo.light.png" alt="" class="sidebar-logo light-content py-0 d-lg-inline d-none">
      <img src="../../images/logo.light.png" alt="" class="sidebar-logo dark-content py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main tools-wide">
    <a href="https://moodle.unil.ch/course/view.php?id=33387" title="Moodle" class="quarto-navigation-tool px-1" aria-label="Moodle"><i class="bi bi-person-rolodex"></i></a>
    <a href="https://github.com/do-unil/mlba" title="GitHub Repo" class="quarto-navigation-tool px-1" aria-label="GitHub Repo"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../schedule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../faq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FAQ</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Lectures</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/01_Introduction/ML_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/02_DataExploration/ML_DataExplo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Exploration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/030_Introduction/ML_Models_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/031_LinearLogisticRegression/ML_LinLogReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/032_Trees/ML_Trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/033_NeuralNetworks/ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/034_SupportVectorMachine/ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/04_Metrics/ML_Metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/05_DataSplitting/ML_DataSplitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/06_Ensembles/ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/07_InterpretableML/ML_Interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/080_Introduction/ML_UnsupIntro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Unsuperised Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/081_Clustering/ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/082_DimensionReduction/ML_DimRed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dimension Reduction</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/00_lab/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/032_Trees/Ex_ML_Tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/033_NeuralNetworks/EX_ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/04_Metrics/Ex_ML_Scoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/06_Ensembles/Ex_ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/07_InterpretableML/Ex_ML_VarImp.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/081_Clustering/Ex_ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/082_DimensionReduction/Ex_ML_PCA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PCA</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Assessments</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Exam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exam</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Project</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Project_Directives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Directives</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Presentation_Guidelines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Presentation Guidelines</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/beginners_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Beginners in R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/data_acquisition/data_sources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Sources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/data_acquisition/web_scraping_api.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Web Scraping</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/cheatsheets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding Cheatsheets</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#data-models" id="toc-data-models" class="nav-link active" data-scroll-target="#data-models">Data &amp; models</a></li>
  <li><a href="#variable-importance-using-dalex" id="toc-variable-importance-using-dalex" class="nav-link" data-scroll-target="#variable-importance-using-dalex">Variable Importance using <code>DALEX</code></a>
  <ul class="collapse">
  <li><a href="#creating-an-explain-object" id="toc-creating-an-explain-object" class="nav-link" data-scroll-target="#creating-an-explain-object">Creating an <code>explain</code> object</a></li>
  <li><a href="#plotting-the-feature-importance" id="toc-plotting-the-feature-importance" class="nav-link" data-scroll-target="#plotting-the-feature-importance">Plotting the feature importance</a></li>
  </ul></li>
  <li><a href="#partial-dependence-plots-pdp" id="toc-partial-dependence-plots-pdp" class="nav-link" data-scroll-target="#partial-dependence-plots-pdp">Partial Dependence Plots (<code>PDP</code>)</a></li>
  <li><a href="#lime-local-interpretable-model-agnostic-explanations" id="toc-lime-local-interpretable-model-agnostic-explanations" class="nav-link" data-scroll-target="#lime-local-interpretable-model-agnostic-explanations"><code>LIME</code> (Local Interpretable Model-agnostic Explanations)</a>
  <ul class="collapse">
  <li><a href="#svm" id="toc-svm" class="nav-link" data-scroll-target="#svm">SVM</a></li>
  <li><a href="#bonus-xgboost" id="toc-bonus-xgboost" class="nav-link" data-scroll-target="#bonus-xgboost">Bonus: XGBoost</a></li>
  </ul></li>
  <li><a href="#your-turn" id="toc-your-turn" class="nav-link" data-scroll-target="#your-turn">Your turn</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/07_InterpretableML/Ex_ML_VarImp.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<script type="application/javascript">
// Description: Change image src depending on body class (quarto-light or quarto-dark)
function updateImageSrc() {
  var bodyClass = window.document.body.classList;
  var images = window.document.getElementsByTagName('img');
  for (var i = 0; i < images.length; i++) {
    var image = images[i];
    var src = image.src;
    var newSrc = src;
    if (bodyClass.contains('quarto-light') && src.includes('.dark')) {
      newSrc = src.replace('.dark', '.light');
    } else if (bodyClass.contains('quarto-dark') && src.includes('.light')) {
      newSrc = src.replace('.light', '.dark');
    }
    if (newSrc !== src) {
      image.src = newSrc;
    }
  }
}

var observer = new MutationObserver(function(mutations) {
  mutations.forEach(function(mutation) {
    if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
      updateImageSrc();
    }
  });
});

observer.observe(window.document.body, {
  attributes: true
});

updateImageSrc();
</script>

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../labs/07_InterpretableML/Ex_ML_VarImp.html">Interpretable ML</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Variable Importance</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="data-models" class="level1">
<h1>Data &amp; models</h1>
<p>This exercise shows an example of model-agnostic variable importance for a regression problem. The dataset that we will be working with is <code>Carseats</code> from the <code>ISLR</code> library which has already been used during some of the exercises such as <code>Ex_ML_Tree</code> and <code>Ex_ML_SVM</code>. It is highly recommended that you try to implement some parts of the exercise yourself before checking the answers.</p>
<ul>
<li><p>Load the data from ISLR package, then assign 90% of the data for training and the remainder for testing. Please keep in mind that we make a training split running the feature importance (instead of using the entire dataset) as we “may” want to re-train the model with only a fewer features rather than biasing our decision by also including the testing data.</p></li>
<li><p>Create three models including a linear regression, a regression tree and a support-vector machine.</p></li>
</ul>
<details>
<summary>
<strong>Answer</strong>
</summary>
<p>
</p><div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" href="" aria-current="page">R</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># divide the data into training and testing sets</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2022</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>carseats_index <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x=</span><span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Carseats), <span class="at">size=</span><span class="fl">0.9</span><span class="sc">*</span><span class="fu">nrow</span>(Carseats), <span class="at">replace=</span><span class="cn">FALSE</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>carseats_tr <span class="ot">&lt;-</span> Carseats[carseats_index,]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>carseats_te <span class="ot">&lt;-</span> Carseats[<span class="sc">-</span>carseats_index,]</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># define a linear regression</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>carseats_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Sales<span class="sc">~</span>., <span class="at">data=</span>carseats_tr)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># define a regression tree (you can also use `adabag::autoprune()`here</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>carseats_rt <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Sales<span class="sc">~</span>., <span class="at">data=</span>carseats_tr)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># define a support-vector machine</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>carseats_svm <span class="ot">&lt;-</span> <span class="fu">svm</span>(Sales <span class="sc">~</span> ., <span class="at">data=</span>carseats_tr)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="python" class="level3">
<h3 class="anchored" data-anchor-id="python">Python</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVR</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the training and test sets created in R (no easy way to get the `Carseats` data in python)</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the categorical columns to one-hot encoded ones</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>carseats_train, carseats_test <span class="op">=</span> pd.get_dummies(r.carseats_tr.copy()), pd.get_dummies(r.carseats_tr.copy())</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a linear regression</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>carseats_lr <span class="op">=</span> LinearRegression()</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>carseats_lr.fit(carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>])</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a decision tree regressor</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>carseats_dtr <span class="op">=</span> DecisionTreeRegressor()</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>carseats_dtr.fit(carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>])</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a support-vector machine</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>carseats_svr <span class="op">=</span> SVR()</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>carseats_svr.fit(carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</div>
</div>
</div>
<p></p>
</details>
</section>
<section id="variable-importance-using-dalex" class="level1">
<h1>Variable Importance using <code>DALEX</code></h1>
<p>Feature importance can be manually computed by permuting one column and computing the drop in the value of the loss function (e.g.&nbsp;RMSE for regression and Accuracy for classification). This permutation can be repeated n-times to calculate a mean drop in loss value across various runs. This form of variable importance is often referred to as “permutation feature importance”.</p>
<p>Fortunately, in R there are some nice packages that can help you with that. Three common libraries (among many) for model-agnostic feature importance in R are <code>iml</code>, <code>DALEX</code> and <code>vip</code> . If you would like to learn about the model-specific and model-agnostic feature importance and the various packages in R, you can refer to the chapter 16 of the book <a href="https://ema.drwhy.ai/featureImportance.html">“Hands-on Machine Learning with R”</a>. For the purpose of this part of the exercise, we will be using the <code>DALEX</code> library. Please note that the exercise has been largely inspired by the same chapter 16 of the book. You can also check out other variations such as <code>iml</code> and <code>vip</code> implementations.</p>
<section id="creating-an-explain-object" class="level2">
<h2 class="anchored" data-anchor-id="creating-an-explain-object">Creating an <code>explain</code> object</h2>
<p><code>DALEX</code> has an <code>explain</code> object which allows you to do various kind of explanatory analysis. Try reading about the required inputs for it by referring to its documentations (<code>?DALEX::explain()</code>) and also referring to the book mentioned at the beginning of this exercise (<a href="https://ema.drwhy.ai/featureImportance.html">“Hands-on Machine Learning with R”</a>). Create one explain object per model for the training data and set the inputs that you need which are <code>model</code>, <code>data</code> (data frame of features) and <code>y</code> (vector of observed outcomes). Also, you can give a caption to your model through the <code>label</code> argument.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true" href="">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false" href="">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DALEX)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> <span class="fu">select</span>(carseats_tr, <span class="sc">-</span>Sales)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> <span class="fu">pull</span>(carseats_tr, Sales)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>explainer_lm <span class="ot">&lt;-</span> DALEX<span class="sc">::</span><span class="fu">explain</span>(<span class="at">model =</span> carseats_lm, </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">data =</span> x_train, </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">y =</span> y_train,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">label =</span> <span class="st">"Linear Regression"</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>explainer_rt <span class="ot">&lt;-</span> DALEX<span class="sc">::</span><span class="fu">explain</span>(<span class="at">model =</span> carseats_rt,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>                               <span class="at">data =</span> x_train,</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>                               <span class="at">y =</span> y_train,</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>                               <span class="at">label =</span> <span class="st">"Regression Tree"</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>explainer_svm <span class="ot">&lt;-</span> DALEX<span class="sc">::</span><span class="fu">explain</span>(<span class="at">model =</span> carseats_svm,</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>                                <span class="at">data =</span> x_train,</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>                                <span class="at">y =</span> y_train,</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>                                <span class="at">label =</span> <span class="st">"Support Vector Machine"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>To calculate the feature importances using Python, we’ll be using the <code>permutation_importance</code> function from the <code>sklearn</code> library.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale the features (relevant to SVM)</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>carseats_train_scaled <span class="op">=</span> carseats_train.copy()</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>carseats_test_scaled <span class="op">=</span> carseats_test.copy()</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate feature importances for each model</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>importance_lr <span class="op">=</span> permutation_importance(carseats_lr, carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>], n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">2022</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>importance_dtr <span class="op">=</span> permutation_importance(carseats_dtr, carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>], n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">2022</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>importance_svr <span class="op">=</span> permutation_importance(carseats_svr, carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>], n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">2022</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the SVM model on scaled data</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>carseats_svr_scaled <span class="op">=</span> SVR(kernel<span class="op">=</span><span class="st">'linear'</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>carseats_svr_scaled.fit(carseats_train_scaled.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train_scaled[<span class="st">'Sales'</span>])</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>importance_svr_scaled <span class="op">=</span> permutation_importance(carseats_svr_scaled, carseats_train_scaled.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train_scaled[<span class="st">'Sales'</span>], n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">2022</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the feature importances</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>importance_df <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>{</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]).columns,</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Linear Regression'</span>: importance_lr.importances_mean,</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Decision Tree'</span>: importance_dtr.importances_mean,</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Support Vector Machine (unscaled)'</span>: importance_svr.importances_mean,</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Support Vector Machine (scaled)'</span>: importance_svr_scaled.importances_mean</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(importance_df)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>You can observe the value of scaling for SVM. The results seems to agree that <code>Price</code> is the most important feature.</p>
</div>
</div>
</div>
</section>
<section id="plotting-the-feature-importance" class="level2">
<h2 class="anchored" data-anchor-id="plotting-the-feature-importance">Plotting the feature importance</h2>
<p>Now that you have created the <code>DALEX::explain</code> objects, we will use another function called <code>model_parts</code> which takes care of the feature permutation. Try reading about the function <code>DALEX::model_parts()</code> . The main arguments that you need to provide to the <code>explain</code> function are:</p>
<ul>
<li><p>An <code>explainer</code> object (what you created above).</p></li>
<li><p><code>B</code> which is the number of permutations (i.e.&nbsp;how many times you want to randomly shuffle each column).</p></li>
<li><p>The <code>type</code> of scores you would like it to return (raw score vs differences vs ratios) which in this case we set to <code>ratio</code> and you can read more the differences in the documentation.</p></li>
<li><p><code>N</code> argument which you can set to <code>N=NULL</code> which essentially asks how many samples you would like to use for calculating the variable importance, where setting it to <code>NULL</code> means that we use the entire training set.</p></li>
<li><p>There is also a <code>loss_function</code> which by default is <code>RMSE</code> for regression (our case) and <code>1-AUC</code> for classification, by there are a few more which you can find out about by referring to the documentations (e.g.&nbsp;through <code>?DALEX::loss_root_mean_square</code>).</p></li>
</ul>
<p>After assigning <code>model_parts</code> to a variable, try plotting each model to see the most important variables. What do you see? Are there important features that are in common?</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>calculate_importance <span class="ot">&lt;-</span> <span class="cf">function</span>(your_model_explainer, <span class="at">n_permutations =</span> <span class="dv">10</span>) {</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  imp <span class="ot">&lt;-</span> <span class="fu">model_parts</span>(<span class="at">explainer =</span> your_model_explainer,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">B =</span> n_permutations,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">type =</span> <span class="st">"ratio"</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">N =</span> <span class="cn">NULL</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(imp)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>importance_lm  <span class="ot">&lt;-</span> <span class="fu">calculate_importance</span>(explainer_lm)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>importance_rt  <span class="ot">&lt;-</span> <span class="fu">calculate_importance</span>(explainer_rt)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>importance_svm <span class="ot">&lt;-</span> <span class="fu">calculate_importance</span>(explainer_svm)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(importance_lm, importance_rt, importance_svm) <span class="sc">+</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Mean variable-importance ratio over 10 permutations"</span>, <span class="st">""</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="partial-dependence-plots-pdp" class="level1">
<h1>Partial Dependence Plots (<code>PDP</code>)</h1>
<p>Partial dependence plots (PDPs) show the marginal effect of one or two features on the predicted outcome of a machine learning model. They can be used to visualize and interpret the influence of selected features on the model’s predictions. We’ll continue using the same Carseats data. We first create PDPs for the <code>Price</code> and <code>Advertising</code> features using the the SVM model <code>carseats_svm</code> created earlier:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pdp)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>pdp<span class="sc">::</span><span class="fu">partial</span>(carseats_svm, <span class="at">pred.var =</span> <span class="st">"Price"</span>, <span class="at">plot =</span> <span class="cn">TRUE</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>pdp<span class="sc">::</span><span class="fu">partial</span>(carseats_svm, <span class="at">pred.var =</span> <span class="st">"Advertising"</span>, <span class="at">plot =</span> <span class="cn">TRUE</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>What we see in the first plot is that for this particular model, the higher the <code>price</code>, the number of carseats sold (units) which makes sense. With regards to the advertising, we see that the higher the local advertising budget for the company (see <code>?Carseats</code> for more details), the higher the sales number of units for a car, however, there’s a plateau after which you cannot sell more units. This means that after a certain point, increasing the advertising budget may no longer bring any benefit in terms of the units sold. It’s important to note that in PDP, we study the decision by the model and not the data, however, we can always visualize our results to see if they follow a similar trend or not:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot(Carseats$Advertising, Carseats$Sales, xlab = "Advertising Budget", ylab = "Sales Units")</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> carseats_tr, <span class="fu">aes</span>(<span class="at">x =</span> Advertising, <span class="at">y =</span> Sales)) <span class="sc">+</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Advertising Budget"</span>, <span class="at">y =</span> <span class="st">"Sales Unit"</span>) <span class="sc">+</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Relationship between Sales and Advertising Budget"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>We can see that the trend is not very clear but may be headed in the same direction.</p>
<p>For categorical features, such as <code>ShelveLoc</code>, we can make a similar kind of PDP:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>pdp<span class="sc">::</span><span class="fu">partial</span>(carseats_svm, <span class="at">pred.var =</span> <span class="st">"ShelveLoc"</span>, <span class="at">plot =</span> <span class="cn">TRUE</span>, <span class="at">plot.engine =</span> <span class="st">"ggplot"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>From this plot, we can see that the better the quality of shelving location, the high the number of units sold (which again makes sense).</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Limitations of PDPs
</div>
</div>
<div class="callout-body-container callout-body">
<p>PDPs can have some limitations, which you, as users, should be aware of. These limitations do partially apply to other techniques presented during lab:</p>
<ol type="1">
<li><p><em>Assuming feature independence</em>: PDPs assume that the features being plotted are independent of each other. This can lead to misleading results when there is a strong correlation or interaction between features, as the partial dependence function will not capture their combined effect accurately.</p></li>
<li><p><em>Inaccurate representation of complex interactions</em>: PDPs cannot represent high-order interactions or nonlinear relationships between features.</p></li>
<li><p><em>Unreliable in the presence of outliers</em>: PDPs can be sensitive to outliers and extreme values in the dataset, which may result in distorted representations of the feature’s impact on the model’s predictions. Proper preprocessing and outlier detection techniques should be employed to avoid this issue.</p></li>
<li><p><em>Using the average values</em>: PDPs uses the mean expected value for the final prediction of the target feature. This should be fine in most applications, but it may be inappropriate in some applications.</p></li>
<li><p><em>Computational burden</em>: Generating PDPs can be computationally expensive, especially for high-dimensional datasets or complex models. It is important to weigh the benefits of this technique against the computational resources available.</p></li>
</ol>
<p>Keep in mind these limitations when interpreting PDPs (and other techniques) and consider these limitations when drawing conclusions from them.</p>
</div>
</div>
<p>We can now create a two-way PDP to explore the interaction between <code>Price</code> and <code>Advertising</code>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>pdp<span class="sc">::</span><span class="fu">partial</span>(carseats_svm, <span class="at">pred.var =</span> <span class="fu">c</span>(<span class="st">"Price"</span>, <span class="st">"Advertising"</span>), <span class="at">plot =</span> <span class="cn">TRUE</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>A combination of moderate <code>advertising</code> (around 2-18) and low <code>prices</code> (from around 0-40) seems to produce the highest sales units by the SVM model.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>You may note how no python implementation of PDP has been shown since <code>sklearn.inspection.plot_partial_dependence</code>, which was suitable for this task, has recently changed, and the new alternative does not always work well for categorical variables. However, if you are interested, feel free to look up existing alternatives.</p>
</div>
</div>
</section>
<section id="lime-local-interpretable-model-agnostic-explanations" class="level1">
<h1><code>LIME</code> (Local Interpretable Model-agnostic Explanations)</h1>
<p><code>LIME</code> helps explain individual predictions of machine learning models by fitting a local, interpretable model around a specific data point. This allows for more transparency and understanding of the model’s behavior for individual instances.</p>
<section id="svm" class="level2">
<h2 class="anchored" data-anchor-id="svm">SVM</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true" href="">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false" href="">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<p><code>lime</code> package does not support the SVM model from the <code>e1071</code> package out of the box.You can see the list of supported models via <code>?model_type</code>. There are solutions to this:</p>
<ul>
<li>Re-train your model with the <code>caret</code> library which we then work directly with this library (also may be good practice to build your models with <code>caret</code>).</li>
</ul>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the lime library</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lime)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a caret model using a support vector machine</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>svm_caret_model <span class="ot">&lt;-</span> caret<span class="sc">::</span><span class="fu">train</span>(Sales <span class="sc">~</span> ., <span class="at">data =</span> carseats_tr, <span class="at">method =</span> <span class="st">"svmLinear2"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"none"</span>))</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on a test instance</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>test_instance <span class="ot">&lt;-</span> carseats_te[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a lime explainer object for the SVM model</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>lime_svm_explainer <span class="ot">&lt;-</span> lime<span class="sc">::</span><span class="fu">lime</span>(carseats_tr[, <span class="sc">-</span><span class="dv">1</span>], </span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>                                 svm_caret_model)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Explain a prediction using lime</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>lime_svm_explanation <span class="ot">&lt;-</span> <span class="fu">explain</span>(test_instance, lime_svm_explainer, <span class="at">n_features =</span> <span class="dv">10</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_features</span>(lime_svm_explanation)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<ul>
<li>Create custom <code>predict_model</code> and <code>model_type</code> methods for the SVM model.</li>
</ul>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom predict_model function for SVM</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>predict_model.svm <span class="ot">&lt;-</span> <span class="cf">function</span>(x, newdata, type, ...) {</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (type <span class="sc">==</span> <span class="st">"raw"</span>) {</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    res <span class="ot">&lt;-</span> <span class="fu">predict</span>(x, <span class="at">newdata =</span> newdata, ...)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">data.frame</span>(<span class="at">Response =</span> res, <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>))</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> <span class="cf">if</span> (type <span class="sc">==</span> <span class="st">"prob"</span>) {</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    res <span class="ot">&lt;-</span> <span class="fu">predict</span>(x, <span class="at">newdata =</span> newdata, ...)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    prob <span class="ot">&lt;-</span> kernlab<span class="sc">::</span><span class="fu">kernel</span>(x, newdata, <span class="at">j =</span> <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">as.data.frame</span>(prob, <span class="at">check.names =</span> <span class="cn">FALSE</span>))</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom model_type function for SVM</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>model_type.svm <span class="ot">&lt;-</span> <span class="cf">function</span>(x, ...) {</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (x<span class="sc">$</span>type <span class="sc">==</span> <span class="st">"C-classification"</span>) {</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="st">"classification"</span>)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="st">"regression"</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a LIME explainer for the SVM model</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>lime_svm_explainer <span class="ot">&lt;-</span> <span class="fu">lime</span>(x_train, carseats_svm)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose a specific instance from the test set to explain</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>test_instance <span class="ot">&lt;-</span> carseats_te[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate explanations for the chosen instance</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>lime_svm_explanation <span class="ot">&lt;-</span> <span class="fu">explain</span>(test_instance, lime_svm_explainer, <span class="at">n_features =</span> <span class="dv">10</span>)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the explanation</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_features</span>(lime_svm_explanation)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>You can see the prediction plot for 4 test observations. We can see several bar charts. On the y-axis, you see the features (and their intervals), while the x-axis shows the relative strength of each feature at a given value or interval. The positive value (blue color) shows that the feature support or increases the value of the prediction, while the negative value (red color) has a negative effect or decreases the prediction value. Please note that the interpretation for each observation can be different (this explanation has been taken from <a href="https://algotech.netlify.app/blog/interpreting-black-box-regression-model-with-lime/">this blog</a>, which you can visit for further details).</p>
<p>We give the interpretation of the first test observation as an example. The first subplot shows that a <code>price</code> of less than 100 results in purchasing a higher quantity than expected. Additionally, people between the ages of 40 and 55 were most likely to buy the seat, which are people who are not too young nor too old. However, in a typical scenario, we would generally expect younger people to buy car seats, but that’s probably because of the high ages in our dataset (1st. quantile of age is around 40). If the price by the competitor (<code>CompPrice</code>) is also low, it’ll impact the sales units badly. Once again, please note that this is specific to the first observation (i.e., the first subplot).</p>
<p>The next element is <code>Explanation Fit</code>. These values indicate how well LIME explains the model, similar to an R-Squared in linear regression. Here we see the explanation Fit only has values around 0.50-0.7 (50%-70%), which can be interpreted that LIME can only explain a little about our model (in some cases, like the 3rd sub-plot, this value is extremely low). You may choose not to trust the LIME output since it only has a low Explanation Fit.</p>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>We’ll be using provide a small demonstration on how this can be achieved in python. Please note the same logic for the interpretation (and explanation) of the R version applies here, therefore, the code is shorter and there’s no further comment provided for its output.</p>
<p>We use <code>lime</code> package in python (already installed in the lab <code>setup</code>). Then we can run our model in the same way as R:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lime <span class="im">import</span> lime_tabular</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming carseats_tr and carseats_te are already defined as pandas DataFrames</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> carseats_train.drop(columns<span class="op">=</span><span class="st">'Sales'</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> carseats_train[<span class="st">'Sales'</span>]</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> carseats_test.drop(columns<span class="op">=</span><span class="st">'Sales'</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a support vector machine model</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>svm_caret_model <span class="op">=</span> svm.LinearSVR(random_state<span class="op">=</span><span class="dv">2022</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>svm_caret_model.fit(X_train, y_train)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on a test instance</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>test_instance <span class="op">=</span> X_test.iloc[<span class="dv">0</span>:<span class="dv">4</span>]</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a lime explainer object for the SVM model</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>lime_svm_explainer <span class="op">=</span> lime_tabular.LimeTabularExplainer(X_train.values,</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>                                                       feature_names<span class="op">=</span>X_train.columns,</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>                                                       class_names<span class="op">=</span>[<span class="st">'Sales'</span>],</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>                                                       mode<span class="op">=</span><span class="st">'regression'</span>)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Explain a prediction using lime</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>lime_svm_explanation <span class="op">=</span> lime_svm_explainer.explain_instance(test_instance.values[<span class="dv">0</span>], svm_caret_model.predict, num_features<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the features</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.clf()</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>lime_svm_explanation.as_pyplot_figure()</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</div>
</section>
<section id="bonus-xgboost" class="level2">
<h2 class="anchored" data-anchor-id="bonus-xgboost">Bonus: XGBoost</h2>
<p>To give you an example for a classification problem, we can also train an XGBoost using the <code>xgboost</code> library:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and prepare the data</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>carseats_df <span class="ot">&lt;-</span> Carseats</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>carseats_df<span class="sc">$</span>High <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(carseats_df<span class="sc">$</span>Sales <span class="sc">&lt;=</span> <span class="dv">8</span>, <span class="st">"yes"</span>, <span class="st">"no"</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>carseats_df<span class="sc">$</span>High <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(carseats_df<span class="sc">$</span>High)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>carseats_df<span class="sc">$</span>ShelveLoc <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(carseats_df<span class="sc">$</span>ShelveLoc)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>carseats_df<span class="sc">$</span>Urban <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(carseats_df<span class="sc">$</span>Urban)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>carseats_df<span class="sc">$</span>US <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(carseats_df<span class="sc">$</span>US)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the data for xgboost (as shown in the boosting excercises)</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>xgb_data <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(High <span class="sc">~</span> ., <span class="at">data =</span> carseats_df)[,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>xgb_label <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(carseats_df<span class="sc">$</span>High) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>xgb_dmatrix <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> xgb_data, <span class="at">label =</span> xgb_label)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Train a gradient boosting model</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>carseats_xgb <span class="ot">&lt;-</span> <span class="fu">xgboost</span>(<span class="at">data =</span> xgb_dmatrix, <span class="at">nrounds =</span> <span class="dv">100</span>, <span class="at">objective =</span> <span class="st">"binary:logistic"</span>, <span class="at">eval_metric =</span> <span class="st">"logloss"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Identify instances with predicted probabilities close to 1, 0, and 0.5:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># LIME explanations for a gradient boosting model</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>xgb_preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(carseats_xgb, xgb_dmatrix)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="fu">which.max</span>(xgb_preds)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(xgb_preds)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(<span class="fu">abs</span>(xgb_preds <span class="sc">-</span> <span class="fl">0.5</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Generate LIME explanations for the selected instances:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># before making the prediction, we need to also one-hot encode the categorical variables</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>to_explain <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">model.matrix</span>(<span class="sc">~</span>.,<span class="at">data =</span> carseats_df[<span class="fu">c</span>(<span class="dv">120</span>, <span class="dv">4</span>, <span class="dv">60</span>), <span class="sc">-</span><span class="fu">ncol</span>(carseats_df)])[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># we can finally run LIME on our results</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>carseats_lime_xgb <span class="ot">&lt;-</span> <span class="fu">lime</span>(<span class="fu">data.frame</span>(xgb_data), carseats_xgb, <span class="at">bin_continuous =</span> <span class="cn">TRUE</span>, <span class="at">quantile_bins =</span> <span class="cn">FALSE</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>carseats_expl_xgb <span class="ot">&lt;-</span> lime<span class="sc">::</span><span class="fu">explain</span>(to_explain, carseats_lime_xgb, <span class="at">n_labels =</span> <span class="dv">1</span>, <span class="at">n_features =</span> <span class="dv">10</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Visualize the LIME explanations</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_features</span>(carseats_expl_xgb, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>What can you observe from these subplots?</p>
</section>
</section>
<section id="your-turn" class="level1">
<h1>Your turn</h1>
<p>After having done this for the training set, make a selection of the most important variables and run the model again. Would you go for this simpler model that has less features or the more complicated one? (hint: you can compute some scores to see whether dropping features would justify the performance drop).</p>
<p>As a final remark, the same kind of analysis can also be done for classification and different loss functions. As a good example, you can see <a href="https://bookdown.org/gaetan_lovey/data_analytics/dalex.html">a project</a> done by some of the previous students of MScM_BA which also includes a section on feature importance.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/do-unil\.github\.io\/mlba");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../labs/06_Ensembles/Ex_ML_Ensemble.html" class="pagination-link" aria-label="Ensemble Methods">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Ensemble Methods</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../labs/08_UnsupervisedLearning/081_Clustering/Ex_ML_Clustering.html" class="pagination-link" aria-label="Clustering">
        <span class="nav-page-text">Clustering</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Variable Importance"</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r global_options, include = FALSE}</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">fig.align=</span><span class="st">"center"</span>, <span class="at">results =</span> <span class="st">'hide'</span>, <span class="at">fig.show =</span> <span class="st">'hide'</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="fu"># Data &amp; models</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>This exercise shows an example of model-agnostic variable importance for a regression problem. The dataset that we will be working with is <span class="in">`Carseats`</span> from the <span class="in">`ISLR`</span> library which has already been used during some of the exercises such as <span class="in">`Ex_ML_Tree`</span> and <span class="in">`Ex_ML_SVM`</span>. It is highly recommended that you try to implement some parts of the exercise yourself before checking the answers.</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Load the data from ISLR package, then assign 90% of the data for training and the remainder for testing. Please keep in mind that we make a training split running the feature importance (instead of using the entire dataset) as we "may" want to re-train the model with only a fewer features rather than biasing our decision by also including the testing data.</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Create three models including a linear regression, a regression tree and a support-vector machine.</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>**Answer** <span class="dt">&lt;/</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">p</span><span class="dt">&gt;</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="fu">## R</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="co"># divide the data into training and testing sets</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2022</span>)</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>carseats_index <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x=</span><span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Carseats), <span class="at">size=</span><span class="fl">0.9</span><span class="sc">*</span><span class="fu">nrow</span>(Carseats), <span class="at">replace=</span><span class="cn">FALSE</span>)</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>carseats_tr <span class="ot">&lt;-</span> Carseats[carseats_index,]</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>carseats_te <span class="ot">&lt;-</span> Carseats[<span class="sc">-</span>carseats_index,]</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="co"># define a linear regression</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>carseats_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Sales<span class="sc">~</span>., <span class="at">data=</span>carseats_tr)</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a><span class="co"># define a regression tree (you can also use `adabag::autoprune()`here</span></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>carseats_rt <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Sales<span class="sc">~</span>., <span class="at">data=</span>carseats_tr)</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a><span class="co"># define a support-vector machine</span></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>carseats_svm <span class="ot">&lt;-</span> <span class="fu">svm</span>(Sales <span class="sc">~</span> ., <span class="at">data=</span>carseats_tr)</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>)</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVR</span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the training and test sets created in R (no easy way to get the `Carseats` data in python)</span></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the categorical columns to one-hot encoded ones</span></span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>carseats_train, carseats_test <span class="op">=</span> pd.get_dummies(r.carseats_tr.copy()), pd.get_dummies(r.carseats_tr.copy())</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a linear regression</span></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>carseats_lr <span class="op">=</span> LinearRegression()</span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>carseats_lr.fit(carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>])</span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a decision tree regressor</span></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>carseats_dtr <span class="op">=</span> DecisionTreeRegressor()</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a>carseats_dtr.fit(carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>])</span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a support-vector machine</span></span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>carseats_svr <span class="op">=</span> SVR()</span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a>carseats_svr.fit(carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>])</span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">p</span><span class="dt">&gt;</span></span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a><span class="fu"># Variable Importance using `DALEX`</span></span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>Feature importance can be manually computed by permuting one column and computing the drop in the value of the loss function (e.g. RMSE for regression and Accuracy for classification). This permutation can be repeated n-times to calculate a mean drop in loss value across various runs. This form of variable importance is often referred to as "permutation feature importance".</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a>Fortunately, in R there are some nice packages that can help you with that. Three common libraries (among many) for model-agnostic feature importance in R are <span class="in">`iml`</span>, <span class="in">`DALEX`</span> and <span class="in">`vip`</span> . If you would like to learn about the model-specific and model-agnostic feature importance and the various packages in R, you can refer to the chapter 16 of the book <span class="co">[</span><span class="ot">"Hands-on Machine Learning with R"</span><span class="co">](https://ema.drwhy.ai/featureImportance.html)</span>. For the purpose of this part of the exercise, we will be using the <span class="in">`DALEX`</span> library. Please note that the exercise has been largely inspired by the same chapter 16 of the book. You can also check out other variations such as <span class="in">`iml`</span> and <span class="in">`vip`</span> implementations.</span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a><span class="fu">## Creating an `explain` object</span></span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a><span class="in">`DALEX`</span> has an <span class="in">`explain`</span> object which allows you to do various kind of explanatory analysis. Try reading about the required inputs for it by referring to its documentations (<span class="in">`?DALEX::explain()`</span>) and also referring to the book mentioned at the beginning of this exercise (<span class="co">[</span><span class="ot">"Hands-on Machine Learning with R"</span><span class="co">](https://ema.drwhy.ai/featureImportance.html)</span>). Create one explain object per model for the training data and set the inputs that you need which are <span class="in">`model`</span>, <span class="in">`data`</span> (data frame of features) and <span class="in">`y`</span> (vector of observed outcomes). Also, you can give a caption to your model through the <span class="in">`label`</span> argument.</span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DALEX)</span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> <span class="fu">select</span>(carseats_tr, <span class="sc">-</span>Sales)</span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> <span class="fu">pull</span>(carseats_tr, Sales)</span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a>explainer_lm <span class="ot">&lt;-</span> DALEX<span class="sc">::</span><span class="fu">explain</span>(<span class="at">model =</span> carseats_lm, </span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">data =</span> x_train, </span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">y =</span> y_train,</span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">label =</span> <span class="st">"Linear Regression"</span>)</span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a>explainer_rt <span class="ot">&lt;-</span> DALEX<span class="sc">::</span><span class="fu">explain</span>(<span class="at">model =</span> carseats_rt,</span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a>                               <span class="at">data =</span> x_train,</span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a>                               <span class="at">y =</span> y_train,</span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a>                               <span class="at">label =</span> <span class="st">"Regression Tree"</span>)</span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a>explainer_svm <span class="ot">&lt;-</span> DALEX<span class="sc">::</span><span class="fu">explain</span>(<span class="at">model =</span> carseats_svm,</span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a>                                <span class="at">data =</span> x_train,</span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a>                                <span class="at">y =</span> y_train,</span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a>                                <span class="at">label =</span> <span class="st">"Support Vector Machine"</span>)</span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a>To calculate the feature importances using Python, we'll be using the <span class="in">`permutation_importance`</span> function from the <span class="in">`sklearn`</span> library.</span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-139"><a href="#cb18-139" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-140"><a href="#cb18-140" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span>
<span id="cb18-141"><a href="#cb18-141" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb18-142"><a href="#cb18-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-143"><a href="#cb18-143" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale the features (relevant to SVM)</span></span>
<span id="cb18-144"><a href="#cb18-144" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb18-145"><a href="#cb18-145" aria-hidden="true" tabindex="-1"></a>carseats_train_scaled <span class="op">=</span> carseats_train.copy()</span>
<span id="cb18-146"><a href="#cb18-146" aria-hidden="true" tabindex="-1"></a>carseats_test_scaled <span class="op">=</span> carseats_test.copy()</span>
<span id="cb18-147"><a href="#cb18-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-148"><a href="#cb18-148" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate feature importances for each model</span></span>
<span id="cb18-149"><a href="#cb18-149" aria-hidden="true" tabindex="-1"></a>importance_lr <span class="op">=</span> permutation_importance(carseats_lr, carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>], n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">2022</span>)</span>
<span id="cb18-150"><a href="#cb18-150" aria-hidden="true" tabindex="-1"></a>importance_dtr <span class="op">=</span> permutation_importance(carseats_dtr, carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>], n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">2022</span>)</span>
<span id="cb18-151"><a href="#cb18-151" aria-hidden="true" tabindex="-1"></a>importance_svr <span class="op">=</span> permutation_importance(carseats_svr, carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train[<span class="st">'Sales'</span>], n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">2022</span>)</span>
<span id="cb18-152"><a href="#cb18-152" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the SVM model on scaled data</span></span>
<span id="cb18-153"><a href="#cb18-153" aria-hidden="true" tabindex="-1"></a>carseats_svr_scaled <span class="op">=</span> SVR(kernel<span class="op">=</span><span class="st">'linear'</span>)</span>
<span id="cb18-154"><a href="#cb18-154" aria-hidden="true" tabindex="-1"></a>carseats_svr_scaled.fit(carseats_train_scaled.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train_scaled[<span class="st">'Sales'</span>])</span>
<span id="cb18-155"><a href="#cb18-155" aria-hidden="true" tabindex="-1"></a>importance_svr_scaled <span class="op">=</span> permutation_importance(carseats_svr_scaled, carseats_train_scaled.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]), carseats_train_scaled[<span class="st">'Sales'</span>], n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">2022</span>)</span>
<span id="cb18-156"><a href="#cb18-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-157"><a href="#cb18-157" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the feature importances</span></span>
<span id="cb18-158"><a href="#cb18-158" aria-hidden="true" tabindex="-1"></a>importance_df <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>{</span>
<span id="cb18-159"><a href="#cb18-159" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: carseats_train.drop(columns<span class="op">=</span>[<span class="st">'Sales'</span>]).columns,</span>
<span id="cb18-160"><a href="#cb18-160" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Linear Regression'</span>: importance_lr.importances_mean,</span>
<span id="cb18-161"><a href="#cb18-161" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Decision Tree'</span>: importance_dtr.importances_mean,</span>
<span id="cb18-162"><a href="#cb18-162" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Support Vector Machine (unscaled)'</span>: importance_svr.importances_mean,</span>
<span id="cb18-163"><a href="#cb18-163" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Support Vector Machine (scaled)'</span>: importance_svr_scaled.importances_mean</span>
<span id="cb18-164"><a href="#cb18-164" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb18-165"><a href="#cb18-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-166"><a href="#cb18-166" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(importance_df)</span>
<span id="cb18-167"><a href="#cb18-167" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-168"><a href="#cb18-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-169"><a href="#cb18-169" aria-hidden="true" tabindex="-1"></a>You can observe the value of scaling for SVM. The results seems to agree that <span class="in">`Price`</span> is the most important feature.</span>
<span id="cb18-170"><a href="#cb18-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-171"><a href="#cb18-171" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-172"><a href="#cb18-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-173"><a href="#cb18-173" aria-hidden="true" tabindex="-1"></a><span class="fu">## Plotting the feature importance</span></span>
<span id="cb18-174"><a href="#cb18-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-175"><a href="#cb18-175" aria-hidden="true" tabindex="-1"></a>Now that you have created the <span class="in">`DALEX::explain`</span> objects, we will use another function called <span class="in">`model_parts`</span> which takes care of the feature permutation. Try reading about the function <span class="in">`DALEX::model_parts()`</span> . The main arguments that you need to provide to the <span class="in">`explain`</span> function are:</span>
<span id="cb18-176"><a href="#cb18-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-177"><a href="#cb18-177" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>An <span class="in">`explainer`</span> object (what you created above).</span>
<span id="cb18-178"><a href="#cb18-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-179"><a href="#cb18-179" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`B`</span> which is the number of permutations (i.e. how many times you want to randomly shuffle each column).</span>
<span id="cb18-180"><a href="#cb18-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-181"><a href="#cb18-181" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The <span class="in">`type`</span> of scores you would like it to return (raw score vs differences vs ratios) which in this case we set to <span class="in">`ratio`</span> and you can read more the differences in the documentation.</span>
<span id="cb18-182"><a href="#cb18-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-183"><a href="#cb18-183" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`N`</span> argument which you can set to <span class="in">`N=NULL`</span> which essentially asks how many samples you would like to use for calculating the variable importance, where setting it to <span class="in">`NULL`</span> means that we use the entire training set.</span>
<span id="cb18-184"><a href="#cb18-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-185"><a href="#cb18-185" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>There is also a <span class="in">`loss_function`</span> which by default is <span class="in">`RMSE`</span> for regression (our case) and <span class="in">`1-AUC`</span> for classification, by there are a few more which you can find out about by referring to the documentations (e.g. through <span class="in">`?DALEX::loss_root_mean_square`</span>).</span>
<span id="cb18-186"><a href="#cb18-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-187"><a href="#cb18-187" aria-hidden="true" tabindex="-1"></a>After assigning <span class="in">`model_parts`</span> to a variable, try plotting each model to see the most important variables. What do you see? Are there important features that are in common?</span>
<span id="cb18-188"><a href="#cb18-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-191"><a href="#cb18-191" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-192"><a href="#cb18-192" aria-hidden="true" tabindex="-1"></a>calculate_importance <span class="ot">&lt;-</span> <span class="cf">function</span>(your_model_explainer, <span class="at">n_permutations =</span> <span class="dv">10</span>) {</span>
<span id="cb18-193"><a href="#cb18-193" aria-hidden="true" tabindex="-1"></a>  imp <span class="ot">&lt;-</span> <span class="fu">model_parts</span>(<span class="at">explainer =</span> your_model_explainer,</span>
<span id="cb18-194"><a href="#cb18-194" aria-hidden="true" tabindex="-1"></a>                     <span class="at">B =</span> n_permutations,</span>
<span id="cb18-195"><a href="#cb18-195" aria-hidden="true" tabindex="-1"></a>                     <span class="at">type =</span> <span class="st">"ratio"</span>,</span>
<span id="cb18-196"><a href="#cb18-196" aria-hidden="true" tabindex="-1"></a>                     <span class="at">N =</span> <span class="cn">NULL</span>)</span>
<span id="cb18-197"><a href="#cb18-197" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(imp)</span>
<span id="cb18-198"><a href="#cb18-198" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-199"><a href="#cb18-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-200"><a href="#cb18-200" aria-hidden="true" tabindex="-1"></a>importance_lm  <span class="ot">&lt;-</span> <span class="fu">calculate_importance</span>(explainer_lm)</span>
<span id="cb18-201"><a href="#cb18-201" aria-hidden="true" tabindex="-1"></a>importance_rt  <span class="ot">&lt;-</span> <span class="fu">calculate_importance</span>(explainer_rt)</span>
<span id="cb18-202"><a href="#cb18-202" aria-hidden="true" tabindex="-1"></a>importance_svm <span class="ot">&lt;-</span> <span class="fu">calculate_importance</span>(explainer_svm)</span>
<span id="cb18-203"><a href="#cb18-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-204"><a href="#cb18-204" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb18-205"><a href="#cb18-205" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(importance_lm, importance_rt, importance_svm) <span class="sc">+</span></span>
<span id="cb18-206"><a href="#cb18-206" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Mean variable-importance ratio over 10 permutations"</span>, <span class="st">""</span>)</span>
<span id="cb18-207"><a href="#cb18-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-208"><a href="#cb18-208" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-209"><a href="#cb18-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-210"><a href="#cb18-210" aria-hidden="true" tabindex="-1"></a><span class="fu"># Partial Dependence Plots (`PDP`)</span></span>
<span id="cb18-211"><a href="#cb18-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-212"><a href="#cb18-212" aria-hidden="true" tabindex="-1"></a>Partial dependence plots (PDPs) show the marginal effect of one or two features on the predicted outcome of a machine learning model. They can be used to visualize and interpret the influence of selected features on the model's predictions. We'll continue using the same Carseats data. We first create PDPs for the <span class="in">`Price`</span> and <span class="in">`Advertising`</span> features using the the SVM model <span class="in">`carseats_svm`</span> created earlier:</span>
<span id="cb18-213"><a href="#cb18-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-216"><a href="#cb18-216" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-217"><a href="#cb18-217" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb18-218"><a href="#cb18-218" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb18-219"><a href="#cb18-219" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pdp)</span>
<span id="cb18-220"><a href="#cb18-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-221"><a href="#cb18-221" aria-hidden="true" tabindex="-1"></a>pdp<span class="sc">::</span><span class="fu">partial</span>(carseats_svm, <span class="at">pred.var =</span> <span class="st">"Price"</span>, <span class="at">plot =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-222"><a href="#cb18-222" aria-hidden="true" tabindex="-1"></a>pdp<span class="sc">::</span><span class="fu">partial</span>(carseats_svm, <span class="at">pred.var =</span> <span class="st">"Advertising"</span>, <span class="at">plot =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-223"><a href="#cb18-223" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-224"><a href="#cb18-224" aria-hidden="true" tabindex="-1"></a>What we see in the first plot is that for this particular model, the higher the <span class="in">`price`</span>, the number of carseats sold (units) which makes sense. With regards to the advertising, we see that the higher the local advertising budget for the company (see <span class="in">`?Carseats`</span> for more details), the higher the sales number of units for a car, however, there's a plateau after which you cannot sell more units. This means that after a certain point, increasing the advertising budget may no longer bring any benefit in terms of the units sold. It's important to note that in PDP, we study the decision by the model and not the data, however, we can always visualize our results to see if they follow a similar trend or not:</span>
<span id="cb18-225"><a href="#cb18-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-228"><a href="#cb18-228" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-229"><a href="#cb18-229" aria-hidden="true" tabindex="-1"></a><span class="co"># plot(Carseats$Advertising, Carseats$Sales, xlab = "Advertising Budget", ylab = "Sales Units")</span></span>
<span id="cb18-230"><a href="#cb18-230" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> carseats_tr, <span class="fu">aes</span>(<span class="at">x =</span> Advertising, <span class="at">y =</span> Sales)) <span class="sc">+</span></span>
<span id="cb18-231"><a href="#cb18-231" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb18-232"><a href="#cb18-232" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Advertising Budget"</span>, <span class="at">y =</span> <span class="st">"Sales Unit"</span>) <span class="sc">+</span></span>
<span id="cb18-233"><a href="#cb18-233" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Relationship between Sales and Advertising Budget"</span>)</span>
<span id="cb18-234"><a href="#cb18-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-235"><a href="#cb18-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-236"><a href="#cb18-236" aria-hidden="true" tabindex="-1"></a>We can see that the trend is not very clear but may be headed in the same direction.</span>
<span id="cb18-237"><a href="#cb18-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-238"><a href="#cb18-238" aria-hidden="true" tabindex="-1"></a>For categorical features, such as <span class="in">`ShelveLoc`</span>, we can make a similar kind of PDP:</span>
<span id="cb18-239"><a href="#cb18-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-242"><a href="#cb18-242" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-243"><a href="#cb18-243" aria-hidden="true" tabindex="-1"></a>pdp<span class="sc">::</span><span class="fu">partial</span>(carseats_svm, <span class="at">pred.var =</span> <span class="st">"ShelveLoc"</span>, <span class="at">plot =</span> <span class="cn">TRUE</span>, <span class="at">plot.engine =</span> <span class="st">"ggplot"</span>)</span>
<span id="cb18-244"><a href="#cb18-244" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-245"><a href="#cb18-245" aria-hidden="true" tabindex="-1"></a>From this plot, we can see that the better the quality of shelving location, the high the number of units sold (which again makes sense).</span>
<span id="cb18-246"><a href="#cb18-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-247"><a href="#cb18-247" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb18-248"><a href="#cb18-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-249"><a href="#cb18-249" aria-hidden="true" tabindex="-1"></a><span class="fu">## Limitations of PDPs</span></span>
<span id="cb18-250"><a href="#cb18-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-251"><a href="#cb18-251" aria-hidden="true" tabindex="-1"></a>PDPs can have some limitations, which you, as users, should be aware of. These limitations do partially apply to other techniques presented during lab:</span>
<span id="cb18-252"><a href="#cb18-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-253"><a href="#cb18-253" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>*Assuming feature independence*: PDPs assume that the features being plotted are independent of each other. This can lead to misleading results when there is a strong correlation or interaction between features, as the partial dependence function will not capture their combined effect accurately.</span>
<span id="cb18-254"><a href="#cb18-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-255"><a href="#cb18-255" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>*Inaccurate representation of complex interactions*: PDPs cannot represent high-order interactions or nonlinear relationships between features.</span>
<span id="cb18-256"><a href="#cb18-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-257"><a href="#cb18-257" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>*Unreliable in the presence of outliers*: PDPs can be sensitive to outliers and extreme values in the dataset, which may result in distorted representations of the feature's impact on the model's predictions. Proper preprocessing and outlier detection techniques should be employed to avoid this issue.</span>
<span id="cb18-258"><a href="#cb18-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-259"><a href="#cb18-259" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>*Using the average values*: PDPs uses the mean expected value for the final prediction of the target feature. This should be fine in most applications, but it may be inappropriate in some applications.</span>
<span id="cb18-260"><a href="#cb18-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-261"><a href="#cb18-261" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>*Computational burden*: Generating PDPs can be computationally expensive, especially for high-dimensional datasets or complex models. It is important to weigh the benefits of this technique against the computational resources available.</span>
<span id="cb18-262"><a href="#cb18-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-263"><a href="#cb18-263" aria-hidden="true" tabindex="-1"></a>Keep in mind these limitations when interpreting PDPs (and other techniques) and consider these limitations when drawing conclusions from them.</span>
<span id="cb18-264"><a href="#cb18-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-265"><a href="#cb18-265" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-266"><a href="#cb18-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-267"><a href="#cb18-267" aria-hidden="true" tabindex="-1"></a>We can now create a two-way PDP to explore the interaction between <span class="in">`Price`</span> and <span class="in">`Advertising`</span>:</span>
<span id="cb18-268"><a href="#cb18-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-271"><a href="#cb18-271" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-272"><a href="#cb18-272" aria-hidden="true" tabindex="-1"></a>pdp<span class="sc">::</span><span class="fu">partial</span>(carseats_svm, <span class="at">pred.var =</span> <span class="fu">c</span>(<span class="st">"Price"</span>, <span class="st">"Advertising"</span>), <span class="at">plot =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-273"><a href="#cb18-273" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-274"><a href="#cb18-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-275"><a href="#cb18-275" aria-hidden="true" tabindex="-1"></a>A combination of moderate <span class="in">`advertising`</span> (around 2-18) and low <span class="in">`prices`</span> (from around 0-40) seems to produce the highest sales units by the SVM model.</span>
<span id="cb18-276"><a href="#cb18-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-277"><a href="#cb18-277" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb18-278"><a href="#cb18-278" aria-hidden="true" tabindex="-1"></a>You may note how no python implementation of PDP has been shown since <span class="in">`sklearn.inspection.plot_partial_dependence`</span>, which was suitable for this task, has recently changed, and the new alternative does not always work well for categorical variables. However, if you are interested, feel free to look up existing alternatives.</span>
<span id="cb18-279"><a href="#cb18-279" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-280"><a href="#cb18-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-281"><a href="#cb18-281" aria-hidden="true" tabindex="-1"></a><span class="fu"># `LIME` (Local Interpretable Model-agnostic Explanations)</span></span>
<span id="cb18-282"><a href="#cb18-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-283"><a href="#cb18-283" aria-hidden="true" tabindex="-1"></a><span class="in">`LIME`</span> helps explain individual predictions of machine learning models by fitting a local, interpretable model around a specific data point. This allows for more transparency and understanding of the model's behavior for individual instances.</span>
<span id="cb18-284"><a href="#cb18-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-285"><a href="#cb18-285" aria-hidden="true" tabindex="-1"></a><span class="fu">## SVM</span></span>
<span id="cb18-286"><a href="#cb18-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-287"><a href="#cb18-287" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb18-288"><a href="#cb18-288" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb18-289"><a href="#cb18-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-290"><a href="#cb18-290" aria-hidden="true" tabindex="-1"></a><span class="in">`lime`</span> package does not support the SVM model from the <span class="in">`e1071`</span> package out of the box.You can see the list of supported models via <span class="in">` ?model_type`</span>. There are solutions to this:</span>
<span id="cb18-291"><a href="#cb18-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-292"><a href="#cb18-292" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Re-train your model with the <span class="in">`caret`</span> library which we then work directly with this library (also may be good practice to build your models with <span class="in">`caret`</span>).</span>
<span id="cb18-293"><a href="#cb18-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-296"><a href="#cb18-296" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-297"><a href="#cb18-297" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the lime library</span></span>
<span id="cb18-298"><a href="#cb18-298" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lime)</span>
<span id="cb18-299"><a href="#cb18-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-300"><a href="#cb18-300" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a caret model using a support vector machine</span></span>
<span id="cb18-301"><a href="#cb18-301" aria-hidden="true" tabindex="-1"></a>svm_caret_model <span class="ot">&lt;-</span> caret<span class="sc">::</span><span class="fu">train</span>(Sales <span class="sc">~</span> ., <span class="at">data =</span> carseats_tr, <span class="at">method =</span> <span class="st">"svmLinear2"</span>, <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"none"</span>))</span>
<span id="cb18-302"><a href="#cb18-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-303"><a href="#cb18-303" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on a test instance</span></span>
<span id="cb18-304"><a href="#cb18-304" aria-hidden="true" tabindex="-1"></a>test_instance <span class="ot">&lt;-</span> carseats_te[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb18-305"><a href="#cb18-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-306"><a href="#cb18-306" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a lime explainer object for the SVM model</span></span>
<span id="cb18-307"><a href="#cb18-307" aria-hidden="true" tabindex="-1"></a>lime_svm_explainer <span class="ot">&lt;-</span> lime<span class="sc">::</span><span class="fu">lime</span>(carseats_tr[, <span class="sc">-</span><span class="dv">1</span>], </span>
<span id="cb18-308"><a href="#cb18-308" aria-hidden="true" tabindex="-1"></a>                                 svm_caret_model)</span>
<span id="cb18-309"><a href="#cb18-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-310"><a href="#cb18-310" aria-hidden="true" tabindex="-1"></a><span class="co"># Explain a prediction using lime</span></span>
<span id="cb18-311"><a href="#cb18-311" aria-hidden="true" tabindex="-1"></a>lime_svm_explanation <span class="ot">&lt;-</span> <span class="fu">explain</span>(test_instance, lime_svm_explainer, <span class="at">n_features =</span> <span class="dv">10</span>)</span>
<span id="cb18-312"><a href="#cb18-312" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_features</span>(lime_svm_explanation)</span>
<span id="cb18-313"><a href="#cb18-313" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-314"><a href="#cb18-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-315"><a href="#cb18-315" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Create custom <span class="in">`predict_model`</span> and <span class="in">`model_type`</span> methods for the SVM model. </span>
<span id="cb18-316"><a href="#cb18-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-319"><a href="#cb18-319" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-320"><a href="#cb18-320" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom predict_model function for SVM</span></span>
<span id="cb18-321"><a href="#cb18-321" aria-hidden="true" tabindex="-1"></a>predict_model.svm <span class="ot">&lt;-</span> <span class="cf">function</span>(x, newdata, type, ...) {</span>
<span id="cb18-322"><a href="#cb18-322" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (type <span class="sc">==</span> <span class="st">"raw"</span>) {</span>
<span id="cb18-323"><a href="#cb18-323" aria-hidden="true" tabindex="-1"></a>    res <span class="ot">&lt;-</span> <span class="fu">predict</span>(x, <span class="at">newdata =</span> newdata, ...)</span>
<span id="cb18-324"><a href="#cb18-324" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">data.frame</span>(<span class="at">Response =</span> res, <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>))</span>
<span id="cb18-325"><a href="#cb18-325" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> <span class="cf">if</span> (type <span class="sc">==</span> <span class="st">"prob"</span>) {</span>
<span id="cb18-326"><a href="#cb18-326" aria-hidden="true" tabindex="-1"></a>    res <span class="ot">&lt;-</span> <span class="fu">predict</span>(x, <span class="at">newdata =</span> newdata, ...)</span>
<span id="cb18-327"><a href="#cb18-327" aria-hidden="true" tabindex="-1"></a>    prob <span class="ot">&lt;-</span> kernlab<span class="sc">::</span><span class="fu">kernel</span>(x, newdata, <span class="at">j =</span> <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb18-328"><a href="#cb18-328" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">as.data.frame</span>(prob, <span class="at">check.names =</span> <span class="cn">FALSE</span>))</span>
<span id="cb18-329"><a href="#cb18-329" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb18-330"><a href="#cb18-330" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-331"><a href="#cb18-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-332"><a href="#cb18-332" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom model_type function for SVM</span></span>
<span id="cb18-333"><a href="#cb18-333" aria-hidden="true" tabindex="-1"></a>model_type.svm <span class="ot">&lt;-</span> <span class="cf">function</span>(x, ...) {</span>
<span id="cb18-334"><a href="#cb18-334" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (x<span class="sc">$</span>type <span class="sc">==</span> <span class="st">"C-classification"</span>) {</span>
<span id="cb18-335"><a href="#cb18-335" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="st">"classification"</span>)</span>
<span id="cb18-336"><a href="#cb18-336" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb18-337"><a href="#cb18-337" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="st">"regression"</span>)</span>
<span id="cb18-338"><a href="#cb18-338" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb18-339"><a href="#cb18-339" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-340"><a href="#cb18-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-341"><a href="#cb18-341" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a LIME explainer for the SVM model</span></span>
<span id="cb18-342"><a href="#cb18-342" aria-hidden="true" tabindex="-1"></a>lime_svm_explainer <span class="ot">&lt;-</span> <span class="fu">lime</span>(x_train, carseats_svm)</span>
<span id="cb18-343"><a href="#cb18-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-344"><a href="#cb18-344" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose a specific instance from the test set to explain</span></span>
<span id="cb18-345"><a href="#cb18-345" aria-hidden="true" tabindex="-1"></a>test_instance <span class="ot">&lt;-</span> carseats_te[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb18-346"><a href="#cb18-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-347"><a href="#cb18-347" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate explanations for the chosen instance</span></span>
<span id="cb18-348"><a href="#cb18-348" aria-hidden="true" tabindex="-1"></a>lime_svm_explanation <span class="ot">&lt;-</span> <span class="fu">explain</span>(test_instance, lime_svm_explainer, <span class="at">n_features =</span> <span class="dv">10</span>)</span>
<span id="cb18-349"><a href="#cb18-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-350"><a href="#cb18-350" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the explanation</span></span>
<span id="cb18-351"><a href="#cb18-351" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_features</span>(lime_svm_explanation)</span>
<span id="cb18-352"><a href="#cb18-352" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-353"><a href="#cb18-353" aria-hidden="true" tabindex="-1"></a>You can see the prediction plot for 4 test observations. We can see several bar charts. On the y-axis, you see the features (and their intervals), while the x-axis shows the relative strength of each feature at a given value or interval. The positive value (blue color) shows that the feature support or increases the value of the prediction, while the negative value (red color) has a negative effect or decreases the prediction value. Please note that the interpretation for each observation can be different (this explanation has been taken from <span class="co">[</span><span class="ot">this blog</span><span class="co">](https://algotech.netlify.app/blog/interpreting-black-box-regression-model-with-lime/)</span>, which you can visit for further details). </span>
<span id="cb18-354"><a href="#cb18-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-355"><a href="#cb18-355" aria-hidden="true" tabindex="-1"></a>We give the interpretation of the first test observation as an example. The first subplot shows that a <span class="in">`price`</span> of less than 100 results in purchasing a higher quantity than expected. Additionally, people between the ages of 40 and 55 were most likely to buy the seat, which are people who are not too young nor too old. However, in a typical scenario, we would generally expect younger people to buy car seats, but that's probably because of the high ages in our dataset (1st. quantile of age is around 40). If the price by the competitor (<span class="in">`CompPrice`</span>) is also low, it'll impact the sales units badly. Once again, please note that this is specific to the first observation (i.e., the first subplot).</span>
<span id="cb18-356"><a href="#cb18-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-357"><a href="#cb18-357" aria-hidden="true" tabindex="-1"></a>The next element is <span class="in">`Explanation Fit`</span>. These values indicate how well LIME explains the model, similar to an R-Squared in linear regression. Here we see the explanation Fit only has values around 0.50-0.7 (50%-70%), which can be interpreted that LIME can only explain a little about our model (in some cases, like the 3rd sub-plot, this value is extremely low). You may choose not to trust the LIME output since it only has a low Explanation Fit.</span>
<span id="cb18-358"><a href="#cb18-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-359"><a href="#cb18-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-360"><a href="#cb18-360" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb18-361"><a href="#cb18-361" aria-hidden="true" tabindex="-1"></a>We'll be using provide a small demonstration on how this can be achieved in python. Please note the same logic for the </span>
<span id="cb18-362"><a href="#cb18-362" aria-hidden="true" tabindex="-1"></a>interpretation (and explanation) of the R version applies here, therefore, the code is shorter and there's no further comment provided for its output.</span>
<span id="cb18-363"><a href="#cb18-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-364"><a href="#cb18-364" aria-hidden="true" tabindex="-1"></a>We use <span class="in">`lime`</span> package in python (already installed in the lab <span class="in">`setup`</span>). Then we can run our model in the same way as R:</span>
<span id="cb18-365"><a href="#cb18-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-368"><a href="#cb18-368" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-369"><a href="#cb18-369" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb18-370"><a href="#cb18-370" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb18-371"><a href="#cb18-371" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lime <span class="im">import</span> lime_tabular</span>
<span id="cb18-372"><a href="#cb18-372" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-373"><a href="#cb18-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-374"><a href="#cb18-374" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming carseats_tr and carseats_te are already defined as pandas DataFrames</span></span>
<span id="cb18-375"><a href="#cb18-375" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> carseats_train.drop(columns<span class="op">=</span><span class="st">'Sales'</span>)</span>
<span id="cb18-376"><a href="#cb18-376" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> carseats_train[<span class="st">'Sales'</span>]</span>
<span id="cb18-377"><a href="#cb18-377" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> carseats_test.drop(columns<span class="op">=</span><span class="st">'Sales'</span>)</span>
<span id="cb18-378"><a href="#cb18-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-379"><a href="#cb18-379" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a support vector machine model</span></span>
<span id="cb18-380"><a href="#cb18-380" aria-hidden="true" tabindex="-1"></a>svm_caret_model <span class="op">=</span> svm.LinearSVR(random_state<span class="op">=</span><span class="dv">2022</span>)</span>
<span id="cb18-381"><a href="#cb18-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-382"><a href="#cb18-382" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb18-383"><a href="#cb18-383" aria-hidden="true" tabindex="-1"></a>svm_caret_model.fit(X_train, y_train)</span>
<span id="cb18-384"><a href="#cb18-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-385"><a href="#cb18-385" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on a test instance</span></span>
<span id="cb18-386"><a href="#cb18-386" aria-hidden="true" tabindex="-1"></a>test_instance <span class="op">=</span> X_test.iloc[<span class="dv">0</span>:<span class="dv">4</span>]</span>
<span id="cb18-387"><a href="#cb18-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-388"><a href="#cb18-388" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a lime explainer object for the SVM model</span></span>
<span id="cb18-389"><a href="#cb18-389" aria-hidden="true" tabindex="-1"></a>lime_svm_explainer <span class="op">=</span> lime_tabular.LimeTabularExplainer(X_train.values,</span>
<span id="cb18-390"><a href="#cb18-390" aria-hidden="true" tabindex="-1"></a>                                                       feature_names<span class="op">=</span>X_train.columns,</span>
<span id="cb18-391"><a href="#cb18-391" aria-hidden="true" tabindex="-1"></a>                                                       class_names<span class="op">=</span>[<span class="st">'Sales'</span>],</span>
<span id="cb18-392"><a href="#cb18-392" aria-hidden="true" tabindex="-1"></a>                                                       mode<span class="op">=</span><span class="st">'regression'</span>)</span>
<span id="cb18-393"><a href="#cb18-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-394"><a href="#cb18-394" aria-hidden="true" tabindex="-1"></a><span class="co"># Explain a prediction using lime</span></span>
<span id="cb18-395"><a href="#cb18-395" aria-hidden="true" tabindex="-1"></a>lime_svm_explanation <span class="op">=</span> lime_svm_explainer.explain_instance(test_instance.values[<span class="dv">0</span>], svm_caret_model.predict, num_features<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb18-396"><a href="#cb18-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-397"><a href="#cb18-397" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the features</span></span>
<span id="cb18-398"><a href="#cb18-398" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.clf()</span></span>
<span id="cb18-399"><a href="#cb18-399" aria-hidden="true" tabindex="-1"></a>lime_svm_explanation.as_pyplot_figure()</span>
<span id="cb18-400"><a href="#cb18-400" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-401"><a href="#cb18-401" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-402"><a href="#cb18-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-403"><a href="#cb18-403" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-404"><a href="#cb18-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-405"><a href="#cb18-405" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bonus: XGBoost</span></span>
<span id="cb18-406"><a href="#cb18-406" aria-hidden="true" tabindex="-1"></a>To give you an example for a classification problem, we can also train an XGBoost using the <span class="in">`xgboost`</span> library:</span>
<span id="cb18-407"><a href="#cb18-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-410"><a href="#cb18-410" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-411"><a href="#cb18-411" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb18-412"><a href="#cb18-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-413"><a href="#cb18-413" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and prepare the data</span></span>
<span id="cb18-414"><a href="#cb18-414" aria-hidden="true" tabindex="-1"></a>carseats_df <span class="ot">&lt;-</span> Carseats</span>
<span id="cb18-415"><a href="#cb18-415" aria-hidden="true" tabindex="-1"></a>carseats_df<span class="sc">$</span>High <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(carseats_df<span class="sc">$</span>Sales <span class="sc">&lt;=</span> <span class="dv">8</span>, <span class="st">"yes"</span>, <span class="st">"no"</span>)</span>
<span id="cb18-416"><a href="#cb18-416" aria-hidden="true" tabindex="-1"></a>carseats_df<span class="sc">$</span>High <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(carseats_df<span class="sc">$</span>High)</span>
<span id="cb18-417"><a href="#cb18-417" aria-hidden="true" tabindex="-1"></a>carseats_df<span class="sc">$</span>ShelveLoc <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(carseats_df<span class="sc">$</span>ShelveLoc)</span>
<span id="cb18-418"><a href="#cb18-418" aria-hidden="true" tabindex="-1"></a>carseats_df<span class="sc">$</span>Urban <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(carseats_df<span class="sc">$</span>Urban)</span>
<span id="cb18-419"><a href="#cb18-419" aria-hidden="true" tabindex="-1"></a>carseats_df<span class="sc">$</span>US <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(carseats_df<span class="sc">$</span>US)</span>
<span id="cb18-420"><a href="#cb18-420" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb18-421"><a href="#cb18-421" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the data for xgboost (as shown in the boosting excercises)</span></span>
<span id="cb18-422"><a href="#cb18-422" aria-hidden="true" tabindex="-1"></a>xgb_data <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(High <span class="sc">~</span> ., <span class="at">data =</span> carseats_df)[,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb18-423"><a href="#cb18-423" aria-hidden="true" tabindex="-1"></a>xgb_label <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(carseats_df<span class="sc">$</span>High) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb18-424"><a href="#cb18-424" aria-hidden="true" tabindex="-1"></a>xgb_dmatrix <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> xgb_data, <span class="at">label =</span> xgb_label)</span>
<span id="cb18-425"><a href="#cb18-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-426"><a href="#cb18-426" aria-hidden="true" tabindex="-1"></a><span class="co"># Train a gradient boosting model</span></span>
<span id="cb18-427"><a href="#cb18-427" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb18-428"><a href="#cb18-428" aria-hidden="true" tabindex="-1"></a>carseats_xgb <span class="ot">&lt;-</span> <span class="fu">xgboost</span>(<span class="at">data =</span> xgb_dmatrix, <span class="at">nrounds =</span> <span class="dv">100</span>, <span class="at">objective =</span> <span class="st">"binary:logistic"</span>, <span class="at">eval_metric =</span> <span class="st">"logloss"</span>)</span>
<span id="cb18-429"><a href="#cb18-429" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-430"><a href="#cb18-430" aria-hidden="true" tabindex="-1"></a>Identify instances with predicted probabilities close to 1, 0, and 0.5:</span>
<span id="cb18-431"><a href="#cb18-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-434"><a href="#cb18-434" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-435"><a href="#cb18-435" aria-hidden="true" tabindex="-1"></a><span class="co"># LIME explanations for a gradient boosting model</span></span>
<span id="cb18-436"><a href="#cb18-436" aria-hidden="true" tabindex="-1"></a>xgb_preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(carseats_xgb, xgb_dmatrix)</span>
<span id="cb18-437"><a href="#cb18-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-438"><a href="#cb18-438" aria-hidden="true" tabindex="-1"></a><span class="fu">which.max</span>(xgb_preds)</span>
<span id="cb18-439"><a href="#cb18-439" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(xgb_preds)</span>
<span id="cb18-440"><a href="#cb18-440" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(<span class="fu">abs</span>(xgb_preds <span class="sc">-</span> <span class="fl">0.5</span>))</span>
<span id="cb18-441"><a href="#cb18-441" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-442"><a href="#cb18-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-443"><a href="#cb18-443" aria-hidden="true" tabindex="-1"></a>Generate LIME explanations for the selected instances:</span>
<span id="cb18-444"><a href="#cb18-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-447"><a href="#cb18-447" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-448"><a href="#cb18-448" aria-hidden="true" tabindex="-1"></a><span class="co"># before making the prediction, we need to also one-hot encode the categorical variables</span></span>
<span id="cb18-449"><a href="#cb18-449" aria-hidden="true" tabindex="-1"></a>to_explain <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">model.matrix</span>(<span class="sc">~</span>.,<span class="at">data =</span> carseats_df[<span class="fu">c</span>(<span class="dv">120</span>, <span class="dv">4</span>, <span class="dv">60</span>), <span class="sc">-</span><span class="fu">ncol</span>(carseats_df)])[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb18-450"><a href="#cb18-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-451"><a href="#cb18-451" aria-hidden="true" tabindex="-1"></a><span class="co"># we can finally run LIME on our results</span></span>
<span id="cb18-452"><a href="#cb18-452" aria-hidden="true" tabindex="-1"></a>carseats_lime_xgb <span class="ot">&lt;-</span> <span class="fu">lime</span>(<span class="fu">data.frame</span>(xgb_data), carseats_xgb, <span class="at">bin_continuous =</span> <span class="cn">TRUE</span>, <span class="at">quantile_bins =</span> <span class="cn">FALSE</span>)</span>
<span id="cb18-453"><a href="#cb18-453" aria-hidden="true" tabindex="-1"></a>carseats_expl_xgb <span class="ot">&lt;-</span> lime<span class="sc">::</span><span class="fu">explain</span>(to_explain, carseats_lime_xgb, <span class="at">n_labels =</span> <span class="dv">1</span>, <span class="at">n_features =</span> <span class="dv">10</span>)</span>
<span id="cb18-454"><a href="#cb18-454" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-455"><a href="#cb18-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-456"><a href="#cb18-456" aria-hidden="true" tabindex="-1"></a>Visualize the LIME explanations</span>
<span id="cb18-457"><a href="#cb18-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-460"><a href="#cb18-460" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-461"><a href="#cb18-461" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_features</span>(carseats_expl_xgb, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb18-462"><a href="#cb18-462" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-463"><a href="#cb18-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-464"><a href="#cb18-464" aria-hidden="true" tabindex="-1"></a>What can you observe from these subplots?</span>
<span id="cb18-465"><a href="#cb18-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-466"><a href="#cb18-466" aria-hidden="true" tabindex="-1"></a><span class="fu"># Your turn</span></span>
<span id="cb18-467"><a href="#cb18-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-468"><a href="#cb18-468" aria-hidden="true" tabindex="-1"></a>After having done this for the training set, make a selection of the most important variables and run the model again. Would you go for this simpler model that has less features or the more complicated one? (hint: you can compute some scores to see whether dropping features would justify the performance drop).</span>
<span id="cb18-469"><a href="#cb18-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-470"><a href="#cb18-470" aria-hidden="true" tabindex="-1"></a>As a final remark, the same kind of analysis can also be done for classification and different loss functions. As a good example, you can see <span class="co">[</span><span class="ot">a project</span><span class="co">](https://bookdown.org/gaetan_lovey/data_analytics/dalex.html)</span> done by some of the previous students of MScM_BA which also includes a section on feature importance.</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2026, <a href="https://iliaazizi.com/">Ilia Azizi</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/07_InterpretableML/Ex_ML_VarImp.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 🤍 and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>