<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Models: Linear and logistic regressions – MLBA - S24</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../labs/03_Models/032_Trees/Ex_ML_Tree.html" rel="next">
<link href="../../../labs/00_lab/setup.html" rel="prev">
<link href="../../../images/logo.dark.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-ce80fb680f754bdddd2e33f428b7c2fe.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-a77d94411ef28645364aa138da2dc249.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-96ccf8338fe666a1f86f626509d49180.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-109dea34fb0ab778c1fa5d25b6154e69.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Models: Linear and logistic regressions – MLBA - S24">
<meta property="og:description" content="Homepage for Machine Learning in Business Analytics at HEC Lausanne, Spring 2024.">
<meta property="og:site_name" content="MLBA - S24 ">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html">Linear &amp; Logistic Regression</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../../index.html" class="sidebar-logo-link">
      <img src="../../../images/logo.light.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main tools-wide">
    <a href="http://moodle2.unil.ch/course/view.php?id=8715" title="Moodle" class="quarto-navigation-tool px-1" aria-label="Moodle"><i class="bi bi-person-rolodex"></i></a>
    <a href="https://github.com/do-unil/mlba" title="GitHub Repo" class="quarto-navigation-tool px-1" aria-label="GitHub Repo"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../schedule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../faq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FAQ</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Lectures</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/01_Introduction/ML_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/02_DataExploration/ML_DataExplo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Exploration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/030_Introduction/ML_Models_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/031_LinearLogisticRegression/ML_LinLogReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/032_Trees/ML_Trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/033_NeuralNetworks/ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/034_SupportVectorMachine/ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/04_Metrics/ML_Metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/05_DataSplitting/ML_DataSplitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/06_Ensembles/ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/07_InterpretableML/ML_Interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/08_UnsupervisedLearning/080_Introduction/ML_UnsupIntro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Unsuperised Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/08_UnsupervisedLearning/081_Clustering/ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/08_UnsupervisedLearning/082_DimensionReduction/ML_DimRed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dimension Reduction</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/00_lab/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/032_Trees/Ex_ML_Tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/033_NeuralNetworks/EX_ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/04_Metrics/Ex_ML_Scoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/06_Ensembles/Ex_ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/07_InterpretableML/Ex_ML_VarImp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/08_UnsupervisedLearning/081_Clustering/Ex_ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/08_UnsupervisedLearning/082_DimensionReduction/Ex_ML_PCA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/08_UnsupervisedLearning/083_AutoEncoders/Ex_ML_Autoencoder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Autoencoders</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Assessments</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../assessments/Exam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exam</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Project</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../assessments/Project_Directives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Directives</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../assessments/Presentation_Guidelines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Presentation Guidelines</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/beginners_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Beginners in R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/data_acquisition/data_sources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Sources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/data_acquisition/web_scraping_api.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Web Scraping</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/cheatsheets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding Cheatsheets</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#linear-regression-real-estate-application" id="toc-linear-regression-real-estate-application" class="nav-link active" data-scroll-target="#linear-regression-real-estate-application">Linear regression: real estate application</a>
  <ul class="collapse">
  <li><a href="#eda" id="toc-eda" class="nav-link" data-scroll-target="#eda">EDA</a></li>
  <li><a href="#modelling" id="toc-modelling" class="nav-link" data-scroll-target="#modelling">Modelling</a></li>
  <li><a href="#variable-selection-interpretation" id="toc-variable-selection-interpretation" class="nav-link" data-scroll-target="#variable-selection-interpretation">Variable selection &amp; interpretation</a></li>
  <li><a href="#inference" id="toc-inference" class="nav-link" data-scroll-target="#inference">Inference</a></li>
  </ul></li>
  <li><a href="#logistic-regression-visit-data" id="toc-logistic-regression-visit-data" class="nav-link" data-scroll-target="#logistic-regression-visit-data">Logistic regression: visit data</a>
  <ul class="collapse">
  <li><a href="#modelling-1" id="toc-modelling-1" class="nav-link" data-scroll-target="#modelling-1">Modelling</a></li>
  <li><a href="#variable-selection-interpretation-1" id="toc-variable-selection-interpretation-1" class="nav-link" data-scroll-target="#variable-selection-interpretation-1">Variable selection &amp; interpretation</a></li>
  <li><a href="#inference-1" id="toc-inference-1" class="nav-link" data-scroll-target="#inference-1">Inference</a></li>
  </ul></li>
  <li><a href="#lasso-ridge-regressions" id="toc-lasso-ridge-regressions" class="nav-link" data-scroll-target="#lasso-ridge-regressions">LASSO &amp; Ridge regressions</a></li>
  <li><a href="#your-turn-to-practice" id="toc-your-turn-to-practice" class="nav-link" data-scroll-target="#your-turn-to-practice">Your turn to practice</a>
  <ul class="collapse">
  <li><a href="#linear-regression-nursing-home-data" id="toc-linear-regression-nursing-home-data" class="nav-link" data-scroll-target="#linear-regression-nursing-home-data">Linear regression: nursing home data</a></li>
  <li><a href="#logistic-regression-the-credit-quality" id="toc-logistic-regression-the-credit-quality" class="nav-link" data-scroll-target="#logistic-regression-the-credit-quality">Logistic regression: the credit quality</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<script type="application/javascript">
// Description: Change image src depending on body class (quarto-light or quarto-dark)
function updateImageSrc() {
  var bodyClass = window.document.body.classList;
  var images = window.document.getElementsByTagName('img');
  for (var i = 0; i < images.length; i++) {
    var image = images[i];
    var src = image.src;
    var newSrc = src;
    if (bodyClass.contains('quarto-light') && src.includes('.dark')) {
      newSrc = src.replace('.dark', '.light');
    } else if (bodyClass.contains('quarto-dark') && src.includes('.light')) {
      newSrc = src.replace('.light', '.dark');
    }
    if (newSrc !== src) {
      image.src = newSrc;
    }
  }
}

var observer = new MutationObserver(function(mutations) {
  mutations.forEach(function(mutation) {
    if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
      updateImageSrc();
    }
  });
});

observer.observe(window.document.body, {
  attributes: true
});

updateImageSrc();
</script>

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html">Linear &amp; Logistic Regression</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Models: Linear and logistic regressions</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="linear-regression-real-estate-application" class="level1">
<h1>Linear regression: real estate application</h1>
<p>The dataset we’ll be using for the first part of the exercise is real estate transaction prices in Taiwan, which can be accessed from this link <a href="https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set">this link</a>. This dataset was modified for this exercise. The modified file <code>real_estate_data.csv</code> is in the exercise folder under <code>/data/</code>.</p>
<p>The aim is to predict the house prices from available features: <em>No</em>, <em>Month</em>, <em>Year</em>, <em>TransDate</em>, <em>HouseAge</em>, <em>Dist</em>, <em>NumStores</em>, <em>Lat</em>, <em>Long</em>, <em>Price</em>. <em>No</em> is the transaction number and will not be used.</p>
<section id="eda" class="level2">
<h2 class="anchored" data-anchor-id="eda">EDA</h2>
<p>First, an EDA of the data is needed. After exploring the structure, the <em>Price</em> is shown with the year and month.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/real_estate_data.csv"</span>))</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="do">## adapt the path to the data</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># if you encountered any error with the encoding of the data (`Error in gregexpr...`), just re-run the code again</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(real_estate_data)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(summarytools)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dfSummary</span>(real_estate_data)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>Month, <span class="at">y=</span>Price, <span class="at">fill=</span><span class="fu">as.factor</span>(Year))) <span class="sc">+</span> </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>()<span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span><span class="fu">as.factor</span>(Year))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The results show how important it is to make an EDA! It appears that the data does not contain transactions for all the months of 2012 and 2013, but just some months by the end of 2012 and the first half of 2013. This shows that it is pointless to use month and year here. This is why we prefer <em>TransDate</em>, a value indicating the transaction time on a linear scale (e.g., 2013.250 is March 2013).</p>
<p>Now we focus on the link between <em>Price</em> and the other features.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="sc">%&gt;%</span> </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Price, HouseAge, Dist, Lat, Long, TransDate) <span class="sc">%&gt;%</span> </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggpairs</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>No clear link appears. The linear regression will help to discover if a combination of the features can predict the price.</p>
</section>
<section id="modelling" class="level2">
<h2 class="anchored" data-anchor-id="modelling">Modelling</h2>
<p>First, we split the data into training/test set (75/25).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">size=</span><span class="fu">nrow</span>(real_estate_data), <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.75</span>,<span class="fl">0.25</span>)) <span class="co"># 1==training set, 2==test set</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>dat_tr_restate <span class="ot">&lt;-</span> real_estate_data[index<span class="sc">==</span><span class="dv">1</span>,]</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>dat_te_restate <span class="ot">&lt;-</span> real_estate_data[index<span class="sc">==</span><span class="dv">2</span>,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, we fit the linear regression to the training set.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>mod_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>               HouseAge<span class="sc">+</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>               Dist<span class="sc">+</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>               NumStores<span class="sc">+</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>               Lat<span class="sc">+</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>               Long, <span class="at">data=</span>dat_tr_restate)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># In R, we load the conda environment as usual</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>reticulate<span class="sc">::</span><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>, <span class="at">required =</span> <span class="cn">TRUE</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">gc</span>(<span class="at">full =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In python, we then use the <code>statsmodels</code> library to fit a linear regression model to the training data and perform feature elimination. We use the <code>.fit()</code> method to fit the model with the formula for the variable names. Note that python’s <code>summary()</code> function is unique to the <code>statsmodels</code> libraries and produces similar information to its R counterpart.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"OMP_NUM_THREADS"</span>] <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"MKL_NUM_THREADS"</span>] <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mkl</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># %env OMP_NUM_THREADS=1</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># set the number of threads. Here we set it to 1 to avoid parallelization when rendering quarto, but you can set it to higher values.</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>mkl.set_num_threads(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary library</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a linear regression model to the training data &amp; print the summary</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>mod_lm_py <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long'</span>, data<span class="op">=</span>r.dat_tr_restate).fit()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mod_lm_py.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>It’s not a suprise that the results are same as the ones obtained in R.</p>
</div>
</div>
</div>
</section>
<section id="variable-selection-interpretation" class="level2">
<h2 class="anchored" data-anchor-id="variable-selection-interpretation">Variable selection &amp; interpretation</h2>
<p>The stepwise variable selection can be performed using the function <strong>step</strong>. By default, it is a backward selection; see <code>?step</code> for details (parameter <strong>direction</strong> is <strong>backward</strong> when <strong>scope</strong> is empty).</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">step</span>(mod_lm) <span class="co"># see the result</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>mod_lm_sel <span class="ot">&lt;-</span> <span class="fu">step</span>(mod_lm) <span class="co"># store the final model into mod_lm_sel</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lm_sel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>As python does not have an exact equivalent of <code>stats::step()</code> function, which performs both forward and backward selection based on AIC, we have to implement it manually. We start with the full model and iteratively remove the feature with the highest p-value and add the feature with the lowest AIC until we can no longer improve the AIC. The final model is stored in <code>mod_lm_sel</code>. For an extensive explanation of what this while loop is doing and how the backward+forward is computed, check the code below:</p>
<details>
<summary>
Explaining feature elimination in python (while loop)
</summary>
<p>We start by setting <code>mod_lm_sel_py</code> to the full model <code>mod_lm_py</code>. Then, we enter a while loop that continues until we break out of it. In each iteration of the loop, we store the current model in prev_model for later comparison. We start by dropping the feature with the highest p-value from the current model using <code>idxmax()</code>, which returns the label of the maximum value in the pvalues attribute of the <code>mod_lm_sel_py</code> object. We exclude the intercept term from the list of labels by specifying <code>labels=['Intercept']</code>. We then create a new model using <code>smf.ols()</code> with the feature removed and fit it to the training data using <code>fit()</code>. We store this new model in <code>mod_lm_sel_py</code>.</p>
<p>Next, we check whether the AIC of the new model is larger than the previous model’s. If it is, we break out of the while loop and use the previous model (prev_model) as the final model. If not, we continue to the next step of the loop. Here, we look for the feature with the lowest AIC among the remaining features using <code>idxmin()</code> on the pvalues attribute, again excluding the intercept term. We create a new model by adding this feature to the current model using <code>smf.ols()</code>, fit it to the training data using <code>fit()</code>, and store it in <code>mod_lm_sel_new</code>.</p>
<p>We then check whether the AIC of the new model is larger than that of the current model. If it is, we break out of the while loop and use the current model (<code>mod_lm_sel_py</code>) as the final model. If not, we update <code>mod_lm_sel_py</code> with the new model and continue to the next iteration of the loop. This way, we iteratively remove the feature with the highest p-value and add the feature with the lowest AIC until we can no longer improve the AIC. The final model is stored in <code>mod_lm_sel_py</code>.</p>
</details>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># perform both forward and backward selection using AIC</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>mod_lm_sel_py <span class="op">=</span> mod_lm_py</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    prev_model <span class="op">=</span> mod_lm_sel_py</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># drop the feature with the highest p-value</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    feature_to_drop <span class="op">=</span> mod_lm_sel_py.pvalues.drop(labels<span class="op">=</span>[<span class="st">'Intercept'</span>]).idxmax()</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    mod_lm_sel_py <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long - '</span> <span class="op">+</span> feature_to_drop, data<span class="op">=</span>r.dat_tr_restate).fit()</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># check if AIC has increased, if yes, break the loop and use the previous model</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> mod_lm_sel_py.aic <span class="op">&gt;</span> prev_model.aic:</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        mod_lm_sel_py <span class="op">=</span> prev_model</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add the feature with the lowest AIC</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    feature_to_add <span class="op">=</span> mod_lm_sel_py.pvalues.drop(labels<span class="op">=</span>[<span class="st">'Intercept'</span>]).idxmin()</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    mod_lm_sel_py_new <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long + '</span> <span class="op">+</span> feature_to_add, data<span class="op">=</span>r.dat_tr_restate).fit()</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># check if AIC has increased, if yes, break the loop and use the previous model</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> mod_lm_sel_py_new.aic <span class="op">&gt;</span> mod_lm_sel_py.aic:</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    mod_lm_sel_py <span class="op">=</span> mod_lm_sel_py_new</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mod_lm_sel_py.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>After identifying the most important features, you can fit a new model using only those features and evaluate its performance using the test set.</p>
<p>The final model does not contain <em>Long</em>. In terms of interpretations, for example:</p>
<ul>
<li>The price increased on average by 3.7 per year (<em>TransDate</em>)</li>
<li>It diminishes in average by (-2)2.4 per year (<em>HouseAge</em>)</li>
<li>etc.</li>
</ul>
</section>
<section id="inference" class="level2">
<h2 class="anchored" data-anchor-id="inference">Inference</h2>
<p>We now predict the prices in the test set. We can make a scatter plot of the predictions versus the observed prices to inspect that. We already know by looking at the <span class="math inline">\(R^2\)</span> in the summary that the prediction quality is not good.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>mod_lm_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod_lm_sel, <span class="at">newdata=</span>dat_te_restate)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dat_te_restate<span class="sc">$</span>Price <span class="sc">~</span> mod_lm_pred, <span class="at">xlab=</span><span class="st">"Prediction"</span>, <span class="at">ylab=</span><span class="st">"Observed prices"</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="co"># line showing the obs -- pred agreement</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>mod_lm_sel_pred <span class="op">=</span> mod_lm_sel_py.predict(r.dat_te_restate)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>ax.scatter(x<span class="op">=</span>mod_lm_sel_pred, y<span class="op">=</span>r.dat_te_restate[<span class="st">'Price'</span>])</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Prediction'</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Observed prices'</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>ax.plot(ax.get_xlim(), ax.get_ylim(), ls<span class="op">=</span><span class="st">"--"</span>, c<span class="op">=</span><span class="st">".3"</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>It appears that the lowest and the highest prices are underestimated. At the center (around 30), the prices are slightly overestimated.</p>
<p>As an exercise, write down the prediction equation of the selected model. Use this equation to explain how instances 1 and 2 (test set) are predicted and calculate the predictions manually. Verify your results using the <em>predict</em> function from the previous R code.</p>
<details>
<summary>
Answer
</summary>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>mod_lm_pred[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><span class="math display">\[
y = -0.000133 + 3.66\times TransDate -0.243\times HouseAge \\-0.00464\times Dist + 1.027\times NumStores + 237.8\times Lat
\]</span></p>
</details>
</section>
</section>
<section id="logistic-regression-visit-data" class="level1">
<h1>Logistic regression: visit data</h1>
<p>To illustrate a logistic regression, we use the data set <strong>DocVis</strong> extracted (modified for the exercise) the library <strong>AER</strong>. The data set reports a 1977–1978 Australian Health Survey. The aim is to predict the outcome <strong>visits</strong>, a binary variable indicating if the individual had at least one visit to a doctor in the past two weeks, using all the other features. To learn more about these features, look at the data described below.</p>
<details>
<summary>
Data Description
</summary>
<p>The predictors are as followed:</p>
<ul>
<li>gender: M/F</li>
<li>age: Age in years divided by 100.</li>
<li>income: Annual income in tens of thousands of dollars.</li>
<li>illness: Number of illnesses in past 2 weeks.</li>
<li>reduced: Number of days of reduced activity in past 2 weeks due to illness or injury.</li>
<li>health: General health questionnaire score using Goldberg’s method.</li>
<li>private: Factor. Does the individual have private health insurance?</li>
<li>freepoor: Factor. Does the individual have free government health insurance due to low income?</li>
<li>freerepat: Factor. Does the individual have free government health insurance due to old age, disability or veteran status?</li>
<li>nchronic: Factor. Is there a chronic condition not limiting activity?</li>
<li>lchronic: Factor. Is there a chronic condition limiting activity?</li>
</ul>
</details>
<p>We can now load the dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>DocVis <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/DocVis.csv"</span>)) <span class="do">## found in the same data folder</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To facilitate the use of logistic regression in <strong>R</strong>, it is <strong>strongly recommended</strong> to have a 0/1 outcome rather than a categorical one. This makes much easier the recognition of the positive label (the “1”) and the negative one (the “0”). Since we want to predict <strong>visits</strong>, we transform it accordingly.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>DocVis<span class="sc">$</span>visits <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(DocVis<span class="sc">$</span>visits<span class="sc">==</span><span class="st">"Yes"</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="modelling-1" class="level2">
<h2 class="anchored" data-anchor-id="modelling-1">Modelling</h2>
<p>We can split our data and fit the logistic regression. The function for this is <strong>glm</strong>. This function encompasses a larger class of models (namely, the generalized linear models) which includes the logistic regression, accessible with <strong>family=“binomial”</strong>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">size=</span><span class="fu">nrow</span>(DocVis), <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.75</span>,<span class="fl">0.25</span>)) <span class="co"># 1==training set, 2==test set</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>dat_tr_visit <span class="ot">&lt;-</span> DocVis[index<span class="sc">==</span><span class="dv">1</span>,]</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>dat_te_visit <span class="ot">&lt;-</span> DocVis[index<span class="sc">==</span><span class="dv">2</span>,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>vis_logr <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>dat_tr_visit, <span class="at">family=</span><span class="st">"binomial"</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(vis_logr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># a hack around this technique to not type all the variable names</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>vis_formula <span class="op">=</span> <span class="st">'visits ~ '</span> <span class="op">+</span> <span class="st">' + '</span>.join(r.dat_tr_visit.columns.difference([<span class="st">'visits'</span>]))</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># create a logistic regression model</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>vis_logr_py <span class="op">=</span> sm.formula.logit(formula<span class="op">=</span> vis_formula, data<span class="op">=</span>r.dat_tr_visit).fit()</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vis_logr_py.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Using <code>.</code> for formulas in R vs Python
</div>
</div>
<div class="callout-body-container callout-body">
<p>In R, the dot <code>.</code> is used as shorthand to indicate that we want to include all other variables in the formula as predictors except for the outcome variable. So, if our outcome variable is y and we want to include all other variables in our data frame as predictors, we can write <code>y ~ .</code> in the formula.</p>
<p>In Python, however, the dot <code>.</code> is not used in the same way in formulas. Instead, to include all other variables as predictors except for <code>y</code>, we would write <code>y ~ x1 + x2 + ...</code> where <code>x1, x2</code>, etc. represent the names of the predictor variables. Also, <code>statsmodels</code> has a similar syntax to R base regressions. In most other typical ML libraries in Python, you must provide the column values instead of using the column names.</p>
</div>
</div>
<p>Note that the <code>family="binomial"</code> argument in R is not needed in Python since <code>sm.formula.logit()</code> assumes the logistic regression model is fitted using a binomial distribution by default.</p>
</div>
</div>
</div>
</section>
<section id="variable-selection-interpretation-1" class="level2">
<h2 class="anchored" data-anchor-id="variable-selection-interpretation-1">Variable selection &amp; interpretation</h2>
<p>Now, we can apply the variable selection:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>vis_logr_sel <span class="ot">&lt;-</span> <span class="fu">step</span>(vis_logr)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(vis_logr_sel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<p>As already seen in the linear regression part, in python, we don’t have the same implementation of the step function, hence why we designed the while loop earlier. It is good practice to create a single function with this step while loop to handle all cases (linear, logistic etc); however, we only implement it here for logistic regression. Therefore, to tackle this, we will create a function that does step-wise elimination for us. We define a function called <code>forward_selected</code> that performs forward selection on a given dataset to select the best predictors for a response variable based on AIC. The function takes two arguments: <code>data</code>, a pandas DataFrame containing the predictors and <code>response</code> variable, and response, a string specifying the name of the response variable.</p>
<details>
<summary>
For more explanation of the code, click on me
</summary>
<p>The function first initializes two sets: <code>remaining</code> and <code>selected</code>. <code>remaining</code> contains the names of all columns in the <code>data</code> DataFrame except for the <code>response</code> variable, while <code>selected</code> is initially empty. The function then initializes <code>current_aic</code> and <code>best_new_aic</code> to infinity. The main loop of the function continues as long as <code>remaining</code> is not empty and <code>current_aic</code> is equal to <code>best_new_aic</code>. At each iteration, the function iterates over all columns in <code>remaining</code> and computes the AIC for a logistic regression model that includes the <code>response</code> variable and the currently selected predictors, as well as the current candidate predictor. The function then adds the candidate predictor and its AIC to a list of <code>(aic, candidate)</code> tuples, and sorts the list by increasing AIC. The function then selects the candidate with the lowest AIC and adds it to the <code>selected</code> set, removes it from the <code>remaining</code> set, and updates <code>current_aic</code> to the new lowest AIC. The function continues this process until no candidate can improve the AIC. Finally, the function fits a logistic regression model using the selected predictors and returns the resulting model.</p>
</details>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code taken from the link below and adjusted for logistic regression with AIC criteria</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://planspace.org/20150423-forward_selection_with_statsmodels/</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_selected(data, response):</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Linear model designed by forward selection.</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co">    data : pandas DataFrame with all possible predictors and response</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="co">    response: string, name of response column in data</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="co">    model: an "optimal" fitted statsmodels linear model</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="co">           with an intercept</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="co">           selected by forward selection</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="co">           evaluated by AIC</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    remaining <span class="op">=</span> <span class="bu">set</span>(data.columns)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    remaining.remove(response)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    selected <span class="op">=</span> []</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    current_aic, best_new_aic <span class="op">=</span> <span class="bu">float</span>(<span class="st">"inf"</span>), <span class="bu">float</span>(<span class="st">"inf"</span>)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> remaining <span class="kw">and</span> current_aic <span class="op">==</span> best_new_aic:</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>        aics_with_candidates <span class="op">=</span> []</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> candidate <span class="kw">in</span> remaining:</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>            formula <span class="op">=</span> <span class="st">"</span><span class="sc">{}</span><span class="st"> ~ </span><span class="sc">{}</span><span class="st"> + 1"</span>.<span class="bu">format</span>(response,</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>                                           <span class="st">' + '</span>.join(selected <span class="op">+</span> [candidate]))</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> smf.logit(formula, data).fit(disp<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>            aic <span class="op">=</span> model.aic</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>            aics_with_candidates.append((aic, candidate))</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        aics_with_candidates.sort()</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        best_new_aic, best_candidate <span class="op">=</span> aics_with_candidates.pop(<span class="dv">0</span>)</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> current_aic <span class="op">&gt;</span> best_new_aic:</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>            remaining.remove(best_candidate)</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>            selected.append(best_candidate)</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>            current_aic <span class="op">=</span> best_new_aic</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>    formula <span class="op">=</span> <span class="st">"</span><span class="sc">{}</span><span class="st"> ~ </span><span class="sc">{}</span><span class="st"> + 1"</span>.<span class="bu">format</span>(response,</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>                                   <span class="st">' + '</span>.join(selected))</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> smf.logit(formula, data).fit(disp<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>mod_logit_sel_py <span class="op">=</span> forward_selected(r.dat_tr_visit, <span class="st">'visits'</span>)</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mod_logit_sel_py.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see that the results of <code>mod_logit_sel_py</code> model are slightly different from the R version, but nevertheless, we have reduced the features and the interpretations (see below) with both R and python versions remain the same.</p>
</div>
</div>
</div>
<p>We can see that the probability of a visit is</p>
<ul>
<li>smaller for males</li>
<li>increasing with age</li>
<li>larger with illness</li>
<li>etc.</li>
</ul>
</section>
<section id="inference-1" class="level2">
<h2 class="anchored" data-anchor-id="inference-1">Inference</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<p>The <strong>predict</strong> function with <strong>type=“response”</strong> will predict the probability of the positive class (“1”). If it is set to <strong>“link”</strong> it produces the linear predictor (i.e., the <span class="math inline">\(z\)</span>). To make the prediction, we thus have to identify if the predicted probability is larger or lower than 0.5.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>prob_te_visit <span class="ot">&lt;-</span> <span class="fu">predict</span>(vis_logr_sel, <span class="at">newdata =</span> dat_te_visit, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>pred_te_visit <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(prob_te_visit <span class="sc">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="at">Pred=</span>pred_te_visit, <span class="at">Obs=</span>dat_te_visit<span class="sc">$</span>visits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<p>The explanation is similar to that of R, with a slight different that here we use <code>pandas.crosstab</code> to make our confusion matrix.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>prob_te_visit <span class="op">=</span> mod_logit_sel_py.predict(r.dat_te_visit)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>pred_te_visit <span class="op">=</span> [<span class="dv">1</span> <span class="cf">if</span> p <span class="op">&gt;=</span> <span class="fl">0.5</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> p <span class="kw">in</span> prob_te_visit]</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>conf_mat <span class="op">=</span> pd.crosstab(pred_te_visit, r.dat_te_visit[<span class="st">'visits'</span>], rownames<span class="op">=</span>[<span class="st">'Pred'</span>], colnames<span class="op">=</span>[<span class="st">'Obs'</span>])</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(conf_mat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The results are extremely close to the R version.</p>
</div>
</div>
</div>
<p>The predictions are not really good. It is in fact a difficult data set. Indeed, the number of 0 is so large compare to the 1, that predicting a 0 always provides a good model overall. That issue will be addressed further later on in the course.</p>
<p>For now, this can be further inspected by looking at the predicted probabilities per observed label.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(prob_te_visit<span class="sc">~</span>dat_te_visit<span class="sc">$</span>visits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>ax.boxplot([prob_te_visit[r.dat_te_visit[<span class="st">'visits'</span>]<span class="op">==</span><span class="dv">0</span>], prob_te_visit[r.dat_te_visit[<span class="st">'visits'</span>]<span class="op">==</span><span class="dv">1</span>]])</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels([<span class="st">'No Visit'</span>, <span class="st">'Visit'</span>])</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Predicted Probability'</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Predicted Probabilities by Visit Status'</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>We see that if the lowest predicted probabilities are usually assigned to 0-observations, most of the probabilities remain below 0.5 (even for the 1-observations). A good model would have two well separated boxplots, well away from 0.5.</p>
<p>Now, as an exercise, write down the prediction equation of the selected model, like you did for linear regression. Use this equation to explain how instance 1 and 2 (test set) are predicted, and calculate the predictions manually. Verify your results using the function <em>predict</em> used before.</p>
<details>
<summary>
Answer
</summary>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>prob_te_visit[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><span class="math display">\[
z(x) = -2.31795-0.31838\times gender\_male+0.39762\times age+\\0.28431\times illness+0.16340\times reduced+0.05589\times health+\\0.27249\times private\_eyes -0.65344\times freepoor\_yes+\\0.38038\times freerepat\_yes  
\]</span> Then <span class="math display">\[
P(Y=1 | X=x) = \frac{e^{z(x)}}{1+e^{z(x)}}
\]</span></p>
</details>
</section>
</section>
<section id="lasso-ridge-regressions" class="level1">
<h1>LASSO &amp; Ridge regressions</h1>
<p>You have been introduced to lasso and ridge regression during the <em>Variable selection with penalization</em> part of the lecture.</p>
<p>Lasso and Ridge Regression are two regularization techniques used in regression models to prevent overfitting by adding a penalty term to the loss function. Lasso regression (aka <span class="math inline">\(L_1\)</span>) adds a penalty term equal to the absolute value of the coefficients. In contrast, Ridge regression (aka <span class="math inline">\(L_2\)</span>) adds a penalty term equal to the squared value of the coefficients. The effect of the penalty term is to shrink the coefficients towards zero, which can help reduce model complexity and improve generalization performance. In this case, we apply lasso and ridge to the real estate data and do not cover logistic regression (example already seen during the class).</p>
<p>First, we need to turn our predictors into matrices, as this is required by the <code>glmnet</code> package in R and works with the python implementation.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># glmnet can only work with matrix objects, columns 2-7 correspond to the same ones used by `lm`</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>dat_tr_re_mat_x <span class="ot">&lt;-</span> <span class="fu">select</span>(dat_tr_restate, <span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>)) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>dat_tr_re_mat_y <span class="ot">&lt;-</span> <span class="fu">pull</span>(dat_tr_restate,<span class="st">'Price'</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>dat_te_re_mat_x <span class="ot">&lt;-</span> <span class="fu">select</span>(dat_te_restate, <span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>)) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>dat_te_re_mat_y <span class="ot">&lt;-</span> <span class="fu">pull</span>(dat_te_restate,<span class="st">'Price'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true">R</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false">Python</a></li></ul>
<div class="tab-content">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<p>On the newly created matrices, we run cross-validated lasso and ridge with the <code>cv.glmnet()</code>, function where setting the <code>alpha</code> (penalty) parameter as 1 produces lasso regression and 0 produces ridge regression. The default value of alpha is 1, which corresponds to lasso regression. For 0&lt;alpha&lt;1, it performs Elastic Net regression (a combination of <span class="math inline">\(L_1\)</span> and <span class="math inline">\(L_2\)</span> regularization).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load appropriate library and set a seed</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Ridge regression model</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>ridge_fit <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(<span class="at">x =</span> dat_tr_re_mat_x, <span class="at">y =</span> dat_tr_re_mat_y, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Lasso regression model</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>lasso_fit <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(<span class="at">x =</span> dat_tr_re_mat_x, <span class="at">y =</span> dat_tr_re_mat_y, <span class="at">alpha =</span> <span class="dv">1</span>) <span class="co">#if you change the `family` argument to `bionomial`, you can get also logistic regression</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can then fit the final models with the best parameters:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>ridge_fit_best <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x=</span>dat_tr_re_mat_x, <span class="at">y =</span> dat_tr_re_mat_y, </span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>                         <span class="at">lambda =</span> ridge_fit<span class="sc">$</span>lambda.min)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>lasso_fit_best <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x=</span>dat_tr_re_mat_x, <span class="at">y=</span>dat_tr_re_mat_y, </span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>                         <span class="at">lambda =</span> lasso_fit<span class="sc">$</span>lambda.min) <span class="co">#can also use lasso_fit$lambda.1se</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can compare different performances for this task using <code>caret::postResample()</code>. We will learn more this function and it’s metrics the upcoming courses &amp; lab sessions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># lasso &amp; ridge performance on the training set</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(ridge_fit_best, <span class="at">newx =</span> dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(lasso_fit_best, <span class="at">newx =</span> dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co"># lasso &amp; ridge performance on the test set</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(ridge_fit_best, <span class="at">newx =</span> dat_te_re_mat_x), dat_te_re_mat_y)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(lasso_fit_best, <span class="at">newx =</span> dat_te_re_mat_x), dat_te_re_mat_y)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Step-wise lm performance on training and test sets</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(mod_lm_sel,dat_tr_restate), dat_tr_re_mat_y)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(mod_lm_sel,dat_te_restate), dat_te_re_mat_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In this case, the lasso is better than the ridge on the test set, and if you have many features, this could be a useful technique. However, they are both outperformed by step-wise linear regression. Lasso and ridge are more useful when you have many more variables. You can try this already by taking more variables for your <code>dat_tr_re_mat_x</code> and <code>dat_te_re_mat_x</code> such <code>select(dat_te_restate,-c('Price', 'Month'))</code> to see how (for better or worse) the performance changes. If you want more explanation on why linear model outperformed lasso and ridge, check out (click on) the further explanation below.</p>
<details>
<summary>
Why lm (or step lm) outperformed lasso &amp; ridge
</summary>
<p>In some situations, it is normal to observe that a linear model may perform better than a regularized model, such as a ridge or lasso. This can occur when the number of predictors in the model is small relative to the sample size or when the predictors are highly correlated.</p>
<p>Linear regression assumes that the relationship between the response variable and the predictors is linear and additive. When this assumption holds, a linear model can be a good choice. In contrast, regularized regression methods such as ridge and lasso add a penalty term to the regression objective function to shrink the estimated coefficients towards zero, which can help to avoid overfitting when the number of predictors is large relative to the sample size or when the predictors are highly correlated.</p>
<p>However, when the number of predictors is small relative to the sample size or when the predictors are highly correlated, the additional regularization provided by ridge or lasso may not be necessary, and a simple linear model may perform better.</p>
<p>It is always a good practice to compare the performance of different models using appropriate evaluation metrics and techniques such as cross-validation. The choice of the best model will depend on the specific problem and the goals of the analysis.</p>
</details>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge, Lasso, RidgeCV, LassoCV</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a seed for reproducibility</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Lasso regression model</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>lasso_cv <span class="op">=</span> LassoCV(cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>lasso_cv.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the optimal regularization parameter</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>lasso_optimal_alpha <span class="op">=</span> lasso_cv.alpha_</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Lasso model with the optimal alpha</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>lasso_best_py <span class="op">=</span> Lasso(alpha<span class="op">=</span>lasso_optimal_alpha)</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>lasso_best_py.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Ridge regression model with cross-validation</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>ridge_cv <span class="op">=</span> RidgeCV(cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>ridge_cv.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the optimal regularization parameter</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>ridge_optimal_alpha <span class="op">=</span> ridge_cv.alpha_</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Ridge model with the optimal alpha</span></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>ridge_best_py <span class="op">=</span> Ridge(alpha<span class="op">=</span>ridge_optimal_alpha)</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>ridge_best_py.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>lambda</code> argument in <code>cv.glmnet()</code> from R corresponds to the <code>alpha</code> argument in <code>RidgeCV()</code>/<code>LassoCV()</code> in python. In <code>cv.glmnet()</code>, the lambda argument specifies the range of regularization parameters to be tested in the model selection process. By default, lambda is set to NULL, which means that <code>glmnet()</code> will automatically choose a sequence of lambda values to search over. Note that in <code>glmnet()</code>, lambda values are used for both <span class="math inline">\(L_1\)</span> (lasso) and <span class="math inline">\(L_2\)</span> (ridge) regularization, whereas in <code>RidgeCV()</code>, alpha values are used to control the mix of L1 and L2 regularization, with alpha = 0 corresponding to pure L2 regularization (i.e., ridge regression).</p>
<p>On the contrary (and to avoid confusion), the <code>alpha</code> argument in <code>cv.glmnet()</code> corresponds to the <code>fit_intercept</code> argument in <code>RidgeCV()</code>/<code>LassoCV()</code>. In <code>cv.glmnet()</code>, the alpha argument specifies the mixing parameter between L1 and L2 regularization.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># python lasso &amp; ridge performance on the training set</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>ridge_best_py<span class="sc">$</span><span class="fu">predict</span>(dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>lasso_best_py<span class="sc">$</span><span class="fu">predict</span>(dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co"># python lasso &amp; ridge performance on the test set</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>ridge_best_py<span class="sc">$</span><span class="fu">predict</span>( dat_te_re_mat_x), dat_te_re_mat_y)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>lasso_best_py<span class="sc">$</span><span class="fu">predict</span>(dat_te_re_mat_x), dat_te_re_mat_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The performance is different in python simply because of different default settings for the python vs R implementations.</p>
</div>
</div>
</div>
<p>To understand the decision making of lasso, we can check the beta’s in a similar fashion to a regression (only shown for the R models).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># running the following can tell you a bit about the impact of different variables</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>small.lambda.index <span class="ot">&lt;-</span> <span class="fu">which</span>(lasso_fit<span class="sc">$</span>lambda <span class="sc">==</span> lasso_fit<span class="sc">$</span>lambda.min)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>lasso_fit<span class="sc">$</span>glmnet.fit<span class="sc">$</span>beta[, small.lambda.index]</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co"># or on the final model</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(lasso_fit , <span class="at">s=</span> <span class="st">'lambda.min'</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lasso_fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see that from the first output <code>Long</code> value has almost a beta of 0. In the second output, it is confirmed that the coefficient of this variable is indeed 0. This could explain why <code>mod_lm_sel</code> also dropped this variable. The rest of the coefficient are similar to <code>summary(mod_lm_sel)</code>. as ridge or lasso in some situations. This can occur when the number of predictors in the model is small relative to the sample size, or when the predictors are highly correlated.</p>
</section>
<section id="your-turn-to-practice" class="level1">
<h1>Your turn to practice</h1>
<section id="linear-regression-nursing-home-data" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-nursing-home-data">Linear regression: nursing home data</h2>
<p>Now it is your turn. Make an linear regression (also feel free to try lasso and ridge regressions) on the nursing data described below (found also in <code>/data/nursing_data.csv</code>). Afterwards, use linear regression to build a predictor of the cost using the other features. Replicate the analysis. Split the data, build a model, make the variable selection, make the predictions and analyze the results. Make also an analysis of the coefficients in terms of the associations between the costs and the features.</p>
<details>
<summary>
Data Description
</summary>
<p>The data set is about patients in a nursing home, where elderly people are helped with daily living needs, also known as Activities of Daily Living (ADL, i.e.&nbsp;communication, eating, walking, showering, going to a toilet, etc.).</p>
<p>Since the stay in such facilities is very expensive, it is important to classify the new-coming patient, and estimate the duration of the stay and the corresponding costs.</p>
<p>In practice, there are different types of patients who require different types of help and, consequently, different duration of the stay. For example, there could be a person with severe mobility issues, who requires the help with most of the needs every day; or a person with mental deviations, who don’t need help with daily routine, but requires extra communication hours.</p>
<p>Here, we will focus of total amount of help (measured in minutes of help provided to a person per week) provided and measure the costs of stay of a person.</p>
<p>The data set on which the analysis is based has the following columns:</p>
<ul>
<li><strong>gender</strong>: a categorical variable with levels “<em>M</em>” for male and “<em>F</em>” for female</li>
<li><strong>age</strong>: integer variable</li>
<li><strong>mobil</strong>: categorical variable that represents the physical mobility with levels
<ul>
<li>1 = Full mobility</li>
<li>2 = Reduced mobility</li>
<li>3 = Restricted mobility in the house</li>
<li>4 = Null mobility</li>
</ul></li>
<li><strong>orient</strong>: categorical variable that represents the orientation (interactions with the environment) with levels
<ul>
<li>1 = Full orientation</li>
<li>2 = Moderate disturbance of orientation</li>
<li>3 = Disorientation</li>
</ul></li>
<li><strong>independ</strong>: categorical variable that represents the independence of ADL with levels
<ul>
<li>1 = Independent of help</li>
<li>2 = Dependent less than 24 hours per day</li>
<li>3 = Dependent at unpredictable time intervals for most of the needs</li>
</ul></li>
<li><strong>minut_mob</strong>: numerical variable that represents the total number of minutes of help with movement per week</li>
<li><strong>need_comm</strong>: categorical variable with levels “<em>Yes</em>” for a person who needs extra communication sessions with an employee, and “<em>No</em>” otherwise</li>
<li><strong>minut_comm</strong>: numerical variable that represents the total number of minutes of communication per week</li>
<li><strong>tot_minut</strong>: numerical variable that represents the total number of minutes spent on a patient per week, <span class="math inline">\(tot\_minut = minut\_mob + minut\_comm\)</span></li>
<li><strong>cost</strong>: numerical variable that represents the total costs of having a patient in the nursing house per month.</li>
</ul>
</details>
<p>Note: since tot_minut=minut_mob+minut_comm, you may not find any meaningful result using the 3 features. This is perfectly normal. Just use 2 features only among these 3 (arbitrary choice).</p>
</section>
<section id="logistic-regression-the-credit-quality" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression-the-credit-quality">Logistic regression: the credit quality</h2>
<p>The German Credit Quality Dataset consists of a set of attributes as good or bad credit risks. In order to find find a detailed description of the features, please refer to the <a href="https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)">original link to the dataset</a>. The <code>german.csv</code> file can also be found in <code>/data/german.csv</code> whichis the mdified version of the original dataset to simplify the analysis, especially the data loading in <strong>R</strong>.</p>
<p>The aim here is to predict the credit quality from the other features. The outcome <strong>Quality</strong> is 0 for “bad” and 1 for “good”. Make an analysis of the data and develop the learner. You can follow these notable steps:</p>
<ul>
<li>Make a simple EDA of the features</li>
<li>Split the data and train the model.</li>
<li>Make variable selection and check out the result.</li>
<li>Interpret the coefficients.</li>
<li>Inspect the quality of the model by making the predictions (confusion table and boxplot of the predicted probabilities).</li>
</ul>
<p>Note that the data are unbalanced again and that you may not find a very good predictor. This issue is quite difficult and will be addressed later.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/do-unil\.github\.io\/mlba");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../labs/00_lab/setup.html" class="pagination-link" aria-label="Setup">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Setup</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../labs/03_Models/032_Trees/Ex_ML_Tree.html" class="pagination-link" aria-label="Decision Trees">
        <span class="nav-page-text">Decision Trees</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb32" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Models: Linear and logistic regressions"</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="an">output-file:</span><span class="co"> Ex_ML_LinLogReg.html</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="in">```{r global_options, include = FALSE}</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::opts_chunk$set(fig.align="center", results = 'hide', fig.show = 'hide')</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="fu"># Linear regression: real estate application</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>The dataset we'll be using for the first part of the exercise is real estate transaction prices in Taiwan, which can be accessed from this link <span class="co">[</span><span class="ot">this link</span><span class="co">](https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set)</span>. This dataset was modified for this exercise. The modified file <span class="in">`real_estate_data.csv`</span> is in the exercise folder under <span class="in">`/data/`</span>.</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>The aim is to predict the house prices from available features: *No*, *Month*, *Year*, *TransDate*, *HouseAge*, *Dist*, *NumStores*, *Lat*, *Long*, *Price*. *No* is the transaction number and will not be used.</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="fu">## EDA</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>First, an EDA of the data is needed. After exploring the structure, the *Price* is shown with the year and month.</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/real_estate_data.csv"</span>))</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a><span class="do">## adapt the path to the data</span></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a><span class="co"># if you encountered any error with the encoding of the data (`Error in gregexpr...`), just re-run the code again</span></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(real_estate_data)</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(summarytools)</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a><span class="fu">dfSummary</span>(real_estate_data)</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>Month, <span class="at">y=</span>Price, <span class="at">fill=</span><span class="fu">as.factor</span>(Year))) <span class="sc">+</span> </span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>()<span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span><span class="fu">as.factor</span>(Year))</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>The results show how important it is to make an EDA! It appears that the data does not contain transactions for all the months of 2012 and 2013, but just some months by the end of 2012 and the first half of 2013. This shows that it is pointless to use month and year here. This is why we prefer *TransDate*, a value indicating the transaction time on a linear scale (e.g., 2013.250 is March 2013).</span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>Now we focus on the link between *Price* and the other features.</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="sc">%&gt;%</span> </span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Price, HouseAge, Dist, Lat, Long, TransDate) <span class="sc">%&gt;%</span> </span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggpairs</span>()</span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a>No clear link appears. The linear regression will help to discover if a combination of the features can predict the price.</span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modelling</span></span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a>First, we split the data into training/test set (75/25).</span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">size=</span><span class="fu">nrow</span>(real_estate_data), <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.75</span>,<span class="fl">0.25</span>)) <span class="co"># 1==training set, 2==test set</span></span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a>dat_tr_restate <span class="ot">&lt;-</span> real_estate_data[index<span class="sc">==</span><span class="dv">1</span>,]</span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a>dat_te_restate <span class="ot">&lt;-</span> real_estate_data[index<span class="sc">==</span><span class="dv">2</span>,]</span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>Then, we fit the linear regression to the training set.</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-73"><a href="#cb32-73" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-74"><a href="#cb32-74" aria-hidden="true" tabindex="-1"></a>mod_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span></span>
<span id="cb32-75"><a href="#cb32-75" aria-hidden="true" tabindex="-1"></a>               HouseAge<span class="sc">+</span></span>
<span id="cb32-76"><a href="#cb32-76" aria-hidden="true" tabindex="-1"></a>               Dist<span class="sc">+</span></span>
<span id="cb32-77"><a href="#cb32-77" aria-hidden="true" tabindex="-1"></a>               NumStores<span class="sc">+</span></span>
<span id="cb32-78"><a href="#cb32-78" aria-hidden="true" tabindex="-1"></a>               Lat<span class="sc">+</span></span>
<span id="cb32-79"><a href="#cb32-79" aria-hidden="true" tabindex="-1"></a>               Long, <span class="at">data=</span>dat_tr_restate)</span>
<span id="cb32-80"><a href="#cb32-80" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lm)</span>
<span id="cb32-81"><a href="#cb32-81" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-82"><a href="#cb32-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-83"><a href="#cb32-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-84"><a href="#cb32-84" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb32-85"><a href="#cb32-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-88"><a href="#cb32-88" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-89"><a href="#cb32-89" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load-conda</span></span>
<span id="cb32-90"><a href="#cb32-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-91"><a href="#cb32-91" aria-hidden="true" tabindex="-1"></a><span class="co"># In R, we load the conda environment as usual</span></span>
<span id="cb32-92"><a href="#cb32-92" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb32-93"><a href="#cb32-93" aria-hidden="true" tabindex="-1"></a>reticulate<span class="sc">::</span><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>, <span class="at">required =</span> <span class="cn">TRUE</span>)</span>
<span id="cb32-94"><a href="#cb32-94" aria-hidden="true" tabindex="-1"></a><span class="fu">gc</span>(<span class="at">full =</span> <span class="cn">TRUE</span>)</span>
<span id="cb32-95"><a href="#cb32-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-96"><a href="#cb32-96" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-97"><a href="#cb32-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-98"><a href="#cb32-98" aria-hidden="true" tabindex="-1"></a>In python, we then use the <span class="in">`statsmodels`</span> library to fit a linear regression model to the training data and perform feature elimination. We use the <span class="in">`.fit()`</span> method to fit the model with the formula for the variable names. Note that python's <span class="in">`summary()`</span> function is unique to the <span class="in">`statsmodels`</span> libraries and produces similar information to its R counterpart.</span>
<span id="cb32-99"><a href="#cb32-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-100"><a href="#cb32-100" aria-hidden="true" tabindex="-1"></a><span class="in">```{python import-mkl}</span></span>
<span id="cb32-101"><a href="#cb32-101" aria-hidden="true" tabindex="-1"></a><span class="in">import os</span></span>
<span id="cb32-102"><a href="#cb32-102" aria-hidden="true" tabindex="-1"></a><span class="in">os.environ["OMP_NUM_THREADS"] = "1"</span></span>
<span id="cb32-103"><a href="#cb32-103" aria-hidden="true" tabindex="-1"></a><span class="in">os.environ["MKL_NUM_THREADS"] = "1"</span></span>
<span id="cb32-104"><a href="#cb32-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-105"><a href="#cb32-105" aria-hidden="true" tabindex="-1"></a><span class="in">import mkl</span></span>
<span id="cb32-106"><a href="#cb32-106" aria-hidden="true" tabindex="-1"></a><span class="in"># %env OMP_NUM_THREADS=1</span></span>
<span id="cb32-107"><a href="#cb32-107" aria-hidden="true" tabindex="-1"></a><span class="in"># set the number of threads. Here we set it to 1 to avoid parallelization when rendering quarto, but you can set it to higher values.</span></span>
<span id="cb32-108"><a href="#cb32-108" aria-hidden="true" tabindex="-1"></a><span class="in">mkl.set_num_threads(1)</span></span>
<span id="cb32-109"><a href="#cb32-109" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-110"><a href="#cb32-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-111"><a href="#cb32-111" aria-hidden="true" tabindex="-1"></a><span class="in">```{python stats-import}</span></span>
<span id="cb32-112"><a href="#cb32-112" aria-hidden="true" tabindex="-1"></a><span class="in"># Import necessary library</span></span>
<span id="cb32-113"><a href="#cb32-113" aria-hidden="true" tabindex="-1"></a><span class="in">import statsmodels.formula.api as smf</span></span>
<span id="cb32-114"><a href="#cb32-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-115"><a href="#cb32-115" aria-hidden="true" tabindex="-1"></a><span class="in"># Fit a linear regression model to the training data &amp; print the summary</span></span>
<span id="cb32-116"><a href="#cb32-116" aria-hidden="true" tabindex="-1"></a><span class="in">mod_lm_py = smf.ols(formula='Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long', data=r.dat_tr_restate).fit()</span></span>
<span id="cb32-117"><a href="#cb32-117" aria-hidden="true" tabindex="-1"></a><span class="in">print(mod_lm_py.summary())</span></span>
<span id="cb32-118"><a href="#cb32-118" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-119"><a href="#cb32-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-120"><a href="#cb32-120" aria-hidden="true" tabindex="-1"></a>It's not a suprise that the results are same as the ones obtained in R.</span>
<span id="cb32-121"><a href="#cb32-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-122"><a href="#cb32-122" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-123"><a href="#cb32-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-124"><a href="#cb32-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-125"><a href="#cb32-125" aria-hidden="true" tabindex="-1"></a><span class="fu">## Variable selection &amp; interpretation</span></span>
<span id="cb32-126"><a href="#cb32-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-127"><a href="#cb32-127" aria-hidden="true" tabindex="-1"></a>The stepwise variable selection can be performed using the function **step**. By default, it is a backward selection; see `?step` for details (parameter **direction** is **backward** when **scope** is empty).</span>
<span id="cb32-128"><a href="#cb32-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-129"><a href="#cb32-129" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb32-130"><a href="#cb32-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-131"><a href="#cb32-131" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb32-132"><a href="#cb32-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-135"><a href="#cb32-135" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-136"><a href="#cb32-136" aria-hidden="true" tabindex="-1"></a><span class="fu">step</span>(mod_lm) <span class="co"># see the result</span></span>
<span id="cb32-137"><a href="#cb32-137" aria-hidden="true" tabindex="-1"></a>mod_lm_sel <span class="ot">&lt;-</span> <span class="fu">step</span>(mod_lm) <span class="co"># store the final model into mod_lm_sel</span></span>
<span id="cb32-138"><a href="#cb32-138" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lm_sel)</span>
<span id="cb32-139"><a href="#cb32-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-140"><a href="#cb32-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-141"><a href="#cb32-141" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb32-142"><a href="#cb32-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-143"><a href="#cb32-143" aria-hidden="true" tabindex="-1"></a>As python does not have an exact equivalent of <span class="in">`stats::step()`</span> function, which performs both forward and backward selection based on AIC, we have to implement it manually. We start with the full model and iteratively remove the feature with the highest p-value and add the feature with the lowest AIC until we can no longer improve the AIC. The final model is stored in <span class="in">`mod_lm_sel`</span>. For an extensive explanation of what this while loop is doing and how the backward+forward is computed, check the code below:</span>
<span id="cb32-144"><a href="#cb32-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-145"><a href="#cb32-145" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb32-146"><a href="#cb32-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-147"><a href="#cb32-147" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;Explaining feature elimination in python (while loop) &lt;/summary&gt;</span>
<span id="cb32-148"><a href="#cb32-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-149"><a href="#cb32-149" aria-hidden="true" tabindex="-1"></a>We start by setting <span class="in">`mod_lm_sel_py`</span> to the full model <span class="in">`mod_lm_py`</span>. Then, we enter a while loop that continues until we break out of it. In each iteration of the loop, we store the current model in prev_model for later comparison. We start by dropping the feature with the highest p-value from the current model using <span class="in">`idxmax()`</span>, which returns the label of the maximum value in the pvalues attribute of the <span class="in">`mod_lm_sel_py`</span> object. We exclude the intercept term from the list of labels by specifying <span class="in">`labels=['Intercept']`</span>. We then create a new model using <span class="in">`smf.ols()`</span> with the feature removed and fit it to the training data using <span class="in">`fit()`</span>. We store this new model in <span class="in">`mod_lm_sel_py`</span>.</span>
<span id="cb32-150"><a href="#cb32-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-151"><a href="#cb32-151" aria-hidden="true" tabindex="-1"></a>Next, we check whether the AIC of the new model is larger than the previous model's. If it is, we break out of the while loop and use the previous model (prev_model) as the final model. If not, we continue to the next step of the loop. Here, we look for the feature with the lowest AIC among the remaining features using <span class="in">`idxmin()`</span> on the pvalues attribute, again excluding the intercept term. We create a new model by adding this feature to the current model using <span class="in">`smf.ols()`</span>, fit it to the training data using <span class="in">`fit()`</span>, and store it in <span class="in">`mod_lm_sel_new`</span>.</span>
<span id="cb32-152"><a href="#cb32-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-153"><a href="#cb32-153" aria-hidden="true" tabindex="-1"></a>We then check whether the AIC of the new model is larger than that of the current model. If it is, we break out of the while loop and use the current model (<span class="in">`mod_lm_sel_py`</span>) as the final model. If not, we update <span class="in">`mod_lm_sel_py`</span> with the new model and continue to the next iteration of the loop. This way, we iteratively remove the feature with the highest p-value and add the feature with the lowest AIC until we can no longer improve the AIC. The final model is stored in <span class="in">`mod_lm_sel_py`</span>.</span>
<span id="cb32-154"><a href="#cb32-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-155"><a href="#cb32-155" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb32-156"><a href="#cb32-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-157"><a href="#cb32-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-158"><a href="#cb32-158" aria-hidden="true" tabindex="-1"></a><span class="in">```{python stats-stepwise}</span></span>
<span id="cb32-159"><a href="#cb32-159" aria-hidden="true" tabindex="-1"></a><span class="in">import statsmodels.api as sm</span></span>
<span id="cb32-160"><a href="#cb32-160" aria-hidden="true" tabindex="-1"></a><span class="in">import matplotlib.pyplot as plt</span></span>
<span id="cb32-161"><a href="#cb32-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-162"><a href="#cb32-162" aria-hidden="true" tabindex="-1"></a><span class="in"># perform both forward and backward selection using AIC</span></span>
<span id="cb32-163"><a href="#cb32-163" aria-hidden="true" tabindex="-1"></a><span class="in">mod_lm_sel_py = mod_lm_py</span></span>
<span id="cb32-164"><a href="#cb32-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-165"><a href="#cb32-165" aria-hidden="true" tabindex="-1"></a><span class="in">while True:</span></span>
<span id="cb32-166"><a href="#cb32-166" aria-hidden="true" tabindex="-1"></a><span class="in">    prev_model = mod_lm_sel_py</span></span>
<span id="cb32-167"><a href="#cb32-167" aria-hidden="true" tabindex="-1"></a><span class="in">    # drop the feature with the highest p-value</span></span>
<span id="cb32-168"><a href="#cb32-168" aria-hidden="true" tabindex="-1"></a><span class="in">    feature_to_drop = mod_lm_sel_py.pvalues.drop(labels=['Intercept']).idxmax()</span></span>
<span id="cb32-169"><a href="#cb32-169" aria-hidden="true" tabindex="-1"></a><span class="in">    mod_lm_sel_py = smf.ols(formula='Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long - ' + feature_to_drop, data=r.dat_tr_restate).fit()</span></span>
<span id="cb32-170"><a href="#cb32-170" aria-hidden="true" tabindex="-1"></a><span class="in">    # check if AIC has increased, if yes, break the loop and use the previous model</span></span>
<span id="cb32-171"><a href="#cb32-171" aria-hidden="true" tabindex="-1"></a><span class="in">    if mod_lm_sel_py.aic &gt; prev_model.aic:</span></span>
<span id="cb32-172"><a href="#cb32-172" aria-hidden="true" tabindex="-1"></a><span class="in">        mod_lm_sel_py = prev_model</span></span>
<span id="cb32-173"><a href="#cb32-173" aria-hidden="true" tabindex="-1"></a><span class="in">        break</span></span>
<span id="cb32-174"><a href="#cb32-174" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb32-175"><a href="#cb32-175" aria-hidden="true" tabindex="-1"></a><span class="in">    # add the feature with the lowest AIC</span></span>
<span id="cb32-176"><a href="#cb32-176" aria-hidden="true" tabindex="-1"></a><span class="in">    feature_to_add = mod_lm_sel_py.pvalues.drop(labels=['Intercept']).idxmin()</span></span>
<span id="cb32-177"><a href="#cb32-177" aria-hidden="true" tabindex="-1"></a><span class="in">    mod_lm_sel_py_new = smf.ols(formula='Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long + ' + feature_to_add, data=r.dat_tr_restate).fit()</span></span>
<span id="cb32-178"><a href="#cb32-178" aria-hidden="true" tabindex="-1"></a><span class="in">    # check if AIC has increased, if yes, break the loop and use the previous model</span></span>
<span id="cb32-179"><a href="#cb32-179" aria-hidden="true" tabindex="-1"></a><span class="in">    if mod_lm_sel_py_new.aic &gt; mod_lm_sel_py.aic:</span></span>
<span id="cb32-180"><a href="#cb32-180" aria-hidden="true" tabindex="-1"></a><span class="in">        break</span></span>
<span id="cb32-181"><a href="#cb32-181" aria-hidden="true" tabindex="-1"></a><span class="in">    mod_lm_sel_py = mod_lm_sel_py_new</span></span>
<span id="cb32-182"><a href="#cb32-182" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb32-183"><a href="#cb32-183" aria-hidden="true" tabindex="-1"></a><span class="in">print(mod_lm_sel_py.summary())</span></span>
<span id="cb32-184"><a href="#cb32-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-185"><a href="#cb32-185" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-186"><a href="#cb32-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-187"><a href="#cb32-187" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-188"><a href="#cb32-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-189"><a href="#cb32-189" aria-hidden="true" tabindex="-1"></a>After identifying the most important features, you can fit a new model using only those features and evaluate its performance using the test set.</span>
<span id="cb32-190"><a href="#cb32-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-191"><a href="#cb32-191" aria-hidden="true" tabindex="-1"></a>The final model does not contain *Long*. In terms of interpretations, for example:</span>
<span id="cb32-192"><a href="#cb32-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-193"><a href="#cb32-193" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The price increased on average by 3.7 per year (*TransDate*)</span>
<span id="cb32-194"><a href="#cb32-194" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>It diminishes in average by (-2)2.4 per year (*HouseAge*)</span>
<span id="cb32-195"><a href="#cb32-195" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>etc.</span>
<span id="cb32-196"><a href="#cb32-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-197"><a href="#cb32-197" aria-hidden="true" tabindex="-1"></a><span class="fu">## Inference</span></span>
<span id="cb32-198"><a href="#cb32-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-199"><a href="#cb32-199" aria-hidden="true" tabindex="-1"></a>We now predict the prices in the test set. We can make a scatter plot of the predictions versus the observed prices to inspect that. We already know by looking at the $R^2$ in the summary that the prediction quality is not good.</span>
<span id="cb32-200"><a href="#cb32-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-201"><a href="#cb32-201" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb32-202"><a href="#cb32-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-203"><a href="#cb32-203" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb32-204"><a href="#cb32-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-207"><a href="#cb32-207" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-208"><a href="#cb32-208" aria-hidden="true" tabindex="-1"></a>mod_lm_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod_lm_sel, <span class="at">newdata=</span>dat_te_restate)</span>
<span id="cb32-209"><a href="#cb32-209" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dat_te_restate<span class="sc">$</span>Price <span class="sc">~</span> mod_lm_pred, <span class="at">xlab=</span><span class="st">"Prediction"</span>, <span class="at">ylab=</span><span class="st">"Observed prices"</span>)</span>
<span id="cb32-210"><a href="#cb32-210" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="co"># line showing the obs -- pred agreement</span></span>
<span id="cb32-211"><a href="#cb32-211" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-212"><a href="#cb32-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-213"><a href="#cb32-213" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb32-216"><a href="#cb32-216" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-217"><a href="#cb32-217" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: predict-output</span></span>
<span id="cb32-218"><a href="#cb32-218" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb32-219"><a href="#cb32-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-220"><a href="#cb32-220" aria-hidden="true" tabindex="-1"></a>mod_lm_sel_pred <span class="op">=</span> mod_lm_sel_py.predict(r.dat_te_restate)</span>
<span id="cb32-221"><a href="#cb32-221" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb32-222"><a href="#cb32-222" aria-hidden="true" tabindex="-1"></a>ax.scatter(x<span class="op">=</span>mod_lm_sel_pred, y<span class="op">=</span>r.dat_te_restate[<span class="st">'Price'</span>])</span>
<span id="cb32-223"><a href="#cb32-223" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Prediction'</span>)</span>
<span id="cb32-224"><a href="#cb32-224" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Observed prices'</span>)</span>
<span id="cb32-225"><a href="#cb32-225" aria-hidden="true" tabindex="-1"></a>ax.plot(ax.get_xlim(), ax.get_ylim(), ls<span class="op">=</span><span class="st">"--"</span>, c<span class="op">=</span><span class="st">".3"</span>)</span>
<span id="cb32-226"><a href="#cb32-226" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb32-227"><a href="#cb32-227" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-228"><a href="#cb32-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-229"><a href="#cb32-229" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-230"><a href="#cb32-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-231"><a href="#cb32-231" aria-hidden="true" tabindex="-1"></a>It appears that the lowest and the highest prices are underestimated. At the center (around 30), the prices are slightly overestimated.</span>
<span id="cb32-232"><a href="#cb32-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-233"><a href="#cb32-233" aria-hidden="true" tabindex="-1"></a>As an exercise, write down the prediction equation of the selected model. Use this equation to explain how instances 1 and 2 (test set) are predicted and calculate the predictions manually. Verify your results using the *predict* function from the previous R code.</span>
<span id="cb32-234"><a href="#cb32-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-235"><a href="#cb32-235" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb32-236"><a href="#cb32-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-237"><a href="#cb32-237" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;Answer&lt;/summary&gt;</span>
<span id="cb32-238"><a href="#cb32-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-241"><a href="#cb32-241" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-242"><a href="#cb32-242" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: show-model-output</span></span>
<span id="cb32-243"><a href="#cb32-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-244"><a href="#cb32-244" aria-hidden="true" tabindex="-1"></a>mod_lm_pred[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)]</span>
<span id="cb32-245"><a href="#cb32-245" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-246"><a href="#cb32-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-247"><a href="#cb32-247" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-248"><a href="#cb32-248" aria-hidden="true" tabindex="-1"></a>y = -0.000133 + 3.66\times TransDate -0.243\times HouseAge <span class="sc">\\</span>-0.00464\times Dist + 1.027\times NumStores + 237.8\times Lat</span>
<span id="cb32-249"><a href="#cb32-249" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-250"><a href="#cb32-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-251"><a href="#cb32-251" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb32-252"><a href="#cb32-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-253"><a href="#cb32-253" aria-hidden="true" tabindex="-1"></a><span class="fu"># Logistic regression: visit data</span></span>
<span id="cb32-254"><a href="#cb32-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-255"><a href="#cb32-255" aria-hidden="true" tabindex="-1"></a>To illustrate a logistic regression, we use the data set **DocVis** extracted (modified for the exercise) the library **AER**. The data set reports a 1977--1978 Australian Health Survey. The aim is to predict the outcome **visits**, a binary variable indicating if the individual had at least one visit to a doctor in the past two weeks, using all the other features. To learn more about these features, look at the data described below.</span>
<span id="cb32-256"><a href="#cb32-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-257"><a href="#cb32-257" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb32-258"><a href="#cb32-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-259"><a href="#cb32-259" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;Data Description&lt;/summary&gt;</span>
<span id="cb32-260"><a href="#cb32-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-261"><a href="#cb32-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-262"><a href="#cb32-262" aria-hidden="true" tabindex="-1"></a>The predictors are as followed:</span>
<span id="cb32-263"><a href="#cb32-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-264"><a href="#cb32-264" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>gender: M/F</span>
<span id="cb32-265"><a href="#cb32-265" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>age: Age in years divided by 100.</span>
<span id="cb32-266"><a href="#cb32-266" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>income: Annual income in tens of thousands of dollars.</span>
<span id="cb32-267"><a href="#cb32-267" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>illness: Number of illnesses in past 2 weeks.</span>
<span id="cb32-268"><a href="#cb32-268" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>reduced: Number of days of reduced activity in past 2 weeks due to illness or injury.</span>
<span id="cb32-269"><a href="#cb32-269" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>health: General health questionnaire score using Goldberg's method.</span>
<span id="cb32-270"><a href="#cb32-270" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>private: Factor. Does the individual have private health insurance?</span>
<span id="cb32-271"><a href="#cb32-271" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>freepoor: Factor. Does the individual have free government health insurance due to low income?</span>
<span id="cb32-272"><a href="#cb32-272" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>freerepat: Factor. Does the individual have free government health insurance due to old age, disability or veteran status?</span>
<span id="cb32-273"><a href="#cb32-273" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>nchronic: Factor. Is there a chronic condition not limiting activity?</span>
<span id="cb32-274"><a href="#cb32-274" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>lchronic: Factor. Is there a chronic condition limiting activity?</span>
<span id="cb32-275"><a href="#cb32-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-276"><a href="#cb32-276" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb32-277"><a href="#cb32-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-278"><a href="#cb32-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-279"><a href="#cb32-279" aria-hidden="true" tabindex="-1"></a>We can now load the dataset.</span>
<span id="cb32-280"><a href="#cb32-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-283"><a href="#cb32-283" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-284"><a href="#cb32-284" aria-hidden="true" tabindex="-1"></a>DocVis <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/DocVis.csv"</span>)) <span class="do">## found in the same data folder</span></span>
<span id="cb32-285"><a href="#cb32-285" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-286"><a href="#cb32-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-287"><a href="#cb32-287" aria-hidden="true" tabindex="-1"></a>To facilitate the use of logistic regression in **R**, it is **strongly recommended** to have a 0/1 outcome rather than a categorical one. This makes much easier the recognition of the positive label (the "1") and the negative one (the "0"). Since we want to predict **visits**, we transform it accordingly.</span>
<span id="cb32-288"><a href="#cb32-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-291"><a href="#cb32-291" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-292"><a href="#cb32-292" aria-hidden="true" tabindex="-1"></a>DocVis<span class="sc">$</span>visits <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(DocVis<span class="sc">$</span>visits<span class="sc">==</span><span class="st">"Yes"</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb32-293"><a href="#cb32-293" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-294"><a href="#cb32-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-295"><a href="#cb32-295" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modelling</span></span>
<span id="cb32-296"><a href="#cb32-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-297"><a href="#cb32-297" aria-hidden="true" tabindex="-1"></a>We can split our data and fit the logistic regression. The function for this is **glm**. This function encompasses a larger class of models (namely, the generalized linear models) which includes the logistic regression, accessible with **family="binomial"**.</span>
<span id="cb32-298"><a href="#cb32-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-301"><a href="#cb32-301" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-302"><a href="#cb32-302" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb32-303"><a href="#cb32-303" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">size=</span><span class="fu">nrow</span>(DocVis), <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.75</span>,<span class="fl">0.25</span>)) <span class="co"># 1==training set, 2==test set</span></span>
<span id="cb32-304"><a href="#cb32-304" aria-hidden="true" tabindex="-1"></a>dat_tr_visit <span class="ot">&lt;-</span> DocVis[index<span class="sc">==</span><span class="dv">1</span>,]</span>
<span id="cb32-305"><a href="#cb32-305" aria-hidden="true" tabindex="-1"></a>dat_te_visit <span class="ot">&lt;-</span> DocVis[index<span class="sc">==</span><span class="dv">2</span>,]</span>
<span id="cb32-306"><a href="#cb32-306" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-307"><a href="#cb32-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-308"><a href="#cb32-308" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb32-309"><a href="#cb32-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-310"><a href="#cb32-310" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb32-313"><a href="#cb32-313" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-314"><a href="#cb32-314" aria-hidden="true" tabindex="-1"></a>vis_logr <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>dat_tr_visit, <span class="at">family=</span><span class="st">"binomial"</span>)</span>
<span id="cb32-315"><a href="#cb32-315" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(vis_logr)</span>
<span id="cb32-316"><a href="#cb32-316" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-317"><a href="#cb32-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-318"><a href="#cb32-318" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb32-319"><a href="#cb32-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-322"><a href="#cb32-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-323"><a href="#cb32-323" aria-hidden="true" tabindex="-1"></a><span class="co"># a hack around this technique to not type all the variable names</span></span>
<span id="cb32-324"><a href="#cb32-324" aria-hidden="true" tabindex="-1"></a>vis_formula <span class="op">=</span> <span class="st">'visits ~ '</span> <span class="op">+</span> <span class="st">' + '</span>.join(r.dat_tr_visit.columns.difference([<span class="st">'visits'</span>]))</span>
<span id="cb32-325"><a href="#cb32-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-326"><a href="#cb32-326" aria-hidden="true" tabindex="-1"></a><span class="co"># create a logistic regression model</span></span>
<span id="cb32-327"><a href="#cb32-327" aria-hidden="true" tabindex="-1"></a>vis_logr_py <span class="op">=</span> sm.formula.logit(formula<span class="op">=</span> vis_formula, data<span class="op">=</span>r.dat_tr_visit).fit()</span>
<span id="cb32-328"><a href="#cb32-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-329"><a href="#cb32-329" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vis_logr_py.summary())</span>
<span id="cb32-330"><a href="#cb32-330" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-331"><a href="#cb32-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-332"><a href="#cb32-332" aria-hidden="true" tabindex="-1"></a>::: callout-warning</span>
<span id="cb32-333"><a href="#cb32-333" aria-hidden="true" tabindex="-1"></a><span class="fu"># Using `.` for formulas in R vs Python </span></span>
<span id="cb32-334"><a href="#cb32-334" aria-hidden="true" tabindex="-1"></a>In R, the dot <span class="in">`.`</span> is used as shorthand to indicate that we want to include all other variables in the formula as predictors except for the outcome variable. So, if our outcome variable is y and we want to include all other variables in our data frame as predictors, we can write <span class="in">`y ~ .`</span> in the formula. </span>
<span id="cb32-335"><a href="#cb32-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-336"><a href="#cb32-336" aria-hidden="true" tabindex="-1"></a>In Python, however, the dot <span class="in">`.`</span> is not used in the same way in formulas. Instead, to include all other variables as predictors except for <span class="in">`y`</span>, we would write <span class="in">`y ~ x1 + x2 + ...`</span> where <span class="in">`x1, x2`</span>, etc. represent the names of the predictor variables. Also, <span class="in">`statsmodels`</span> has a similar syntax to R base regressions. In most other typical ML libraries in Python, you must provide the column values instead of using the column names.</span>
<span id="cb32-337"><a href="#cb32-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-338"><a href="#cb32-338" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-339"><a href="#cb32-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-340"><a href="#cb32-340" aria-hidden="true" tabindex="-1"></a>Note that the <span class="in">`family="binomial"`</span> argument in R is not needed in Python since <span class="in">`sm.formula.logit()`</span> assumes the logistic regression model is fitted using a binomial distribution by default.</span>
<span id="cb32-341"><a href="#cb32-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-342"><a href="#cb32-342" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-343"><a href="#cb32-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-344"><a href="#cb32-344" aria-hidden="true" tabindex="-1"></a><span class="fu">## Variable selection &amp; interpretation</span></span>
<span id="cb32-345"><a href="#cb32-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-346"><a href="#cb32-346" aria-hidden="true" tabindex="-1"></a>Now, we can apply the variable selection:</span>
<span id="cb32-347"><a href="#cb32-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-348"><a href="#cb32-348" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb32-349"><a href="#cb32-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-350"><a href="#cb32-350" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb32-353"><a href="#cb32-353" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-354"><a href="#cb32-354" aria-hidden="true" tabindex="-1"></a>vis_logr_sel <span class="ot">&lt;-</span> <span class="fu">step</span>(vis_logr)</span>
<span id="cb32-355"><a href="#cb32-355" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(vis_logr_sel)</span>
<span id="cb32-356"><a href="#cb32-356" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-357"><a href="#cb32-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-358"><a href="#cb32-358" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb32-359"><a href="#cb32-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-360"><a href="#cb32-360" aria-hidden="true" tabindex="-1"></a>As already seen in the linear regression part, in python, we don't have the same implementation of the step function, hence why we designed the while loop earlier. It is good practice to create a single function with this step while loop to handle all cases (linear, logistic etc); however, we only implement it here for logistic regression. Therefore, to tackle this, we will create a function that does step-wise elimination for us. We define a function called <span class="in">`forward_selected`</span> that performs forward selection on a given dataset to select the best predictors for a response variable based on AIC. The function takes two arguments: <span class="in">`data`</span>, a pandas DataFrame containing the predictors and <span class="in">`response`</span> variable, and response, a string specifying the name of the response variable.</span>
<span id="cb32-361"><a href="#cb32-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-362"><a href="#cb32-362" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb32-363"><a href="#cb32-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-364"><a href="#cb32-364" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;For more explanation of the code, click on me&lt;/summary&gt;</span>
<span id="cb32-365"><a href="#cb32-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-366"><a href="#cb32-366" aria-hidden="true" tabindex="-1"></a>The function first initializes two sets: <span class="in">`remaining`</span> and <span class="in">`selected`</span>. <span class="in">`remaining`</span> contains the names of all columns in the <span class="in">`data`</span> DataFrame except for the <span class="in">`response`</span> variable, while <span class="in">`selected`</span> is initially empty. The function then initializes <span class="in">`current_aic`</span> and <span class="in">`best_new_aic`</span> to infinity. The main loop of the function continues as long as <span class="in">`remaining`</span> is not empty and <span class="in">`current_aic`</span> is equal to <span class="in">`best_new_aic`</span>. At each iteration, the function iterates over all columns in <span class="in">`remaining`</span> and computes the AIC for a logistic regression model that includes the <span class="in">`response`</span> variable and the currently selected predictors, as well as the current candidate predictor. The function then adds the candidate predictor and its AIC to a list of <span class="in">`(aic, candidate)`</span> tuples, and sorts the list by increasing AIC. The function then selects the candidate with the lowest AIC and adds it to the <span class="in">`selected`</span> set, removes it from the <span class="in">`remaining`</span> set, and updates <span class="in">`current_aic`</span> to the new lowest AIC. The function continues this process until no candidate can improve the AIC. Finally, the function fits a logistic regression model using the selected predictors and returns the resulting model.</span>
<span id="cb32-367"><a href="#cb32-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-368"><a href="#cb32-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-369"><a href="#cb32-369" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb32-370"><a href="#cb32-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-371"><a href="#cb32-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-374"><a href="#cb32-374" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-375"><a href="#cb32-375" aria-hidden="true" tabindex="-1"></a><span class="co"># code taken from the link below and adjusted for logistic regression with AIC criteria</span></span>
<span id="cb32-376"><a href="#cb32-376" aria-hidden="true" tabindex="-1"></a><span class="co"># https://planspace.org/20150423-forward_selection_with_statsmodels/</span></span>
<span id="cb32-377"><a href="#cb32-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-378"><a href="#cb32-378" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_selected(data, response):</span>
<span id="cb32-379"><a href="#cb32-379" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Linear model designed by forward selection.</span></span>
<span id="cb32-380"><a href="#cb32-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-381"><a href="#cb32-381" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb32-382"><a href="#cb32-382" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb32-383"><a href="#cb32-383" aria-hidden="true" tabindex="-1"></a><span class="co">    data : pandas DataFrame with all possible predictors and response</span></span>
<span id="cb32-384"><a href="#cb32-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-385"><a href="#cb32-385" aria-hidden="true" tabindex="-1"></a><span class="co">    response: string, name of response column in data</span></span>
<span id="cb32-386"><a href="#cb32-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-387"><a href="#cb32-387" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb32-388"><a href="#cb32-388" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb32-389"><a href="#cb32-389" aria-hidden="true" tabindex="-1"></a><span class="co">    model: an "optimal" fitted statsmodels linear model</span></span>
<span id="cb32-390"><a href="#cb32-390" aria-hidden="true" tabindex="-1"></a><span class="co">           with an intercept</span></span>
<span id="cb32-391"><a href="#cb32-391" aria-hidden="true" tabindex="-1"></a><span class="co">           selected by forward selection</span></span>
<span id="cb32-392"><a href="#cb32-392" aria-hidden="true" tabindex="-1"></a><span class="co">           evaluated by AIC</span></span>
<span id="cb32-393"><a href="#cb32-393" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb32-394"><a href="#cb32-394" aria-hidden="true" tabindex="-1"></a>    remaining <span class="op">=</span> <span class="bu">set</span>(data.columns)</span>
<span id="cb32-395"><a href="#cb32-395" aria-hidden="true" tabindex="-1"></a>    remaining.remove(response)</span>
<span id="cb32-396"><a href="#cb32-396" aria-hidden="true" tabindex="-1"></a>    selected <span class="op">=</span> []</span>
<span id="cb32-397"><a href="#cb32-397" aria-hidden="true" tabindex="-1"></a>    current_aic, best_new_aic <span class="op">=</span> <span class="bu">float</span>(<span class="st">"inf"</span>), <span class="bu">float</span>(<span class="st">"inf"</span>)</span>
<span id="cb32-398"><a href="#cb32-398" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> remaining <span class="kw">and</span> current_aic <span class="op">==</span> best_new_aic:</span>
<span id="cb32-399"><a href="#cb32-399" aria-hidden="true" tabindex="-1"></a>        aics_with_candidates <span class="op">=</span> []</span>
<span id="cb32-400"><a href="#cb32-400" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> candidate <span class="kw">in</span> remaining:</span>
<span id="cb32-401"><a href="#cb32-401" aria-hidden="true" tabindex="-1"></a>            formula <span class="op">=</span> <span class="st">"</span><span class="sc">{}</span><span class="st"> ~ </span><span class="sc">{}</span><span class="st"> + 1"</span>.<span class="bu">format</span>(response,</span>
<span id="cb32-402"><a href="#cb32-402" aria-hidden="true" tabindex="-1"></a>                                           <span class="st">' + '</span>.join(selected <span class="op">+</span> [candidate]))</span>
<span id="cb32-403"><a href="#cb32-403" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> smf.logit(formula, data).fit(disp<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb32-404"><a href="#cb32-404" aria-hidden="true" tabindex="-1"></a>            aic <span class="op">=</span> model.aic</span>
<span id="cb32-405"><a href="#cb32-405" aria-hidden="true" tabindex="-1"></a>            aics_with_candidates.append((aic, candidate))</span>
<span id="cb32-406"><a href="#cb32-406" aria-hidden="true" tabindex="-1"></a>        aics_with_candidates.sort()</span>
<span id="cb32-407"><a href="#cb32-407" aria-hidden="true" tabindex="-1"></a>        best_new_aic, best_candidate <span class="op">=</span> aics_with_candidates.pop(<span class="dv">0</span>)</span>
<span id="cb32-408"><a href="#cb32-408" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> current_aic <span class="op">&gt;</span> best_new_aic:</span>
<span id="cb32-409"><a href="#cb32-409" aria-hidden="true" tabindex="-1"></a>            remaining.remove(best_candidate)</span>
<span id="cb32-410"><a href="#cb32-410" aria-hidden="true" tabindex="-1"></a>            selected.append(best_candidate)</span>
<span id="cb32-411"><a href="#cb32-411" aria-hidden="true" tabindex="-1"></a>            current_aic <span class="op">=</span> best_new_aic</span>
<span id="cb32-412"><a href="#cb32-412" aria-hidden="true" tabindex="-1"></a>    formula <span class="op">=</span> <span class="st">"</span><span class="sc">{}</span><span class="st"> ~ </span><span class="sc">{}</span><span class="st"> + 1"</span>.<span class="bu">format</span>(response,</span>
<span id="cb32-413"><a href="#cb32-413" aria-hidden="true" tabindex="-1"></a>                                   <span class="st">' + '</span>.join(selected))</span>
<span id="cb32-414"><a href="#cb32-414" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> smf.logit(formula, data).fit(disp<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb32-415"><a href="#cb32-415" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb32-416"><a href="#cb32-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-417"><a href="#cb32-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-418"><a href="#cb32-418" aria-hidden="true" tabindex="-1"></a>mod_logit_sel_py <span class="op">=</span> forward_selected(r.dat_tr_visit, <span class="st">'visits'</span>)</span>
<span id="cb32-419"><a href="#cb32-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-420"><a href="#cb32-420" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mod_logit_sel_py.summary())</span>
<span id="cb32-421"><a href="#cb32-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-422"><a href="#cb32-422" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-423"><a href="#cb32-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-424"><a href="#cb32-424" aria-hidden="true" tabindex="-1"></a>We can see that the results of <span class="in">`mod_logit_sel_py`</span> model are slightly different from the R version, but nevertheless, we have reduced the features and the interpretations (see below) with both R and python versions remain the same.</span>
<span id="cb32-425"><a href="#cb32-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-426"><a href="#cb32-426" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-427"><a href="#cb32-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-428"><a href="#cb32-428" aria-hidden="true" tabindex="-1"></a>We can see that the probability of a visit is</span>
<span id="cb32-429"><a href="#cb32-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-430"><a href="#cb32-430" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>smaller for males</span>
<span id="cb32-431"><a href="#cb32-431" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>increasing with age</span>
<span id="cb32-432"><a href="#cb32-432" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>larger with illness</span>
<span id="cb32-433"><a href="#cb32-433" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>etc.</span>
<span id="cb32-434"><a href="#cb32-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-435"><a href="#cb32-435" aria-hidden="true" tabindex="-1"></a><span class="fu">## Inference</span></span>
<span id="cb32-436"><a href="#cb32-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-437"><a href="#cb32-437" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb32-438"><a href="#cb32-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-439"><a href="#cb32-439" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb32-440"><a href="#cb32-440" aria-hidden="true" tabindex="-1"></a>The **predict** function with **type="response"** will predict the probability of the positive class ("1"). If it is set to **"link"** it produces the linear predictor (i.e., the $z$). To make the prediction, we thus have to identify if the predicted probability is larger or lower than 0.5.</span>
<span id="cb32-441"><a href="#cb32-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-444"><a href="#cb32-444" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-445"><a href="#cb32-445" aria-hidden="true" tabindex="-1"></a>prob_te_visit <span class="ot">&lt;-</span> <span class="fu">predict</span>(vis_logr_sel, <span class="at">newdata =</span> dat_te_visit, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb32-446"><a href="#cb32-446" aria-hidden="true" tabindex="-1"></a>pred_te_visit <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(prob_te_visit <span class="sc">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb32-447"><a href="#cb32-447" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="at">Pred=</span>pred_te_visit, <span class="at">Obs=</span>dat_te_visit<span class="sc">$</span>visits)</span>
<span id="cb32-448"><a href="#cb32-448" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-449"><a href="#cb32-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-450"><a href="#cb32-450" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb32-451"><a href="#cb32-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-452"><a href="#cb32-452" aria-hidden="true" tabindex="-1"></a>The explanation is similar to that of R, with a slight different that here we use <span class="in">`pandas.crosstab`</span> to make our confusion matrix.</span>
<span id="cb32-453"><a href="#cb32-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-456"><a href="#cb32-456" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-457"><a href="#cb32-457" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: visualize-prediction</span></span>
<span id="cb32-458"><a href="#cb32-458" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb32-459"><a href="#cb32-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-460"><a href="#cb32-460" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb32-461"><a href="#cb32-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-462"><a href="#cb32-462" aria-hidden="true" tabindex="-1"></a>prob_te_visit <span class="op">=</span> mod_logit_sel_py.predict(r.dat_te_visit)</span>
<span id="cb32-463"><a href="#cb32-463" aria-hidden="true" tabindex="-1"></a>pred_te_visit <span class="op">=</span> [<span class="dv">1</span> <span class="cf">if</span> p <span class="op">&gt;=</span> <span class="fl">0.5</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> p <span class="kw">in</span> prob_te_visit]</span>
<span id="cb32-464"><a href="#cb32-464" aria-hidden="true" tabindex="-1"></a>conf_mat <span class="op">=</span> pd.crosstab(pred_te_visit, r.dat_te_visit[<span class="st">'visits'</span>], rownames<span class="op">=</span>[<span class="st">'Pred'</span>], colnames<span class="op">=</span>[<span class="st">'Obs'</span>])</span>
<span id="cb32-465"><a href="#cb32-465" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(conf_mat)</span>
<span id="cb32-466"><a href="#cb32-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-467"><a href="#cb32-467" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-468"><a href="#cb32-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-469"><a href="#cb32-469" aria-hidden="true" tabindex="-1"></a>The results are extremely close to the R version.</span>
<span id="cb32-470"><a href="#cb32-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-471"><a href="#cb32-471" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-472"><a href="#cb32-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-473"><a href="#cb32-473" aria-hidden="true" tabindex="-1"></a>The predictions are not really good. It is in fact a difficult data set. Indeed, the number of 0 is so large compare to the 1, that predicting a 0 always provides a good model overall. That issue will be addressed further later on in the course.</span>
<span id="cb32-474"><a href="#cb32-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-475"><a href="#cb32-475" aria-hidden="true" tabindex="-1"></a>For now, this can be further inspected by looking at the predicted probabilities per observed label.</span>
<span id="cb32-476"><a href="#cb32-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-477"><a href="#cb32-477" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb32-478"><a href="#cb32-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-479"><a href="#cb32-479" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb32-480"><a href="#cb32-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-483"><a href="#cb32-483" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-484"><a href="#cb32-484" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(prob_te_visit<span class="sc">~</span>dat_te_visit<span class="sc">$</span>visits)</span>
<span id="cb32-485"><a href="#cb32-485" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-486"><a href="#cb32-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-487"><a href="#cb32-487" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb32-488"><a href="#cb32-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-491"><a href="#cb32-491" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-492"><a href="#cb32-492" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: visualize-prediction2</span></span>
<span id="cb32-493"><a href="#cb32-493" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb32-494"><a href="#cb32-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-495"><a href="#cb32-495" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb32-496"><a href="#cb32-496" aria-hidden="true" tabindex="-1"></a>ax.boxplot([prob_te_visit[r.dat_te_visit[<span class="st">'visits'</span>]<span class="op">==</span><span class="dv">0</span>], prob_te_visit[r.dat_te_visit[<span class="st">'visits'</span>]<span class="op">==</span><span class="dv">1</span>]])</span>
<span id="cb32-497"><a href="#cb32-497" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels([<span class="st">'No Visit'</span>, <span class="st">'Visit'</span>])</span>
<span id="cb32-498"><a href="#cb32-498" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Predicted Probability'</span>)</span>
<span id="cb32-499"><a href="#cb32-499" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Predicted Probabilities by Visit Status'</span>)</span>
<span id="cb32-500"><a href="#cb32-500" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb32-501"><a href="#cb32-501" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-502"><a href="#cb32-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-503"><a href="#cb32-503" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-504"><a href="#cb32-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-505"><a href="#cb32-505" aria-hidden="true" tabindex="-1"></a>We see that if the lowest predicted probabilities are usually assigned to 0-observations, most of the probabilities remain below 0.5 (even for the 1-observations). A good model would have two well separated boxplots, well away from 0.5.</span>
<span id="cb32-506"><a href="#cb32-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-507"><a href="#cb32-507" aria-hidden="true" tabindex="-1"></a>Now, as an exercise, write down the prediction equation of the selected model, like you did for linear regression. Use this equation to explain how instance 1 and 2 (test set) are predicted, and calculate the predictions manually. Verify your results using the function *predict* used before.</span>
<span id="cb32-508"><a href="#cb32-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-509"><a href="#cb32-509" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb32-510"><a href="#cb32-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-511"><a href="#cb32-511" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;Answer&lt;/summary&gt;</span>
<span id="cb32-512"><a href="#cb32-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-515"><a href="#cb32-515" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-516"><a href="#cb32-516" aria-hidden="true" tabindex="-1"></a>prob_te_visit[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)]</span>
<span id="cb32-517"><a href="#cb32-517" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-518"><a href="#cb32-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-519"><a href="#cb32-519" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-520"><a href="#cb32-520" aria-hidden="true" tabindex="-1"></a>z(x) = -2.31795-0.31838\times gender<span class="sc">\_</span>male+0.39762\times age+<span class="sc">\\</span>0.28431\times illness+0.16340\times reduced+0.05589\times health+<span class="sc">\\</span>0.27249\times private<span class="sc">\_</span>eyes -0.65344\times freepoor<span class="sc">\_</span>yes+<span class="sc">\\</span>0.38038\times freerepat<span class="sc">\_</span>yes  </span>
<span id="cb32-521"><a href="#cb32-521" aria-hidden="true" tabindex="-1"></a>$$ Then $$</span>
<span id="cb32-522"><a href="#cb32-522" aria-hidden="true" tabindex="-1"></a>P(Y=1 | X=x) = \frac{e^{z(x)}}{1+e^{z(x)}}</span>
<span id="cb32-523"><a href="#cb32-523" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb32-524"><a href="#cb32-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-525"><a href="#cb32-525" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb32-526"><a href="#cb32-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-527"><a href="#cb32-527" aria-hidden="true" tabindex="-1"></a><span class="fu"># LASSO &amp; Ridge regressions</span></span>
<span id="cb32-528"><a href="#cb32-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-529"><a href="#cb32-529" aria-hidden="true" tabindex="-1"></a>You have been introduced to lasso and ridge regression during the *Variable selection with penalization* part of the lecture.</span>
<span id="cb32-530"><a href="#cb32-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-531"><a href="#cb32-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-532"><a href="#cb32-532" aria-hidden="true" tabindex="-1"></a>Lasso and Ridge Regression are two regularization techniques used in regression models to prevent overfitting by adding a penalty term to the loss function. Lasso regression (aka $L_1$) adds a penalty term equal to the absolute value of the coefficients. In contrast, Ridge regression (aka $L_2$) adds a penalty term equal to the squared value of the coefficients. The effect of the penalty term is to shrink the coefficients towards zero, which can help reduce model complexity and improve generalization performance. In this case, we apply lasso and ridge to the real estate data and do not cover logistic regression (example already seen during the class).</span>
<span id="cb32-533"><a href="#cb32-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-534"><a href="#cb32-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-535"><a href="#cb32-535" aria-hidden="true" tabindex="-1"></a>First, we need to turn our predictors into matrices, as this is required by the <span class="in">`glmnet`</span> package in R and works with the python implementation.</span>
<span id="cb32-536"><a href="#cb32-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-539"><a href="#cb32-539" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-540"><a href="#cb32-540" aria-hidden="true" tabindex="-1"></a><span class="co"># glmnet can only work with matrix objects, columns 2-7 correspond to the same ones used by `lm`</span></span>
<span id="cb32-541"><a href="#cb32-541" aria-hidden="true" tabindex="-1"></a>dat_tr_re_mat_x <span class="ot">&lt;-</span> <span class="fu">select</span>(dat_tr_restate, <span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>)) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb32-542"><a href="#cb32-542" aria-hidden="true" tabindex="-1"></a>dat_tr_re_mat_y <span class="ot">&lt;-</span> <span class="fu">pull</span>(dat_tr_restate,<span class="st">'Price'</span>)</span>
<span id="cb32-543"><a href="#cb32-543" aria-hidden="true" tabindex="-1"></a>dat_te_re_mat_x <span class="ot">&lt;-</span> <span class="fu">select</span>(dat_te_restate, <span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>)) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb32-544"><a href="#cb32-544" aria-hidden="true" tabindex="-1"></a>dat_te_re_mat_y <span class="ot">&lt;-</span> <span class="fu">pull</span>(dat_te_restate,<span class="st">'Price'</span>)</span>
<span id="cb32-545"><a href="#cb32-545" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-546"><a href="#cb32-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-547"><a href="#cb32-547" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb32-548"><a href="#cb32-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-549"><a href="#cb32-549" aria-hidden="true" tabindex="-1"></a><span class="fu">## R</span></span>
<span id="cb32-550"><a href="#cb32-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-551"><a href="#cb32-551" aria-hidden="true" tabindex="-1"></a>On the newly created matrices, we run cross-validated lasso and ridge with the <span class="in">`cv.glmnet()`</span>, function where setting the <span class="in">`alpha`</span> (penalty) parameter as 1 produces lasso regression and 0 produces ridge regression. The default value of alpha is 1, which corresponds to lasso regression. For 0&lt;alpha&lt;1, it performs Elastic Net regression (a combination of $L_1$ and $L_2$ regularization).</span>
<span id="cb32-552"><a href="#cb32-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-553"><a href="#cb32-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-556"><a href="#cb32-556" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-557"><a href="#cb32-557" aria-hidden="true" tabindex="-1"></a><span class="co"># Load appropriate library and set a seed</span></span>
<span id="cb32-558"><a href="#cb32-558" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb32-559"><a href="#cb32-559" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb32-560"><a href="#cb32-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-561"><a href="#cb32-561" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Ridge regression model</span></span>
<span id="cb32-562"><a href="#cb32-562" aria-hidden="true" tabindex="-1"></a>ridge_fit <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(<span class="at">x =</span> dat_tr_re_mat_x, <span class="at">y =</span> dat_tr_re_mat_y, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb32-563"><a href="#cb32-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-564"><a href="#cb32-564" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Lasso regression model</span></span>
<span id="cb32-565"><a href="#cb32-565" aria-hidden="true" tabindex="-1"></a>lasso_fit <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(<span class="at">x =</span> dat_tr_re_mat_x, <span class="at">y =</span> dat_tr_re_mat_y, <span class="at">alpha =</span> <span class="dv">1</span>) <span class="co">#if you change the `family` argument to `bionomial`, you can get also logistic regression</span></span>
<span id="cb32-566"><a href="#cb32-566" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-567"><a href="#cb32-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-568"><a href="#cb32-568" aria-hidden="true" tabindex="-1"></a>We can then fit the final models with the best parameters:</span>
<span id="cb32-569"><a href="#cb32-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-572"><a href="#cb32-572" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-573"><a href="#cb32-573" aria-hidden="true" tabindex="-1"></a>ridge_fit_best <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x=</span>dat_tr_re_mat_x, <span class="at">y =</span> dat_tr_re_mat_y, </span>
<span id="cb32-574"><a href="#cb32-574" aria-hidden="true" tabindex="-1"></a>                         <span class="at">lambda =</span> ridge_fit<span class="sc">$</span>lambda.min)</span>
<span id="cb32-575"><a href="#cb32-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-576"><a href="#cb32-576" aria-hidden="true" tabindex="-1"></a>lasso_fit_best <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x=</span>dat_tr_re_mat_x, <span class="at">y=</span>dat_tr_re_mat_y, </span>
<span id="cb32-577"><a href="#cb32-577" aria-hidden="true" tabindex="-1"></a>                         <span class="at">lambda =</span> lasso_fit<span class="sc">$</span>lambda.min) <span class="co">#can also use lasso_fit$lambda.1se</span></span>
<span id="cb32-578"><a href="#cb32-578" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-579"><a href="#cb32-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-580"><a href="#cb32-580" aria-hidden="true" tabindex="-1"></a>We can compare different performances for this task using <span class="in">`caret::postResample()`</span>. We will learn more this function and it's metrics the upcoming courses &amp; lab sessions.</span>
<span id="cb32-581"><a href="#cb32-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-584"><a href="#cb32-584" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-585"><a href="#cb32-585" aria-hidden="true" tabindex="-1"></a><span class="co"># lasso &amp; ridge performance on the training set</span></span>
<span id="cb32-586"><a href="#cb32-586" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(ridge_fit_best, <span class="at">newx =</span> dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb32-587"><a href="#cb32-587" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(lasso_fit_best, <span class="at">newx =</span> dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb32-588"><a href="#cb32-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-589"><a href="#cb32-589" aria-hidden="true" tabindex="-1"></a><span class="co"># lasso &amp; ridge performance on the test set</span></span>
<span id="cb32-590"><a href="#cb32-590" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(ridge_fit_best, <span class="at">newx =</span> dat_te_re_mat_x), dat_te_re_mat_y)</span>
<span id="cb32-591"><a href="#cb32-591" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(lasso_fit_best, <span class="at">newx =</span> dat_te_re_mat_x), dat_te_re_mat_y)</span>
<span id="cb32-592"><a href="#cb32-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-593"><a href="#cb32-593" aria-hidden="true" tabindex="-1"></a><span class="co"># Step-wise lm performance on training and test sets</span></span>
<span id="cb32-594"><a href="#cb32-594" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(mod_lm_sel,dat_tr_restate), dat_tr_re_mat_y)</span>
<span id="cb32-595"><a href="#cb32-595" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(mod_lm_sel,dat_te_restate), dat_te_re_mat_y)</span>
<span id="cb32-596"><a href="#cb32-596" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-597"><a href="#cb32-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-598"><a href="#cb32-598" aria-hidden="true" tabindex="-1"></a>In this case, the lasso is better than the ridge on the test set, and if you have many features, this could be a useful technique. However, they are both outperformed by step-wise linear regression. Lasso and ridge are more useful when you have many more variables. You can try this already by taking more variables for your <span class="in">`dat_tr_re_mat_x`</span> and <span class="in">`dat_te_re_mat_x`</span> such <span class="in">`select(dat_te_restate,-c('Price', 'Month'))`</span> to see how (for better or worse) the performance changes. If you want more explanation on why linear model outperformed lasso and ridge, check out (click on) the further explanation below.</span>
<span id="cb32-599"><a href="#cb32-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-600"><a href="#cb32-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-601"><a href="#cb32-601" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb32-602"><a href="#cb32-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-603"><a href="#cb32-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-604"><a href="#cb32-604" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;Why lm (or step lm) outperformed lasso &amp; ridge &lt;/summary&gt;</span>
<span id="cb32-605"><a href="#cb32-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-606"><a href="#cb32-606" aria-hidden="true" tabindex="-1"></a>In some situations, it is normal to observe that a linear model may perform better than a regularized model, such as a ridge or lasso. This can occur when the number of predictors in the model is small relative to the sample size or when the predictors are highly correlated.</span>
<span id="cb32-607"><a href="#cb32-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-608"><a href="#cb32-608" aria-hidden="true" tabindex="-1"></a>Linear regression assumes that the relationship between the response variable and the predictors is linear and additive. When this assumption holds, a linear model can be a good choice. In contrast, regularized regression methods such as ridge and lasso add a penalty term to the regression objective function to shrink the estimated coefficients towards zero, which can help to avoid overfitting when the number of predictors is large relative to the sample size or when the predictors are highly correlated.</span>
<span id="cb32-609"><a href="#cb32-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-610"><a href="#cb32-610" aria-hidden="true" tabindex="-1"></a>However, when the number of predictors is small relative to the sample size or when the predictors are highly correlated, the additional regularization provided by ridge or lasso may not be necessary, and a simple linear model may perform better.</span>
<span id="cb32-611"><a href="#cb32-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-612"><a href="#cb32-612" aria-hidden="true" tabindex="-1"></a>It is always a good practice to compare the performance of different models using appropriate evaluation metrics and techniques such as cross-validation. The choice of the best model will depend on the specific problem and the goals of the analysis.</span>
<span id="cb32-613"><a href="#cb32-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-614"><a href="#cb32-614" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb32-615"><a href="#cb32-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-616"><a href="#cb32-616" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python</span></span>
<span id="cb32-617"><a href="#cb32-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-620"><a href="#cb32-620" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-621"><a href="#cb32-621" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge, Lasso, RidgeCV, LassoCV</span>
<span id="cb32-622"><a href="#cb32-622" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb32-623"><a href="#cb32-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-624"><a href="#cb32-624" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a seed for reproducibility</span></span>
<span id="cb32-625"><a href="#cb32-625" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb32-626"><a href="#cb32-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-627"><a href="#cb32-627" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Lasso regression model</span></span>
<span id="cb32-628"><a href="#cb32-628" aria-hidden="true" tabindex="-1"></a>lasso_cv <span class="op">=</span> LassoCV(cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb32-629"><a href="#cb32-629" aria-hidden="true" tabindex="-1"></a>lasso_cv.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)</span>
<span id="cb32-630"><a href="#cb32-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-631"><a href="#cb32-631" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the optimal regularization parameter</span></span>
<span id="cb32-632"><a href="#cb32-632" aria-hidden="true" tabindex="-1"></a>lasso_optimal_alpha <span class="op">=</span> lasso_cv.alpha_</span>
<span id="cb32-633"><a href="#cb32-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-634"><a href="#cb32-634" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Lasso model with the optimal alpha</span></span>
<span id="cb32-635"><a href="#cb32-635" aria-hidden="true" tabindex="-1"></a>lasso_best_py <span class="op">=</span> Lasso(alpha<span class="op">=</span>lasso_optimal_alpha)</span>
<span id="cb32-636"><a href="#cb32-636" aria-hidden="true" tabindex="-1"></a>lasso_best_py.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)</span>
<span id="cb32-637"><a href="#cb32-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-638"><a href="#cb32-638" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Ridge regression model with cross-validation</span></span>
<span id="cb32-639"><a href="#cb32-639" aria-hidden="true" tabindex="-1"></a>ridge_cv <span class="op">=</span> RidgeCV(cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb32-640"><a href="#cb32-640" aria-hidden="true" tabindex="-1"></a>ridge_cv.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)</span>
<span id="cb32-641"><a href="#cb32-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-642"><a href="#cb32-642" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the optimal regularization parameter</span></span>
<span id="cb32-643"><a href="#cb32-643" aria-hidden="true" tabindex="-1"></a>ridge_optimal_alpha <span class="op">=</span> ridge_cv.alpha_</span>
<span id="cb32-644"><a href="#cb32-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-645"><a href="#cb32-645" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Ridge model with the optimal alpha</span></span>
<span id="cb32-646"><a href="#cb32-646" aria-hidden="true" tabindex="-1"></a>ridge_best_py <span class="op">=</span> Ridge(alpha<span class="op">=</span>ridge_optimal_alpha)</span>
<span id="cb32-647"><a href="#cb32-647" aria-hidden="true" tabindex="-1"></a>ridge_best_py.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)</span>
<span id="cb32-648"><a href="#cb32-648" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-649"><a href="#cb32-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-650"><a href="#cb32-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-651"><a href="#cb32-651" aria-hidden="true" tabindex="-1"></a>The <span class="in">`lambda`</span> argument in <span class="in">`cv.glmnet()`</span> from R corresponds to the <span class="in">`alpha`</span> argument in <span class="in">`RidgeCV()`</span>/<span class="in">`LassoCV()`</span> in python. In <span class="in">`cv.glmnet()`</span>, the lambda argument specifies the range of regularization parameters to be tested in the model selection process. By default, lambda is set to NULL, which means that <span class="in">`glmnet()`</span> will automatically choose a sequence of lambda values to search over. Note that in <span class="in">`glmnet()`</span>, lambda values are used for both $L_1$ (lasso) and $L_2$ (ridge) regularization, whereas in <span class="in">`RidgeCV()`</span>, alpha values are used to control the mix of L1 and L2 regularization, with alpha = 0 corresponding to pure L2 regularization (i.e., ridge regression).</span>
<span id="cb32-652"><a href="#cb32-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-653"><a href="#cb32-653" aria-hidden="true" tabindex="-1"></a>On the contrary (and to avoid confusion), the <span class="in">`alpha`</span> argument in <span class="in">`cv.glmnet()`</span> corresponds to the <span class="in">`fit_intercept`</span> argument in <span class="in">`RidgeCV()`</span>/<span class="in">`LassoCV()`</span>. In <span class="in">`cv.glmnet()`</span>, the alpha argument specifies the mixing parameter between L1 and L2 regularization. </span>
<span id="cb32-654"><a href="#cb32-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-657"><a href="#cb32-657" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-658"><a href="#cb32-658" aria-hidden="true" tabindex="-1"></a><span class="co"># python lasso &amp; ridge performance on the training set</span></span>
<span id="cb32-659"><a href="#cb32-659" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>ridge_best_py<span class="sc">$</span><span class="fu">predict</span>(dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb32-660"><a href="#cb32-660" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>lasso_best_py<span class="sc">$</span><span class="fu">predict</span>(dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb32-661"><a href="#cb32-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-662"><a href="#cb32-662" aria-hidden="true" tabindex="-1"></a><span class="co"># python lasso &amp; ridge performance on the test set</span></span>
<span id="cb32-663"><a href="#cb32-663" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>ridge_best_py<span class="sc">$</span><span class="fu">predict</span>( dat_te_re_mat_x), dat_te_re_mat_y)</span>
<span id="cb32-664"><a href="#cb32-664" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>lasso_best_py<span class="sc">$</span><span class="fu">predict</span>(dat_te_re_mat_x), dat_te_re_mat_y)</span>
<span id="cb32-665"><a href="#cb32-665" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-666"><a href="#cb32-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-667"><a href="#cb32-667" aria-hidden="true" tabindex="-1"></a>The performance is different in python simply because of different default settings for the python vs R implementations.</span>
<span id="cb32-668"><a href="#cb32-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-669"><a href="#cb32-669" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb32-670"><a href="#cb32-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-671"><a href="#cb32-671" aria-hidden="true" tabindex="-1"></a>To understand the decision making of lasso, we can check the beta's in a similar fashion to a regression (only shown for the R models).</span>
<span id="cb32-672"><a href="#cb32-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-675"><a href="#cb32-675" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-676"><a href="#cb32-676" aria-hidden="true" tabindex="-1"></a><span class="co"># running the following can tell you a bit about the impact of different variables</span></span>
<span id="cb32-677"><a href="#cb32-677" aria-hidden="true" tabindex="-1"></a>small.lambda.index <span class="ot">&lt;-</span> <span class="fu">which</span>(lasso_fit<span class="sc">$</span>lambda <span class="sc">==</span> lasso_fit<span class="sc">$</span>lambda.min)</span>
<span id="cb32-678"><a href="#cb32-678" aria-hidden="true" tabindex="-1"></a>lasso_fit<span class="sc">$</span>glmnet.fit<span class="sc">$</span>beta[, small.lambda.index]</span>
<span id="cb32-679"><a href="#cb32-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-680"><a href="#cb32-680" aria-hidden="true" tabindex="-1"></a><span class="co"># or on the final model</span></span>
<span id="cb32-681"><a href="#cb32-681" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(lasso_fit , <span class="at">s=</span> <span class="st">'lambda.min'</span>)</span>
<span id="cb32-682"><a href="#cb32-682" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lasso_fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)</span>
<span id="cb32-683"><a href="#cb32-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-684"><a href="#cb32-684" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-685"><a href="#cb32-685" aria-hidden="true" tabindex="-1"></a>We can see that from the first output <span class="in">`Long`</span> value has almost a beta of 0. In the second output, it is confirmed that the coefficient of this variable is indeed 0. This could explain why <span class="in">`mod_lm_sel`</span> also dropped this variable. The rest of the coefficient are similar to <span class="in">`summary(mod_lm_sel)`</span>.  as ridge or lasso in some situations. This can occur when the number of predictors in the model is small relative to the sample size, or when the predictors are highly correlated.</span>
<span id="cb32-686"><a href="#cb32-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-687"><a href="#cb32-687" aria-hidden="true" tabindex="-1"></a><span class="fu"># Your turn to practice</span></span>
<span id="cb32-688"><a href="#cb32-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-689"><a href="#cb32-689" aria-hidden="true" tabindex="-1"></a><span class="fu">## Linear regression: nursing home data</span></span>
<span id="cb32-690"><a href="#cb32-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-691"><a href="#cb32-691" aria-hidden="true" tabindex="-1"></a>Now it is your turn. Make an linear regression (also feel free to try lasso and ridge regressions) on the nursing data described below (found also in <span class="in">`/data/nursing_data.csv`</span>). Afterwards, use linear regression to build a predictor of the cost using the other features. Replicate the analysis. Split the data, build a model, make the variable selection, make the predictions and analyze the results. Make also an analysis of the coefficients in terms of the associations between the costs and the features.</span>
<span id="cb32-692"><a href="#cb32-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-693"><a href="#cb32-693" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb32-694"><a href="#cb32-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-695"><a href="#cb32-695" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;Data Description&lt;/summary&gt;</span>
<span id="cb32-696"><a href="#cb32-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-697"><a href="#cb32-697" aria-hidden="true" tabindex="-1"></a>The data set is about patients in a nursing home, where elderly people are helped with daily living needs, also known as Activities of Daily Living (ADL, i.e. communication, eating, walking, showering, going to a toilet, etc.).</span>
<span id="cb32-698"><a href="#cb32-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-699"><a href="#cb32-699" aria-hidden="true" tabindex="-1"></a>Since the stay in such facilities is very expensive, it is important to classify the new-coming patient, and estimate the duration of the stay and the corresponding costs.</span>
<span id="cb32-700"><a href="#cb32-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-701"><a href="#cb32-701" aria-hidden="true" tabindex="-1"></a>In practice, there are different types of patients who require different types of help and, consequently, different duration of the stay. For example, there could be a person with severe mobility issues, who requires the help with most of the needs every day; or a person with mental deviations, who don't need help with daily routine, but requires extra communication hours.</span>
<span id="cb32-702"><a href="#cb32-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-703"><a href="#cb32-703" aria-hidden="true" tabindex="-1"></a>Here, we will focus of total amount of help (measured in minutes of help provided to a person per week) provided and measure the costs of stay of a person.</span>
<span id="cb32-704"><a href="#cb32-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-705"><a href="#cb32-705" aria-hidden="true" tabindex="-1"></a>The data set on which the analysis is based has the following columns:</span>
<span id="cb32-706"><a href="#cb32-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-707"><a href="#cb32-707" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**gender**: a categorical variable with levels "*M*" for male and "*F*" for female</span>
<span id="cb32-708"><a href="#cb32-708" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**age**: integer variable</span>
<span id="cb32-709"><a href="#cb32-709" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**mobil**: categorical variable that represents the physical mobility with levels</span>
<span id="cb32-710"><a href="#cb32-710" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>1 = Full mobility</span>
<span id="cb32-711"><a href="#cb32-711" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>2 = Reduced mobility</span>
<span id="cb32-712"><a href="#cb32-712" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>3 = Restricted mobility in the house</span>
<span id="cb32-713"><a href="#cb32-713" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>4 = Null mobility</span>
<span id="cb32-714"><a href="#cb32-714" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**orient**: categorical variable that represents the orientation (interactions with the environment) with levels</span>
<span id="cb32-715"><a href="#cb32-715" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>1 = Full orientation</span>
<span id="cb32-716"><a href="#cb32-716" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>2 = Moderate disturbance of orientation</span>
<span id="cb32-717"><a href="#cb32-717" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>3 = Disorientation</span>
<span id="cb32-718"><a href="#cb32-718" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**independ**: categorical variable that represents the independence of ADL with levels</span>
<span id="cb32-719"><a href="#cb32-719" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>1 = Independent of help</span>
<span id="cb32-720"><a href="#cb32-720" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>2 = Dependent less than 24 hours per day</span>
<span id="cb32-721"><a href="#cb32-721" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>3 = Dependent at unpredictable time intervals for most of the needs</span>
<span id="cb32-722"><a href="#cb32-722" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**minut_mob**: numerical variable that represents the total number of minutes of help with movement per week</span>
<span id="cb32-723"><a href="#cb32-723" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**need_comm**: categorical variable with levels "*Yes*" for a person who needs extra communication sessions with an employee, and "*No*" otherwise</span>
<span id="cb32-724"><a href="#cb32-724" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**minut_comm**: numerical variable that represents the total number of minutes of communication per week</span>
<span id="cb32-725"><a href="#cb32-725" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**tot_minut**: numerical variable that represents the total number of minutes spent on a patient per week, $tot<span class="sc">\_</span>minut = minut<span class="sc">\_</span>mob + minut<span class="sc">\_</span>comm$</span>
<span id="cb32-726"><a href="#cb32-726" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**cost**: numerical variable that represents the total costs of having a patient in the nursing house per month.</span>
<span id="cb32-727"><a href="#cb32-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-728"><a href="#cb32-728" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb32-729"><a href="#cb32-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-730"><a href="#cb32-730" aria-hidden="true" tabindex="-1"></a>Note: since tot_minut=minut_mob+minut_comm, you may not find any meaningful result using the 3 features. This is perfectly normal. Just use 2 features only among these 3 (arbitrary choice).</span>
<span id="cb32-731"><a href="#cb32-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-732"><a href="#cb32-732" aria-hidden="true" tabindex="-1"></a><span class="fu">## Logistic regression: the credit quality</span></span>
<span id="cb32-733"><a href="#cb32-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-734"><a href="#cb32-734" aria-hidden="true" tabindex="-1"></a>The German Credit Quality Dataset consists of a set of attributes as good or bad credit risks. In order to find find a detailed description of the features, please refer to the <span class="co">[</span><span class="ot">original link to the dataset</span><span class="co">]</span>(https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)). The <span class="in">`german.csv`</span> file can also be found in <span class="in">`/data/german.csv`</span> whichis the mdified version of the original dataset to simplify the analysis, especially the data loading in **R**.</span>
<span id="cb32-735"><a href="#cb32-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-736"><a href="#cb32-736" aria-hidden="true" tabindex="-1"></a>The aim here is to predict the credit quality from the other features. The outcome **Quality** is 0 for "bad" and 1 for "good". Make an analysis of the data and develop the learner. You can follow these notable steps:</span>
<span id="cb32-737"><a href="#cb32-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-738"><a href="#cb32-738" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Make a simple EDA of the features</span>
<span id="cb32-739"><a href="#cb32-739" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Split the data and train the model.</span>
<span id="cb32-740"><a href="#cb32-740" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Make variable selection and check out the result.</span>
<span id="cb32-741"><a href="#cb32-741" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpret the coefficients.</span>
<span id="cb32-742"><a href="#cb32-742" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Inspect the quality of the model by making the predictions (confusion table and boxplot of the predicted probabilities).</span>
<span id="cb32-743"><a href="#cb32-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-744"><a href="#cb32-744" aria-hidden="true" tabindex="-1"></a>Note that the data are unbalanced again and that you may not find a very good predictor. This issue is quite difficult and will be addressed later.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2024, <a href="https://iliaazizi.com/">Ilia Azizi &amp; Marc-Olivier Boldi</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 🤍 and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>