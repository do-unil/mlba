<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Models: Linear and logistic regressions – MLBA - S26</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../labs/03_Models/032_Trees/Ex_ML_Tree.html" rel="next">
<link href="../../../labs/00_lab/setup.html" rel="prev">
<link href="../../../images/logo.dark.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dcd6dad1d9027e0fc018a6aab5a8b21b.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-fc6169d2ff87708b539fd584a3ca0747.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dcd6dad1d9027e0fc018a6aab5a8b21b.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-e7d98c3c06872cc71abfe53bf8dbfef8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-9fc88ccb7d1699df7914753e2965a537.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-e7d98c3c06872cc71abfe53bf8dbfef8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
<meta property="og:title" content="Models: Linear and logistic regressions – MLBA - S26">
<meta property="og:description" content="Homepage for Machine Learning in Business Analytics at HEC Lausanne, Spring 2026.">
<meta property="og:image" content="https://do-unil.github.io/mlba/labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg_files/figure-html/unnamed-chunk-1-1.png">
<meta property="og:site_name" content="MLBA - S26">
<meta property="og:image:height" content="960">
<meta property="og:image:width" content="1344">
</head>
<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html">Linear &amp; Logistic Regression</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../../index.html" class="sidebar-logo-link">
      <img src="../../../images/logo.light.png" alt="" class="sidebar-logo light-content py-0 d-lg-inline d-none"><img src="../../../images/logo.light.png" alt="" class="sidebar-logo dark-content py-0 d-lg-inline d-none"></a>
      <div class="sidebar-tools-main tools-wide">
    <a href="https://moodle.unil.ch/course/view.php?id=36198" title="Moodle" class="quarto-navigation-tool px-1" aria-label="Moodle"><i class="bi bi-person-rolodex"></i></a>
    <a href="https://github.com/do-unil/mlba" title="GitHub Repo" class="quarto-navigation-tool px-1" aria-label="GitHub Repo"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../schedule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../faq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FAQ</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Lectures</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/01_Introduction/ML_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/02_DataExploration/ML_DataExplo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Exploration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/030_Introduction/ML_Models_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/031_LinearLogisticRegression/ML_LinLogReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/032_Trees/ML_Trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/033_NeuralNetworks/ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/034_SupportVectorMachine/ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/04_Metrics/ML_Metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/05_DataSplitting/ML_DataSplitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/06_Ensembles/ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/07_InterpretableML/ML_Interp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/08_UnsupervisedLearning/080_Introduction/ML_UnsupIntro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Unsuperised Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/08_UnsupervisedLearning/081_Clustering/ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/08_UnsupervisedLearning/082_DimensionReduction/ML_DimRed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dimension Reduction</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/00_lab/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/032_Trees/Ex_ML_Tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/033_NeuralNetworks/EX_ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/04_Metrics/Ex_ML_Scoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/06_Ensembles/Ex_ML_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/07_InterpretableML/Ex_ML_VarImp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/08_UnsupervisedLearning/081_Clustering/Ex_ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/08_UnsupervisedLearning/082_DimensionReduction/Ex_ML_PCA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PCA</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Assessments</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../assessments/Exam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exam</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Project</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../assessments/Project_Directives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Directives</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../assessments/Presentation_Guidelines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Presentation Guidelines</span></a>
  </div>
</li>
      </ul>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/beginners_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Beginners in R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/data_acquisition/data_sources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Sources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/data_acquisition/web_scraping_api.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Web Scraping</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/cheatsheets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding Cheatsheets</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">On this page</h2>
   
  <ul>
<li>
<a href="#linear-regression-real-estate-application" id="toc-linear-regression-real-estate-application" class="nav-link active" data-scroll-target="#linear-regression-real-estate-application">Linear regression: real estate application</a>
  <ul class="collapse">
<li><a href="#eda" id="toc-eda" class="nav-link" data-scroll-target="#eda">EDA</a></li>
  <li><a href="#modelling" id="toc-modelling" class="nav-link" data-scroll-target="#modelling">Modelling</a></li>
  <li><a href="#variable-selection-interpretation" id="toc-variable-selection-interpretation" class="nav-link" data-scroll-target="#variable-selection-interpretation">Variable selection &amp; interpretation</a></li>
  <li><a href="#inference" id="toc-inference" class="nav-link" data-scroll-target="#inference">Inference</a></li>
  </ul>
</li>
  <li>
<a href="#logistic-regression-visit-data" id="toc-logistic-regression-visit-data" class="nav-link" data-scroll-target="#logistic-regression-visit-data">Logistic regression: visit data</a>
  <ul class="collapse">
<li><a href="#modelling-1" id="toc-modelling-1" class="nav-link" data-scroll-target="#modelling-1">Modelling</a></li>
  <li><a href="#variable-selection-interpretation-1" id="toc-variable-selection-interpretation-1" class="nav-link" data-scroll-target="#variable-selection-interpretation-1">Variable selection &amp; interpretation</a></li>
  <li><a href="#inference-1" id="toc-inference-1" class="nav-link" data-scroll-target="#inference-1">Inference</a></li>
  </ul>
</li>
  <li><a href="#lasso-ridge-regressions" id="toc-lasso-ridge-regressions" class="nav-link" data-scroll-target="#lasso-ridge-regressions">LASSO &amp; Ridge regressions</a></li>
  <li>
<a href="#your-turn-to-practice" id="toc-your-turn-to-practice" class="nav-link" data-scroll-target="#your-turn-to-practice">Your turn to practice</a>
  <ul class="collapse">
<li><a href="#linear-regression-nursing-home-data" id="toc-linear-regression-nursing-home-data" class="nav-link" data-scroll-target="#linear-regression-nursing-home-data">Linear regression: nursing home data</a></li>
  <li><a href="#logistic-regression-the-credit-quality" id="toc-logistic-regression-the-credit-quality" class="nav-link" data-scroll-target="#logistic-regression-the-credit-quality">Logistic regression: the credit quality</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><script type="application/javascript">
// Description: Change image src depending on body class (quarto-light or quarto-dark)
function updateImageSrc() {
  var bodyClass = window.document.body.classList;
  var images = window.document.getElementsByTagName('img');
  for (var i = 0; i < images.length; i++) {
    var image = images[i];
    var src = image.src;
    var newSrc = src;
    if (bodyClass.contains('quarto-light') && src.includes('.dark')) {
      newSrc = src.replace('.dark', '.light');
    } else if (bodyClass.contains('quarto-dark') && src.includes('.light')) {
      newSrc = src.replace('.light', '.dark');
    }
    if (newSrc !== src) {
      image.src = newSrc;
    }
  }
}

var observer = new MutationObserver(function(mutations) {
  mutations.forEach(function(mutation) {
    if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
      updateImageSrc();
    }
  });
});

observer.observe(window.document.body, {
  attributes: true
});

updateImageSrc();
</script><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html">Linear &amp; Logistic Regression</a></li></ol></nav><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Models: Linear and logistic regressions</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><section id="linear-regression-real-estate-application" class="level1"><h1>Linear regression: real estate application</h1>
<p>The dataset we’ll be using for the first part of the exercise is real estate transaction prices in Taiwan, which can be accessed from this link <a href="https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set">this link</a>. This dataset was modified for this exercise. The modified file <code>real_estate_data.csv</code> is in the exercise folder under <code>/data/</code>.</p>
<p>The aim is to predict the house prices from available features: <em>No</em>, <em>Month</em>, <em>Year</em>, <em>TransDate</em>, <em>HouseAge</em>, <em>Dist</em>, <em>NumStores</em>, <em>Lat</em>, <em>Long</em>, <em>Price</em>. <em>No</em> is the transaction number and will not be used.</p>
<section id="eda" class="level2"><h2 class="anchored" data-anchor-id="eda">EDA</h2>
<p>First, an EDA of the data is needed. After exploring the structure, the <em>Price</em> is shown with the year and month.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">real_estate_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org/reference/here.html">here</a></span><span class="op">(</span><span class="st">"labs/data/real_estate_data.csv"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## adapt the path to the data</span></span>
<span><span class="co"># if you encountered any error with the encoding of the data (`Error in gregexpr...`), just re-run the code again</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">real_estate_data</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dcomtois/summarytools">summarytools</a></span><span class="op">)</span></span>
<span><span class="fu">dfSummary</span><span class="op">(</span><span class="va">real_estate_data</span><span class="op">)</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="va">real_estate_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">Month</span>, y<span class="op">=</span><span class="va">Price</span>, fill<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Year</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">Year</span><span class="op">)</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="Ex_ML_LinLogReg_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   414 obs. of  10 variables:
 $ No       : int  1 2 3 4 5 6 7 8 9 10 ...
 $ TransDate: num  2013 2013 2014 2014 2013 ...
 $ HouseAge : num  32 19.5 13.3 13.3 5 7.1 34.5 20.3 31.7 17.9 ...
 $ Dist     : num  84.9 306.6 562 562 390.6 ...
 $ NumStores: int  10 9 5 5 5 3 7 6 1 3 ...
 $ Lat      : num  25 25 25 25 25 ...
 $ Long     : num  122 122 122 122 122 ...
 $ Price    : num  37.9 42.2 47.3 54.8 43.1 32.1 40.3 46.7 18.8 22.1 ...
 $ Month    : chr  "Dec" "Dec" "Jul" "Jul" ...
 $ Year     : int  2012 2012 2013 2013 2012 2012 2012 2013 2013 2013 ...
Data Frame Summary  
real_estate_data  
Dimensions: 414 x 10  
Duplicates: 0  

-----------------------------------------------------------------------------------------------------------------
No   Variable      Stats / Values                Freqs (% of Valid)    Graph                 Valid      Missing  
---- ------------- ----------------------------- --------------------- --------------------- ---------- ---------
1    No            Mean (sd) : 207.5 (119.7)     414 distinct values   : : : : : : : :       414        0        
     [integer]     min &lt; med &lt; max:              (Integer sequence)    : : : : : : : :       (100.0%)   (0.0%)   
                   1 &lt; 207.5 &lt; 414                                     : : : : : : : :                           
                   IQR (CV) : 206.5 (0.6)                              : : : : : : : : .                         
                                                                       : : : : : : : : :                         

2    TransDate     Mean (sd) : 2013.1 (0.3)      12 distinct values                      :   414        0        
     [numeric]     min &lt; med &lt; max:                                    :       .       : :   (100.0%)   (0.0%)   
                   2012.7 &lt; 2013.2 &lt; 2013.6                            :   .   :   .   : :                       
                   IQR (CV) : 0.5 (0)                                  : : : : : : : : : :                       
                                                                       : : : : : : : : : :                       

3    HouseAge      Mean (sd) : 17.7 (11.4)       236 distinct values       : :               414        0        
     [numeric]     min &lt; med &lt; max:                                    :   : :     .         (100.0%)   (0.0%)   
                   0 &lt; 16.1 &lt; 43.8                                     : . : :     :                             
                   IQR (CV) : 19.1 (0.6)                               : : : :   . : .                           
                                                                       : : : : : : : : .                         

4    Dist          Mean (sd) : 1083.9 (1262.1)   259 distinct values   :                     414        0        
     [numeric]     min &lt; med &lt; max:                                    :                     (100.0%)   (0.0%)   
                   23.4 &lt; 492.2 &lt; 6488                                 :                                         
                   IQR (CV) : 1165 (1.2)                               :                                         
                                                                       : : : .     .                             

5    NumStores     Mean (sd) : 4.1 (2.9)         11 distinct values    :                     414        0        
     [integer]     min &lt; med &lt; max:                                    :                     (100.0%)   (0.0%)   
                   0 &lt; 4 &lt; 10                                          :       :                                 
                   IQR (CV) : 5 (0.7)                                  :   : . : . . .                           
                                                                       : : : : : : : : : .                       

6    Lat           Mean (sd) : 25 (0)            234 distinct values           :             414        0        
     [numeric]     min &lt; med &lt; max:                                          . :             (100.0%)   (0.0%)   
                   24.9 &lt; 25 &lt; 25                                            : : .                               
                   IQR (CV) : 0 (0)                                        . : : :                               
                                                                         : : : : :                               

7    Long          Mean (sd) : 121.5 (0)         232 distinct values                 :       414        0        
     [numeric]     min &lt; med &lt; max:                                                  :       (100.0%)   (0.0%)   
                   121.5 &lt; 121.5 &lt; 121.6                                           : :                           
                   IQR (CV) : 0 (0)                                            .   : :                           
                                                                           . . : . : : :                         

8    Price         Mean (sd) : 38 (13.6)         270 distinct values       : :               414        0        
     [numeric]     min &lt; med &lt; max:                                      : : :               (100.0%)   (0.0%)   
                   7.6 &lt; 38.5 &lt; 117.5                                    : : : .                                 
                   IQR (CV) : 18.9 (0.4)                                 : : : :                                 
                                                                       : : : : : .                               

9    Month         1. Apr                        61 (14.7%)            II                    414        0        
     [character]   2. Dec                        38 ( 9.2%)            I                     (100.0%)   (0.0%)   
                   3. Jan                        74 (17.9%)            III                                       
                   4. Jul                        70 (16.9%)            III                                       
                   5. Jun                        58 (14.0%)            II                                        
                   6. Mar                        25 ( 6.0%)            I                                         
                   7. Oct                        58 (14.0%)            II                                        
                   8. Sep                        30 ( 7.2%)            I                                         

10   Year          Min  : 2012                   2012 : 126 (30.4%)    IIIIII                414        0        
     [integer]     Mean : 2012.7                 2013 : 288 (69.6%)    IIIIIIIIIIIII         (100.0%)   (0.0%)   
                   Max  : 2013                                                                                   
-----------------------------------------------------------------------------------------------------------------</code></pre>
</div>
</div>
<p>The results show how important it is to make an EDA! It appears that the data does not contain transactions for all the months of 2012 and 2013, but just some months by the end of 2012 and the first half of 2013. This shows that it is pointless to use month and year here. This is why we prefer <em>TransDate</em>, a value indicating the transaction time on a linear scale (e.g., 2013.250 is March 2013).</p>
<p>Now we focus on the link between <em>Price</em> and the other features.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggobi.github.io/ggally/">GGally</a></span><span class="op">)</span></span>
<span><span class="va">real_estate_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">Price</span>, <span class="va">HouseAge</span>, <span class="va">Dist</span>, <span class="va">Lat</span>, <span class="va">Long</span>, <span class="va">TransDate</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">ggpairs</span><span class="op">(</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="Ex_ML_LinLogReg_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>No clear link appears. The linear regression will help to discover if a combination of the features can predict the price.</p>
</section><section id="modelling" class="level2"><h2 class="anchored" data-anchor-id="modelling">Modelling</h2>
<p>First, we split the data into training/test set (75/25).</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">234</span><span class="op">)</span></span>
<span><span class="va">index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span>, size<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">real_estate_data</span><span class="op">)</span>, replace<span class="op">=</span><span class="cn">TRUE</span>, prob<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.75</span>,<span class="fl">0.25</span><span class="op">)</span><span class="op">)</span> <span class="co"># 1==training set, 2==test set</span></span>
<span><span class="va">dat_tr_restate</span> <span class="op">&lt;-</span> <span class="va">real_estate_data</span><span class="op">[</span><span class="va">index</span><span class="op">==</span><span class="fl">1</span>,<span class="op">]</span></span>
<span><span class="va">dat_te_restate</span> <span class="op">&lt;-</span> <span class="va">real_estate_data</span><span class="op">[</span><span class="va">index</span><span class="op">==</span><span class="fl">2</span>,<span class="op">]</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Then, we fit the linear regression to the training set.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" href="" aria-current="page">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Price</span><span class="op">~</span><span class="va">TransDate</span><span class="op">+</span></span>
<span>               <span class="va">HouseAge</span><span class="op">+</span></span>
<span>               <span class="va">Dist</span><span class="op">+</span></span>
<span>               <span class="va">NumStores</span><span class="op">+</span></span>
<span>               <span class="va">Lat</span><span class="op">+</span></span>
<span>               <span class="va">Long</span>, data<span class="op">=</span><span class="va">dat_tr_restate</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_lm</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Price ~ TransDate + HouseAge + Dist + NumStores + 
    Lat + Long, data = dat_tr_restate)

Residuals:
    Min      1Q  Median      3Q     Max 
-35.031  -5.167  -1.115   3.771  75.027 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -9.413e+03  7.826e+03  -1.203   0.2299    
TransDate    3.720e+00  1.760e+00   2.113   0.0353 *  
HouseAge    -2.433e-01  4.434e-02  -5.487 8.22e-08 ***
Dist        -4.981e-03  8.287e-04  -6.010 4.97e-09 ***
NumStores    1.021e+00  2.129e-01   4.796 2.47e-06 ***
Lat          2.350e+02  5.045e+01   4.659 4.64e-06 ***
Long        -3.210e+01  5.783e+01  -0.555   0.5791    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 8.991 on 325 degrees of freedom
Multiple R-squared:  0.564, Adjusted R-squared:  0.5559 
F-statistic: 70.07 on 6 and 325 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># In R, we load the conda environment as usual</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rstudio.github.io/reticulate/">reticulate</a></span><span class="op">)</span></span>
<span><span class="fu">reticulate</span><span class="fu">::</span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/use_python.html">use_condaenv</a></span><span class="op">(</span><span class="st">"MLBA"</span>, required <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/gc.html">gc</a></span><span class="op">(</span>full <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>          used  (Mb) gc trigger  (Mb) max used  (Mb)
Ncells 2663127 142.3    5024474 268.4  3525680 188.3
Vcells 4810159  36.7   10146329  77.5  8346827  63.7</code></pre>
</div>
</div>
<p>In python, we then use the <code>statsmodels</code> library to fit a linear regression model to the training data and perform feature elimination. We use the <code>.fit()</code> method to fit the model with the formula for the variable names. Note that python’s <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> function is unique to the <code>statsmodels</code> libraries and produces similar information to its R counterpart.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"OMP_NUM_THREADS"</span>] <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"MKL_NUM_THREADS"</span>] <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mkl</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># %env OMP_NUM_THREADS=1</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># set the number of threads. Here we set it to 1 to avoid parallelization when rendering quarto, but you can set it to higher values.</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>mkl.set_num_threads(<span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>1</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary library</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a linear regression model to the training data &amp; print the summary</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>mod_lm_py <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long'</span>, data<span class="op">=</span>r.dat_tr_restate).fit()</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mod_lm_py.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>                             OLS Regression Results                            
===============================================================================
Dep. Variable:                   Price   R-squared:                       0.564
Model:                             OLS   Adj. R-squared:                  0.556
Method:                  Least Squares   F-statistic:                     70.07
Date:              sam., 28 févr. 2026   Prob (F-statistic):           1.13e-55
Time:                         23:01:11   Log-Likelihood:                -1196.7
No. Observations:                  332   AIC:                             2407.
Df Residuals:                      325   BIC:                             2434.
Df Model:                            6                                         
Covariance Type:             nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept  -9413.4672   7825.675     -1.203      0.230   -2.48e+04    5981.905
TransDate      3.7205      1.760      2.113      0.035       0.257       7.184
HouseAge      -0.2433      0.044     -5.487      0.000      -0.331      -0.156
Dist          -0.0050      0.001     -6.010      0.000      -0.007      -0.003
NumStores      1.0211      0.213      4.796      0.000       0.602       1.440
Lat          235.0369     50.448      4.659      0.000     135.791     334.283
Long         -32.1049     57.826     -0.555      0.579    -145.865      81.656
==============================================================================
Omnibus:                      207.286   Durbin-Watson:                   2.246
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3757.196
Skew:                           2.219   Prob(JB):                         0.00
Kurtosis:                      18.871   Cond. No.                     3.76e+07
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.76e+07. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<p>It’s not a suprise that the results are same as the ones obtained in R.</p>
</div>
</div>
</div>
</section><section id="variable-selection-interpretation" class="level2"><h2 class="anchored" data-anchor-id="variable-selection-interpretation">Variable selection &amp; interpretation</h2>
<p>The stepwise variable selection can be performed using the function <strong>step</strong>. By default, it is a backward selection; see <code><a href="https://rdrr.io/r/stats/step.html">?step</a></code> for details (parameter <strong>direction</strong> is <strong>backward</strong> when <strong>scope</strong> is empty).</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/step.html">step</a></span><span class="op">(</span><span class="va">mod_lm</span><span class="op">)</span> <span class="co"># see the result</span></span>
<span><span class="va">mod_lm_sel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/step.html">step</a></span><span class="op">(</span><span class="va">mod_lm</span><span class="op">)</span> <span class="co"># store the final model into mod_lm_sel</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">mod_lm_sel</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Start:  AIC=1465.21
Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long

            Df Sum of Sq   RSS    AIC
- Long       1     24.92 26297 1463.5
&lt;none&gt;                   26272 1465.2
- TransDate  1    361.09 26633 1467.8
- Lat        1   1754.67 28027 1484.7
- NumStores  1   1859.23 28131 1485.9
- HouseAge   1   2434.13 28706 1492.6
- Dist       1   2920.26 29192 1498.2

Step:  AIC=1463.53
Price ~ TransDate + HouseAge + Dist + NumStores + Lat

            Df Sum of Sq   RSS    AIC
&lt;none&gt;                   26297 1463.5
- TransDate  1     350.5 26647 1465.9
- Lat        1    1813.8 28111 1483.7
- NumStores  1    1885.2 28182 1484.5
- HouseAge   1    2431.5 28728 1490.9
- Dist       1    5821.3 32118 1527.9

Call:
lm(formula = Price ~ TransDate + HouseAge + Dist + NumStores + 
    Lat, data = dat_tr_restate)

Coefficients:
(Intercept)    TransDate     HouseAge         Dist    NumStores          Lat  
 -1.326e+04    3.658e+00   -2.432e-01   -4.635e-03    1.027e+00    2.378e+02  

Start:  AIC=1465.21
Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long

            Df Sum of Sq   RSS    AIC
- Long       1     24.92 26297 1463.5
&lt;none&gt;                   26272 1465.2
- TransDate  1    361.09 26633 1467.8
- Lat        1   1754.67 28027 1484.7
- NumStores  1   1859.23 28131 1485.9
- HouseAge   1   2434.13 28706 1492.6
- Dist       1   2920.26 29192 1498.2

Step:  AIC=1463.53
Price ~ TransDate + HouseAge + Dist + NumStores + Lat

            Df Sum of Sq   RSS    AIC
&lt;none&gt;                   26297 1463.5
- TransDate  1     350.5 26647 1465.9
- Lat        1    1813.8 28111 1483.7
- NumStores  1    1885.2 28182 1484.5
- HouseAge   1    2431.5 28728 1490.9
- Dist       1    5821.3 32118 1527.9

Call:
lm(formula = Price ~ TransDate + HouseAge + Dist + NumStores + 
    Lat, data = dat_tr_restate)

Residuals:
    Min      1Q  Median      3Q     Max 
-34.934  -5.236  -1.201   3.825  75.413 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -1.326e+04  3.639e+03  -3.643 0.000313 ***
TransDate    3.658e+00  1.755e+00   2.084 0.037898 *  
HouseAge    -2.432e-01  4.429e-02  -5.490 8.08e-08 ***
Dist        -4.635e-03  5.456e-04  -8.495 7.15e-16 ***
NumStores    1.027e+00  2.124e-01   4.834 2.06e-06 ***
Lat          2.378e+02  5.015e+01   4.742 3.17e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 8.981 on 326 degrees of freedom
Multiple R-squared:  0.5636,    Adjusted R-squared:  0.5569 
F-statistic:  84.2 on 5 and 326 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>As python does not have an exact equivalent of <code><a href="https://rdrr.io/r/stats/step.html">stats::step()</a></code> function, which performs both forward and backward selection based on AIC, we have to implement it manually. We start with the full model and iteratively remove the feature with the highest p-value and add the feature with the lowest AIC until we can no longer improve the AIC. The final model is stored in <code>mod_lm_sel</code>. For an extensive explanation of what this while loop is doing and how the backward+forward is computed, check the code below:</p>
<details><summary>
Explaining feature elimination in python (while loop)
</summary><p>We start by setting <code>mod_lm_sel_py</code> to the full model <code>mod_lm_py</code>. Then, we enter a while loop that continues until we break out of it. In each iteration of the loop, we store the current model in prev_model for later comparison. We start by dropping the feature with the highest p-value from the current model using <code>idxmax()</code>, which returns the label of the maximum value in the pvalues attribute of the <code>mod_lm_sel_py</code> object. We exclude the intercept term from the list of labels by specifying <code>labels=['Intercept']</code>. We then create a new model using <code>smf.ols()</code> with the feature removed and fit it to the training data using <code>fit()</code>. We store this new model in <code>mod_lm_sel_py</code>.</p>
<p>Next, we check whether the AIC of the new model is larger than the previous model’s. If it is, we break out of the while loop and use the previous model (prev_model) as the final model. If not, we continue to the next step of the loop. Here, we look for the feature with the lowest AIC among the remaining features using <code>idxmin()</code> on the pvalues attribute, again excluding the intercept term. We create a new model by adding this feature to the current model using <code>smf.ols()</code>, fit it to the training data using <code>fit()</code>, and store it in <code>mod_lm_sel_new</code>.</p>
<p>We then check whether the AIC of the new model is larger than that of the current model. If it is, we break out of the while loop and use the current model (<code>mod_lm_sel_py</code>) as the final model. If not, we update <code>mod_lm_sel_py</code> with the new model and continue to the next iteration of the loop. This way, we iteratively remove the feature with the highest p-value and add the feature with the lowest AIC until we can no longer improve the AIC. The final model is stored in <code>mod_lm_sel_py</code>.</p>
</details><div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># perform both forward and backward selection using AIC</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>mod_lm_sel_py <span class="op">=</span> mod_lm_py</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    prev_model <span class="op">=</span> mod_lm_sel_py</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># drop the feature with the highest p-value</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    feature_to_drop <span class="op">=</span> mod_lm_sel_py.pvalues.drop(labels<span class="op">=</span>[<span class="st">'Intercept'</span>]).idxmax()</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    mod_lm_sel_py <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long - '</span> <span class="op">+</span> feature_to_drop, data<span class="op">=</span>r.dat_tr_restate).fit()</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># check if AIC has increased, if yes, break the loop and use the previous model</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> mod_lm_sel_py.aic <span class="op">&gt;</span> prev_model.aic:</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>        mod_lm_sel_py <span class="op">=</span> prev_model</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add the feature with the lowest AIC</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    feature_to_add <span class="op">=</span> mod_lm_sel_py.pvalues.drop(labels<span class="op">=</span>[<span class="st">'Intercept'</span>]).idxmin()</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    mod_lm_sel_py_new <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long + '</span> <span class="op">+</span> feature_to_add, data<span class="op">=</span>r.dat_tr_restate).fit()</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># check if AIC has increased, if yes, break the loop and use the previous model</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> mod_lm_sel_py_new.aic <span class="op">&gt;</span> mod_lm_sel_py.aic:</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    mod_lm_sel_py <span class="op">=</span> mod_lm_sel_py_new</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mod_lm_sel_py.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>                             OLS Regression Results                            
===============================================================================
Dep. Variable:                   Price   R-squared:                       0.564
Model:                             OLS   Adj. R-squared:                  0.557
Method:                  Least Squares   F-statistic:                     84.20
Date:              sam., 28 févr. 2026   Prob (F-statistic):           1.36e-56
Time:                         23:01:12   Log-Likelihood:                -1196.9
No. Observations:                  332   AIC:                             2406.
Df Residuals:                      326   BIC:                             2429.
Df Model:                            5                                         
Covariance Type:             nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept  -1.326e+04   3639.370     -3.643      0.000   -2.04e+04   -6099.096
TransDate      3.6579      1.755      2.084      0.038       0.206       7.110
HouseAge      -0.2432      0.044     -5.490      0.000      -0.330      -0.156
Dist          -0.0046      0.001     -8.495      0.000      -0.006      -0.004
NumStores      1.0270      0.212      4.834      0.000       0.609       1.445
Lat          237.7985     50.149      4.742      0.000     139.142     336.455
==============================================================================
Omnibus:                      209.843   Durbin-Watson:                   2.249
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3876.569
Skew:                           2.252   Prob(JB):                         0.00
Kurtosis:                      19.123   Cond. No.                     1.75e+07
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.75e+07. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>After identifying the most important features, you can fit a new model using only those features and evaluate its performance using the test set.</p>
<p>The final model does not contain <em>Long</em>. In terms of interpretations, for example:</p>
<ul>
<li>The price increased on average by 3.7 per year (<em>TransDate</em>)</li>
<li>It diminishes in average by (-2)2.4 per year (<em>HouseAge</em>)</li>
<li>etc.</li>
</ul></section><section id="inference" class="level2"><h2 class="anchored" data-anchor-id="inference">Inference</h2>
<p>We now predict the prices in the test set. We can make a scatter plot of the predictions versus the observed prices to inspect that. We already know by looking at the <span class="math inline">\(R^2\)</span> in the summary that the prediction quality is not good.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod_lm_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod_lm_sel</span>, newdata<span class="op">=</span><span class="va">dat_te_restate</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">dat_te_restate</span><span class="op">$</span><span class="va">Price</span> <span class="op">~</span> <span class="va">mod_lm_pred</span>, xlab<span class="op">=</span><span class="st">"Prediction"</span>, ylab<span class="op">=</span><span class="st">"Observed prices"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span> <span class="co"># line showing the obs -- pred agreement</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="Ex_ML_LinLogReg_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>mod_lm_sel_pred <span class="op">=</span> mod_lm_sel_py.predict(r.dat_te_restate)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>ax.scatter(x<span class="op">=</span>mod_lm_sel_pred, y<span class="op">=</span>r.dat_te_restate[<span class="st">'Price'</span>])<span class="op">;</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Prediction'</span>)<span class="op">;</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Observed prices'</span>)<span class="op">;</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>ax.plot(ax.get_xlim(), ax.get_ylim(), ls<span class="op">=</span><span class="st">"--"</span>, c<span class="op">=</span><span class="st">".3"</span>)<span class="op">;</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</div>
<p>It appears that the lowest and the highest prices are underestimated. At the center (around 30), the prices are slightly overestimated.</p>
<p>As an exercise, write down the prediction equation of the selected model. Use this equation to explain how instances 1 and 2 (test set) are predicted and calculate the predictions manually. Verify your results using the <em>predict</em> function from the previous R code.</p>
<details><summary>
Answer
</summary><div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mod_lm_pred</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">]</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>       2        4 
47.77995 47.82163 </code></pre>
</div>
</div>
<p><span class="math display">\[
y = -0.000133 + 3.66\times TransDate -0.243\times HouseAge \\-0.00464\times Dist + 1.027\times NumStores + 237.8\times Lat
\]</span></p>
</details></section></section><section id="logistic-regression-visit-data" class="level1"><h1>Logistic regression: visit data</h1>
<p>To illustrate a logistic regression, we use the data set <strong>DocVis</strong> extracted (modified for the exercise) the library <strong>AER</strong>. The data set reports a 1977–1978 Australian Health Survey. The aim is to predict the outcome <strong>visits</strong>, a binary variable indicating if the individual had at least one visit to a doctor in the past two weeks, using all the other features. To learn more about these features, look at the data described below.</p>
<details><summary>
Data Description
</summary><p>The predictors are as followed:</p>
<ul>
<li>gender: M/F</li>
<li>age: Age in years divided by 100.</li>
<li>income: Annual income in tens of thousands of dollars.</li>
<li>illness: Number of illnesses in past 2 weeks.</li>
<li>reduced: Number of days of reduced activity in past 2 weeks due to illness or injury.</li>
<li>health: General health questionnaire score using Goldberg’s method.</li>
<li>private: Factor. Does the individual have private health insurance?</li>
<li>freepoor: Factor. Does the individual have free government health insurance due to low income?</li>
<li>freerepat: Factor. Does the individual have free government health insurance due to old age, disability or veteran status?</li>
<li>nchronic: Factor. Is there a chronic condition not limiting activity?</li>
<li>lchronic: Factor. Is there a chronic condition limiting activity?</li>
</ul></details><p>We can now load the dataset.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">DocVis</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org/reference/here.html">here</a></span><span class="op">(</span><span class="st">"labs/data/DocVis.csv"</span><span class="op">)</span><span class="op">)</span> <span class="co">## found in the same data folder</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>To facilitate the use of logistic regression in <strong>R</strong>, it is <strong>strongly recommended</strong> to have a 0/1 outcome rather than a categorical one. This makes much easier the recognition of the positive label (the “1”) and the negative one (the “0”). Since we want to predict <strong>visits</strong>, we transform it accordingly.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">DocVis</span><span class="op">$</span><span class="va">visits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">DocVis</span><span class="op">$</span><span class="va">visits</span><span class="op">==</span><span class="st">"Yes"</span>,<span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="modelling-1" class="level2"><h2 class="anchored" data-anchor-id="modelling-1">Modelling</h2>
<p>We can split our data and fit the logistic regression. The function for this is <strong>glm</strong>. This function encompasses a larger class of models (namely, the generalized linear models) which includes the logistic regression, accessible with <strong>family=“binomial”</strong>.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">234</span><span class="op">)</span></span>
<span><span class="va">index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span>, size<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">DocVis</span><span class="op">)</span>, replace<span class="op">=</span><span class="cn">TRUE</span>, prob<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.75</span>,<span class="fl">0.25</span><span class="op">)</span><span class="op">)</span> <span class="co"># 1==training set, 2==test set</span></span>
<span><span class="va">dat_tr_visit</span> <span class="op">&lt;-</span> <span class="va">DocVis</span><span class="op">[</span><span class="va">index</span><span class="op">==</span><span class="fl">1</span>,<span class="op">]</span></span>
<span><span class="va">dat_te_visit</span> <span class="op">&lt;-</span> <span class="va">DocVis</span><span class="op">[</span><span class="va">index</span><span class="op">==</span><span class="fl">2</span>,<span class="op">]</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">vis_logr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">visits</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">dat_tr_visit</span>, family<span class="op">=</span><span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">vis_logr</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = visits ~ ., family = "binomial", data = dat_tr_visit)

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -2.333303   0.164588 -14.177  &lt; 2e-16 ***
gendermale   -0.318588   0.093701  -3.400 0.000674 ***
age           0.344459   0.285299   1.207 0.227293    
income        0.009721   0.137314   0.071 0.943562    
illness       0.273529   0.033011   8.286  &lt; 2e-16 ***
reduced       0.161265   0.013531  11.918  &lt; 2e-16 ***
health        0.054113   0.019843   2.727 0.006392 ** 
privateyes    0.263077   0.113554   2.317 0.020518 *  
freepooryes  -0.665795   0.288494  -2.308 0.021009 *  
freerepatyes  0.364835   0.160273   2.276 0.022826 *  
nchronicyes   0.089645   0.103798   0.864 0.387782    
lchronicyes   0.176745   0.143272   1.234 0.217340    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 3985.6  on 3912  degrees of freedom
Residual deviance: 3494.8  on 3901  degrees of freedom
AIC: 3518.8

Number of Fisher Scoring iterations: 4</code></pre>
</div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># a hack around this technique to not type all the variable names</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>vis_formula <span class="op">=</span> <span class="st">'visits ~ '</span> <span class="op">+</span> <span class="st">' + '</span>.join(r.dat_tr_visit.columns.difference([<span class="st">'visits'</span>]))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># create a logistic regression model</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>vis_logr_py <span class="op">=</span> sm.formula.logit(formula<span class="op">=</span> vis_formula, data<span class="op">=</span>r.dat_tr_visit).fit()</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vis_logr_py.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimization terminated successfully.
         Current function value: 0.446559
         Iterations 6
                            Logit Regression Results                           
===============================================================================
Dep. Variable:                  visits   No. Observations:                 3913
Model:                           Logit   Df Residuals:                     3901
Method:                            MLE   Df Model:                           11
Date:              sam., 28 févr. 2026   Pseudo R-squ.:                  0.1231
Time:                         23:01:12   Log-Likelihood:                -1747.4
converged:                        True   LL-Null:                       -1992.8
Covariance Type:             nonrobust   LLR p-value:                 2.963e-98
====================================================================================
                       coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           -2.3333      0.165    -14.176      0.000      -2.656      -2.011
freepoor[T.yes]     -0.6658      0.289     -2.307      0.021      -1.231      -0.100
freerepat[T.yes]     0.3648      0.160      2.276      0.023       0.051       0.679
gender[T.male]      -0.3186      0.094     -3.400      0.001      -0.502      -0.135
lchronic[T.yes]      0.1767      0.143      1.234      0.217      -0.104       0.458
nchronic[T.yes]      0.0896      0.104      0.864      0.388      -0.114       0.293
private[T.yes]       0.2631      0.114      2.317      0.021       0.041       0.486
age                  0.3445      0.285      1.207      0.227      -0.215       0.904
health               0.0541      0.020      2.727      0.006       0.015       0.093
illness              0.2735      0.033      8.286      0.000       0.209       0.338
income               0.0097      0.137      0.071      0.944      -0.259       0.279
reduced              0.1613      0.014     11.918      0.000       0.135       0.188
====================================================================================</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Using <code>.</code> for formulas in R vs Python
</div>
</div>
<div class="callout-body-container callout-body">
<p>In R, the dot <code>.</code> is used as shorthand to indicate that we want to include all other variables in the formula as predictors except for the outcome variable. So, if our outcome variable is y and we want to include all other variables in our data frame as predictors, we can write <code>y ~ .</code> in the formula.</p>
<p>In Python, however, the dot <code>.</code> is not used in the same way in formulas. Instead, to include all other variables as predictors except for <code>y</code>, we would write <code>y ~ x1 + x2 + ...</code> where <code>x1, x2</code>, etc. represent the names of the predictor variables. Also, <code>statsmodels</code> has a similar syntax to R base regressions. In most other typical ML libraries in Python, you must provide the column values instead of using the column names.</p>
</div>
</div>
<p>Note that the <code>family="binomial"</code> argument in R is not needed in Python since <code>sm.formula.logit()</code> assumes the logistic regression model is fitted using a binomial distribution by default.</p>
</div>
</div>
</div>
</section><section id="variable-selection-interpretation-1" class="level2"><h2 class="anchored" data-anchor-id="variable-selection-interpretation-1">Variable selection &amp; interpretation</h2>
<p>Now, we can apply the variable selection:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">vis_logr_sel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/step.html">step</a></span><span class="op">(</span><span class="va">vis_logr</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">vis_logr_sel</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Start:  AIC=3518.77
visits ~ gender + age + income + illness + reduced + health + 
    private + freepoor + freerepat + nchronic + lchronic

            Df Deviance    AIC
- income     1   3494.8 3516.8
- nchronic   1   3495.5 3517.5
- age        1   3496.2 3518.2
- lchronic   1   3496.3 3518.3
&lt;none&gt;           3494.8 3518.8
- freerepat  1   3500.0 3522.0
- private    1   3500.2 3522.2
- freepoor   1   3500.7 3522.7
- health     1   3502.1 3524.1
- gender     1   3506.4 3528.4
- illness    1   3562.9 3584.9
- reduced    1   3650.9 3672.9

Step:  AIC=3516.77
visits ~ gender + age + illness + reduced + health + private + 
    freepoor + freerepat + nchronic + lchronic

            Df Deviance    AIC
- nchronic   1   3495.5 3515.5
- age        1   3496.2 3516.2
- lchronic   1   3496.3 3516.3
&lt;none&gt;           3494.8 3516.8
- freerepat  1   3500.1 3520.1
- private    1   3500.3 3520.3
- freepoor   1   3501.0 3521.0
- health     1   3502.1 3522.1
- gender     1   3506.9 3526.9
- illness    1   3563.0 3583.0
- reduced    1   3651.0 3671.0

Step:  AIC=3515.52
visits ~ gender + age + illness + reduced + health + private + 
    freepoor + freerepat + lchronic

            Df Deviance    AIC
- lchronic   1   3496.4 3514.4
&lt;none&gt;           3495.5 3515.5
- age        1   3497.6 3515.6
- freerepat  1   3501.0 3519.0
- private    1   3501.3 3519.3
- freepoor   1   3501.6 3519.6
- health     1   3502.7 3520.7
- gender     1   3508.0 3526.0
- illness    1   3573.5 3591.5
- reduced    1   3651.9 3669.9

Step:  AIC=3514.4
visits ~ gender + age + illness + reduced + health + private + 
    freepoor + freerepat

            Df Deviance    AIC
&lt;none&gt;           3496.4 3514.4
- age        1   3498.5 3514.5
- private    1   3502.3 3518.3
- freerepat  1   3502.3 3518.3
- freepoor   1   3502.3 3518.3
- health     1   3504.3 3520.3
- gender     1   3508.6 3524.6
- illness    1   3577.0 3593.0
- reduced    1   3661.4 3677.4

Call:
glm(formula = visits ~ gender + age + illness + reduced + health + 
    private + freepoor + freerepat, family = "binomial", data = dat_tr_visit)

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -2.31795    0.13920 -16.652  &lt; 2e-16 ***
gendermale   -0.31838    0.09136  -3.485 0.000492 ***
age           0.39762    0.27656   1.438 0.150503    
illness       0.28431    0.03152   9.019  &lt; 2e-16 ***
reduced       0.16340    0.01337  12.217  &lt; 2e-16 ***
health        0.05589    0.01966   2.843 0.004470 ** 
privateyes    0.27249    0.11258   2.420 0.015503 *  
freepooryes  -0.65344    0.28444  -2.297 0.021601 *  
freerepatyes  0.38038    0.15674   2.427 0.015231 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 3985.6  on 3912  degrees of freedom
Residual deviance: 3496.4  on 3904  degrees of freedom
AIC: 3514.4

Number of Fisher Scoring iterations: 4</code></pre>
</div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<p>As already seen in the linear regression part, in python, we don’t have the same implementation of the step function, hence why we designed the while loop earlier. It is good practice to create a single function with this step while loop to handle all cases (linear, logistic etc); however, we only implement it here for logistic regression. Therefore, to tackle this, we will create a function that does step-wise elimination for us. We define a function called <code>forward_selected</code> that performs forward selection on a given dataset to select the best predictors for a response variable based on AIC. The function takes two arguments: <code>data</code>, a pandas DataFrame containing the predictors and <code>response</code> variable, and response, a string specifying the name of the response variable.</p>
<details><summary>
For more explanation of the code, click on me
</summary><p>The function first initializes two sets: <code>remaining</code> and <code>selected</code>. <code>remaining</code> contains the names of all columns in the <code>data</code> DataFrame except for the <code>response</code> variable, while <code>selected</code> is initially empty. The function then initializes <code>current_aic</code> and <code>best_new_aic</code> to infinity. The main loop of the function continues as long as <code>remaining</code> is not empty and <code>current_aic</code> is equal to <code>best_new_aic</code>. At each iteration, the function iterates over all columns in <code>remaining</code> and computes the AIC for a logistic regression model that includes the <code>response</code> variable and the currently selected predictors, as well as the current candidate predictor. The function then adds the candidate predictor and its AIC to a list of <code>(aic, candidate)</code> tuples, and sorts the list by increasing AIC. The function then selects the candidate with the lowest AIC and adds it to the <code>selected</code> set, removes it from the <code>remaining</code> set, and updates <code>current_aic</code> to the new lowest AIC. The function continues this process until no candidate can improve the AIC. Finally, the function fits a logistic regression model using the selected predictors and returns the resulting model.</p>
</details><div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code taken from the link below and adjusted for logistic regression with AIC criteria</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://planspace.org/20150423-forward_selection_with_statsmodels/</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_selected(data, response):</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Linear model designed by forward selection.</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co">    data : pandas DataFrame with all possible predictors and response</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="co">    response: string, name of response column in data</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co">    model: an "optimal" fitted statsmodels linear model</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="co">           with an intercept</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="co">           selected by forward selection</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="co">           evaluated by AIC</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    remaining <span class="op">=</span> <span class="bu">set</span>(data.columns)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    remaining.remove(response)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    selected <span class="op">=</span> []</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    current_aic, best_new_aic <span class="op">=</span> <span class="bu">float</span>(<span class="st">"inf"</span>), <span class="bu">float</span>(<span class="st">"inf"</span>)</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> remaining <span class="kw">and</span> current_aic <span class="op">==</span> best_new_aic:</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>        aics_with_candidates <span class="op">=</span> []</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> candidate <span class="kw">in</span> remaining:</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>            formula <span class="op">=</span> <span class="st">"</span><span class="sc">{}</span><span class="st"> ~ </span><span class="sc">{}</span><span class="st"> + 1"</span>.<span class="bu">format</span>(response,</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>                                           <span class="st">' + '</span>.join(selected <span class="op">+</span> [candidate]))</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> smf.logit(formula, data).fit(disp<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>            aic <span class="op">=</span> model.aic</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>            aics_with_candidates.append((aic, candidate))</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>        aics_with_candidates.sort()</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>        best_new_aic, best_candidate <span class="op">=</span> aics_with_candidates.pop(<span class="dv">0</span>)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> current_aic <span class="op">&gt;</span> best_new_aic:</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>            remaining.remove(best_candidate)</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>            selected.append(best_candidate)</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>            current_aic <span class="op">=</span> best_new_aic</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>    formula <span class="op">=</span> <span class="st">"</span><span class="sc">{}</span><span class="st"> ~ </span><span class="sc">{}</span><span class="st"> + 1"</span>.<span class="bu">format</span>(response,</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>                                   <span class="st">' + '</span>.join(selected))</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> smf.logit(formula, data).fit(disp<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>mod_logit_sel_py <span class="op">=</span> forward_selected(r.dat_tr_visit, <span class="st">'visits'</span>)</span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mod_logit_sel_py.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            Logit Regression Results                           
===============================================================================
Dep. Variable:                  visits   No. Observations:                 3913
Model:                           Logit   Df Residuals:                     3906
Method:                            MLE   Df Model:                            6
Date:              sam., 28 févr. 2026   Pseudo R-squ.:                  0.1209
Time:                         23:01:15   Log-Likelihood:                -1751.9
converged:                        True   LL-Null:                       -1992.8
Covariance Type:             nonrobust   LLR p-value:                6.902e-101
===================================================================================
                      coef    std err          z      P&gt;|z|      [0.025      0.975]
-----------------------------------------------------------------------------------
Intercept          -2.2457      0.125    -17.989      0.000      -2.490      -2.001
gender[T.male]     -0.3542      0.090     -3.919      0.000      -0.531      -0.177
freepoor[T.yes]    -0.8098      0.278     -2.917      0.004      -1.354      -0.266
reduced             0.1620      0.013     12.159      0.000       0.136       0.188
illness             0.2864      0.031      9.123      0.000       0.225       0.348
age                 0.7754      0.216      3.591      0.000       0.352       1.199
health              0.0565      0.020      2.880      0.004       0.018       0.095
===================================================================================</code></pre>
</div>
</div>
<p>We can see that the results of <code>mod_logit_sel_py</code> model are slightly different from the R version, but nevertheless, we have reduced the features and the interpretations (see below) with both R and python versions remain the same.</p>
</div>
</div>
</div>
<p>We can see that the probability of a visit is</p>
<ul>
<li>smaller for males</li>
<li>increasing with age</li>
<li>larger with illness</li>
<li>etc.</li>
</ul></section><section id="inference-1" class="level2"><h2 class="anchored" data-anchor-id="inference-1">Inference</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<p>The <strong>predict</strong> function with <strong>type=“response”</strong> will predict the probability of the positive class (“1”). If it is set to <strong>“link”</strong> it produces the linear predictor (i.e., the <span class="math inline">\(z\)</span>). To make the prediction, we thus have to identify if the predicted probability is larger or lower than 0.5.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prob_te_visit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">vis_logr_sel</span>, newdata <span class="op">=</span> <span class="va">dat_te_visit</span>, type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span></span>
<span><span class="va">pred_te_visit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">prob_te_visit</span> <span class="op">&gt;=</span> <span class="fl">0.5</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span>Pred<span class="op">=</span><span class="va">pred_te_visit</span>, Obs<span class="op">=</span><span class="va">dat_te_visit</span><span class="op">$</span><span class="va">visits</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Obs
Pred    0    1
   0 1011  204
   1   25   37</code></pre>
</div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<p>The explanation is similar to that of R, with a slight different that here we use <code>pandas.crosstab</code> to make our confusion matrix.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>prob_te_visit <span class="op">=</span> mod_logit_sel_py.predict(r.dat_te_visit)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>pred_te_visit <span class="op">=</span> [<span class="dv">1</span> <span class="cf">if</span> p <span class="op">&gt;=</span> <span class="fl">0.5</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> p <span class="kw">in</span> prob_te_visit]</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>conf_mat <span class="op">=</span> pd.crosstab(pred_te_visit, r.dat_te_visit[<span class="st">'visits'</span>], rownames<span class="op">=</span>[<span class="st">'Pred'</span>], colnames<span class="op">=</span>[<span class="st">'Obs'</span>])</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(conf_mat)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>The results are extremely close to the R version.</p>
</div>
</div>
</div>
<p>The predictions are not really good. It is in fact a difficult data set. Indeed, the number of 0 is so large compare to the 1, that predicting a 0 always provides a good model overall. That issue will be addressed further later on in the course.</p>
<p>For now, this can be further inspected by looking at the predicted probabilities per observed label.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.html">boxplot</a></span><span class="op">(</span><span class="va">prob_te_visit</span><span class="op">~</span><span class="va">dat_te_visit</span><span class="op">$</span><span class="va">visits</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="Ex_ML_LinLogReg_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>ax.boxplot([prob_te_visit[r.dat_te_visit[<span class="st">'visits'</span>]<span class="op">==</span><span class="dv">0</span>], prob_te_visit[r.dat_te_visit[<span class="st">'visits'</span>]<span class="op">==</span><span class="dv">1</span>]])<span class="op">;</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels([<span class="st">'No Visit'</span>, <span class="st">'Visit'</span>])<span class="op">;</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Predicted Probability'</span>)<span class="op">;</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Predicted Probabilities by Visit Status'</span>)<span class="op">;</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</div>
<p>We see that if the lowest predicted probabilities are usually assigned to 0-observations, most of the probabilities remain below 0.5 (even for the 1-observations). A good model would have two well separated boxplots, well away from 0.5.</p>
<p>Now, as an exercise, write down the prediction equation of the selected model, like you did for linear regression. Use this equation to explain how instance 1 and 2 (test set) are predicted, and calculate the predictions manually. Verify your results using the function <em>predict</em> used before.</p>
<details><summary>
Answer
</summary><div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prob_te_visit</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">]</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         2          4 
0.21367628 0.09309046 </code></pre>
</div>
</div>
<p><span class="math display">\[
z(x) = -2.31795-0.31838\times gender\_male+0.39762\times age+\\0.28431\times illness+0.16340\times reduced+0.05589\times health+\\0.27249\times private\_eyes -0.65344\times freepoor\_yes+\\0.38038\times freerepat\_yes  
\]</span> Then <span class="math display">\[
P(Y=1 | X=x) = \frac{e^{z(x)}}{1+e^{z(x)}}
\]</span></p>
</details></section></section><section id="lasso-ridge-regressions" class="level1"><h1>LASSO &amp; Ridge regressions</h1>
<p>You have been introduced to lasso and ridge regression during the <em>Variable selection with penalization</em> part of the lecture.</p>
<p>Lasso and Ridge Regression are two regularization techniques used in regression models to prevent overfitting by adding a penalty term to the loss function. Lasso regression (aka <span class="math inline">\(L_1\)</span>) adds a penalty term equal to the absolute value of the coefficients. In contrast, Ridge regression (aka <span class="math inline">\(L_2\)</span>) adds a penalty term equal to the squared value of the coefficients. The effect of the penalty term is to shrink the coefficients towards zero, which can help reduce model complexity and improve generalization performance. In this case, we apply lasso and ridge to the real estate data and do not cover logistic regression (example already seen during the class).</p>
<p>First, we need to turn our predictors into matrices, as this is required by the <code>glmnet</code> package in R and works with the python implementation.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># glmnet can only work with matrix objects, columns 2-7 correspond to the same ones used by `lm`</span></span>
<span><span class="va">dat_tr_re_mat_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">dat_tr_restate</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span><span class="op">:</span><span class="fl">7</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">dat_tr_re_mat_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">dat_tr_restate</span>,<span class="st">'Price'</span><span class="op">)</span></span>
<span><span class="va">dat_te_re_mat_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">dat_te_restate</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span><span class="op">:</span><span class="fl">7</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">dat_te_re_mat_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">dat_te_restate</span>,<span class="st">'Price'</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true" href="">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false" href="">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<p>On the newly created matrices, we run cross-validated lasso and ridge with the <code>cv.glmnet()</code>, function where setting the <code>alpha</code> (penalty) parameter as 1 produces lasso regression and 0 produces ridge regression. The default value of alpha is 1, which corresponds to lasso regression. For 0&lt;alpha&lt;1, it performs Elastic Net regression (a combination of <span class="math inline">\(L_1\)</span> and <span class="math inline">\(L_2\)</span> regularization).</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load appropriate library and set a seed</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu">glmnet</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit Ridge regression model</span></span>
<span><span class="va">ridge_fit</span> <span class="op">&lt;-</span> <span class="fu">cv.glmnet</span><span class="op">(</span>x <span class="op">=</span> <span class="va">dat_tr_re_mat_x</span>, y <span class="op">=</span> <span class="va">dat_tr_re_mat_y</span>, alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit Lasso regression model</span></span>
<span><span class="va">lasso_fit</span> <span class="op">&lt;-</span> <span class="fu">cv.glmnet</span><span class="op">(</span>x <span class="op">=</span> <span class="va">dat_tr_re_mat_x</span>, y <span class="op">=</span> <span class="va">dat_tr_re_mat_y</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="co">#if you change the `family` argument to `bionomial`, you can get also logistic regression</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>We can then fit the final models with the best parameters:</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ridge_fit_best</span> <span class="op">&lt;-</span> <span class="fu">glmnet</span><span class="op">(</span>x<span class="op">=</span><span class="va">dat_tr_re_mat_x</span>, y <span class="op">=</span> <span class="va">dat_tr_re_mat_y</span>, </span>
<span>                         lambda <span class="op">=</span> <span class="va">ridge_fit</span><span class="op">$</span><span class="va">lambda.min</span><span class="op">)</span></span>
<span></span>
<span><span class="va">lasso_fit_best</span> <span class="op">&lt;-</span> <span class="fu">glmnet</span><span class="op">(</span>x<span class="op">=</span><span class="va">dat_tr_re_mat_x</span>, y<span class="op">=</span><span class="va">dat_tr_re_mat_y</span>, </span>
<span>                         lambda <span class="op">=</span> <span class="va">lasso_fit</span><span class="op">$</span><span class="va">lambda.min</span><span class="op">)</span> <span class="co">#can also use lasso_fit$lambda.1se</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>We can compare different performances for this task using <code>caret::postResample()</code>. We will learn more this function and it’s metrics the upcoming courses &amp; lab sessions.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># lasso &amp; ridge performance on the training set</span></span>
<span><span class="fu">caret</span><span class="fu">::</span><span class="fu">postResample</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">ridge_fit_best</span>, newx <span class="op">=</span> <span class="va">dat_tr_re_mat_x</span><span class="op">)</span>, <span class="va">dat_tr_re_mat_y</span><span class="op">)</span></span>
<span><span class="fu">caret</span><span class="fu">::</span><span class="fu">postResample</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">lasso_fit_best</span>, newx <span class="op">=</span> <span class="va">dat_tr_re_mat_x</span><span class="op">)</span>, <span class="va">dat_tr_re_mat_y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># lasso &amp; ridge performance on the test set</span></span>
<span><span class="fu">caret</span><span class="fu">::</span><span class="fu">postResample</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">ridge_fit_best</span>, newx <span class="op">=</span> <span class="va">dat_te_re_mat_x</span><span class="op">)</span>, <span class="va">dat_te_re_mat_y</span><span class="op">)</span></span>
<span><span class="fu">caret</span><span class="fu">::</span><span class="fu">postResample</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">lasso_fit_best</span>, newx <span class="op">=</span> <span class="va">dat_te_re_mat_x</span><span class="op">)</span>, <span class="va">dat_te_re_mat_y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Step-wise lm performance on training and test sets</span></span>
<span><span class="fu">caret</span><span class="fu">::</span><span class="fu">postResample</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod_lm_sel</span>,<span class="va">dat_tr_restate</span><span class="op">)</span>, <span class="va">dat_tr_re_mat_y</span><span class="op">)</span></span>
<span><span class="fu">caret</span><span class="fu">::</span><span class="fu">postResample</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod_lm_sel</span>,<span class="va">dat_te_restate</span><span class="op">)</span>, <span class="va">dat_te_re_mat_y</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>     RMSE  Rsquared       MAE 
9.0656535 0.5558078 6.2141456 
     RMSE  Rsquared       MAE 
8.9037222 0.5634319 6.1024607 
     RMSE  Rsquared       MAE 
8.9111448 0.6089043 6.6326836 
     RMSE  Rsquared       MAE 
8.4792450 0.6434067 6.3485929 
     RMSE  Rsquared       MAE 
8.8998617 0.5635734 6.1053064 
     RMSE  Rsquared       MAE 
8.4307702 0.6479616 6.3107488 </code></pre>
</div>
</div>
<p>In this case, the lasso is better than the ridge on the test set, and if you have many features, this could be a useful technique. However, they are both outperformed by step-wise linear regression. Lasso and ridge are more useful when you have many more variables. You can try this already by taking more variables for your <code>dat_tr_re_mat_x</code> and <code>dat_te_re_mat_x</code> such <code>select(dat_te_restate,-c('Price', 'Month'))</code> to see how (for better or worse) the performance changes. If you want more explanation on why linear model outperformed lasso and ridge, check out (click on) the further explanation below.</p>
<details><summary>
Why lm (or step lm) outperformed lasso &amp; ridge
</summary><p>In some situations, it is normal to observe that a linear model may perform better than a regularized model, such as a ridge or lasso. This can occur when the number of predictors in the model is small relative to the sample size or when the predictors are highly correlated.</p>
<p>Linear regression assumes that the relationship between the response variable and the predictors is linear and additive. When this assumption holds, a linear model can be a good choice. In contrast, regularized regression methods such as ridge and lasso add a penalty term to the regression objective function to shrink the estimated coefficients towards zero, which can help to avoid overfitting when the number of predictors is large relative to the sample size or when the predictors are highly correlated.</p>
<p>However, when the number of predictors is small relative to the sample size or when the predictors are highly correlated, the additional regularization provided by ridge or lasso may not be necessary, and a simple linear model may perform better.</p>
<p>It is always a good practice to compare the performance of different models using appropriate evaluation metrics and techniques such as cross-validation. The choice of the best model will depend on the specific problem and the goals of the analysis.</p>
</details>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge, Lasso, RidgeCV, LassoCV</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a seed for reproducibility</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Lasso regression model</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>lasso_cv <span class="op">=</span> LassoCV(cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>lasso_cv.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)<span class="op">;</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the optimal regularization parameter</span></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>lasso_optimal_alpha <span class="op">=</span> lasso_cv.alpha_</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Lasso model with the optimal alpha</span></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>lasso_best_py <span class="op">=</span> Lasso(alpha<span class="op">=</span>lasso_optimal_alpha)</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>lasso_best_py.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)<span class="op">;</span></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Ridge regression model with cross-validation</span></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>ridge_cv <span class="op">=</span> RidgeCV(cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>ridge_cv.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)<span class="op">;</span></span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the optimal regularization parameter</span></span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>ridge_optimal_alpha <span class="op">=</span> ridge_cv.alpha_</span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Ridge model with the optimal alpha</span></span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>ridge_best_py <span class="op">=</span> Ridge(alpha<span class="op">=</span>ridge_optimal_alpha)</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>ridge_best_py.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>The <code>lambda</code> argument in <code>cv.glmnet()</code> from R corresponds to the <code>alpha</code> argument in <code>RidgeCV()</code>/<code>LassoCV()</code> in python. In <code>cv.glmnet()</code>, the lambda argument specifies the range of regularization parameters to be tested in the model selection process. By default, lambda is set to NULL, which means that <code>glmnet()</code> will automatically choose a sequence of lambda values to search over. Note that in <code>glmnet()</code>, lambda values are used for both <span class="math inline">\(L_1\)</span> (lasso) and <span class="math inline">\(L_2\)</span> (ridge) regularization, whereas in <code>RidgeCV()</code>, alpha values are used to control the mix of L1 and L2 regularization, with alpha = 0 corresponding to pure L2 regularization (i.e., ridge regression).</p>
<p>On the contrary (and to avoid confusion), the <code>alpha</code> argument in <code>cv.glmnet()</code> corresponds to the <code>fit_intercept</code> argument in <code>RidgeCV()</code>/<code>LassoCV()</code>. In <code>cv.glmnet()</code>, the alpha argument specifies the mixing parameter between L1 and L2 regularization.</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># python lasso &amp; ridge performance on the training set</span></span>
<span><span class="fu">caret</span><span class="fu">::</span><span class="fu">postResample</span><span class="op">(</span><span class="va">py</span><span class="op">$</span><span class="va">ridge_best_py</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">dat_tr_re_mat_x</span><span class="op">)</span>, <span class="va">dat_tr_re_mat_y</span><span class="op">)</span></span>
<span><span class="fu">caret</span><span class="fu">::</span><span class="fu">postResample</span><span class="op">(</span><span class="va">py</span><span class="op">$</span><span class="va">lasso_best_py</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">dat_tr_re_mat_x</span><span class="op">)</span>, <span class="va">dat_tr_re_mat_y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># python lasso &amp; ridge performance on the test set</span></span>
<span><span class="fu">caret</span><span class="fu">::</span><span class="fu">postResample</span><span class="op">(</span><span class="va">py</span><span class="op">$</span><span class="va">ridge_best_py</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span> <span class="va">dat_te_re_mat_x</span><span class="op">)</span>, <span class="va">dat_te_re_mat_y</span><span class="op">)</span></span>
<span><span class="fu">caret</span><span class="fu">::</span><span class="fu">postResample</span><span class="op">(</span><span class="va">py</span><span class="op">$</span><span class="va">lasso_best_py</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">dat_te_re_mat_x</span><span class="op">)</span>, <span class="va">dat_te_re_mat_y</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>     RMSE  Rsquared       MAE 
9.0705968 0.5467287 6.2383143 
     RMSE  Rsquared       MAE 
9.7290338 0.4785813 6.7449560 
     RMSE  Rsquared       MAE 
8.5033987 0.6389774 6.4632568 
      RMSE   Rsquared        MAE 
10.0543556  0.4971724  7.4724012 </code></pre>
</div>
</div>
<p>The performance is different in python simply because of different default settings for the python vs R implementations.</p>
</div>
</div>
</div>
<p>To understand the decision making of lasso, we can check the beta’s in a similar fashion to a regression (only shown for the R models).</p>
<div class="cell" data-layout-align="center">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># running the following can tell you a bit about the impact of different variables</span></span>
<span><span class="va">small.lambda.index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="va">lasso_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">lasso_fit</span><span class="op">$</span><span class="va">lambda.min</span><span class="op">)</span></span>
<span><span class="va">lasso_fit</span><span class="op">$</span><span class="va">glmnet.fit</span><span class="op">$</span><span class="va">beta</span><span class="op">[</span>, <span class="va">small.lambda.index</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># or on the final model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">lasso_fit</span> , s<span class="op">=</span> <span class="st">'lambda.min'</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">lasso_fit</span>, xvar <span class="op">=</span> <span class="st">"lambda"</span>, label <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="Ex_ML_LinLogReg_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>   TransDate     HouseAge         Dist    NumStores          Lat         Long 
  3.19017320  -0.22968625  -0.00460157   0.99674463 230.81613231   0.00000000 
7 x 1 sparse Matrix of class "dgCMatrix"
                       s1
(Intercept) -1.214284e+04
TransDate    3.190173e+00
HouseAge    -2.296862e-01
Dist        -4.601570e-03
NumStores    9.967446e-01
Lat          2.308161e+02
Long         .           </code></pre>
</div>
</div>
<p>We can see that from the first output <code>Long</code> value has almost a beta of 0. In the second output, it is confirmed that the coefficient of this variable is indeed 0. This could explain why <code>mod_lm_sel</code> also dropped this variable. The rest of the coefficient are similar to <code>summary(mod_lm_sel)</code>. as ridge or lasso in some situations. This can occur when the number of predictors in the model is small relative to the sample size, or when the predictors are highly correlated.</p>
</section><section id="your-turn-to-practice" class="level1"><h1>Your turn to practice</h1>
<section id="linear-regression-nursing-home-data" class="level2"><h2 class="anchored" data-anchor-id="linear-regression-nursing-home-data">Linear regression: nursing home data</h2>
<p>Now it is your turn. Make an linear regression (also feel free to try lasso and ridge regressions) on the nursing data described below (found also in <code>/data/nursing_data.csv</code>). Afterwards, use linear regression to build a predictor of the cost using the other features. Replicate the analysis. Split the data, build a model, make the variable selection, make the predictions and analyze the results. Make also an analysis of the coefficients in terms of the associations between the costs and the features.</p>
<details><summary>
Data Description
</summary><p>The data set is about patients in a nursing home, where elderly people are helped with daily living needs, also known as Activities of Daily Living (ADL, i.e.&nbsp;communication, eating, walking, showering, going to a toilet, etc.).</p>
<p>Since the stay in such facilities is very expensive, it is important to classify the new-coming patient, and estimate the duration of the stay and the corresponding costs.</p>
<p>In practice, there are different types of patients who require different types of help and, consequently, different duration of the stay. For example, there could be a person with severe mobility issues, who requires the help with most of the needs every day; or a person with mental deviations, who don’t need help with daily routine, but requires extra communication hours.</p>
<p>Here, we will focus of total amount of help (measured in minutes of help provided to a person per week) provided and measure the costs of stay of a person.</p>
<p>The data set on which the analysis is based has the following columns:</p>
<ul>
<li>
<strong>gender</strong>: a categorical variable with levels “<em>M</em>” for male and “<em>F</em>” for female</li>
<li>
<strong>age</strong>: integer variable</li>
<li>
<strong>mobil</strong>: categorical variable that represents the physical mobility with levels
<ul>
<li>1 = Full mobility</li>
<li>2 = Reduced mobility</li>
<li>3 = Restricted mobility in the house</li>
<li>4 = Null mobility</li>
</ul>
</li>
<li>
<strong>orient</strong>: categorical variable that represents the orientation (interactions with the environment) with levels
<ul>
<li>1 = Full orientation</li>
<li>2 = Moderate disturbance of orientation</li>
<li>3 = Disorientation</li>
</ul>
</li>
<li>
<strong>independ</strong>: categorical variable that represents the independence of ADL with levels
<ul>
<li>1 = Independent of help</li>
<li>2 = Dependent less than 24 hours per day</li>
<li>3 = Dependent at unpredictable time intervals for most of the needs</li>
</ul>
</li>
<li>
<strong>minut_mob</strong>: numerical variable that represents the total number of minutes of help with movement per week</li>
<li>
<strong>need_comm</strong>: categorical variable with levels “<em>Yes</em>” for a person who needs extra communication sessions with an employee, and “<em>No</em>” otherwise</li>
<li>
<strong>minut_comm</strong>: numerical variable that represents the total number of minutes of communication per week</li>
<li>
<strong>tot_minut</strong>: numerical variable that represents the total number of minutes spent on a patient per week, <span class="math inline">\(tot\_minut = minut\_mob + minut\_comm\)</span>
</li>
<li>
<strong>cost</strong>: numerical variable that represents the total costs of having a patient in the nursing house per month.</li>
</ul></details><p>Note: since tot_minut=minut_mob+minut_comm, you may not find any meaningful result using the 3 features. This is perfectly normal. Just use 2 features only among these 3 (arbitrary choice).</p>
</section><section id="logistic-regression-the-credit-quality" class="level2"><h2 class="anchored" data-anchor-id="logistic-regression-the-credit-quality">Logistic regression: the credit quality</h2>
<p>The German Credit Quality Dataset consists of a set of attributes as good or bad credit risks. In order to find find a detailed description of the features, please refer to the <a href="https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)">original link to the dataset</a>. The <code>german.csv</code> file can also be found in <code>/data/german.csv</code> whichis the mdified version of the original dataset to simplify the analysis, especially the data loading in <strong>R</strong>.</p>
<p>The aim here is to predict the credit quality from the other features. The outcome <strong>Quality</strong> is 0 for “bad” and 1 for “good”. Make an analysis of the data and develop the learner. You can follow these notable steps:</p>
<ul>
<li>Make a simple EDA of the features</li>
<li>Split the data and train the model.</li>
<li>Make variable selection and check out the result.</li>
<li>Interpret the coefficients.</li>
<li>Inspect the quality of the model by making the predictions (confusion table and boxplot of the predicted probabilities).</li>
</ul>
<p>Note that the data are unbalanced again and that you may not find a very good predictor. This issue is quite difficult and will be addressed later.</p>


<!-- -->

</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/do-unil\.github\.io\/mlba");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../../labs/00_lab/setup.html" class="pagination-link" aria-label="Setup">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Setup</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../labs/03_Models/032_Trees/Ex_ML_Tree.html" class="pagination-link" aria-label="Decision Trees">
        <span class="nav-page-text">Decision Trees</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb49" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Models: Linear and logistic regressions"</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="an">output-file:</span><span class="co"> Ex_ML_LinLogReg.html</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="in">```{r global_options, include = FALSE}</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">fig.align=</span><span class="st">"center"</span>, <span class="at">results =</span> <span class="st">'hold'</span>, <span class="at">fig.show =</span> <span class="st">'show'</span>, <span class="at">warning =</span> <span class="cn">FALSE</span>, <span class="at">message =</span> <span class="cn">FALSE</span>)</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a><span class="fu"># Linear regression: real estate application</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>The dataset we'll be using for the first part of the exercise is real estate transaction prices in Taiwan, which can be accessed from this link <span class="co">[</span><span class="ot">this link</span><span class="co">](https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set)</span>. This dataset was modified for this exercise. The modified file <span class="in">`real_estate_data.csv`</span> is in the exercise folder under <span class="in">`/data/`</span>.</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>The aim is to predict the house prices from available features: *No*, *Month*, *Year*, *TransDate*, *HouseAge*, *Dist*, *NumStores*, *Lat*, *Long*, *Price*. *No* is the transaction number and will not be used.</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a><span class="fu">## EDA</span></span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>First, an EDA of the data is needed. After exploring the structure, the *Price* is shown with the year and month.</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/real_estate_data.csv"</span>))</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a><span class="do">## adapt the path to the data</span></span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a><span class="co"># if you encountered any error with the encoding of the data (`Error in gregexpr...`), just re-run the code again</span></span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(real_estate_data)</span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(summarytools)</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a><span class="fu">dfSummary</span>(real_estate_data)</span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>Month, <span class="at">y=</span>Price, <span class="at">fill=</span><span class="fu">as.factor</span>(Year))) <span class="sc">+</span> </span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>()<span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span><span class="fu">as.factor</span>(Year))</span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-36"><a href="#cb49-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a>The results show how important it is to make an EDA! It appears that the data does not contain transactions for all the months of 2012 and 2013, but just some months by the end of 2012 and the first half of 2013. This shows that it is pointless to use month and year here. This is why we prefer *TransDate*, a value indicating the transaction time on a linear scale (e.g., 2013.250 is March 2013).</span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-39"><a href="#cb49-39" aria-hidden="true" tabindex="-1"></a>Now we focus on the link between *Price* and the other features.</span>
<span id="cb49-40"><a href="#cb49-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-43"><a href="#cb49-43" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-44"><a href="#cb49-44" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb49-45"><a href="#cb49-45" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="sc">%&gt;%</span> </span>
<span id="cb49-46"><a href="#cb49-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Price, HouseAge, Dist, Lat, Long, TransDate) <span class="sc">%&gt;%</span> </span>
<span id="cb49-47"><a href="#cb49-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggpairs</span>()</span>
<span id="cb49-48"><a href="#cb49-48" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-49"><a href="#cb49-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-50"><a href="#cb49-50" aria-hidden="true" tabindex="-1"></a>No clear link appears. The linear regression will help to discover if a combination of the features can predict the price.</span>
<span id="cb49-51"><a href="#cb49-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-52"><a href="#cb49-52" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modelling</span></span>
<span id="cb49-53"><a href="#cb49-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-54"><a href="#cb49-54" aria-hidden="true" tabindex="-1"></a>First, we split the data into training/test set (75/25).</span>
<span id="cb49-55"><a href="#cb49-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-58"><a href="#cb49-58" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-59"><a href="#cb49-59" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb49-60"><a href="#cb49-60" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">size=</span><span class="fu">nrow</span>(real_estate_data), <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.75</span>,<span class="fl">0.25</span>)) <span class="co"># 1==training set, 2==test set</span></span>
<span id="cb49-61"><a href="#cb49-61" aria-hidden="true" tabindex="-1"></a>dat_tr_restate <span class="ot">&lt;-</span> real_estate_data[index<span class="sc">==</span><span class="dv">1</span>,]</span>
<span id="cb49-62"><a href="#cb49-62" aria-hidden="true" tabindex="-1"></a>dat_te_restate <span class="ot">&lt;-</span> real_estate_data[index<span class="sc">==</span><span class="dv">2</span>,]</span>
<span id="cb49-63"><a href="#cb49-63" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-64"><a href="#cb49-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-65"><a href="#cb49-65" aria-hidden="true" tabindex="-1"></a>Then, we fit the linear regression to the training set.</span>
<span id="cb49-66"><a href="#cb49-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-67"><a href="#cb49-67" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb49-68"><a href="#cb49-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-69"><a href="#cb49-69" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb49-70"><a href="#cb49-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-73"><a href="#cb49-73" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-74"><a href="#cb49-74" aria-hidden="true" tabindex="-1"></a>mod_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Price<span class="sc">~</span>TransDate<span class="sc">+</span></span>
<span id="cb49-75"><a href="#cb49-75" aria-hidden="true" tabindex="-1"></a>               HouseAge<span class="sc">+</span></span>
<span id="cb49-76"><a href="#cb49-76" aria-hidden="true" tabindex="-1"></a>               Dist<span class="sc">+</span></span>
<span id="cb49-77"><a href="#cb49-77" aria-hidden="true" tabindex="-1"></a>               NumStores<span class="sc">+</span></span>
<span id="cb49-78"><a href="#cb49-78" aria-hidden="true" tabindex="-1"></a>               Lat<span class="sc">+</span></span>
<span id="cb49-79"><a href="#cb49-79" aria-hidden="true" tabindex="-1"></a>               Long, <span class="at">data=</span>dat_tr_restate)</span>
<span id="cb49-80"><a href="#cb49-80" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lm)</span>
<span id="cb49-81"><a href="#cb49-81" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-82"><a href="#cb49-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-83"><a href="#cb49-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-84"><a href="#cb49-84" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb49-85"><a href="#cb49-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-88"><a href="#cb49-88" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-89"><a href="#cb49-89" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load-conda</span></span>
<span id="cb49-90"><a href="#cb49-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-91"><a href="#cb49-91" aria-hidden="true" tabindex="-1"></a><span class="co"># In R, we load the conda environment as usual</span></span>
<span id="cb49-92"><a href="#cb49-92" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb49-93"><a href="#cb49-93" aria-hidden="true" tabindex="-1"></a>reticulate<span class="sc">::</span><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>, <span class="at">required =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-94"><a href="#cb49-94" aria-hidden="true" tabindex="-1"></a><span class="fu">gc</span>(<span class="at">full =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-95"><a href="#cb49-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-96"><a href="#cb49-96" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-97"><a href="#cb49-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-98"><a href="#cb49-98" aria-hidden="true" tabindex="-1"></a>In python, we then use the <span class="in">`statsmodels`</span> library to fit a linear regression model to the training data and perform feature elimination. We use the <span class="in">`.fit()`</span> method to fit the model with the formula for the variable names. Note that python's <span class="in">`summary()`</span> function is unique to the <span class="in">`statsmodels`</span> libraries and produces similar information to its R counterpart.</span>
<span id="cb49-99"><a href="#cb49-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-100"><a href="#cb49-100" aria-hidden="true" tabindex="-1"></a><span class="in">```{python import-mkl}</span></span>
<span id="cb49-101"><a href="#cb49-101" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb49-102"><a href="#cb49-102" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"OMP_NUM_THREADS"</span>] <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb49-103"><a href="#cb49-103" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"MKL_NUM_THREADS"</span>] <span class="op">=</span> <span class="st">"1"</span></span>
<span id="cb49-104"><a href="#cb49-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-105"><a href="#cb49-105" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mkl</span>
<span id="cb49-106"><a href="#cb49-106" aria-hidden="true" tabindex="-1"></a><span class="co"># %env OMP_NUM_THREADS=1</span></span>
<span id="cb49-107"><a href="#cb49-107" aria-hidden="true" tabindex="-1"></a><span class="co"># set the number of threads. Here we set it to 1 to avoid parallelization when rendering quarto, but you can set it to higher values.</span></span>
<span id="cb49-108"><a href="#cb49-108" aria-hidden="true" tabindex="-1"></a>mkl.set_num_threads(<span class="dv">1</span>)</span>
<span id="cb49-109"><a href="#cb49-109" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-110"><a href="#cb49-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-111"><a href="#cb49-111" aria-hidden="true" tabindex="-1"></a><span class="in">```{python stats-import}</span></span>
<span id="cb49-112"><a href="#cb49-112" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary library</span></span>
<span id="cb49-113"><a href="#cb49-113" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb49-114"><a href="#cb49-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-115"><a href="#cb49-115" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a linear regression model to the training data &amp; print the summary</span></span>
<span id="cb49-116"><a href="#cb49-116" aria-hidden="true" tabindex="-1"></a>mod_lm_py <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long'</span>, data<span class="op">=</span>r.dat_tr_restate).fit()</span>
<span id="cb49-117"><a href="#cb49-117" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mod_lm_py.summary())</span>
<span id="cb49-118"><a href="#cb49-118" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-119"><a href="#cb49-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-120"><a href="#cb49-120" aria-hidden="true" tabindex="-1"></a>It's not a suprise that the results are same as the ones obtained in R.</span>
<span id="cb49-121"><a href="#cb49-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-122"><a href="#cb49-122" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-123"><a href="#cb49-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-124"><a href="#cb49-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-125"><a href="#cb49-125" aria-hidden="true" tabindex="-1"></a><span class="fu">## Variable selection &amp; interpretation</span></span>
<span id="cb49-126"><a href="#cb49-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-127"><a href="#cb49-127" aria-hidden="true" tabindex="-1"></a>The stepwise variable selection can be performed using the function **step**. By default, it is a backward selection; see `?step` for details (parameter **direction** is **backward** when **scope** is empty).</span>
<span id="cb49-128"><a href="#cb49-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-129"><a href="#cb49-129" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb49-130"><a href="#cb49-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-131"><a href="#cb49-131" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb49-132"><a href="#cb49-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-135"><a href="#cb49-135" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-136"><a href="#cb49-136" aria-hidden="true" tabindex="-1"></a><span class="fu">step</span>(mod_lm) <span class="co"># see the result</span></span>
<span id="cb49-137"><a href="#cb49-137" aria-hidden="true" tabindex="-1"></a>mod_lm_sel <span class="ot">&lt;-</span> <span class="fu">step</span>(mod_lm) <span class="co"># store the final model into mod_lm_sel</span></span>
<span id="cb49-138"><a href="#cb49-138" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod_lm_sel)</span>
<span id="cb49-139"><a href="#cb49-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-140"><a href="#cb49-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-141"><a href="#cb49-141" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb49-142"><a href="#cb49-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-143"><a href="#cb49-143" aria-hidden="true" tabindex="-1"></a>As python does not have an exact equivalent of <span class="in">`stats::step()`</span> function, which performs both forward and backward selection based on AIC, we have to implement it manually. We start with the full model and iteratively remove the feature with the highest p-value and add the feature with the lowest AIC until we can no longer improve the AIC. The final model is stored in <span class="in">`mod_lm_sel`</span>. For an extensive explanation of what this while loop is doing and how the backward+forward is computed, check the code below:</span>
<span id="cb49-144"><a href="#cb49-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-145"><a href="#cb49-145" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-146"><a href="#cb49-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-147"><a href="#cb49-147" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">summary</span><span class="dt">&gt;</span>Explaining feature elimination in python (while loop) <span class="dt">&lt;/</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb49-148"><a href="#cb49-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-149"><a href="#cb49-149" aria-hidden="true" tabindex="-1"></a>We start by setting <span class="in">`mod_lm_sel_py`</span> to the full model <span class="in">`mod_lm_py`</span>. Then, we enter a while loop that continues until we break out of it. In each iteration of the loop, we store the current model in prev_model for later comparison. We start by dropping the feature with the highest p-value from the current model using <span class="in">`idxmax()`</span>, which returns the label of the maximum value in the pvalues attribute of the <span class="in">`mod_lm_sel_py`</span> object. We exclude the intercept term from the list of labels by specifying <span class="in">`labels=['Intercept']`</span>. We then create a new model using <span class="in">`smf.ols()`</span> with the feature removed and fit it to the training data using <span class="in">`fit()`</span>. We store this new model in <span class="in">`mod_lm_sel_py`</span>.</span>
<span id="cb49-150"><a href="#cb49-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-151"><a href="#cb49-151" aria-hidden="true" tabindex="-1"></a>Next, we check whether the AIC of the new model is larger than the previous model's. If it is, we break out of the while loop and use the previous model (prev_model) as the final model. If not, we continue to the next step of the loop. Here, we look for the feature with the lowest AIC among the remaining features using <span class="in">`idxmin()`</span> on the pvalues attribute, again excluding the intercept term. We create a new model by adding this feature to the current model using <span class="in">`smf.ols()`</span>, fit it to the training data using <span class="in">`fit()`</span>, and store it in <span class="in">`mod_lm_sel_new`</span>.</span>
<span id="cb49-152"><a href="#cb49-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-153"><a href="#cb49-153" aria-hidden="true" tabindex="-1"></a>We then check whether the AIC of the new model is larger than that of the current model. If it is, we break out of the while loop and use the current model (<span class="in">`mod_lm_sel_py`</span>) as the final model. If not, we update <span class="in">`mod_lm_sel_py`</span> with the new model and continue to the next iteration of the loop. This way, we iteratively remove the feature with the highest p-value and add the feature with the lowest AIC until we can no longer improve the AIC. The final model is stored in <span class="in">`mod_lm_sel_py`</span>.</span>
<span id="cb49-154"><a href="#cb49-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-155"><a href="#cb49-155" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-156"><a href="#cb49-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-157"><a href="#cb49-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-158"><a href="#cb49-158" aria-hidden="true" tabindex="-1"></a><span class="in">```{python stats-stepwise}</span></span>
<span id="cb49-159"><a href="#cb49-159" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb49-160"><a href="#cb49-160" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb49-161"><a href="#cb49-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-162"><a href="#cb49-162" aria-hidden="true" tabindex="-1"></a><span class="co"># perform both forward and backward selection using AIC</span></span>
<span id="cb49-163"><a href="#cb49-163" aria-hidden="true" tabindex="-1"></a>mod_lm_sel_py <span class="op">=</span> mod_lm_py</span>
<span id="cb49-164"><a href="#cb49-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-165"><a href="#cb49-165" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb49-166"><a href="#cb49-166" aria-hidden="true" tabindex="-1"></a>    prev_model <span class="op">=</span> mod_lm_sel_py</span>
<span id="cb49-167"><a href="#cb49-167" aria-hidden="true" tabindex="-1"></a>    <span class="co"># drop the feature with the highest p-value</span></span>
<span id="cb49-168"><a href="#cb49-168" aria-hidden="true" tabindex="-1"></a>    feature_to_drop <span class="op">=</span> mod_lm_sel_py.pvalues.drop(labels<span class="op">=</span>[<span class="st">'Intercept'</span>]).idxmax()</span>
<span id="cb49-169"><a href="#cb49-169" aria-hidden="true" tabindex="-1"></a>    mod_lm_sel_py <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long - '</span> <span class="op">+</span> feature_to_drop, data<span class="op">=</span>r.dat_tr_restate).fit()</span>
<span id="cb49-170"><a href="#cb49-170" aria-hidden="true" tabindex="-1"></a>    <span class="co"># check if AIC has increased, if yes, break the loop and use the previous model</span></span>
<span id="cb49-171"><a href="#cb49-171" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> mod_lm_sel_py.aic <span class="op">&gt;</span> prev_model.aic:</span>
<span id="cb49-172"><a href="#cb49-172" aria-hidden="true" tabindex="-1"></a>        mod_lm_sel_py <span class="op">=</span> prev_model</span>
<span id="cb49-173"><a href="#cb49-173" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb49-174"><a href="#cb49-174" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb49-175"><a href="#cb49-175" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add the feature with the lowest AIC</span></span>
<span id="cb49-176"><a href="#cb49-176" aria-hidden="true" tabindex="-1"></a>    feature_to_add <span class="op">=</span> mod_lm_sel_py.pvalues.drop(labels<span class="op">=</span>[<span class="st">'Intercept'</span>]).idxmin()</span>
<span id="cb49-177"><a href="#cb49-177" aria-hidden="true" tabindex="-1"></a>    mod_lm_sel_py_new <span class="op">=</span> smf.ols(formula<span class="op">=</span><span class="st">'Price ~ TransDate + HouseAge + Dist + NumStores + Lat + Long + '</span> <span class="op">+</span> feature_to_add, data<span class="op">=</span>r.dat_tr_restate).fit()</span>
<span id="cb49-178"><a href="#cb49-178" aria-hidden="true" tabindex="-1"></a>    <span class="co"># check if AIC has increased, if yes, break the loop and use the previous model</span></span>
<span id="cb49-179"><a href="#cb49-179" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> mod_lm_sel_py_new.aic <span class="op">&gt;</span> mod_lm_sel_py.aic:</span>
<span id="cb49-180"><a href="#cb49-180" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb49-181"><a href="#cb49-181" aria-hidden="true" tabindex="-1"></a>    mod_lm_sel_py <span class="op">=</span> mod_lm_sel_py_new</span>
<span id="cb49-182"><a href="#cb49-182" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb49-183"><a href="#cb49-183" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mod_lm_sel_py.summary())</span>
<span id="cb49-184"><a href="#cb49-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-185"><a href="#cb49-185" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-186"><a href="#cb49-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-187"><a href="#cb49-187" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-188"><a href="#cb49-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-189"><a href="#cb49-189" aria-hidden="true" tabindex="-1"></a>After identifying the most important features, you can fit a new model using only those features and evaluate its performance using the test set.</span>
<span id="cb49-190"><a href="#cb49-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-191"><a href="#cb49-191" aria-hidden="true" tabindex="-1"></a>The final model does not contain *Long*. In terms of interpretations, for example:</span>
<span id="cb49-192"><a href="#cb49-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-193"><a href="#cb49-193" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The price increased on average by 3.7 per year (*TransDate*)</span>
<span id="cb49-194"><a href="#cb49-194" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>It diminishes in average by (-2)2.4 per year (*HouseAge*)</span>
<span id="cb49-195"><a href="#cb49-195" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>etc.</span>
<span id="cb49-196"><a href="#cb49-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-197"><a href="#cb49-197" aria-hidden="true" tabindex="-1"></a><span class="fu">## Inference</span></span>
<span id="cb49-198"><a href="#cb49-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-199"><a href="#cb49-199" aria-hidden="true" tabindex="-1"></a>We now predict the prices in the test set. We can make a scatter plot of the predictions versus the observed prices to inspect that. We already know by looking at the $R^2$ in the summary that the prediction quality is not good.</span>
<span id="cb49-200"><a href="#cb49-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-201"><a href="#cb49-201" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb49-202"><a href="#cb49-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-203"><a href="#cb49-203" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb49-204"><a href="#cb49-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-207"><a href="#cb49-207" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-208"><a href="#cb49-208" aria-hidden="true" tabindex="-1"></a>mod_lm_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod_lm_sel, <span class="at">newdata=</span>dat_te_restate)</span>
<span id="cb49-209"><a href="#cb49-209" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dat_te_restate<span class="sc">$</span>Price <span class="sc">~</span> mod_lm_pred, <span class="at">xlab=</span><span class="st">"Prediction"</span>, <span class="at">ylab=</span><span class="st">"Observed prices"</span>)</span>
<span id="cb49-210"><a href="#cb49-210" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="co"># line showing the obs -- pred agreement</span></span>
<span id="cb49-211"><a href="#cb49-211" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-212"><a href="#cb49-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-213"><a href="#cb49-213" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb49-216"><a href="#cb49-216" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb49-217"><a href="#cb49-217" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: predict-output</span></span>
<span id="cb49-218"><a href="#cb49-218" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb49-219"><a href="#cb49-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-220"><a href="#cb49-220" aria-hidden="true" tabindex="-1"></a>mod_lm_sel_pred <span class="op">=</span> mod_lm_sel_py.predict(r.dat_te_restate)</span>
<span id="cb49-221"><a href="#cb49-221" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb49-222"><a href="#cb49-222" aria-hidden="true" tabindex="-1"></a>ax.scatter(x<span class="op">=</span>mod_lm_sel_pred, y<span class="op">=</span>r.dat_te_restate[<span class="st">'Price'</span>])<span class="op">;</span></span>
<span id="cb49-223"><a href="#cb49-223" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Prediction'</span>)<span class="op">;</span></span>
<span id="cb49-224"><a href="#cb49-224" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Observed prices'</span>)<span class="op">;</span></span>
<span id="cb49-225"><a href="#cb49-225" aria-hidden="true" tabindex="-1"></a>ax.plot(ax.get_xlim(), ax.get_ylim(), ls<span class="op">=</span><span class="st">"--"</span>, c<span class="op">=</span><span class="st">".3"</span>)<span class="op">;</span></span>
<span id="cb49-226"><a href="#cb49-226" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb49-227"><a href="#cb49-227" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-228"><a href="#cb49-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-229"><a href="#cb49-229" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-230"><a href="#cb49-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-231"><a href="#cb49-231" aria-hidden="true" tabindex="-1"></a>It appears that the lowest and the highest prices are underestimated. At the center (around 30), the prices are slightly overestimated.</span>
<span id="cb49-232"><a href="#cb49-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-233"><a href="#cb49-233" aria-hidden="true" tabindex="-1"></a>As an exercise, write down the prediction equation of the selected model. Use this equation to explain how instances 1 and 2 (test set) are predicted and calculate the predictions manually. Verify your results using the *predict* function from the previous R code.</span>
<span id="cb49-234"><a href="#cb49-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-235"><a href="#cb49-235" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-236"><a href="#cb49-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-237"><a href="#cb49-237" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">summary</span><span class="dt">&gt;</span>Answer<span class="dt">&lt;/</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb49-238"><a href="#cb49-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-241"><a href="#cb49-241" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-242"><a href="#cb49-242" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: show-model-output</span></span>
<span id="cb49-243"><a href="#cb49-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-244"><a href="#cb49-244" aria-hidden="true" tabindex="-1"></a>mod_lm_pred[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)]</span>
<span id="cb49-245"><a href="#cb49-245" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-246"><a href="#cb49-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-247"><a href="#cb49-247" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-248"><a href="#cb49-248" aria-hidden="true" tabindex="-1"></a>y = -0.000133 + 3.66\times TransDate -0.243\times HouseAge <span class="sc">\\</span>-0.00464\times Dist + 1.027\times NumStores + 237.8\times Lat</span>
<span id="cb49-249"><a href="#cb49-249" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-250"><a href="#cb49-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-251"><a href="#cb49-251" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-252"><a href="#cb49-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-253"><a href="#cb49-253" aria-hidden="true" tabindex="-1"></a><span class="fu"># Logistic regression: visit data</span></span>
<span id="cb49-254"><a href="#cb49-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-255"><a href="#cb49-255" aria-hidden="true" tabindex="-1"></a>To illustrate a logistic regression, we use the data set **DocVis** extracted (modified for the exercise) the library **AER**. The data set reports a 1977--1978 Australian Health Survey. The aim is to predict the outcome **visits**, a binary variable indicating if the individual had at least one visit to a doctor in the past two weeks, using all the other features. To learn more about these features, look at the data described below.</span>
<span id="cb49-256"><a href="#cb49-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-257"><a href="#cb49-257" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-258"><a href="#cb49-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-259"><a href="#cb49-259" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">summary</span><span class="dt">&gt;</span>Data Description<span class="dt">&lt;/</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb49-260"><a href="#cb49-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-261"><a href="#cb49-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-262"><a href="#cb49-262" aria-hidden="true" tabindex="-1"></a>The predictors are as followed:</span>
<span id="cb49-263"><a href="#cb49-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-264"><a href="#cb49-264" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>gender: M/F</span>
<span id="cb49-265"><a href="#cb49-265" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>age: Age in years divided by 100.</span>
<span id="cb49-266"><a href="#cb49-266" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>income: Annual income in tens of thousands of dollars.</span>
<span id="cb49-267"><a href="#cb49-267" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>illness: Number of illnesses in past 2 weeks.</span>
<span id="cb49-268"><a href="#cb49-268" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>reduced: Number of days of reduced activity in past 2 weeks due to illness or injury.</span>
<span id="cb49-269"><a href="#cb49-269" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>health: General health questionnaire score using Goldberg's method.</span>
<span id="cb49-270"><a href="#cb49-270" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>private: Factor. Does the individual have private health insurance?</span>
<span id="cb49-271"><a href="#cb49-271" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>freepoor: Factor. Does the individual have free government health insurance due to low income?</span>
<span id="cb49-272"><a href="#cb49-272" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>freerepat: Factor. Does the individual have free government health insurance due to old age, disability or veteran status?</span>
<span id="cb49-273"><a href="#cb49-273" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>nchronic: Factor. Is there a chronic condition not limiting activity?</span>
<span id="cb49-274"><a href="#cb49-274" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>lchronic: Factor. Is there a chronic condition limiting activity?</span>
<span id="cb49-275"><a href="#cb49-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-276"><a href="#cb49-276" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-277"><a href="#cb49-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-278"><a href="#cb49-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-279"><a href="#cb49-279" aria-hidden="true" tabindex="-1"></a>We can now load the dataset.</span>
<span id="cb49-280"><a href="#cb49-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-283"><a href="#cb49-283" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-284"><a href="#cb49-284" aria-hidden="true" tabindex="-1"></a>DocVis <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/DocVis.csv"</span>)) <span class="do">## found in the same data folder</span></span>
<span id="cb49-285"><a href="#cb49-285" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-286"><a href="#cb49-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-287"><a href="#cb49-287" aria-hidden="true" tabindex="-1"></a>To facilitate the use of logistic regression in **R**, it is **strongly recommended** to have a 0/1 outcome rather than a categorical one. This makes much easier the recognition of the positive label (the "1") and the negative one (the "0"). Since we want to predict **visits**, we transform it accordingly.</span>
<span id="cb49-288"><a href="#cb49-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-291"><a href="#cb49-291" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-292"><a href="#cb49-292" aria-hidden="true" tabindex="-1"></a>DocVis<span class="sc">$</span>visits <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(DocVis<span class="sc">$</span>visits<span class="sc">==</span><span class="st">"Yes"</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb49-293"><a href="#cb49-293" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-294"><a href="#cb49-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-295"><a href="#cb49-295" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modelling</span></span>
<span id="cb49-296"><a href="#cb49-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-297"><a href="#cb49-297" aria-hidden="true" tabindex="-1"></a>We can split our data and fit the logistic regression. The function for this is **glm**. This function encompasses a larger class of models (namely, the generalized linear models) which includes the logistic regression, accessible with **family="binomial"**.</span>
<span id="cb49-298"><a href="#cb49-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-301"><a href="#cb49-301" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-302"><a href="#cb49-302" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb49-303"><a href="#cb49-303" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">size=</span><span class="fu">nrow</span>(DocVis), <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.75</span>,<span class="fl">0.25</span>)) <span class="co"># 1==training set, 2==test set</span></span>
<span id="cb49-304"><a href="#cb49-304" aria-hidden="true" tabindex="-1"></a>dat_tr_visit <span class="ot">&lt;-</span> DocVis[index<span class="sc">==</span><span class="dv">1</span>,]</span>
<span id="cb49-305"><a href="#cb49-305" aria-hidden="true" tabindex="-1"></a>dat_te_visit <span class="ot">&lt;-</span> DocVis[index<span class="sc">==</span><span class="dv">2</span>,]</span>
<span id="cb49-306"><a href="#cb49-306" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-307"><a href="#cb49-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-308"><a href="#cb49-308" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb49-309"><a href="#cb49-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-310"><a href="#cb49-310" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb49-313"><a href="#cb49-313" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-314"><a href="#cb49-314" aria-hidden="true" tabindex="-1"></a>vis_logr <span class="ot">&lt;-</span> <span class="fu">glm</span>(visits<span class="sc">~</span>., <span class="at">data=</span>dat_tr_visit, <span class="at">family=</span><span class="st">"binomial"</span>)</span>
<span id="cb49-315"><a href="#cb49-315" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(vis_logr)</span>
<span id="cb49-316"><a href="#cb49-316" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-317"><a href="#cb49-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-318"><a href="#cb49-318" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb49-319"><a href="#cb49-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-322"><a href="#cb49-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb49-323"><a href="#cb49-323" aria-hidden="true" tabindex="-1"></a><span class="co"># a hack around this technique to not type all the variable names</span></span>
<span id="cb49-324"><a href="#cb49-324" aria-hidden="true" tabindex="-1"></a>vis_formula <span class="op">=</span> <span class="st">'visits ~ '</span> <span class="op">+</span> <span class="st">' + '</span>.join(r.dat_tr_visit.columns.difference([<span class="st">'visits'</span>]))</span>
<span id="cb49-325"><a href="#cb49-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-326"><a href="#cb49-326" aria-hidden="true" tabindex="-1"></a><span class="co"># create a logistic regression model</span></span>
<span id="cb49-327"><a href="#cb49-327" aria-hidden="true" tabindex="-1"></a>vis_logr_py <span class="op">=</span> sm.formula.logit(formula<span class="op">=</span> vis_formula, data<span class="op">=</span>r.dat_tr_visit).fit()</span>
<span id="cb49-328"><a href="#cb49-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-329"><a href="#cb49-329" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(vis_logr_py.summary())</span>
<span id="cb49-330"><a href="#cb49-330" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-331"><a href="#cb49-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-332"><a href="#cb49-332" aria-hidden="true" tabindex="-1"></a>::: callout-warning</span>
<span id="cb49-333"><a href="#cb49-333" aria-hidden="true" tabindex="-1"></a><span class="fu"># Using `.` for formulas in R vs Python </span></span>
<span id="cb49-334"><a href="#cb49-334" aria-hidden="true" tabindex="-1"></a>In R, the dot <span class="in">`.`</span> is used as shorthand to indicate that we want to include all other variables in the formula as predictors except for the outcome variable. So, if our outcome variable is y and we want to include all other variables in our data frame as predictors, we can write <span class="in">`y ~ .`</span> in the formula. </span>
<span id="cb49-335"><a href="#cb49-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-336"><a href="#cb49-336" aria-hidden="true" tabindex="-1"></a>In Python, however, the dot <span class="in">`.`</span> is not used in the same way in formulas. Instead, to include all other variables as predictors except for <span class="in">`y`</span>, we would write <span class="in">`y ~ x1 + x2 + ...`</span> where <span class="in">`x1, x2`</span>, etc. represent the names of the predictor variables. Also, <span class="in">`statsmodels`</span> has a similar syntax to R base regressions. In most other typical ML libraries in Python, you must provide the column values instead of using the column names.</span>
<span id="cb49-337"><a href="#cb49-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-338"><a href="#cb49-338" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-339"><a href="#cb49-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-340"><a href="#cb49-340" aria-hidden="true" tabindex="-1"></a>Note that the <span class="in">`family="binomial"`</span> argument in R is not needed in Python since <span class="in">`sm.formula.logit()`</span> assumes the logistic regression model is fitted using a binomial distribution by default.</span>
<span id="cb49-341"><a href="#cb49-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-342"><a href="#cb49-342" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-343"><a href="#cb49-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-344"><a href="#cb49-344" aria-hidden="true" tabindex="-1"></a><span class="fu">## Variable selection &amp; interpretation</span></span>
<span id="cb49-345"><a href="#cb49-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-346"><a href="#cb49-346" aria-hidden="true" tabindex="-1"></a>Now, we can apply the variable selection:</span>
<span id="cb49-347"><a href="#cb49-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-348"><a href="#cb49-348" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb49-349"><a href="#cb49-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-350"><a href="#cb49-350" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb49-353"><a href="#cb49-353" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-354"><a href="#cb49-354" aria-hidden="true" tabindex="-1"></a>vis_logr_sel <span class="ot">&lt;-</span> <span class="fu">step</span>(vis_logr)</span>
<span id="cb49-355"><a href="#cb49-355" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(vis_logr_sel)</span>
<span id="cb49-356"><a href="#cb49-356" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-357"><a href="#cb49-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-358"><a href="#cb49-358" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb49-359"><a href="#cb49-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-360"><a href="#cb49-360" aria-hidden="true" tabindex="-1"></a>As already seen in the linear regression part, in python, we don't have the same implementation of the step function, hence why we designed the while loop earlier. It is good practice to create a single function with this step while loop to handle all cases (linear, logistic etc); however, we only implement it here for logistic regression. Therefore, to tackle this, we will create a function that does step-wise elimination for us. We define a function called <span class="in">`forward_selected`</span> that performs forward selection on a given dataset to select the best predictors for a response variable based on AIC. The function takes two arguments: <span class="in">`data`</span>, a pandas DataFrame containing the predictors and <span class="in">`response`</span> variable, and response, a string specifying the name of the response variable.</span>
<span id="cb49-361"><a href="#cb49-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-362"><a href="#cb49-362" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-363"><a href="#cb49-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-364"><a href="#cb49-364" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">summary</span><span class="dt">&gt;</span>For more explanation of the code, click on me<span class="dt">&lt;/</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb49-365"><a href="#cb49-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-366"><a href="#cb49-366" aria-hidden="true" tabindex="-1"></a>The function first initializes two sets: <span class="in">`remaining`</span> and <span class="in">`selected`</span>. <span class="in">`remaining`</span> contains the names of all columns in the <span class="in">`data`</span> DataFrame except for the <span class="in">`response`</span> variable, while <span class="in">`selected`</span> is initially empty. The function then initializes <span class="in">`current_aic`</span> and <span class="in">`best_new_aic`</span> to infinity. The main loop of the function continues as long as <span class="in">`remaining`</span> is not empty and <span class="in">`current_aic`</span> is equal to <span class="in">`best_new_aic`</span>. At each iteration, the function iterates over all columns in <span class="in">`remaining`</span> and computes the AIC for a logistic regression model that includes the <span class="in">`response`</span> variable and the currently selected predictors, as well as the current candidate predictor. The function then adds the candidate predictor and its AIC to a list of <span class="in">`(aic, candidate)`</span> tuples, and sorts the list by increasing AIC. The function then selects the candidate with the lowest AIC and adds it to the <span class="in">`selected`</span> set, removes it from the <span class="in">`remaining`</span> set, and updates <span class="in">`current_aic`</span> to the new lowest AIC. The function continues this process until no candidate can improve the AIC. Finally, the function fits a logistic regression model using the selected predictors and returns the resulting model.</span>
<span id="cb49-367"><a href="#cb49-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-368"><a href="#cb49-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-369"><a href="#cb49-369" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-370"><a href="#cb49-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-371"><a href="#cb49-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-374"><a href="#cb49-374" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb49-375"><a href="#cb49-375" aria-hidden="true" tabindex="-1"></a><span class="co"># code taken from the link below and adjusted for logistic regression with AIC criteria</span></span>
<span id="cb49-376"><a href="#cb49-376" aria-hidden="true" tabindex="-1"></a><span class="co"># https://planspace.org/20150423-forward_selection_with_statsmodels/</span></span>
<span id="cb49-377"><a href="#cb49-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-378"><a href="#cb49-378" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_selected(data, response):</span>
<span id="cb49-379"><a href="#cb49-379" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Linear model designed by forward selection.</span></span>
<span id="cb49-380"><a href="#cb49-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-381"><a href="#cb49-381" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb49-382"><a href="#cb49-382" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb49-383"><a href="#cb49-383" aria-hidden="true" tabindex="-1"></a><span class="co">    data : pandas DataFrame with all possible predictors and response</span></span>
<span id="cb49-384"><a href="#cb49-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-385"><a href="#cb49-385" aria-hidden="true" tabindex="-1"></a><span class="co">    response: string, name of response column in data</span></span>
<span id="cb49-386"><a href="#cb49-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-387"><a href="#cb49-387" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb49-388"><a href="#cb49-388" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb49-389"><a href="#cb49-389" aria-hidden="true" tabindex="-1"></a><span class="co">    model: an "optimal" fitted statsmodels linear model</span></span>
<span id="cb49-390"><a href="#cb49-390" aria-hidden="true" tabindex="-1"></a><span class="co">           with an intercept</span></span>
<span id="cb49-391"><a href="#cb49-391" aria-hidden="true" tabindex="-1"></a><span class="co">           selected by forward selection</span></span>
<span id="cb49-392"><a href="#cb49-392" aria-hidden="true" tabindex="-1"></a><span class="co">           evaluated by AIC</span></span>
<span id="cb49-393"><a href="#cb49-393" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb49-394"><a href="#cb49-394" aria-hidden="true" tabindex="-1"></a>    remaining <span class="op">=</span> <span class="bu">set</span>(data.columns)</span>
<span id="cb49-395"><a href="#cb49-395" aria-hidden="true" tabindex="-1"></a>    remaining.remove(response)</span>
<span id="cb49-396"><a href="#cb49-396" aria-hidden="true" tabindex="-1"></a>    selected <span class="op">=</span> []</span>
<span id="cb49-397"><a href="#cb49-397" aria-hidden="true" tabindex="-1"></a>    current_aic, best_new_aic <span class="op">=</span> <span class="bu">float</span>(<span class="st">"inf"</span>), <span class="bu">float</span>(<span class="st">"inf"</span>)</span>
<span id="cb49-398"><a href="#cb49-398" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> remaining <span class="kw">and</span> current_aic <span class="op">==</span> best_new_aic:</span>
<span id="cb49-399"><a href="#cb49-399" aria-hidden="true" tabindex="-1"></a>        aics_with_candidates <span class="op">=</span> []</span>
<span id="cb49-400"><a href="#cb49-400" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> candidate <span class="kw">in</span> remaining:</span>
<span id="cb49-401"><a href="#cb49-401" aria-hidden="true" tabindex="-1"></a>            formula <span class="op">=</span> <span class="st">"</span><span class="sc">{}</span><span class="st"> ~ </span><span class="sc">{}</span><span class="st"> + 1"</span>.<span class="bu">format</span>(response,</span>
<span id="cb49-402"><a href="#cb49-402" aria-hidden="true" tabindex="-1"></a>                                           <span class="st">' + '</span>.join(selected <span class="op">+</span> [candidate]))</span>
<span id="cb49-403"><a href="#cb49-403" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> smf.logit(formula, data).fit(disp<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb49-404"><a href="#cb49-404" aria-hidden="true" tabindex="-1"></a>            aic <span class="op">=</span> model.aic</span>
<span id="cb49-405"><a href="#cb49-405" aria-hidden="true" tabindex="-1"></a>            aics_with_candidates.append((aic, candidate))</span>
<span id="cb49-406"><a href="#cb49-406" aria-hidden="true" tabindex="-1"></a>        aics_with_candidates.sort()</span>
<span id="cb49-407"><a href="#cb49-407" aria-hidden="true" tabindex="-1"></a>        best_new_aic, best_candidate <span class="op">=</span> aics_with_candidates.pop(<span class="dv">0</span>)</span>
<span id="cb49-408"><a href="#cb49-408" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> current_aic <span class="op">&gt;</span> best_new_aic:</span>
<span id="cb49-409"><a href="#cb49-409" aria-hidden="true" tabindex="-1"></a>            remaining.remove(best_candidate)</span>
<span id="cb49-410"><a href="#cb49-410" aria-hidden="true" tabindex="-1"></a>            selected.append(best_candidate)</span>
<span id="cb49-411"><a href="#cb49-411" aria-hidden="true" tabindex="-1"></a>            current_aic <span class="op">=</span> best_new_aic</span>
<span id="cb49-412"><a href="#cb49-412" aria-hidden="true" tabindex="-1"></a>    formula <span class="op">=</span> <span class="st">"</span><span class="sc">{}</span><span class="st"> ~ </span><span class="sc">{}</span><span class="st"> + 1"</span>.<span class="bu">format</span>(response,</span>
<span id="cb49-413"><a href="#cb49-413" aria-hidden="true" tabindex="-1"></a>                                   <span class="st">' + '</span>.join(selected))</span>
<span id="cb49-414"><a href="#cb49-414" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> smf.logit(formula, data).fit(disp<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb49-415"><a href="#cb49-415" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb49-416"><a href="#cb49-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-417"><a href="#cb49-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-418"><a href="#cb49-418" aria-hidden="true" tabindex="-1"></a>mod_logit_sel_py <span class="op">=</span> forward_selected(r.dat_tr_visit, <span class="st">'visits'</span>)</span>
<span id="cb49-419"><a href="#cb49-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-420"><a href="#cb49-420" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mod_logit_sel_py.summary())</span>
<span id="cb49-421"><a href="#cb49-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-422"><a href="#cb49-422" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-423"><a href="#cb49-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-424"><a href="#cb49-424" aria-hidden="true" tabindex="-1"></a>We can see that the results of <span class="in">`mod_logit_sel_py`</span> model are slightly different from the R version, but nevertheless, we have reduced the features and the interpretations (see below) with both R and python versions remain the same.</span>
<span id="cb49-425"><a href="#cb49-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-426"><a href="#cb49-426" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-427"><a href="#cb49-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-428"><a href="#cb49-428" aria-hidden="true" tabindex="-1"></a>We can see that the probability of a visit is</span>
<span id="cb49-429"><a href="#cb49-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-430"><a href="#cb49-430" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>smaller for males</span>
<span id="cb49-431"><a href="#cb49-431" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>increasing with age</span>
<span id="cb49-432"><a href="#cb49-432" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>larger with illness</span>
<span id="cb49-433"><a href="#cb49-433" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>etc.</span>
<span id="cb49-434"><a href="#cb49-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-435"><a href="#cb49-435" aria-hidden="true" tabindex="-1"></a><span class="fu">## Inference</span></span>
<span id="cb49-436"><a href="#cb49-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-437"><a href="#cb49-437" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb49-438"><a href="#cb49-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-439"><a href="#cb49-439" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb49-440"><a href="#cb49-440" aria-hidden="true" tabindex="-1"></a>The **predict** function with **type="response"** will predict the probability of the positive class ("1"). If it is set to **"link"** it produces the linear predictor (i.e., the $z$). To make the prediction, we thus have to identify if the predicted probability is larger or lower than 0.5.</span>
<span id="cb49-441"><a href="#cb49-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-444"><a href="#cb49-444" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-445"><a href="#cb49-445" aria-hidden="true" tabindex="-1"></a>prob_te_visit <span class="ot">&lt;-</span> <span class="fu">predict</span>(vis_logr_sel, <span class="at">newdata =</span> dat_te_visit, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb49-446"><a href="#cb49-446" aria-hidden="true" tabindex="-1"></a>pred_te_visit <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(prob_te_visit <span class="sc">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb49-447"><a href="#cb49-447" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="at">Pred=</span>pred_te_visit, <span class="at">Obs=</span>dat_te_visit<span class="sc">$</span>visits)</span>
<span id="cb49-448"><a href="#cb49-448" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-449"><a href="#cb49-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-450"><a href="#cb49-450" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb49-451"><a href="#cb49-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-452"><a href="#cb49-452" aria-hidden="true" tabindex="-1"></a>The explanation is similar to that of R, with a slight different that here we use <span class="in">`pandas.crosstab`</span> to make our confusion matrix.</span>
<span id="cb49-453"><a href="#cb49-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-456"><a href="#cb49-456" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb49-457"><a href="#cb49-457" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: visualize-prediction</span></span>
<span id="cb49-458"><a href="#cb49-458" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb49-459"><a href="#cb49-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-460"><a href="#cb49-460" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb49-461"><a href="#cb49-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-462"><a href="#cb49-462" aria-hidden="true" tabindex="-1"></a>prob_te_visit <span class="op">=</span> mod_logit_sel_py.predict(r.dat_te_visit)</span>
<span id="cb49-463"><a href="#cb49-463" aria-hidden="true" tabindex="-1"></a>pred_te_visit <span class="op">=</span> [<span class="dv">1</span> <span class="cf">if</span> p <span class="op">&gt;=</span> <span class="fl">0.5</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> p <span class="kw">in</span> prob_te_visit]</span>
<span id="cb49-464"><a href="#cb49-464" aria-hidden="true" tabindex="-1"></a>conf_mat <span class="op">=</span> pd.crosstab(pred_te_visit, r.dat_te_visit[<span class="st">'visits'</span>], rownames<span class="op">=</span>[<span class="st">'Pred'</span>], colnames<span class="op">=</span>[<span class="st">'Obs'</span>])</span>
<span id="cb49-465"><a href="#cb49-465" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(conf_mat)</span>
<span id="cb49-466"><a href="#cb49-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-467"><a href="#cb49-467" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-468"><a href="#cb49-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-469"><a href="#cb49-469" aria-hidden="true" tabindex="-1"></a>The results are extremely close to the R version.</span>
<span id="cb49-470"><a href="#cb49-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-471"><a href="#cb49-471" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-472"><a href="#cb49-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-473"><a href="#cb49-473" aria-hidden="true" tabindex="-1"></a>The predictions are not really good. It is in fact a difficult data set. Indeed, the number of 0 is so large compare to the 1, that predicting a 0 always provides a good model overall. That issue will be addressed further later on in the course.</span>
<span id="cb49-474"><a href="#cb49-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-475"><a href="#cb49-475" aria-hidden="true" tabindex="-1"></a>For now, this can be further inspected by looking at the predicted probabilities per observed label.</span>
<span id="cb49-476"><a href="#cb49-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-477"><a href="#cb49-477" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb49-478"><a href="#cb49-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-479"><a href="#cb49-479" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb49-480"><a href="#cb49-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-483"><a href="#cb49-483" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-484"><a href="#cb49-484" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(prob_te_visit<span class="sc">~</span>dat_te_visit<span class="sc">$</span>visits)</span>
<span id="cb49-485"><a href="#cb49-485" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-486"><a href="#cb49-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-487"><a href="#cb49-487" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb49-488"><a href="#cb49-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-491"><a href="#cb49-491" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb49-492"><a href="#cb49-492" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: visualize-prediction2</span></span>
<span id="cb49-493"><a href="#cb49-493" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb49-494"><a href="#cb49-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-495"><a href="#cb49-495" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb49-496"><a href="#cb49-496" aria-hidden="true" tabindex="-1"></a>ax.boxplot([prob_te_visit[r.dat_te_visit[<span class="st">'visits'</span>]<span class="op">==</span><span class="dv">0</span>], prob_te_visit[r.dat_te_visit[<span class="st">'visits'</span>]<span class="op">==</span><span class="dv">1</span>]])<span class="op">;</span></span>
<span id="cb49-497"><a href="#cb49-497" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels([<span class="st">'No Visit'</span>, <span class="st">'Visit'</span>])<span class="op">;</span></span>
<span id="cb49-498"><a href="#cb49-498" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Predicted Probability'</span>)<span class="op">;</span></span>
<span id="cb49-499"><a href="#cb49-499" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Predicted Probabilities by Visit Status'</span>)<span class="op">;</span></span>
<span id="cb49-500"><a href="#cb49-500" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb49-501"><a href="#cb49-501" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-502"><a href="#cb49-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-503"><a href="#cb49-503" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-504"><a href="#cb49-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-505"><a href="#cb49-505" aria-hidden="true" tabindex="-1"></a>We see that if the lowest predicted probabilities are usually assigned to 0-observations, most of the probabilities remain below 0.5 (even for the 1-observations). A good model would have two well separated boxplots, well away from 0.5.</span>
<span id="cb49-506"><a href="#cb49-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-507"><a href="#cb49-507" aria-hidden="true" tabindex="-1"></a>Now, as an exercise, write down the prediction equation of the selected model, like you did for linear regression. Use this equation to explain how instance 1 and 2 (test set) are predicted, and calculate the predictions manually. Verify your results using the function *predict* used before.</span>
<span id="cb49-508"><a href="#cb49-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-509"><a href="#cb49-509" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-510"><a href="#cb49-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-511"><a href="#cb49-511" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">summary</span><span class="dt">&gt;</span>Answer<span class="dt">&lt;/</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb49-512"><a href="#cb49-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-515"><a href="#cb49-515" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-516"><a href="#cb49-516" aria-hidden="true" tabindex="-1"></a>prob_te_visit[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)]</span>
<span id="cb49-517"><a href="#cb49-517" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-518"><a href="#cb49-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-519"><a href="#cb49-519" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-520"><a href="#cb49-520" aria-hidden="true" tabindex="-1"></a>z(x) = -2.31795-0.31838\times gender<span class="sc">\_</span>male+0.39762\times age+<span class="sc">\\</span>0.28431\times illness+0.16340\times reduced+0.05589\times health+<span class="sc">\\</span>0.27249\times private<span class="sc">\_</span>eyes -0.65344\times freepoor<span class="sc">\_</span>yes+<span class="sc">\\</span>0.38038\times freerepat<span class="sc">\_</span>yes  </span>
<span id="cb49-521"><a href="#cb49-521" aria-hidden="true" tabindex="-1"></a>$$ Then $$</span>
<span id="cb49-522"><a href="#cb49-522" aria-hidden="true" tabindex="-1"></a>P(Y=1 | X=x) = \frac{e^{z(x)}}{1+e^{z(x)}}</span>
<span id="cb49-523"><a href="#cb49-523" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-524"><a href="#cb49-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-525"><a href="#cb49-525" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-526"><a href="#cb49-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-527"><a href="#cb49-527" aria-hidden="true" tabindex="-1"></a><span class="fu"># LASSO &amp; Ridge regressions</span></span>
<span id="cb49-528"><a href="#cb49-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-529"><a href="#cb49-529" aria-hidden="true" tabindex="-1"></a>You have been introduced to lasso and ridge regression during the *Variable selection with penalization* part of the lecture.</span>
<span id="cb49-530"><a href="#cb49-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-531"><a href="#cb49-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-532"><a href="#cb49-532" aria-hidden="true" tabindex="-1"></a>Lasso and Ridge Regression are two regularization techniques used in regression models to prevent overfitting by adding a penalty term to the loss function. Lasso regression (aka $L_1$) adds a penalty term equal to the absolute value of the coefficients. In contrast, Ridge regression (aka $L_2$) adds a penalty term equal to the squared value of the coefficients. The effect of the penalty term is to shrink the coefficients towards zero, which can help reduce model complexity and improve generalization performance. In this case, we apply lasso and ridge to the real estate data and do not cover logistic regression (example already seen during the class).</span>
<span id="cb49-533"><a href="#cb49-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-534"><a href="#cb49-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-535"><a href="#cb49-535" aria-hidden="true" tabindex="-1"></a>First, we need to turn our predictors into matrices, as this is required by the <span class="in">`glmnet`</span> package in R and works with the python implementation.</span>
<span id="cb49-536"><a href="#cb49-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-539"><a href="#cb49-539" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-540"><a href="#cb49-540" aria-hidden="true" tabindex="-1"></a><span class="co"># glmnet can only work with matrix objects, columns 2-7 correspond to the same ones used by `lm`</span></span>
<span id="cb49-541"><a href="#cb49-541" aria-hidden="true" tabindex="-1"></a>dat_tr_re_mat_x <span class="ot">&lt;-</span> <span class="fu">select</span>(dat_tr_restate, <span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>)) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb49-542"><a href="#cb49-542" aria-hidden="true" tabindex="-1"></a>dat_tr_re_mat_y <span class="ot">&lt;-</span> <span class="fu">pull</span>(dat_tr_restate,<span class="st">'Price'</span>)</span>
<span id="cb49-543"><a href="#cb49-543" aria-hidden="true" tabindex="-1"></a>dat_te_re_mat_x <span class="ot">&lt;-</span> <span class="fu">select</span>(dat_te_restate, <span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>)) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb49-544"><a href="#cb49-544" aria-hidden="true" tabindex="-1"></a>dat_te_re_mat_y <span class="ot">&lt;-</span> <span class="fu">pull</span>(dat_te_restate,<span class="st">'Price'</span>)</span>
<span id="cb49-545"><a href="#cb49-545" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-546"><a href="#cb49-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-547"><a href="#cb49-547" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb49-548"><a href="#cb49-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-549"><a href="#cb49-549" aria-hidden="true" tabindex="-1"></a><span class="fu">## R</span></span>
<span id="cb49-550"><a href="#cb49-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-551"><a href="#cb49-551" aria-hidden="true" tabindex="-1"></a>On the newly created matrices, we run cross-validated lasso and ridge with the <span class="in">`cv.glmnet()`</span>, function where setting the <span class="in">`alpha`</span> (penalty) parameter as 1 produces lasso regression and 0 produces ridge regression. The default value of alpha is 1, which corresponds to lasso regression. For 0&lt;alpha&lt;1, it performs Elastic Net regression (a combination of $L_1$ and $L_2$ regularization).</span>
<span id="cb49-552"><a href="#cb49-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-553"><a href="#cb49-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-556"><a href="#cb49-556" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-557"><a href="#cb49-557" aria-hidden="true" tabindex="-1"></a><span class="co"># Load appropriate library and set a seed</span></span>
<span id="cb49-558"><a href="#cb49-558" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb49-559"><a href="#cb49-559" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb49-560"><a href="#cb49-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-561"><a href="#cb49-561" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Ridge regression model</span></span>
<span id="cb49-562"><a href="#cb49-562" aria-hidden="true" tabindex="-1"></a>ridge_fit <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(<span class="at">x =</span> dat_tr_re_mat_x, <span class="at">y =</span> dat_tr_re_mat_y, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb49-563"><a href="#cb49-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-564"><a href="#cb49-564" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Lasso regression model</span></span>
<span id="cb49-565"><a href="#cb49-565" aria-hidden="true" tabindex="-1"></a>lasso_fit <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(<span class="at">x =</span> dat_tr_re_mat_x, <span class="at">y =</span> dat_tr_re_mat_y, <span class="at">alpha =</span> <span class="dv">1</span>) <span class="co">#if you change the `family` argument to `bionomial`, you can get also logistic regression</span></span>
<span id="cb49-566"><a href="#cb49-566" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-567"><a href="#cb49-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-568"><a href="#cb49-568" aria-hidden="true" tabindex="-1"></a>We can then fit the final models with the best parameters:</span>
<span id="cb49-569"><a href="#cb49-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-572"><a href="#cb49-572" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-573"><a href="#cb49-573" aria-hidden="true" tabindex="-1"></a>ridge_fit_best <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x=</span>dat_tr_re_mat_x, <span class="at">y =</span> dat_tr_re_mat_y, </span>
<span id="cb49-574"><a href="#cb49-574" aria-hidden="true" tabindex="-1"></a>                         <span class="at">lambda =</span> ridge_fit<span class="sc">$</span>lambda.min)</span>
<span id="cb49-575"><a href="#cb49-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-576"><a href="#cb49-576" aria-hidden="true" tabindex="-1"></a>lasso_fit_best <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x=</span>dat_tr_re_mat_x, <span class="at">y=</span>dat_tr_re_mat_y, </span>
<span id="cb49-577"><a href="#cb49-577" aria-hidden="true" tabindex="-1"></a>                         <span class="at">lambda =</span> lasso_fit<span class="sc">$</span>lambda.min) <span class="co">#can also use lasso_fit$lambda.1se</span></span>
<span id="cb49-578"><a href="#cb49-578" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-579"><a href="#cb49-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-580"><a href="#cb49-580" aria-hidden="true" tabindex="-1"></a>We can compare different performances for this task using <span class="in">`caret::postResample()`</span>. We will learn more this function and it's metrics the upcoming courses &amp; lab sessions.</span>
<span id="cb49-581"><a href="#cb49-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-584"><a href="#cb49-584" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-585"><a href="#cb49-585" aria-hidden="true" tabindex="-1"></a><span class="co"># lasso &amp; ridge performance on the training set</span></span>
<span id="cb49-586"><a href="#cb49-586" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(ridge_fit_best, <span class="at">newx =</span> dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb49-587"><a href="#cb49-587" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(lasso_fit_best, <span class="at">newx =</span> dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb49-588"><a href="#cb49-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-589"><a href="#cb49-589" aria-hidden="true" tabindex="-1"></a><span class="co"># lasso &amp; ridge performance on the test set</span></span>
<span id="cb49-590"><a href="#cb49-590" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(ridge_fit_best, <span class="at">newx =</span> dat_te_re_mat_x), dat_te_re_mat_y)</span>
<span id="cb49-591"><a href="#cb49-591" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(lasso_fit_best, <span class="at">newx =</span> dat_te_re_mat_x), dat_te_re_mat_y)</span>
<span id="cb49-592"><a href="#cb49-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-593"><a href="#cb49-593" aria-hidden="true" tabindex="-1"></a><span class="co"># Step-wise lm performance on training and test sets</span></span>
<span id="cb49-594"><a href="#cb49-594" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(mod_lm_sel,dat_tr_restate), dat_tr_re_mat_y)</span>
<span id="cb49-595"><a href="#cb49-595" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(<span class="fu">predict</span>(mod_lm_sel,dat_te_restate), dat_te_re_mat_y)</span>
<span id="cb49-596"><a href="#cb49-596" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-597"><a href="#cb49-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-598"><a href="#cb49-598" aria-hidden="true" tabindex="-1"></a>In this case, the lasso is better than the ridge on the test set, and if you have many features, this could be a useful technique. However, they are both outperformed by step-wise linear regression. Lasso and ridge are more useful when you have many more variables. You can try this already by taking more variables for your <span class="in">`dat_tr_re_mat_x`</span> and <span class="in">`dat_te_re_mat_x`</span> such <span class="in">`select(dat_te_restate,-c('Price', 'Month'))`</span> to see how (for better or worse) the performance changes. If you want more explanation on why linear model outperformed lasso and ridge, check out (click on) the further explanation below.</span>
<span id="cb49-599"><a href="#cb49-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-600"><a href="#cb49-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-601"><a href="#cb49-601" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-602"><a href="#cb49-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-603"><a href="#cb49-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-604"><a href="#cb49-604" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">summary</span><span class="dt">&gt;</span>Why lm (or step lm) outperformed lasso &amp; ridge <span class="dt">&lt;/</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb49-605"><a href="#cb49-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-606"><a href="#cb49-606" aria-hidden="true" tabindex="-1"></a>In some situations, it is normal to observe that a linear model may perform better than a regularized model, such as a ridge or lasso. This can occur when the number of predictors in the model is small relative to the sample size or when the predictors are highly correlated.</span>
<span id="cb49-607"><a href="#cb49-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-608"><a href="#cb49-608" aria-hidden="true" tabindex="-1"></a>Linear regression assumes that the relationship between the response variable and the predictors is linear and additive. When this assumption holds, a linear model can be a good choice. In contrast, regularized regression methods such as ridge and lasso add a penalty term to the regression objective function to shrink the estimated coefficients towards zero, which can help to avoid overfitting when the number of predictors is large relative to the sample size or when the predictors are highly correlated.</span>
<span id="cb49-609"><a href="#cb49-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-610"><a href="#cb49-610" aria-hidden="true" tabindex="-1"></a>However, when the number of predictors is small relative to the sample size or when the predictors are highly correlated, the additional regularization provided by ridge or lasso may not be necessary, and a simple linear model may perform better.</span>
<span id="cb49-611"><a href="#cb49-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-612"><a href="#cb49-612" aria-hidden="true" tabindex="-1"></a>It is always a good practice to compare the performance of different models using appropriate evaluation metrics and techniques such as cross-validation. The choice of the best model will depend on the specific problem and the goals of the analysis.</span>
<span id="cb49-613"><a href="#cb49-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-614"><a href="#cb49-614" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-615"><a href="#cb49-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-616"><a href="#cb49-616" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python</span></span>
<span id="cb49-617"><a href="#cb49-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-620"><a href="#cb49-620" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb49-621"><a href="#cb49-621" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge, Lasso, RidgeCV, LassoCV</span>
<span id="cb49-622"><a href="#cb49-622" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb49-623"><a href="#cb49-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-624"><a href="#cb49-624" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a seed for reproducibility</span></span>
<span id="cb49-625"><a href="#cb49-625" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb49-626"><a href="#cb49-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-627"><a href="#cb49-627" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Lasso regression model</span></span>
<span id="cb49-628"><a href="#cb49-628" aria-hidden="true" tabindex="-1"></a>lasso_cv <span class="op">=</span> LassoCV(cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb49-629"><a href="#cb49-629" aria-hidden="true" tabindex="-1"></a>lasso_cv.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)<span class="op">;</span></span>
<span id="cb49-630"><a href="#cb49-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-631"><a href="#cb49-631" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the optimal regularization parameter</span></span>
<span id="cb49-632"><a href="#cb49-632" aria-hidden="true" tabindex="-1"></a>lasso_optimal_alpha <span class="op">=</span> lasso_cv.alpha_</span>
<span id="cb49-633"><a href="#cb49-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-634"><a href="#cb49-634" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Lasso model with the optimal alpha</span></span>
<span id="cb49-635"><a href="#cb49-635" aria-hidden="true" tabindex="-1"></a>lasso_best_py <span class="op">=</span> Lasso(alpha<span class="op">=</span>lasso_optimal_alpha)</span>
<span id="cb49-636"><a href="#cb49-636" aria-hidden="true" tabindex="-1"></a>lasso_best_py.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)<span class="op">;</span></span>
<span id="cb49-637"><a href="#cb49-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-638"><a href="#cb49-638" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Ridge regression model with cross-validation</span></span>
<span id="cb49-639"><a href="#cb49-639" aria-hidden="true" tabindex="-1"></a>ridge_cv <span class="op">=</span> RidgeCV(cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb49-640"><a href="#cb49-640" aria-hidden="true" tabindex="-1"></a>ridge_cv.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)<span class="op">;</span></span>
<span id="cb49-641"><a href="#cb49-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-642"><a href="#cb49-642" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the optimal regularization parameter</span></span>
<span id="cb49-643"><a href="#cb49-643" aria-hidden="true" tabindex="-1"></a>ridge_optimal_alpha <span class="op">=</span> ridge_cv.alpha_</span>
<span id="cb49-644"><a href="#cb49-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-645"><a href="#cb49-645" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Ridge model with the optimal alpha</span></span>
<span id="cb49-646"><a href="#cb49-646" aria-hidden="true" tabindex="-1"></a>ridge_best_py <span class="op">=</span> Ridge(alpha<span class="op">=</span>ridge_optimal_alpha)</span>
<span id="cb49-647"><a href="#cb49-647" aria-hidden="true" tabindex="-1"></a>ridge_best_py.fit(r.dat_tr_re_mat_x, r.dat_tr_re_mat_y)<span class="op">;</span></span>
<span id="cb49-648"><a href="#cb49-648" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-649"><a href="#cb49-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-650"><a href="#cb49-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-651"><a href="#cb49-651" aria-hidden="true" tabindex="-1"></a>The <span class="in">`lambda`</span> argument in <span class="in">`cv.glmnet()`</span> from R corresponds to the <span class="in">`alpha`</span> argument in <span class="in">`RidgeCV()`</span>/<span class="in">`LassoCV()`</span> in python. In <span class="in">`cv.glmnet()`</span>, the lambda argument specifies the range of regularization parameters to be tested in the model selection process. By default, lambda is set to NULL, which means that <span class="in">`glmnet()`</span> will automatically choose a sequence of lambda values to search over. Note that in <span class="in">`glmnet()`</span>, lambda values are used for both $L_1$ (lasso) and $L_2$ (ridge) regularization, whereas in <span class="in">`RidgeCV()`</span>, alpha values are used to control the mix of L1 and L2 regularization, with alpha = 0 corresponding to pure L2 regularization (i.e., ridge regression).</span>
<span id="cb49-652"><a href="#cb49-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-653"><a href="#cb49-653" aria-hidden="true" tabindex="-1"></a>On the contrary (and to avoid confusion), the <span class="in">`alpha`</span> argument in <span class="in">`cv.glmnet()`</span> corresponds to the <span class="in">`fit_intercept`</span> argument in <span class="in">`RidgeCV()`</span>/<span class="in">`LassoCV()`</span>. In <span class="in">`cv.glmnet()`</span>, the alpha argument specifies the mixing parameter between L1 and L2 regularization. </span>
<span id="cb49-654"><a href="#cb49-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-657"><a href="#cb49-657" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-658"><a href="#cb49-658" aria-hidden="true" tabindex="-1"></a><span class="co"># python lasso &amp; ridge performance on the training set</span></span>
<span id="cb49-659"><a href="#cb49-659" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>ridge_best_py<span class="sc">$</span><span class="fu">predict</span>(dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb49-660"><a href="#cb49-660" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>lasso_best_py<span class="sc">$</span><span class="fu">predict</span>(dat_tr_re_mat_x), dat_tr_re_mat_y)</span>
<span id="cb49-661"><a href="#cb49-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-662"><a href="#cb49-662" aria-hidden="true" tabindex="-1"></a><span class="co"># python lasso &amp; ridge performance on the test set</span></span>
<span id="cb49-663"><a href="#cb49-663" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>ridge_best_py<span class="sc">$</span><span class="fu">predict</span>( dat_te_re_mat_x), dat_te_re_mat_y)</span>
<span id="cb49-664"><a href="#cb49-664" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(py<span class="sc">$</span>lasso_best_py<span class="sc">$</span><span class="fu">predict</span>(dat_te_re_mat_x), dat_te_re_mat_y)</span>
<span id="cb49-665"><a href="#cb49-665" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-666"><a href="#cb49-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-667"><a href="#cb49-667" aria-hidden="true" tabindex="-1"></a>The performance is different in python simply because of different default settings for the python vs R implementations.</span>
<span id="cb49-668"><a href="#cb49-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-669"><a href="#cb49-669" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-670"><a href="#cb49-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-671"><a href="#cb49-671" aria-hidden="true" tabindex="-1"></a>To understand the decision making of lasso, we can check the beta's in a similar fashion to a regression (only shown for the R models).</span>
<span id="cb49-672"><a href="#cb49-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-675"><a href="#cb49-675" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-676"><a href="#cb49-676" aria-hidden="true" tabindex="-1"></a><span class="co"># running the following can tell you a bit about the impact of different variables</span></span>
<span id="cb49-677"><a href="#cb49-677" aria-hidden="true" tabindex="-1"></a>small.lambda.index <span class="ot">&lt;-</span> <span class="fu">which</span>(lasso_fit<span class="sc">$</span>lambda <span class="sc">==</span> lasso_fit<span class="sc">$</span>lambda.min)</span>
<span id="cb49-678"><a href="#cb49-678" aria-hidden="true" tabindex="-1"></a>lasso_fit<span class="sc">$</span>glmnet.fit<span class="sc">$</span>beta[, small.lambda.index]</span>
<span id="cb49-679"><a href="#cb49-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-680"><a href="#cb49-680" aria-hidden="true" tabindex="-1"></a><span class="co"># or on the final model</span></span>
<span id="cb49-681"><a href="#cb49-681" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(lasso_fit , <span class="at">s=</span> <span class="st">'lambda.min'</span>)</span>
<span id="cb49-682"><a href="#cb49-682" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lasso_fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-683"><a href="#cb49-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-684"><a href="#cb49-684" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-685"><a href="#cb49-685" aria-hidden="true" tabindex="-1"></a>We can see that from the first output <span class="in">`Long`</span> value has almost a beta of 0. In the second output, it is confirmed that the coefficient of this variable is indeed 0. This could explain why <span class="in">`mod_lm_sel`</span> also dropped this variable. The rest of the coefficient are similar to <span class="in">`summary(mod_lm_sel)`</span>.  as ridge or lasso in some situations. This can occur when the number of predictors in the model is small relative to the sample size, or when the predictors are highly correlated.</span>
<span id="cb49-686"><a href="#cb49-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-687"><a href="#cb49-687" aria-hidden="true" tabindex="-1"></a><span class="fu"># Your turn to practice</span></span>
<span id="cb49-688"><a href="#cb49-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-689"><a href="#cb49-689" aria-hidden="true" tabindex="-1"></a><span class="fu">## Linear regression: nursing home data</span></span>
<span id="cb49-690"><a href="#cb49-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-691"><a href="#cb49-691" aria-hidden="true" tabindex="-1"></a>Now it is your turn. Make an linear regression (also feel free to try lasso and ridge regressions) on the nursing data described below (found also in <span class="in">`/data/nursing_data.csv`</span>). Afterwards, use linear regression to build a predictor of the cost using the other features. Replicate the analysis. Split the data, build a model, make the variable selection, make the predictions and analyze the results. Make also an analysis of the coefficients in terms of the associations between the costs and the features.</span>
<span id="cb49-692"><a href="#cb49-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-693"><a href="#cb49-693" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-694"><a href="#cb49-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-695"><a href="#cb49-695" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">summary</span><span class="dt">&gt;</span>Data Description<span class="dt">&lt;/</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb49-696"><a href="#cb49-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-697"><a href="#cb49-697" aria-hidden="true" tabindex="-1"></a>The data set is about patients in a nursing home, where elderly people are helped with daily living needs, also known as Activities of Daily Living (ADL, i.e. communication, eating, walking, showering, going to a toilet, etc.).</span>
<span id="cb49-698"><a href="#cb49-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-699"><a href="#cb49-699" aria-hidden="true" tabindex="-1"></a>Since the stay in such facilities is very expensive, it is important to classify the new-coming patient, and estimate the duration of the stay and the corresponding costs.</span>
<span id="cb49-700"><a href="#cb49-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-701"><a href="#cb49-701" aria-hidden="true" tabindex="-1"></a>In practice, there are different types of patients who require different types of help and, consequently, different duration of the stay. For example, there could be a person with severe mobility issues, who requires the help with most of the needs every day; or a person with mental deviations, who don't need help with daily routine, but requires extra communication hours.</span>
<span id="cb49-702"><a href="#cb49-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-703"><a href="#cb49-703" aria-hidden="true" tabindex="-1"></a>Here, we will focus of total amount of help (measured in minutes of help provided to a person per week) provided and measure the costs of stay of a person.</span>
<span id="cb49-704"><a href="#cb49-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-705"><a href="#cb49-705" aria-hidden="true" tabindex="-1"></a>The data set on which the analysis is based has the following columns:</span>
<span id="cb49-706"><a href="#cb49-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-707"><a href="#cb49-707" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**gender**: a categorical variable with levels "*M*" for male and "*F*" for female</span>
<span id="cb49-708"><a href="#cb49-708" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**age**: integer variable</span>
<span id="cb49-709"><a href="#cb49-709" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**mobil**: categorical variable that represents the physical mobility with levels</span>
<span id="cb49-710"><a href="#cb49-710" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>1 = Full mobility</span>
<span id="cb49-711"><a href="#cb49-711" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>2 = Reduced mobility</span>
<span id="cb49-712"><a href="#cb49-712" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>3 = Restricted mobility in the house</span>
<span id="cb49-713"><a href="#cb49-713" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>4 = Null mobility</span>
<span id="cb49-714"><a href="#cb49-714" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**orient**: categorical variable that represents the orientation (interactions with the environment) with levels</span>
<span id="cb49-715"><a href="#cb49-715" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>1 = Full orientation</span>
<span id="cb49-716"><a href="#cb49-716" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>2 = Moderate disturbance of orientation</span>
<span id="cb49-717"><a href="#cb49-717" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>3 = Disorientation</span>
<span id="cb49-718"><a href="#cb49-718" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**independ**: categorical variable that represents the independence of ADL with levels</span>
<span id="cb49-719"><a href="#cb49-719" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>1 = Independent of help</span>
<span id="cb49-720"><a href="#cb49-720" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>2 = Dependent less than 24 hours per day</span>
<span id="cb49-721"><a href="#cb49-721" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>3 = Dependent at unpredictable time intervals for most of the needs</span>
<span id="cb49-722"><a href="#cb49-722" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**minut_mob**: numerical variable that represents the total number of minutes of help with movement per week</span>
<span id="cb49-723"><a href="#cb49-723" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**need_comm**: categorical variable with levels "*Yes*" for a person who needs extra communication sessions with an employee, and "*No*" otherwise</span>
<span id="cb49-724"><a href="#cb49-724" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**minut_comm**: numerical variable that represents the total number of minutes of communication per week</span>
<span id="cb49-725"><a href="#cb49-725" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**tot_minut**: numerical variable that represents the total number of minutes spent on a patient per week, $tot<span class="sc">\_</span>minut = minut<span class="sc">\_</span>mob + minut<span class="sc">\_</span>comm$</span>
<span id="cb49-726"><a href="#cb49-726" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**cost**: numerical variable that represents the total costs of having a patient in the nursing house per month.</span>
<span id="cb49-727"><a href="#cb49-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-728"><a href="#cb49-728" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb49-729"><a href="#cb49-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-730"><a href="#cb49-730" aria-hidden="true" tabindex="-1"></a>Note: since tot_minut=minut_mob+minut_comm, you may not find any meaningful result using the 3 features. This is perfectly normal. Just use 2 features only among these 3 (arbitrary choice).</span>
<span id="cb49-731"><a href="#cb49-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-732"><a href="#cb49-732" aria-hidden="true" tabindex="-1"></a><span class="fu">## Logistic regression: the credit quality</span></span>
<span id="cb49-733"><a href="#cb49-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-734"><a href="#cb49-734" aria-hidden="true" tabindex="-1"></a>The German Credit Quality Dataset consists of a set of attributes as good or bad credit risks. In order to find find a detailed description of the features, please refer to the <span class="co">[</span><span class="ot">original link to the dataset</span><span class="co">]</span>(https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)). The <span class="in">`german.csv`</span> file can also be found in <span class="in">`/data/german.csv`</span> whichis the mdified version of the original dataset to simplify the analysis, especially the data loading in **R**.</span>
<span id="cb49-735"><a href="#cb49-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-736"><a href="#cb49-736" aria-hidden="true" tabindex="-1"></a>The aim here is to predict the credit quality from the other features. The outcome **Quality** is 0 for "bad" and 1 for "good". Make an analysis of the data and develop the learner. You can follow these notable steps:</span>
<span id="cb49-737"><a href="#cb49-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-738"><a href="#cb49-738" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Make a simple EDA of the features</span>
<span id="cb49-739"><a href="#cb49-739" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Split the data and train the model.</span>
<span id="cb49-740"><a href="#cb49-740" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Make variable selection and check out the result.</span>
<span id="cb49-741"><a href="#cb49-741" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Interpret the coefficients.</span>
<span id="cb49-742"><a href="#cb49-742" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Inspect the quality of the model by making the predictions (confusion table and boxplot of the predicted probabilities).</span>
<span id="cb49-743"><a href="#cb49-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-744"><a href="#cb49-744" aria-hidden="true" tabindex="-1"></a>Note that the data are unbalanced again and that you may not find a very good predictor. This issue is quite difficult and will be addressed later.</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2026, <a href="https://iliaazizi.com/">Ilia Azizi</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 🤍 and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>