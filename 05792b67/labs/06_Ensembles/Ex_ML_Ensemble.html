<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>MLBA - S24 - Ensemble Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../labs/07_InterpretableML/Ex_ML_VarImp.html" rel="next">
<link href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" rel="prev">
<link href="../../images/logo.dark.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
<meta property="og:title" content="MLBA - S24 - Ensemble Methods">
<meta property="og:description" content="In this part of the lab, we will look at how the randomForest library (alternative to ranger) can be applied for classification and regression tasks.">
<meta property="og:site-name" content="MLBA - S24 ">
</head>
<body class="nav-sidebar docked">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Ensemble Methods</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../images/logo.light.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
      <div class="sidebar-tools-main tools-wide">
    <a href="http://moodle2.unil.ch/course/view.php?id=8715" title="Moodle" class="sidebar-tool px-1"><i class="bi bi-person-rolodex"></i></a>
    <a href="https://github.com/do-unil/mlba" title="GitHub Repo" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle sidebar-tool" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">Course information</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">Overview</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../schedule.html" class="sidebar-item-text sidebar-link">Schedule</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../faq.html" class="sidebar-item-text sidebar-link">FAQ</a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">Lectures</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/01_Introduction/ML_Intro.html" class="sidebar-item-text sidebar-link">Intro to ML</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/02_DataExploration/ML_DataExplo.html" class="sidebar-item-text sidebar-link">Data Exploration</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/030_Introduction/ML_Models_Intro.html" class="sidebar-item-text sidebar-link">Intro to Models</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/031_LinearLogisticRegression/ML_LinLogReg.html" class="sidebar-item-text sidebar-link">Linear &amp; Logistic Regression</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/032_Trees/ML_Trees.html" class="sidebar-item-text sidebar-link">Decision Trees</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/033_NeuralNetworks/ML_NN.html" class="sidebar-item-text sidebar-link">Neural Networks</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/03_Models/034_SupportVectorMachine/ML_SVM.html" class="sidebar-item-text sidebar-link">Support Vector Machines</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/04_Metrics/ML_Metrics.html" class="sidebar-item-text sidebar-link">Metrics</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/05_DataSplitting/ML_DataSplitting.html" class="sidebar-item-text sidebar-link">Data Splitting</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/06_Ensembles/ML_Ensemble.html" class="sidebar-item-text sidebar-link">Ensemble Methods</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/07_InterpretableML/ML_Interp.html" class="sidebar-item-text sidebar-link">Interpretable ML</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/080_Introduction/ML_UnsupIntro.html" class="sidebar-item-text sidebar-link">Intro to Unsuperised Learning</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/081_Clustering/ML_Clustering.html" class="sidebar-item-text sidebar-link">Clustering</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/08_UnsupervisedLearning/082_DimensionReduction/ML_DimRed.html" class="sidebar-item-text sidebar-link">Dimension Reduction</a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Labs</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/00_lab/setup.html" class="sidebar-item-text sidebar-link">Setup</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html" class="sidebar-item-text sidebar-link">Linear &amp; Logistic Regression</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/032_Trees/Ex_ML_Tree.html" class="sidebar-item-text sidebar-link">Decision Trees</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/033_NeuralNetworks/EX_ML_NN.html" class="sidebar-item-text sidebar-link">Neural Networks</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" class="sidebar-item-text sidebar-link">Support Vector Machines</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/04_Metrics/Ex_ML_Scoring.html" class="sidebar-item-text sidebar-link">Metrics</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="sidebar-item-text sidebar-link">Data Splitting</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/06_Ensembles/Ex_ML_Ensemble.html" class="sidebar-item-text sidebar-link active">Ensemble Methods</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/07_InterpretableML/Ex_ML_VarImp.html" class="sidebar-item-text sidebar-link">Interpretable ML</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/081_Clustering/Ex_ML_Clustering.html" class="sidebar-item-text sidebar-link">Clustering</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/082_DimensionReduction/Ex_ML_PCA.html" class="sidebar-item-text sidebar-link">PCA</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/083_AutoEncoders/Ex_ML_Autoencoder.html" class="sidebar-item-text sidebar-link">Autoencoders</a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">Assessments</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Exam.html" class="sidebar-item-text sidebar-link">Exam</a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">Project</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Project_Directives.html" class="sidebar-item-text sidebar-link">Project Directives</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Report_Guideline.html" class="sidebar-item-text sidebar-link">Report Guidelines</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/Presentation_Guidelines.html" class="sidebar-item-text sidebar-link">Presentation Guidelines</a>
  </div>
</li>
      </ul>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">Resources</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/beginners_r.html" class="sidebar-item-text sidebar-link">Beginners in R</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/data_acquisition/data_sources.html" class="sidebar-item-text sidebar-link">Data Sources</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/data_acquisition/web_scraping_api.html" class="sidebar-item-text sidebar-link">Web Scraping</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/cheatsheets.html" class="sidebar-item-text sidebar-link">Coding Cheatsheets</a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">On this page</h2>
   
  <ul>
<li>
<a href="#random-forest" id="toc-random-forest" class="nav-link active" data-scroll-target="#random-forest">Random Forest</a>
  <ul class="collapse">
<li>
<a href="#classification" id="toc-classification" class="nav-link" data-scroll-target="#classification">Classification</a>
  <ul class="collapse">
<li><a href="#data-preparation-for-random-forest" id="toc-data-preparation-for-random-forest" class="nav-link" data-scroll-target="#data-preparation-for-random-forest">Data preparation for Random Forest</a></li>
  <li><a href="#training-and-testing-the-model" id="toc-training-and-testing-the-model" class="nav-link" data-scroll-target="#training-and-testing-the-model">Training and testing the model</a></li>
  <li><a href="#variable-importance" id="toc-variable-importance" class="nav-link" data-scroll-target="#variable-importance">Variable importance</a></li>
  </ul>
</li>
  <li><a href="#regression" id="toc-regression" class="nav-link" data-scroll-target="#regression">Regression</a></li>
  </ul>
</li>
  <li>
<a href="#gradient-boosting-machines-gbm" id="toc-gradient-boosting-machines-gbm" class="nav-link" data-scroll-target="#gradient-boosting-machines-gbm">Gradient Boosting Machines (GBM)</a>
  <ul class="collapse">
<li>
<a href="#classification-1" id="toc-classification-1" class="nav-link" data-scroll-target="#classification-1">Classification</a>
  <ul class="collapse">
<li><a href="#training-and-testing-the-model-1" id="toc-training-and-testing-the-model-1" class="nav-link" data-scroll-target="#training-and-testing-the-model-1">Training and testing the model</a></li>
  </ul>
</li>
  <li><a href="#regression-1" id="toc-regression-1" class="nav-link" data-scroll-target="#regression-1">Regression</a></li>
  </ul>
</li>
  <li>
<a href="#bonus-xgboost" id="toc-bonus-xgboost" class="nav-link" data-scroll-target="#bonus-xgboost">Bonus: XGBoost</a>
  <ul class="collapse">
<li><a href="#what-is-xgboost" id="toc-what-is-xgboost" class="nav-link" data-scroll-target="#what-is-xgboost">What is XGBoost?</a></li>
  <li><a href="#modelling-with-xgboost" id="toc-modelling-with-xgboost" class="nav-link" data-scroll-target="#modelling-with-xgboost">Modelling with XGBoost</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/do-unil/mlba/blob/main/labs/06_Ensembles/Ex_ML_Ensemble.qmd" class="toc-action">View source</a></p><p><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><script type="application/javascript">
// Description: Change image src depending on body class (quarto-light or quarto-dark)
function updateImageSrc() {
  var bodyClass = window.document.body.classList;
  var images = window.document.getElementsByTagName('img');
  for (var i = 0; i < images.length; i++) {
    var image = images[i];
    var src = image.src;
    var newSrc = src;
    if (bodyClass.contains('quarto-light') && src.includes('.dark')) {
      newSrc = src.replace('.dark', '.light');
    } else if (bodyClass.contains('quarto-dark') && src.includes('.light')) {
      newSrc = src.replace('.light', '.dark');
    }
    if (newSrc !== src) {
      image.src = newSrc;
    }
  }
}

var observer = new MutationObserver(function(mutations) {
  mutations.forEach(function(mutation) {
    if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
      updateImageSrc();
    }
  });
});

observer.observe(window.document.body, {
  attributes: true
});

updateImageSrc();
</script><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title d-none d-lg-block">Ensemble Methods</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><section id="random-forest" class="level1"><h1>Random Forest</h1>
<p>In this part of the lab, we will look at how the <code>randomForest</code> library (alternative to <code>ranger</code>) can be applied for classification and regression tasks. At the very end, please feel free to apply these techniques to one of your favorite datasets seen in class (classification or regression).</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Hyperparameters of RF
</div>
</div>
<div class="callout-body-container callout-body">
<p>R (using the <code>randomForest</code> library):</p>
<ol type="1">
<li>
<code>ntree</code>: The number of trees in the forest (equivalent to <code>n_estimators</code> in python).</li>
<li>
<code>mtry</code>: The number of features to consider when looking for the best split. (similar to <code>max_features</code> in python)</li>
<li>
<code>max.depth</code>: The maximum depth of each tree.</li>
<li>
<code>nodesize</code>: The minimum number of samples required to split an internal node (equivalent to <code>min_samples_split</code> in python).</li>
</ol>
<p>Python (using the <code>sklearn</code> library):</p>
<ol type="1">
<li>
<code>n_estimators</code>: The number of trees in the forest.</li>
<li>
<code>max_features</code>: The number of features to consider when looking for the best split.</li>
<li>
<code>max_depth</code>: The maximum depth of each tree.</li>
<li>
<code>min_samples_split</code>: The minimum number of samples required to split an internal node.</li>
<li>
<code>min_samples_leaf</code>: The minimum number of samples required to be at a leaf node.</li>
</ol>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Few tips on RF hyperparameters
</div>
</div>
<div class="callout-body-container callout-body">
<p>A few (among many) tips for finding the ideal hyperparameters for RF:</p>
<ol type="1">
<li>
<code>ntree</code> (R) / <code>n_estimators</code> (python): Use a large number of trees in the forest to improve model performance, but be aware of the increased computation time. The default value is usually a good starting point.</li>
<li>
<code>mtry</code> (R) / <code>max_features</code> (python): Experiment with different values, usually starting with the default (square root of the number of features for classification or one-third of the number of features for regression). Increasing this value may improve model performance but can also increase computation time.</li>
<li>
<code>max.depth</code>: Control the depth of each tree to manage overfitting. Deeper trees capture more complex patterns but can lead to overfitting. Experiment with different values, keeping in mind that a shallower tree can be more interpretable and less prone to overfitting.</li>
<li>
<code>nodesize</code> (R) / <code>min_samples_split</code> (python): Increasing this value can help reduce overfitting, but setting it too high might lead to underfitting. Experiment with different values to find the optimal balance.</li>
</ol>
</div>
</div>
<section id="classification" class="level2"><h2 class="anchored" data-anchor-id="classification">Classification</h2>
<section id="data-preparation-for-random-forest" class="level3"><h3 class="anchored" data-anchor-id="data-preparation-for-random-forest">Data preparation for Random Forest</h3>
<p>Load the library <code>randomForest</code> in R. Then, load the <code>wine</code> data set. This dataset is about white wine quality (in fact Portuguese vinho verde). The data contains 11 numerical features and 1 factor variable:</p>
<ul>
<li><code>fixed.acidity</code></li>
<li><code>volatile.acidity</code></li>
<li><code>citric.acid</code></li>
<li><code>residual.sugar</code></li>
<li><code>chlorides</code></li>
<li><code>free.sulfur.dioxide</code></li>
<li><code>total.sulfur.dioxide</code></li>
<li><code>density</code></li>
<li><code>pH</code></li>
<li><code>sulphates</code></li>
<li><code>alcohol</code></li>
<li><code>quality: Good/Bad</code></li>
</ul>
<p>All the numerical features have units. The data source can be found <a href="https://archive.ics.uci.edu/ml/datasets/wine+quality">here</a>. For simplicity, only an extraction of 200 wines are used in this exercise. Note that in the original data set, the <code>quality</code> is a score (0 to 10) that was turned as factor here for the exercise (Bad: 0 to 5, Good: 6 to 10). Also, note that in the data source, the objective is to predict the quality from the other features (supervised learning).</p>
<p>As mentioned, the outcome variable used for this dataset is the wine <code>quality</code>. We should first coerce the classes as factors. Then, we make the training/test set random split with a 75/25 scheme.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.stat.berkeley.edu/~breiman/RandomForests/">randomForest</a></span><span class="op">)</span></span>
<span><span class="va">wine</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org//reference/here.html">here</a></span><span class="op">(</span><span class="st">"data/Wine.csv"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">wine</span><span class="op">$</span><span class="va">quality</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">wine</span><span class="op">$</span><span class="va">quality</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># define a function to get the splitting index (training and testing) of a given dataset</span></span>
<span><span class="va">get_split_index</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">dataset</span>, <span class="va">train_proportion</span> <span class="op">=</span> <span class="fl">0.75</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span>  <span class="va">index</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span></span>
<span>      x <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,</span>
<span>      size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">dataset</span><span class="op">)</span>,</span>
<span>      replace <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>      prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">train_proportion</span>, <span class="fl">1</span> <span class="op">-</span> <span class="va">train_proportion</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">index</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">wine_index</span> <span class="op">&lt;-</span> <span class="fu">get_split_index</span><span class="op">(</span><span class="va">wine</span><span class="op">)</span></span>
<span><span class="va">wine_tr</span> <span class="op">&lt;-</span> <span class="va">wine</span><span class="op">[</span><span class="va">wine_index</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span></span>
<span><span class="va">wine_te</span> <span class="op">&lt;-</span> <span class="va">wine</span><span class="op">[</span><span class="va">wine_index</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load the course python environment as usual with a r code chunks.</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rstudio.github.io/reticulate/">reticulate</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/use_python.html">use_condaenv</a></span><span class="op">(</span><span class="st">"MLBA"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Similar to the previous labs, in python, we can use the usual <code>sklearn</code> library to do all our modelling. Please note that we will load the data again in python to make the demo easier. Additionally, we’ll load all the necessary libraries for this lab in this code chunk.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, RandomForestRegressor</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score, mean_squared_error</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># we first move up one directory to achieve relative paths</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>wine <span class="op">=</span> pd.read_csv(<span class="st">'../data/Wine.csv'</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>wine[<span class="st">'quality'</span>] <span class="op">=</span> wine[<span class="st">'quality'</span>].astype(<span class="st">'category'</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Split wine dataset into train and test</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>train_wine, test_wine <span class="op">=</span> train_test_split(wine, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p><strong>Note:</strong> Here, we have written a function to make the split as we will also need to apply it also for another dataset in the regression part.</p>
</section><section id="training-and-testing-the-model" class="level3"><h3 class="anchored" data-anchor-id="training-and-testing-the-model">Training and testing the model</h3>
<p>Fit a random forest on the train set. The target is the <code>taste</code> variable that we want to predict. Specify for the number of trees <code>ntree=1000</code> (by default, the function selects <span class="math inline">\(500\)</span> trees). Remember to exclude <code>quality</code> in the predictors of the formula. Also, use the option <code>importance=TRUE</code>, we will need it afterward. Then test the model by computing the accuracy on the test set. You may use <code>confusionMatrix</code> from <code>caret</code>.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">wine_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest</a></span><span class="op">(</span><span class="va">quality</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">wine_tr</span>, ntree<span class="op">=</span><span class="fl">1000</span>, importance<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">wine.pred_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">wine_rf</span>, newdata<span class="op">=</span><span class="va">wine_te</span><span class="op">)</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/caret/">caret</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span>data<span class="op">=</span><span class="va">wine.pred_rf</span>, reference <span class="op">=</span> <span class="va">wine_te</span><span class="op">$</span><span class="va">quality</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Random Forest classifier on the train set</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>wine_rf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>wine_rf.fit(train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_wine[<span class="st">'quality'</span>])</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the accuracy</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>wine_pred_rf <span class="op">=</span> wine_rf.predict(test_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(test_wine[<span class="st">'quality'</span>], wine_pred_rf))</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(test_wine[<span class="st">'quality'</span>], wine_pred_rf))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This model is worse than the R version mostly because of the different defaults.</p>
</div>
</div>
</div>
</section><section id="variable-importance" class="level3"><h3 class="anchored" data-anchor-id="variable-importance">Variable importance</h3>
<p>Extract the model-specific variable importance using the functions <code>varImpPlot</code> (plots) and <code>importance</code> (values) on the model. Observe well that the mean decrease in accuracy of each variable is also computed for each specific class. In particular, what makes <code>density</code> special for predicting <code>Good</code> compare to another variable (like for example <code>citric.acid</code>)?</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/varImpPlot.html">varImpPlot</a></span><span class="op">(</span><span class="va">wine_rf</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/importance.html">importance</a></span><span class="op">(</span><span class="va">wine_rf</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable importance</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>wine_importances <span class="op">=</span> pd.Series(wine_rf.feature_importances_, index<span class="op">=</span>train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>).columns)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>wine_importances.sort_values(ascending<span class="op">=</span><span class="va">False</span>).plot(kind<span class="op">=</span><span class="st">'bar'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p><code>density</code> is important for predicting the <code>Good</code> since their predictions is much less accurate if we do not use it. <code>citric.acid</code> is both overall less important than <code>density</code> but especially for prediction of <code>Good</code>.</p>
</section></section><section id="regression" class="level2"><h2 class="anchored" data-anchor-id="regression">Regression</h2>
<p>In this part, we will be using the <code>real_estate_data.csv</code> once again. After reading the data, apply a random forest to predict <code>price</code> using all the other variables except <code>No</code>, <code>Month</code> and <code>Year</code>. Compute the RMSE and inspect the prediction quality with a graph. Note that the importance is not specific to any class here.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://magrittr.tidyverse.org">magrittr</a></span><span class="op">)</span></span>
<span><span class="va">real_estate_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org//reference/here.html">here</a></span><span class="op">(</span><span class="st">"labs/data/real_estate_data.csv"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># select the columns of interest</span></span>
<span><span class="va">real_estate_data</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">real_estate_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">No</span>, <span class="va">Month</span>, <span class="va">Year</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># once again, divide the data into training and testing sets using the function created earlier</span></span>
<span><span class="va">restate_index</span> <span class="op">&lt;-</span> <span class="fu">get_split_index</span><span class="op">(</span><span class="va">real_estate_data</span><span class="op">)</span></span>
<span><span class="va">restate_tr</span> <span class="op">&lt;-</span> <span class="va">real_estate_data</span><span class="op">[</span><span class="va">restate_index</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span></span>
<span><span class="va">restate_te</span> <span class="op">&lt;-</span> <span class="va">real_estate_data</span><span class="op">[</span><span class="va">restate_index</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span></span>
<span></span>
<span><span class="co"># apply the RF model as a regression</span></span>
<span><span class="va">restate_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest</a></span><span class="op">(</span><span class="va">Price</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">restate_tr</span>, ntree<span class="op">=</span><span class="fl">1000</span>, importance<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">restate.pred_rf</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">restate_rf</span>, newdata<span class="op">=</span><span class="va">restate_te</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute rmse and plot the results as well the VarImp</span></span>
<span><span class="op">(</span><span class="va">rmse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">-</span> <span class="va">restate.pred_rf</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">~</span> <span class="va">restate.pred_rf</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/varImpPlot.html">varImpPlot</a></span><span class="op">(</span><span class="va">restate_rf</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/importance.html">importance</a></span><span class="op">(</span><span class="va">restate_rf</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load real estate dataset</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="op">=</span> pd.read_csv(<span class="st">"../data/real_estate_data.csv"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="op">=</span> real_estate_data.drop([<span class="st">'No'</span>, <span class="st">'Month'</span>, <span class="st">'Year'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Split real estate dataset into train and test</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>train_restate, test_restate <span class="op">=</span> train_test_split(real_estate_data, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Random Forest regressor on the train set</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>restate_rf <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>restate_rf.fit(train_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_restate[<span class="st">'Price'</span>])</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>restate_pred_rf <span class="op">=</span> restate_rf.predict(test_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> np.sqrt(mean_squared_error(test_restate[<span class="st">'Price'</span>], restate_pred_rf))</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RMSE:"</span>, rmse)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the prediction quality</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>plt.scatter(test_restate[<span class="st">'Price'</span>], restate_pred_rf)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Actual Price'</span>)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted Price'</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], [<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable importance</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>restate_importances <span class="op">=</span> pd.Series(restate_rf.feature_importances_, index<span class="op">=</span>train_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>).columns)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>restate_importances.sort_values(ascending<span class="op">=</span><span class="va">False</span>).plot(kind<span class="op">=</span><span class="st">'bar'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>Compare this model with the one you came up with in <code>Ex_ML_LinLogReg</code> . Which one would you go for?</p>
</section></section><section id="gradient-boosting-machines-gbm" class="level1"><h1>Gradient Boosting Machines (GBM)</h1>
<p>In this part of the lab, we will look at how the <code>gbm</code> library in R and the <code>GradientBoostingClassifier</code> and <code>GradientBoostingRegressor</code> in Python can be applied for classification and regression tasks. We will continue using the <code>wine</code> dataset for classification and <code>real_estate_data</code> for regression.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Hyperparameters of GBM
</div>
</div>
<div class="callout-body-container callout-body">
<p>R (using the <code>gbm</code> library):</p>
<ol type="1">
<li>
<code>n.trees</code>: The number of boosting stages to perform (equivalent to <code>n_estimators</code> in python).</li>
<li>
<code>interaction.depth</code>: The maximum depth of each tree (equivalent to <code>max_depth</code> in python).</li>
<li>
<code>shrinkage</code>: The learning rate.</li>
<li>
<code>n.minobsinnode</code>: The minimum number of samples required to split an internal node (equivalent to <code>min_samples_split</code> in python).</li>
<li>
<code>bag.fraction</code>: The fraction of samples to be used for fitting individual base learners (equivalent to <code>subsample</code> in python).</li>
</ol>
<p>Python (using the <code>sklearn</code> library):</p>
<ol type="1">
<li>
<code>n_estimators</code>: The number of boosting stages to perform. Similar to Random Forest, increasing the number of estimators can improve the model’s performance but may also increase the computational complexity and training time.</li>
<li>
<code>learning_rate</code>: The learning rate shrinks the contribution of each tree. A smaller learning rate requires more boosting stages to achieve the same performance as a larger learning rate, but it can also result in a more robust model.</li>
<li>
<code>max_depth</code>: The maximum depth of each tree. Similar to Random Forest, a higher depth can capture more complex patterns in the data, but it may also lead to overfitting.</li>
<li>
<code>min_samples_split</code>: The minimum number of samples required to split an internal node. Similar to Random Forest, a smaller value allows the model to capture finer details in the data, while a larger value can help prevent overfitting.</li>
<li>
<code>min_samples_leaf</code>: The minimum number of samples required to be at a leaf node. Similar to Random Forest, a smaller value allows the model to capture finer details, while a larger value can help prevent overfitting.</li>
<li>
<code>subsample</code>: The fraction of samples to be used for fitting individual base learners. A value smaller than 1.0 can lead to a reduction in variance and an increase in bias, resulting in a more robust model.</li>
</ol>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Few tips on GBM hyperparameters
</div>
</div>
<div class="callout-body-container callout-body">
<p>Similar to R, here are some tips for finding the best combination of the hyperparameters:</p>
<ol type="1">
<li>
<code>n.trees</code> (R) / <code>n_estimators</code> (python): Start with a lower number of trees and increase it until no further improvement in performance is observed. Be aware of the increased computation time with a larger number of trees.</li>
<li>
<code>interaction.depth</code> (R) / <code>max_depth</code> (python): Keep the depth of each tree relatively shallow (3-5 levels) to prevent overfitting. Deeper trees can capture more complex patterns but may lead to overfitting.</li>
<li>
<code>shrinkage</code> (R) / <code>learning_rate</code> (python): Use a smaller learning rate for better model performance, but be prepared for slower convergence and increased computation time. Typically, values range between 0.01 and 0.1.</li>
<li>
<code>n.minobsinnode</code> (R) / <code>min_samples_split</code> (python): Similar to Random Forest, experiment with different values to find the optimal balance between overfitting and underfitting.</li>
<li>
<code>bag.fraction</code> (R) / <code>subsample</code> (python): Using a subsample of the data (e.g., 0.5-0.8) can help reduce overfitting and speed up the training process. Experiment with different values to find the best trade-off between performance and computation time.</li>
</ol>
</div>
</div>
<section id="classification-1" class="level2"><h2 class="anchored" data-anchor-id="classification-1">Classification</h2>
<section id="training-and-testing-the-model-1" class="level3"><h3 class="anchored" data-anchor-id="training-and-testing-the-model-1">Training and testing the model</h3>
<p>We now fit a GBM model on the <code>wine</code> training set and apply it to the same target variable <code>quality</code>. We can train the model and add</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/gbm-developers/gbm">gbm</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">wine_gbm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gbm/man/gbm.html">gbm</a></span><span class="op">(</span><span class="va">quality</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">wine_tr</span>, distribution<span class="op">=</span><span class="st">"multinomial"</span>, n.trees<span class="op">=</span><span class="fl">1000</span>, interaction.depth<span class="op">=</span><span class="fl">4</span>, shrinkage<span class="op">=</span><span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="va">wine.pred_gbm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">wine_gbm</span>, newdata<span class="op">=</span><span class="va">wine_te</span>, n.trees<span class="op">=</span><span class="fl">1000</span>, type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span></span>
<span><span class="va">wine.pred_gbm_class</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">wine.pred_gbm</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">wine_te</span><span class="op">$</span><span class="va">quality</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">wine_te</span><span class="op">$</span><span class="va">quality</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">wine.pred_gbm_class</span><span class="op">)</span>, <span class="va">wine_te</span><span class="op">$</span><span class="va">quality</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingClassifier</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Gradient Boosting classifier on the train set</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>wine_gbm <span class="op">=</span> GradientBoostingClassifier(n_estimators<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.01</span>, max_depth<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>wine_gbm.fit(train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_wine[<span class="st">'quality'</span>])</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the accuracy</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>wine_pred_gbm <span class="op">=</span> wine_gbm.predict(test_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(test_wine[<span class="st">'quality'</span>], wine_pred_gbm))</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(test_wine[<span class="st">'quality'</span>], wine_pred_gbm))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section></section><section id="regression-1" class="level2"><h2 class="anchored" data-anchor-id="regression-1">Regression</h2>
<p>In this part, we will continue using the <code>real_estate_data.csv</code>. Fit a GBM model on the real estate training set to predict <code>price</code> using all the other variables except <code>No</code>, <code>Month</code>, and <code>Year</code>. Then compute the metrics and plot the predictions.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">restate_gbm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gbm/man/gbm.html">gbm</a></span><span class="op">(</span><span class="va">Price</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">restate_tr</span>, distribution<span class="op">=</span><span class="st">"gaussian"</span>, n.trees<span class="op">=</span><span class="fl">1000</span>, interaction.depth<span class="op">=</span><span class="fl">4</span>, shrinkage<span class="op">=</span><span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="va">restate.pred_gbm</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">restate_gbm</span>, newdata<span class="op">=</span><span class="va">restate_te</span>, n.trees<span class="op">=</span><span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute rmse and plot the results</span></span>
<span><span class="op">(</span><span class="va">rmse_gbm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">-</span> <span class="va">restate.pred_gbm</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">~</span> <span class="va">restate.pred_gbm</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run the code below if you have not cleared the plot yet</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Gradient Boosting regressor on the train set</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>restate_gbm <span class="op">=</span> GradientBoostingRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.01</span>, max_depth<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>restate_gbm.fit(train_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_restate[<span class="st">'Price'</span>])</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>restate_pred_gbm <span class="op">=</span> restate_gbm.predict(test_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>rmse_gbm <span class="op">=</span> np.sqrt(mean_squared_error(test_restate[<span class="st">'Price'</span>], restate_pred_gbm))</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RMSE:"</span>, rmse_gbm)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the prediction quality</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(test_restate[<span class="st">'Price'</span>], restate_pred_gbm)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Actual Price'</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted Price'</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], [<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>Compare the GBM model with the Random Forest model you came up with earlier. Which one would you go for?</p>
</section></section><section id="bonus-xgboost" class="level1"><h1>Bonus: XGBoost</h1>
<section id="what-is-xgboost" class="level2"><h2 class="anchored" data-anchor-id="what-is-xgboost">What is XGBoost?</h2>
<p>XGBoost (Extreme Gradient Boosting) is an optimized implementation of the gradient boosting algorithm. It is designed for high performance and efficient memory usage. XGBoost improves upon the base Gradient Boosting Machine (GBM) by incorporating regularization to prevent overfitting and implementing parallel processing techniques for faster training. The algorithm also offers built-in cross-validation and early stopping to save time and resources during model training.</p>
</section><section id="modelling-with-xgboost" class="level2"><h2 class="anchored" data-anchor-id="modelling-with-xgboost">Modelling with XGBoost</h2>
<p>We’ll use the <a href="https://xgboost.readthedocs.io/en/stable/index.html"><code>xgboost</code></a> library in both R and python. You can see some of the hyperparameters below:</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Hyperparameters of XGBoost
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>
<code>eta</code>: Controls the learning rate, which determines the step size at each iteration while updating the model weights. Smaller values make the model more robust to overfitting but require more iterations to converge. Typical values range from 0.01 to 0.3.</li>
<li>
<code>max_depth</code>: Controls the maximum depth of each tree. Deeper trees can model more complex relationships but are more prone to overfitting. Experiment with different values, keeping in mind that a shallower tree can be more interpretable and less prone to overfitting.</li>
<li>
<code>min_child_weight</code>: Controls the minimum sum of instance weights needed in a child node. Increasing this value helps to prevent overfitting by making the model more conservative.</li>
</ol>
</div>
</div>
<p>You can read more about the package in its documentation.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Install and load the package</span></span>
<span><span class="co"># install.packages("xgboost")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dmlc/xgboost">xgboost</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prepare data for XGBoost</span></span>
<span><span class="va">dtrain</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.DMatrix.html">xgb.DMatrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">restate_tr</span><span class="op">[</span>, <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">restate_tr</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>, label <span class="op">=</span> <span class="va">restate_tr</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span>
<span><span class="va">dtest</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.DMatrix.html">xgb.DMatrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">restate_te</span><span class="op">[</span>, <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">restate_te</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>, label <span class="op">=</span> <span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Set hyperparameters</span></span>
<span><span class="va">params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  objective <span class="op">=</span> <span class="st">"reg:squarederror"</span>,</span>
<span>  eta <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  max_depth <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  min_child_weight <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  subsample <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  colsample_bytree <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Train the model</span></span>
<span><span class="va">xgb_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html">xgb.train</a></span><span class="op">(</span><span class="va">params</span>, <span class="va">dtrain</span>, nrounds <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Test the model and compute the RMSE</span></span>
<span><span class="va">restate_pred_xgb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">xgb_model</span>, <span class="va">dtest</span><span class="op">)</span></span>
<span><span class="va">rmse_xgb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">-</span> <span class="va">restate_pred_xgb</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"RMSE:"</span>, <span class="va">rmse_xgb</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<p>We used the python installation of <code>xgboost</code> from our lab <code>setup</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install and load the package</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for XGBoost</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>dtrain <span class="op">=</span> xgb.DMatrix(train_restate.drop(<span class="st">"Price"</span>, axis<span class="op">=</span><span class="dv">1</span>), label<span class="op">=</span>train_restate[<span class="st">"Price"</span>])</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>dtest <span class="op">=</span> xgb.DMatrix(test_restate.drop(<span class="st">"Price"</span>, axis<span class="op">=</span><span class="dv">1</span>), label<span class="op">=</span>test_restate[<span class="st">"Price"</span>])</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Set hyperparameters</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"objective"</span>: <span class="st">"reg:squarederror"</span>,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eta"</span>: <span class="fl">0.1</span>,</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"max_depth"</span>: <span class="dv">3</span>,</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"min_child_weight"</span>: <span class="dv">1</span>,</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subsample"</span>: <span class="dv">1</span>,</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"colsample_bytree"</span>: <span class="dv">1</span>,</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> xgb.train(params, dtrain, num_boost_round<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>restate_pred_xgb <span class="op">=</span> xgb_model.predict(dtest)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>rmse_xgb <span class="op">=</span> np.sqrt(mean_squared_error(test_restate[<span class="st">"Price"</span>], restate_pred_xgb))</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RMSE:"</span>, rmse_xgb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Although initially our GBM suffered compared to the RF, we can see that XGBoost can help improve the result (the case for the python implementation). However, random forest still outperforms all the other models.</p>
</div>
</div>
</div>
<p>Feel free to apply XGBoost to the dataset of your choice.</p>


<!-- -->

</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Data Splitting</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../labs/07_InterpretableML/Ex_ML_VarImp.html" class="pagination-link">
        <span class="nav-page-text">Interpretable ML</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb16" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Ensemble Methods"</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r global_options, include = FALSE}</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">eval =</span> F, <span class="at">fig.align=</span><span class="st">"center"</span>, <span class="at">results =</span> <span class="st">'hide'</span>, <span class="at">fig.show =</span> <span class="st">'hide'</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="fu"># Random Forest</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>In this part of the lab, we will look at how the <span class="in">`randomForest`</span> library (alternative to <span class="in">`ranger`</span>) can be applied for classification and regression tasks. At the very end, please feel free to apply these techniques to one of your favorite datasets seen in class (classification or regression).</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hyperparameters of RF </span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>R (using the <span class="in">`randomForest`</span> library): </span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`ntree`</span>: The number of trees in the forest (equivalent to <span class="in">`n_estimators`</span> in python). </span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`mtry`</span>: The number of features to consider when looking for the best split. (similar to <span class="in">`max_features`</span> in python)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`max.depth`</span>: The maximum depth of each tree. </span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`nodesize`</span>: The minimum number of samples required to split an internal node (equivalent to <span class="in">`min_samples_split`</span> in python).</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>Python (using the <span class="in">`sklearn`</span> library): </span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`n_estimators`</span>: The number of trees in the forest. </span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`max_features`</span>: The number of features to consider when looking for the best split. </span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`max_depth`</span>: The maximum depth of each tree. </span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`min_samples_split`</span>: The minimum number of samples required to split an internal node. </span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span><span class="in">`min_samples_leaf`</span>: The minimum number of samples required to be at a leaf node.</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a><span class="fu">## Few tips on RF hyperparameters</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>A few (among many) tips for finding the ideal hyperparameters for RF:</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`ntree`</span> (R) / <span class="in">`n_estimators`</span> (python): Use a large number of trees in the forest to improve model performance, but be aware of the increased computation time. The default value is usually a good starting point. </span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`mtry`</span> (R) / <span class="in">`max_features`</span> (python): Experiment with different values, usually starting with the default (square root of the number of features for classification or one-third of the number of features for regression). Increasing this value may improve model performance but can also increase computation time. </span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`max.depth`</span>: Control the depth of each tree to manage overfitting. Deeper trees capture more complex patterns but can lead to overfitting. Experiment with different values, keeping in mind that a shallower tree can be more interpretable and less prone to overfitting. </span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`nodesize`</span> (R) / <span class="in">`min_samples_split`</span> (python): Increasing this value can help reduce overfitting, but setting it too high might lead to underfitting. Experiment with different values to find the optimal balance.</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classification</span></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data preparation for Random Forest</span></span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>Load the library <span class="in">`randomForest`</span> in R. Then, load the <span class="in">`wine`</span> data set. This dataset is about white wine quality (in fact Portuguese vinho verde). The data contains 11 numerical features and 1 factor variable:</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`fixed.acidity`</span></span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`volatile.acidity`</span></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`citric.acid`</span></span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`residual.sugar`</span></span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`chlorides`</span></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`free.sulfur.dioxide`</span></span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`total.sulfur.dioxide`</span></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`density`</span></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`pH`</span></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`sulphates`</span></span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`alcohol`</span></span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`quality: Good/Bad`</span></span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a>All the numerical features have units. The data source can be found <span class="co">[</span><span class="ot">here</span><span class="co">](https://archive.ics.uci.edu/ml/datasets/wine+quality)</span>. For simplicity, only an extraction of 200 wines are used in this exercise. Note that in the original data set, the <span class="in">`quality`</span> is a score (0 to 10) that was turned as factor here for the exercise (Bad: 0 to 5, Good: 6 to 10). Also, note that in the data source, the objective is to predict the quality from the other features (supervised learning).</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>As mentioned, the outcome variable used for this dataset is the wine <span class="in">`quality`</span>. We should first coerce the classes as factors. Then, we make the training/test set random split with a 75/25 scheme.</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a>wine <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"data/Wine.csv"</span>))</span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a>wine<span class="sc">$</span>quality <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(wine<span class="sc">$</span>quality)</span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a><span class="co"># define a function to get the splitting index (training and testing) of a given dataset</span></span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a>get_split_index <span class="ot">&lt;-</span> <span class="cf">function</span>(dataset, <span class="at">train_proportion =</span> <span class="fl">0.75</span>) {</span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a>  index <span class="ot">&lt;-</span></span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sample</span>(</span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,</span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a>      <span class="at">size =</span> <span class="fu">nrow</span>(dataset),</span>
<span id="cb16-82"><a href="#cb16-82" aria-hidden="true" tabindex="-1"></a>      <span class="at">replace =</span> <span class="cn">TRUE</span>,</span>
<span id="cb16-83"><a href="#cb16-83" aria-hidden="true" tabindex="-1"></a>      <span class="at">prob =</span> <span class="fu">c</span>(train_proportion, <span class="dv">1</span> <span class="sc">-</span> train_proportion)</span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(index)</span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a>wine_index <span class="ot">&lt;-</span> <span class="fu">get_split_index</span>(wine)</span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a>wine_tr <span class="ot">&lt;-</span> wine[wine_index <span class="sc">==</span> <span class="dv">1</span>, ]</span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a>wine_te <span class="ot">&lt;-</span> wine[wine_index <span class="sc">==</span> <span class="dv">2</span>, ]</span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-92"><a href="#cb16-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-93"><a href="#cb16-93" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb16-96"><a href="#cb16-96" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb16-97"><a href="#cb16-97" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the course python environment as usual with a r code chunks.</span></span>
<span id="cb16-98"><a href="#cb16-98" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb16-99"><a href="#cb16-99" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>)</span>
<span id="cb16-100"><a href="#cb16-100" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-101"><a href="#cb16-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-102"><a href="#cb16-102" aria-hidden="true" tabindex="-1"></a>Similar to the previous labs, in python, we can use the usual <span class="in">`sklearn`</span> library to do all our modelling. Please note that we will load the data again in python to make the demo easier. Additionally, we'll load all the necessary libraries for this lab in this code chunk.</span>
<span id="cb16-103"><a href="#cb16-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-106"><a href="#cb16-106" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-107"><a href="#cb16-107" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-108"><a href="#cb16-108" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-109"><a href="#cb16-109" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb16-110"><a href="#cb16-110" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, RandomForestRegressor</span>
<span id="cb16-111"><a href="#cb16-111" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score, mean_squared_error</span>
<span id="cb16-112"><a href="#cb16-112" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-113"><a href="#cb16-113" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb16-114"><a href="#cb16-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-115"><a href="#cb16-115" aria-hidden="true" tabindex="-1"></a><span class="co"># we first move up one directory to achieve relative paths</span></span>
<span id="cb16-116"><a href="#cb16-116" aria-hidden="true" tabindex="-1"></a>wine <span class="op">=</span> pd.read_csv(<span class="st">'../data/Wine.csv'</span>)</span>
<span id="cb16-117"><a href="#cb16-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-118"><a href="#cb16-118" aria-hidden="true" tabindex="-1"></a>wine[<span class="st">'quality'</span>] <span class="op">=</span> wine[<span class="st">'quality'</span>].astype(<span class="st">'category'</span>)</span>
<span id="cb16-119"><a href="#cb16-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-120"><a href="#cb16-120" aria-hidden="true" tabindex="-1"></a><span class="co"># Split wine dataset into train and test</span></span>
<span id="cb16-121"><a href="#cb16-121" aria-hidden="true" tabindex="-1"></a>train_wine, test_wine <span class="op">=</span> train_test_split(wine, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb16-122"><a href="#cb16-122" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-123"><a href="#cb16-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-124"><a href="#cb16-124" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-125"><a href="#cb16-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-126"><a href="#cb16-126" aria-hidden="true" tabindex="-1"></a>**Note:** Here, we have written a function to make the split as we will also need to apply it also for another dataset in the regression part.</span>
<span id="cb16-127"><a href="#cb16-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-128"><a href="#cb16-128" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training and testing the model</span></span>
<span id="cb16-129"><a href="#cb16-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-130"><a href="#cb16-130" aria-hidden="true" tabindex="-1"></a>Fit a random forest on the train set. The target is the <span class="in">`taste`</span> variable that we want to predict. Specify for the number of trees <span class="in">`ntree=1000`</span> (by default, the function selects $500$ trees). Remember to exclude <span class="in">`quality`</span> in the predictors of the formula. Also, use the option <span class="in">`importance=TRUE`</span>, we will need it afterward. Then test the model by computing the accuracy on the test set. You may use <span class="in">`confusionMatrix`</span> from <span class="in">`caret`</span>.</span>
<span id="cb16-131"><a href="#cb16-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-132"><a href="#cb16-132" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb16-133"><a href="#cb16-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-134"><a href="#cb16-134" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb16-137"><a href="#cb16-137" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb16-138"><a href="#cb16-138" aria-hidden="true" tabindex="-1"></a>wine_rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(quality<span class="sc">~</span>., <span class="at">data=</span>wine_tr, <span class="at">ntree=</span><span class="dv">1000</span>, <span class="at">importance=</span><span class="cn">TRUE</span>)</span>
<span id="cb16-139"><a href="#cb16-139" aria-hidden="true" tabindex="-1"></a>wine.pred_rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(wine_rf, <span class="at">newdata=</span>wine_te)</span>
<span id="cb16-140"><a href="#cb16-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-141"><a href="#cb16-141" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb16-142"><a href="#cb16-142" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>wine.pred_rf, <span class="at">reference =</span> wine_te<span class="sc">$</span>quality)</span>
<span id="cb16-143"><a href="#cb16-143" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-144"><a href="#cb16-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-145"><a href="#cb16-145" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb16-146"><a href="#cb16-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-149"><a href="#cb16-149" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-150"><a href="#cb16-150" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Random Forest classifier on the train set</span></span>
<span id="cb16-151"><a href="#cb16-151" aria-hidden="true" tabindex="-1"></a>wine_rf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb16-152"><a href="#cb16-152" aria-hidden="true" tabindex="-1"></a>wine_rf.fit(train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_wine[<span class="st">'quality'</span>])</span>
<span id="cb16-153"><a href="#cb16-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-154"><a href="#cb16-154" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the accuracy</span></span>
<span id="cb16-155"><a href="#cb16-155" aria-hidden="true" tabindex="-1"></a>wine_pred_rf <span class="op">=</span> wine_rf.predict(test_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb16-156"><a href="#cb16-156" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(test_wine[<span class="st">'quality'</span>], wine_pred_rf))</span>
<span id="cb16-157"><a href="#cb16-157" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(test_wine[<span class="st">'quality'</span>], wine_pred_rf))</span>
<span id="cb16-158"><a href="#cb16-158" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-159"><a href="#cb16-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-160"><a href="#cb16-160" aria-hidden="true" tabindex="-1"></a>This model is worse than the R version mostly because of the different defaults.</span>
<span id="cb16-161"><a href="#cb16-161" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-162"><a href="#cb16-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-163"><a href="#cb16-163" aria-hidden="true" tabindex="-1"></a><span class="fu">### Variable importance</span></span>
<span id="cb16-164"><a href="#cb16-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-165"><a href="#cb16-165" aria-hidden="true" tabindex="-1"></a>Extract the model-specific variable importance using the functions <span class="in">`varImpPlot`</span> (plots) and <span class="in">`importance`</span> (values) on the model. Observe well that the mean decrease in accuracy of each variable is also computed for each specific class. In particular, what makes <span class="in">`density`</span> special for predicting <span class="in">`Good`</span> compare to another variable (like for example <span class="in">`citric.acid`</span>)?</span>
<span id="cb16-166"><a href="#cb16-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-167"><a href="#cb16-167" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb16-168"><a href="#cb16-168" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb16-171"><a href="#cb16-171" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb16-172"><a href="#cb16-172" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(wine_rf)</span>
<span id="cb16-173"><a href="#cb16-173" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(wine_rf)</span>
<span id="cb16-174"><a href="#cb16-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-175"><a href="#cb16-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-176"><a href="#cb16-176" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb16-177"><a href="#cb16-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-180"><a href="#cb16-180" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-181"><a href="#cb16-181" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable importance</span></span>
<span id="cb16-182"><a href="#cb16-182" aria-hidden="true" tabindex="-1"></a>wine_importances <span class="op">=</span> pd.Series(wine_rf.feature_importances_, index<span class="op">=</span>train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>).columns)</span>
<span id="cb16-183"><a href="#cb16-183" aria-hidden="true" tabindex="-1"></a>wine_importances.sort_values(ascending<span class="op">=</span><span class="va">False</span>).plot(kind<span class="op">=</span><span class="st">'bar'</span>)</span>
<span id="cb16-184"><a href="#cb16-184" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-185"><a href="#cb16-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-186"><a href="#cb16-186" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-187"><a href="#cb16-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-188"><a href="#cb16-188" aria-hidden="true" tabindex="-1"></a><span class="in">`density`</span> is important for predicting the <span class="in">`Good`</span> since their predictions is much less accurate if we do not use it. <span class="in">`citric.acid`</span> is both overall less important than <span class="in">`density`</span> but especially for prediction of <span class="in">`Good`</span>.</span>
<span id="cb16-189"><a href="#cb16-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-190"><a href="#cb16-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-191"><a href="#cb16-191" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression</span></span>
<span id="cb16-192"><a href="#cb16-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-193"><a href="#cb16-193" aria-hidden="true" tabindex="-1"></a>In this part, we will be using the <span class="in">`real_estate_data.csv`</span> once again. After reading the data, apply a random forest to predict <span class="in">`price`</span> using all the other variables except <span class="in">`No`</span>, <span class="in">`Month`</span> and <span class="in">`Year`</span>. Compute the RMSE and inspect the prediction quality with a graph. Note that the importance is not specific to any class here.</span>
<span id="cb16-194"><a href="#cb16-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-195"><a href="#cb16-195" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb16-196"><a href="#cb16-196" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb16-197"><a href="#cb16-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-200"><a href="#cb16-200" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb16-201"><a href="#cb16-201" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb16-202"><a href="#cb16-202" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr)</span>
<span id="cb16-203"><a href="#cb16-203" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/real_estate_data.csv"</span>))</span>
<span id="cb16-204"><a href="#cb16-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-205"><a href="#cb16-205" aria-hidden="true" tabindex="-1"></a><span class="co"># select the columns of interest</span></span>
<span id="cb16-206"><a href="#cb16-206" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="ot">&lt;-</span> </span>
<span id="cb16-207"><a href="#cb16-207" aria-hidden="true" tabindex="-1"></a>  real_estate_data <span class="sc">%&gt;%</span> </span>
<span id="cb16-208"><a href="#cb16-208" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(No, Month, Year))</span>
<span id="cb16-209"><a href="#cb16-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-210"><a href="#cb16-210" aria-hidden="true" tabindex="-1"></a><span class="co"># once again, divide the data into training and testing sets using the function created earlier</span></span>
<span id="cb16-211"><a href="#cb16-211" aria-hidden="true" tabindex="-1"></a>restate_index <span class="ot">&lt;-</span> <span class="fu">get_split_index</span>(real_estate_data)</span>
<span id="cb16-212"><a href="#cb16-212" aria-hidden="true" tabindex="-1"></a>restate_tr <span class="ot">&lt;-</span> real_estate_data[restate_index <span class="sc">==</span> <span class="dv">1</span>, ]</span>
<span id="cb16-213"><a href="#cb16-213" aria-hidden="true" tabindex="-1"></a>restate_te <span class="ot">&lt;-</span> real_estate_data[restate_index <span class="sc">==</span> <span class="dv">2</span>, ]</span>
<span id="cb16-214"><a href="#cb16-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-215"><a href="#cb16-215" aria-hidden="true" tabindex="-1"></a><span class="co"># apply the RF model as a regression</span></span>
<span id="cb16-216"><a href="#cb16-216" aria-hidden="true" tabindex="-1"></a>restate_rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(Price<span class="sc">~</span>., <span class="at">data=</span>restate_tr, <span class="at">ntree=</span><span class="dv">1000</span>, <span class="at">importance=</span><span class="cn">TRUE</span>)</span>
<span id="cb16-217"><a href="#cb16-217" aria-hidden="true" tabindex="-1"></a>restate.pred_rf<span class="ot">&lt;-</span><span class="fu">predict</span>(restate_rf, <span class="at">newdata=</span>restate_te)</span>
<span id="cb16-218"><a href="#cb16-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-219"><a href="#cb16-219" aria-hidden="true" tabindex="-1"></a><span class="co"># compute rmse and plot the results as well the VarImp</span></span>
<span id="cb16-220"><a href="#cb16-220" aria-hidden="true" tabindex="-1"></a>(rmse <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((restate_te<span class="sc">$</span>Price <span class="sc">-</span> restate.pred_rf)<span class="sc">^</span><span class="dv">2</span>)))</span>
<span id="cb16-221"><a href="#cb16-221" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(restate_te<span class="sc">$</span>Price <span class="sc">~</span> restate.pred_rf)</span>
<span id="cb16-222"><a href="#cb16-222" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb16-223"><a href="#cb16-223" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(restate_rf)</span>
<span id="cb16-224"><a href="#cb16-224" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(restate_rf)</span>
<span id="cb16-225"><a href="#cb16-225" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-226"><a href="#cb16-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-227"><a href="#cb16-227" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb16-228"><a href="#cb16-228" aria-hidden="true" tabindex="-1"></a><span class="in">```{python a}</span></span>
<span id="cb16-229"><a href="#cb16-229" aria-hidden="true" tabindex="-1"></a><span class="co"># Load real estate dataset</span></span>
<span id="cb16-230"><a href="#cb16-230" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="op">=</span> pd.read_csv(<span class="st">"../data/real_estate_data.csv"</span>)</span>
<span id="cb16-231"><a href="#cb16-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-232"><a href="#cb16-232" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="op">=</span> real_estate_data.drop([<span class="st">'No'</span>, <span class="st">'Month'</span>, <span class="st">'Year'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-233"><a href="#cb16-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-234"><a href="#cb16-234" aria-hidden="true" tabindex="-1"></a><span class="co"># Split real estate dataset into train and test</span></span>
<span id="cb16-235"><a href="#cb16-235" aria-hidden="true" tabindex="-1"></a>train_restate, test_restate <span class="op">=</span> train_test_split(real_estate_data, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb16-236"><a href="#cb16-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-237"><a href="#cb16-237" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Random Forest regressor on the train set</span></span>
<span id="cb16-238"><a href="#cb16-238" aria-hidden="true" tabindex="-1"></a>restate_rf <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb16-239"><a href="#cb16-239" aria-hidden="true" tabindex="-1"></a>restate_rf.fit(train_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_restate[<span class="st">'Price'</span>])</span>
<span id="cb16-240"><a href="#cb16-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-241"><a href="#cb16-241" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb16-242"><a href="#cb16-242" aria-hidden="true" tabindex="-1"></a>restate_pred_rf <span class="op">=</span> restate_rf.predict(test_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb16-243"><a href="#cb16-243" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> np.sqrt(mean_squared_error(test_restate[<span class="st">'Price'</span>], restate_pred_rf))</span>
<span id="cb16-244"><a href="#cb16-244" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RMSE:"</span>, rmse)</span>
<span id="cb16-245"><a href="#cb16-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-246"><a href="#cb16-246" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the prediction quality</span></span>
<span id="cb16-247"><a href="#cb16-247" aria-hidden="true" tabindex="-1"></a>plt.scatter(test_restate[<span class="st">'Price'</span>], restate_pred_rf)</span>
<span id="cb16-248"><a href="#cb16-248" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Actual Price'</span>)</span>
<span id="cb16-249"><a href="#cb16-249" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted Price'</span>)</span>
<span id="cb16-250"><a href="#cb16-250" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], [<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb16-251"><a href="#cb16-251" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb16-252"><a href="#cb16-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-253"><a href="#cb16-253" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable importance</span></span>
<span id="cb16-254"><a href="#cb16-254" aria-hidden="true" tabindex="-1"></a>restate_importances <span class="op">=</span> pd.Series(restate_rf.feature_importances_, index<span class="op">=</span>train_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>).columns)</span>
<span id="cb16-255"><a href="#cb16-255" aria-hidden="true" tabindex="-1"></a>restate_importances.sort_values(ascending<span class="op">=</span><span class="va">False</span>).plot(kind<span class="op">=</span><span class="st">'bar'</span>)</span>
<span id="cb16-256"><a href="#cb16-256" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-257"><a href="#cb16-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-258"><a href="#cb16-258" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-259"><a href="#cb16-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-260"><a href="#cb16-260" aria-hidden="true" tabindex="-1"></a>Compare this model with the one you came up with in <span class="in">`Ex_ML_LinLogReg`</span> . Which one would you go for?</span>
<span id="cb16-261"><a href="#cb16-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-262"><a href="#cb16-262" aria-hidden="true" tabindex="-1"></a><span class="fu"># Gradient Boosting Machines (GBM)</span></span>
<span id="cb16-263"><a href="#cb16-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-264"><a href="#cb16-264" aria-hidden="true" tabindex="-1"></a>In this part of the lab, we will look at how the <span class="in">`gbm`</span> library in R and the <span class="in">`GradientBoostingClassifier`</span> and <span class="in">`GradientBoostingRegressor`</span> in Python can be applied for classification and regression tasks. We will continue using the <span class="in">`wine`</span> dataset for classification and <span class="in">`real_estate_data`</span> for regression.</span>
<span id="cb16-265"><a href="#cb16-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-266"><a href="#cb16-266" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb16-267"><a href="#cb16-267" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hyperparameters of GBM </span></span>
<span id="cb16-268"><a href="#cb16-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-269"><a href="#cb16-269" aria-hidden="true" tabindex="-1"></a>R (using the <span class="in">`gbm`</span> library): </span>
<span id="cb16-270"><a href="#cb16-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-271"><a href="#cb16-271" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`n.trees`</span>: The number of boosting stages to perform (equivalent to <span class="in">`n_estimators`</span> in python). </span>
<span id="cb16-272"><a href="#cb16-272" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`interaction.depth`</span>: The maximum depth of each tree (equivalent to <span class="in">`max_depth`</span> in python). </span>
<span id="cb16-273"><a href="#cb16-273" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`shrinkage`</span>: The learning rate. </span>
<span id="cb16-274"><a href="#cb16-274" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`n.minobsinnode`</span>: The minimum number of samples required to split an internal node (equivalent to <span class="in">`min_samples_split`</span> in python). </span>
<span id="cb16-275"><a href="#cb16-275" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span><span class="in">`bag.fraction`</span>: The fraction of samples to be used for fitting individual base learners (equivalent to <span class="in">`subsample`</span> in python).</span>
<span id="cb16-276"><a href="#cb16-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-277"><a href="#cb16-277" aria-hidden="true" tabindex="-1"></a>Python (using the <span class="in">`sklearn`</span> library):</span>
<span id="cb16-278"><a href="#cb16-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-279"><a href="#cb16-279" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`n_estimators`</span>: The number of boosting stages to perform. Similar to Random Forest, increasing the number of estimators can improve the model's performance but may also increase the computational complexity and training time. </span>
<span id="cb16-280"><a href="#cb16-280" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`learning_rate`</span>: The learning rate shrinks the contribution of each tree. A smaller learning rate requires more boosting stages to achieve the same performance as a larger learning rate, but it can also result in a more robust model. </span>
<span id="cb16-281"><a href="#cb16-281" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`max_depth`</span>: The maximum depth of each tree. Similar to Random Forest, a higher depth can capture more complex patterns in the data, but it may also lead to overfitting. </span>
<span id="cb16-282"><a href="#cb16-282" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`min_samples_split`</span>: The minimum number of samples required to split an internal node. Similar to Random Forest, a smaller value allows the model to capture finer details in the data, while a larger value can help prevent overfitting. </span>
<span id="cb16-283"><a href="#cb16-283" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span><span class="in">`min_samples_leaf`</span>: The minimum number of samples required to be at a leaf node. Similar to Random Forest, a smaller value allows the model to capture finer details, while a larger value can help prevent overfitting.</span>
<span id="cb16-284"><a href="#cb16-284" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span><span class="in">`subsample`</span>: The fraction of samples to be used for fitting individual base learners. A value smaller than 1.0 can lead to a reduction in variance and an increase in bias, resulting in a more robust model.</span>
<span id="cb16-285"><a href="#cb16-285" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-286"><a href="#cb16-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-287"><a href="#cb16-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-288"><a href="#cb16-288" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb16-289"><a href="#cb16-289" aria-hidden="true" tabindex="-1"></a><span class="fu">## Few tips on GBM hyperparameters</span></span>
<span id="cb16-290"><a href="#cb16-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-291"><a href="#cb16-291" aria-hidden="true" tabindex="-1"></a>Similar to R, here are some tips for finding the best combination of the hyperparameters:</span>
<span id="cb16-292"><a href="#cb16-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-293"><a href="#cb16-293" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`n.trees`</span> (R) / <span class="in">`n_estimators`</span> (python): Start with a lower number of trees and increase it until no further improvement in performance is observed. Be aware of the increased computation time with a larger number of trees. </span>
<span id="cb16-294"><a href="#cb16-294" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`interaction.depth`</span> (R) / <span class="in">`max_depth`</span> (python): Keep the depth of each tree relatively shallow (3-5 levels) to prevent overfitting. Deeper trees can capture more complex patterns but may lead to overfitting. </span>
<span id="cb16-295"><a href="#cb16-295" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`shrinkage`</span> (R) / <span class="in">`learning_rate`</span> (python): Use a smaller learning rate for better model performance, but be prepared for slower convergence and increased computation time. Typically, values range between 0.01 and 0.1. </span>
<span id="cb16-296"><a href="#cb16-296" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`n.minobsinnode`</span> (R) / <span class="in">`min_samples_split`</span> (python): Similar to Random Forest, experiment with different values to find the optimal balance between overfitting and underfitting. </span>
<span id="cb16-297"><a href="#cb16-297" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span><span class="in">`bag.fraction`</span> (R) / <span class="in">`subsample`</span> (python): Using a subsample of the data (e.g., 0.5-0.8) can help reduce overfitting and speed up the training process. Experiment with different values to find the best trade-off between performance and computation time.</span>
<span id="cb16-298"><a href="#cb16-298" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-299"><a href="#cb16-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-300"><a href="#cb16-300" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classification</span></span>
<span id="cb16-301"><a href="#cb16-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-302"><a href="#cb16-302" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training and testing the model</span></span>
<span id="cb16-303"><a href="#cb16-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-304"><a href="#cb16-304" aria-hidden="true" tabindex="-1"></a>We now fit a GBM model on the <span class="in">`wine`</span> training set and apply it to the same target variable <span class="in">`quality`</span>. We can train the model and add</span>
<span id="cb16-305"><a href="#cb16-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-306"><a href="#cb16-306" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb16-307"><a href="#cb16-307" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb16-310"><a href="#cb16-310" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb16-311"><a href="#cb16-311" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gbm)</span>
<span id="cb16-312"><a href="#cb16-312" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb16-313"><a href="#cb16-313" aria-hidden="true" tabindex="-1"></a>wine_gbm <span class="ot">&lt;-</span> <span class="fu">gbm</span>(quality<span class="sc">~</span>., <span class="at">data=</span>wine_tr, <span class="at">distribution=</span><span class="st">"multinomial"</span>, <span class="at">n.trees=</span><span class="dv">1000</span>, <span class="at">interaction.depth=</span><span class="dv">4</span>, <span class="at">shrinkage=</span><span class="fl">0.01</span>)</span>
<span id="cb16-314"><a href="#cb16-314" aria-hidden="true" tabindex="-1"></a>wine.pred_gbm <span class="ot">&lt;-</span> <span class="fu">predict</span>(wine_gbm, <span class="at">newdata=</span>wine_te, <span class="at">n.trees=</span><span class="dv">1000</span>, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb16-315"><a href="#cb16-315" aria-hidden="true" tabindex="-1"></a>wine.pred_gbm_class <span class="ot">&lt;-</span> <span class="fu">apply</span>(wine.pred_gbm, <span class="dv">1</span>, which.max)</span>
<span id="cb16-316"><a href="#cb16-316" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(wine_te<span class="sc">$</span>quality) <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(<span class="fu">levels</span>(wine_te<span class="sc">$</span>quality))</span>
<span id="cb16-317"><a href="#cb16-317" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="fu">factor</span>(wine.pred_gbm_class), wine_te<span class="sc">$</span>quality)</span>
<span id="cb16-318"><a href="#cb16-318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-319"><a href="#cb16-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-320"><a href="#cb16-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-321"><a href="#cb16-321" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb16-322"><a href="#cb16-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-325"><a href="#cb16-325" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-326"><a href="#cb16-326" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingClassifier</span>
<span id="cb16-327"><a href="#cb16-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-328"><a href="#cb16-328" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Gradient Boosting classifier on the train set</span></span>
<span id="cb16-329"><a href="#cb16-329" aria-hidden="true" tabindex="-1"></a>wine_gbm <span class="op">=</span> GradientBoostingClassifier(n_estimators<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.01</span>, max_depth<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb16-330"><a href="#cb16-330" aria-hidden="true" tabindex="-1"></a>wine_gbm.fit(train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_wine[<span class="st">'quality'</span>])</span>
<span id="cb16-331"><a href="#cb16-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-332"><a href="#cb16-332" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the accuracy</span></span>
<span id="cb16-333"><a href="#cb16-333" aria-hidden="true" tabindex="-1"></a>wine_pred_gbm <span class="op">=</span> wine_gbm.predict(test_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb16-334"><a href="#cb16-334" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(test_wine[<span class="st">'quality'</span>], wine_pred_gbm))</span>
<span id="cb16-335"><a href="#cb16-335" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(test_wine[<span class="st">'quality'</span>], wine_pred_gbm))</span>
<span id="cb16-336"><a href="#cb16-336" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-337"><a href="#cb16-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-338"><a href="#cb16-338" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-339"><a href="#cb16-339" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression</span></span>
<span id="cb16-340"><a href="#cb16-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-341"><a href="#cb16-341" aria-hidden="true" tabindex="-1"></a>In this part, we will continue using the <span class="in">`real_estate_data.csv`</span>. Fit a GBM model on the real estate training set to predict <span class="in">`price`</span> using all the other variables except <span class="in">`No`</span>, <span class="in">`Month`</span>, and <span class="in">`Year`</span>. Then compute the metrics and plot the predictions.</span>
<span id="cb16-342"><a href="#cb16-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-343"><a href="#cb16-343" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb16-344"><a href="#cb16-344" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb16-345"><a href="#cb16-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-348"><a href="#cb16-348" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb16-349"><a href="#cb16-349" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb16-350"><a href="#cb16-350" aria-hidden="true" tabindex="-1"></a>restate_gbm <span class="ot">&lt;-</span> <span class="fu">gbm</span>(Price<span class="sc">~</span>., <span class="at">data=</span>restate_tr, <span class="at">distribution=</span><span class="st">"gaussian"</span>, <span class="at">n.trees=</span><span class="dv">1000</span>, <span class="at">interaction.depth=</span><span class="dv">4</span>, <span class="at">shrinkage=</span><span class="fl">0.01</span>)</span>
<span id="cb16-351"><a href="#cb16-351" aria-hidden="true" tabindex="-1"></a>restate.pred_gbm<span class="ot">&lt;-</span><span class="fu">predict</span>(restate_gbm, <span class="at">newdata=</span>restate_te, <span class="at">n.trees=</span><span class="dv">1000</span>)</span>
<span id="cb16-352"><a href="#cb16-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-353"><a href="#cb16-353" aria-hidden="true" tabindex="-1"></a><span class="co"># compute rmse and plot the results</span></span>
<span id="cb16-354"><a href="#cb16-354" aria-hidden="true" tabindex="-1"></a>(rmse_gbm <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((restate_te<span class="sc">$</span>Price <span class="sc">-</span> restate.pred_gbm)<span class="sc">^</span><span class="dv">2</span>)))</span>
<span id="cb16-355"><a href="#cb16-355" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(restate_te<span class="sc">$</span>Price <span class="sc">~</span> restate.pred_gbm)</span>
<span id="cb16-356"><a href="#cb16-356" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb16-357"><a href="#cb16-357" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-358"><a href="#cb16-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-359"><a href="#cb16-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-360"><a href="#cb16-360" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb16-361"><a href="#cb16-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-364"><a href="#cb16-364" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-365"><a href="#cb16-365" aria-hidden="true" tabindex="-1"></a><span class="co"># run the code below if you have not cleared the plot yet</span></span>
<span id="cb16-366"><a href="#cb16-366" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb16-367"><a href="#cb16-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-368"><a href="#cb16-368" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb16-369"><a href="#cb16-369" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Gradient Boosting regressor on the train set</span></span>
<span id="cb16-370"><a href="#cb16-370" aria-hidden="true" tabindex="-1"></a>restate_gbm <span class="op">=</span> GradientBoostingRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.01</span>, max_depth<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb16-371"><a href="#cb16-371" aria-hidden="true" tabindex="-1"></a>restate_gbm.fit(train_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_restate[<span class="st">'Price'</span>])</span>
<span id="cb16-372"><a href="#cb16-372" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb16-373"><a href="#cb16-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-374"><a href="#cb16-374" aria-hidden="true" tabindex="-1"></a>restate_pred_gbm <span class="op">=</span> restate_gbm.predict(test_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb16-375"><a href="#cb16-375" aria-hidden="true" tabindex="-1"></a>rmse_gbm <span class="op">=</span> np.sqrt(mean_squared_error(test_restate[<span class="st">'Price'</span>], restate_pred_gbm))</span>
<span id="cb16-376"><a href="#cb16-376" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RMSE:"</span>, rmse_gbm)</span>
<span id="cb16-377"><a href="#cb16-377" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the prediction quality</span></span>
<span id="cb16-378"><a href="#cb16-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-379"><a href="#cb16-379" aria-hidden="true" tabindex="-1"></a>plt.scatter(test_restate[<span class="st">'Price'</span>], restate_pred_gbm)</span>
<span id="cb16-380"><a href="#cb16-380" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Actual Price'</span>)</span>
<span id="cb16-381"><a href="#cb16-381" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted Price'</span>)</span>
<span id="cb16-382"><a href="#cb16-382" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], [<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb16-383"><a href="#cb16-383" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb16-384"><a href="#cb16-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-385"><a href="#cb16-385" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-386"><a href="#cb16-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-387"><a href="#cb16-387" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-388"><a href="#cb16-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-389"><a href="#cb16-389" aria-hidden="true" tabindex="-1"></a>Compare the GBM model with the Random Forest model you came up with earlier. Which one would you go for?</span>
<span id="cb16-390"><a href="#cb16-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-391"><a href="#cb16-391" aria-hidden="true" tabindex="-1"></a><span class="fu"># Bonus: XGBoost</span></span>
<span id="cb16-392"><a href="#cb16-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-393"><a href="#cb16-393" aria-hidden="true" tabindex="-1"></a><span class="fu">## What is XGBoost?</span></span>
<span id="cb16-394"><a href="#cb16-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-395"><a href="#cb16-395" aria-hidden="true" tabindex="-1"></a>XGBoost (Extreme Gradient Boosting) is an optimized implementation of the gradient boosting algorithm. It is designed for high performance and efficient memory usage. XGBoost improves upon the base Gradient Boosting Machine (GBM) by incorporating regularization to prevent overfitting and implementing parallel processing techniques for faster training. The algorithm also offers built-in cross-validation and early stopping to save time and resources during model training.</span>
<span id="cb16-396"><a href="#cb16-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-397"><a href="#cb16-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-398"><a href="#cb16-398" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modelling with XGBoost</span></span>
<span id="cb16-399"><a href="#cb16-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-400"><a href="#cb16-400" aria-hidden="true" tabindex="-1"></a>We'll use the <span class="co">[</span><span class="ot">`xgboost`</span><span class="co">](https://xgboost.readthedocs.io/en/stable/index.html)</span> library in both R and python. You can see some of the hyperparameters below:</span>
<span id="cb16-401"><a href="#cb16-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-402"><a href="#cb16-402" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb16-403"><a href="#cb16-403" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hyperparameters of XGBoost</span></span>
<span id="cb16-404"><a href="#cb16-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-405"><a href="#cb16-405" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`eta`</span>: Controls the learning rate, which determines the step size at each iteration while updating the model weights. Smaller values make the model more robust to overfitting but require more iterations to converge. Typical values range from 0.01 to 0.3. </span>
<span id="cb16-406"><a href="#cb16-406" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`max_depth`</span>: Controls the maximum depth of each tree. Deeper trees can model more complex relationships but are more prone to overfitting. Experiment with different values, keeping in mind that a shallower tree can be more interpretable and less prone to overfitting. </span>
<span id="cb16-407"><a href="#cb16-407" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`min_child_weight`</span>: Controls the minimum sum of instance weights needed in a child node. Increasing this value helps to prevent overfitting by making the model more conservative.</span>
<span id="cb16-408"><a href="#cb16-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-409"><a href="#cb16-409" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-410"><a href="#cb16-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-411"><a href="#cb16-411" aria-hidden="true" tabindex="-1"></a>You can read more about the package in its documentation.</span>
<span id="cb16-412"><a href="#cb16-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-413"><a href="#cb16-413" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb16-414"><a href="#cb16-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-415"><a href="#cb16-415" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb16-416"><a href="#cb16-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-419"><a href="#cb16-419" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb16-420"><a href="#cb16-420" aria-hidden="true" tabindex="-1"></a><span class="co"># Install and load the package</span></span>
<span id="cb16-421"><a href="#cb16-421" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("xgboost")</span></span>
<span id="cb16-422"><a href="#cb16-422" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb16-423"><a href="#cb16-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-424"><a href="#cb16-424" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for XGBoost</span></span>
<span id="cb16-425"><a href="#cb16-425" aria-hidden="true" tabindex="-1"></a>dtrain <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(restate_tr[, <span class="sc">-</span><span class="fu">ncol</span>(restate_tr)]), <span class="at">label =</span> restate_tr<span class="sc">$</span>Price)</span>
<span id="cb16-426"><a href="#cb16-426" aria-hidden="true" tabindex="-1"></a>dtest <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(restate_te[, <span class="sc">-</span><span class="fu">ncol</span>(restate_te)]), <span class="at">label =</span> restate_te<span class="sc">$</span>Price)</span>
<span id="cb16-427"><a href="#cb16-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-428"><a href="#cb16-428" aria-hidden="true" tabindex="-1"></a><span class="co"># Set hyperparameters</span></span>
<span id="cb16-429"><a href="#cb16-429" aria-hidden="true" tabindex="-1"></a>params <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb16-430"><a href="#cb16-430" aria-hidden="true" tabindex="-1"></a>  <span class="at">objective =</span> <span class="st">"reg:squarederror"</span>,</span>
<span id="cb16-431"><a href="#cb16-431" aria-hidden="true" tabindex="-1"></a>  <span class="at">eta =</span> <span class="fl">0.1</span>,</span>
<span id="cb16-432"><a href="#cb16-432" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_depth =</span> <span class="dv">5</span>,</span>
<span id="cb16-433"><a href="#cb16-433" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_child_weight =</span> <span class="dv">1</span>,</span>
<span id="cb16-434"><a href="#cb16-434" aria-hidden="true" tabindex="-1"></a>  <span class="at">subsample =</span> <span class="dv">1</span>,</span>
<span id="cb16-435"><a href="#cb16-435" aria-hidden="true" tabindex="-1"></a>  <span class="at">colsample_bytree =</span> <span class="dv">1</span></span>
<span id="cb16-436"><a href="#cb16-436" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-437"><a href="#cb16-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-438"><a href="#cb16-438" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb16-439"><a href="#cb16-439" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="ot">&lt;-</span> <span class="fu">xgb.train</span>(params, dtrain, <span class="at">nrounds =</span> <span class="dv">1000</span>)</span>
<span id="cb16-440"><a href="#cb16-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-441"><a href="#cb16-441" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb16-442"><a href="#cb16-442" aria-hidden="true" tabindex="-1"></a>restate_pred_xgb <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb_model, dtest)</span>
<span id="cb16-443"><a href="#cb16-443" aria-hidden="true" tabindex="-1"></a>rmse_xgb <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((restate_te<span class="sc">$</span>Price <span class="sc">-</span> restate_pred_xgb)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb16-444"><a href="#cb16-444" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"RMSE:"</span>, rmse_xgb))</span>
<span id="cb16-445"><a href="#cb16-445" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-446"><a href="#cb16-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-447"><a href="#cb16-447" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb16-448"><a href="#cb16-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-449"><a href="#cb16-449" aria-hidden="true" tabindex="-1"></a>We used the python installation of <span class="in">`xgboost`</span> from our lab <span class="in">`setup`</span>.</span>
<span id="cb16-450"><a href="#cb16-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-453"><a href="#cb16-453" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-454"><a href="#cb16-454" aria-hidden="true" tabindex="-1"></a><span class="co"># Install and load the package</span></span>
<span id="cb16-455"><a href="#cb16-455" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb16-456"><a href="#cb16-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-457"><a href="#cb16-457" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for XGBoost</span></span>
<span id="cb16-458"><a href="#cb16-458" aria-hidden="true" tabindex="-1"></a>dtrain <span class="op">=</span> xgb.DMatrix(train_restate.drop(<span class="st">"Price"</span>, axis<span class="op">=</span><span class="dv">1</span>), label<span class="op">=</span>train_restate[<span class="st">"Price"</span>])</span>
<span id="cb16-459"><a href="#cb16-459" aria-hidden="true" tabindex="-1"></a>dtest <span class="op">=</span> xgb.DMatrix(test_restate.drop(<span class="st">"Price"</span>, axis<span class="op">=</span><span class="dv">1</span>), label<span class="op">=</span>test_restate[<span class="st">"Price"</span>])</span>
<span id="cb16-460"><a href="#cb16-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-461"><a href="#cb16-461" aria-hidden="true" tabindex="-1"></a><span class="co"># Set hyperparameters</span></span>
<span id="cb16-462"><a href="#cb16-462" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb16-463"><a href="#cb16-463" aria-hidden="true" tabindex="-1"></a>    <span class="st">"objective"</span>: <span class="st">"reg:squarederror"</span>,</span>
<span id="cb16-464"><a href="#cb16-464" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eta"</span>: <span class="fl">0.1</span>,</span>
<span id="cb16-465"><a href="#cb16-465" aria-hidden="true" tabindex="-1"></a>    <span class="st">"max_depth"</span>: <span class="dv">3</span>,</span>
<span id="cb16-466"><a href="#cb16-466" aria-hidden="true" tabindex="-1"></a>    <span class="st">"min_child_weight"</span>: <span class="dv">1</span>,</span>
<span id="cb16-467"><a href="#cb16-467" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subsample"</span>: <span class="dv">1</span>,</span>
<span id="cb16-468"><a href="#cb16-468" aria-hidden="true" tabindex="-1"></a>    <span class="st">"colsample_bytree"</span>: <span class="dv">1</span>,</span>
<span id="cb16-469"><a href="#cb16-469" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-470"><a href="#cb16-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-471"><a href="#cb16-471" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb16-472"><a href="#cb16-472" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> xgb.train(params, dtrain, num_boost_round<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb16-473"><a href="#cb16-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-474"><a href="#cb16-474" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb16-475"><a href="#cb16-475" aria-hidden="true" tabindex="-1"></a>restate_pred_xgb <span class="op">=</span> xgb_model.predict(dtest)</span>
<span id="cb16-476"><a href="#cb16-476" aria-hidden="true" tabindex="-1"></a>rmse_xgb <span class="op">=</span> np.sqrt(mean_squared_error(test_restate[<span class="st">"Price"</span>], restate_pred_xgb))</span>
<span id="cb16-477"><a href="#cb16-477" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RMSE:"</span>, rmse_xgb)</span>
<span id="cb16-478"><a href="#cb16-478" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-479"><a href="#cb16-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-480"><a href="#cb16-480" aria-hidden="true" tabindex="-1"></a>Although initially our GBM suffered compared to the RF, we can see that XGBoost can help improve the result (the case for the python implementation). However, random forest still outperforms all the other models. </span>
<span id="cb16-481"><a href="#cb16-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-482"><a href="#cb16-482" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb16-483"><a href="#cb16-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-484"><a href="#cb16-484" aria-hidden="true" tabindex="-1"></a>Feel free to apply XGBoost to the dataset of your choice.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">© Copyright 2024, <a href="https://iliaazizi.com/">Ilia Azizi &amp; Marc-Olivier Boldi</a></div>   
    <div class="nav-footer-right">This page is built with 🤍 and <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>


</body></html>