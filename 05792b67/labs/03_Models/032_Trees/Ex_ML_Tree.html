<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>MLBA - S24 - Models: CART</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../labs/03_Models/033_NeuralNetworks/EX_ML_NN.html" rel="next">
<link href="../../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html" rel="prev">
<link href="../../../images/logo.dark.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<meta property="og:title" content="MLBA - S24 - Models: CART">
<meta property="og:description" content="In this exercise, the classification tree method is used to analyze the data set Carseats from the package ISLR. The exercise took some inspiration from this video.">
<meta property="og:site-name" content="MLBA - S24 ">
</head>
<body class="nav-sidebar docked">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Models: CART</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="../../../index.html" class="sidebar-logo-link">
      <img src="../../../images/logo.light.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
      <div class="sidebar-tools-main tools-wide">
    <a href="http://moodle2.unil.ch/course/view.php?id=8715" title="Moodle" class="sidebar-tool px-1"><i class="bi bi-person-rolodex"></i></a>
    <a href="https://github.com/do-unil/mlba" title="GitHub Repo" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle sidebar-tool" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">Course information</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">Overview</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../schedule.html" class="sidebar-item-text sidebar-link">Schedule</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../faq.html" class="sidebar-item-text sidebar-link">FAQ</a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">Lectures</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/01_Introduction/ML_Intro.html" class="sidebar-item-text sidebar-link">Intro to ML</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/02_DataExploration/ML_DataExplo.html" class="sidebar-item-text sidebar-link">Data Exploration</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/030_Introduction/ML_Models_Intro.html" class="sidebar-item-text sidebar-link">Intro to Models</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/031_LinearLogisticRegression/ML_LinLogReg.html" class="sidebar-item-text sidebar-link">Linear &amp; Logistic Regression</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/032_Trees/ML_Trees.html" class="sidebar-item-text sidebar-link">Decision Trees</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/033_NeuralNetworks/ML_NN.html" class="sidebar-item-text sidebar-link">Neural Networks</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/03_Models/034_SupportVectorMachine/ML_SVM.html" class="sidebar-item-text sidebar-link">Support Vector Machines</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/04_Metrics/ML_Metrics.html" class="sidebar-item-text sidebar-link">Metrics</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/05_DataSplitting/ML_DataSplitting.html" class="sidebar-item-text sidebar-link">Data Splitting</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/06_Ensembles/ML_Ensemble.html" class="sidebar-item-text sidebar-link">Ensemble Methods</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/07_InterpretableML/ML_Interp.html" class="sidebar-item-text sidebar-link">Interpretable ML</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/08_UnsupervisedLearning/080_Introduction/ML_UnsupIntro.html" class="sidebar-item-text sidebar-link">Intro to Unsuperised Learning</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/08_UnsupervisedLearning/081_Clustering/ML_Clustering.html" class="sidebar-item-text sidebar-link">Clustering</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../lectures/08_UnsupervisedLearning/082_DimensionReduction/ML_DimRed.html" class="sidebar-item-text sidebar-link">Dimension Reduction</a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Labs</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/00_lab/setup.html" class="sidebar-item-text sidebar-link">Setup</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html" class="sidebar-item-text sidebar-link">Linear &amp; Logistic Regression</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/032_Trees/Ex_ML_Tree.html" class="sidebar-item-text sidebar-link active">Decision Trees</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/033_NeuralNetworks/EX_ML_NN.html" class="sidebar-item-text sidebar-link">Neural Networks</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" class="sidebar-item-text sidebar-link">Support Vector Machines</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/04_Metrics/Ex_ML_Scoring.html" class="sidebar-item-text sidebar-link">Metrics</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="sidebar-item-text sidebar-link">Data Splitting</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/06_Ensembles/Ex_ML_Ensemble.html" class="sidebar-item-text sidebar-link">Ensemble Methods</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/07_InterpretableML/Ex_ML_VarImp.html" class="sidebar-item-text sidebar-link">Interpretable ML</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/08_UnsupervisedLearning/081_Clustering/Ex_ML_Clustering.html" class="sidebar-item-text sidebar-link">Clustering</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/08_UnsupervisedLearning/082_DimensionReduction/Ex_ML_PCA.html" class="sidebar-item-text sidebar-link">PCA</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../labs/08_UnsupervisedLearning/083_AutoEncoders/Ex_ML_Autoencoder.html" class="sidebar-item-text sidebar-link">Autoencoders</a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">Assessments</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../assessments/Exam.html" class="sidebar-item-text sidebar-link">Exam</a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">Project</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../assessments/Project_Directives.html" class="sidebar-item-text sidebar-link">Project Directives</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../assessments/Report_Guideline.html" class="sidebar-item-text sidebar-link">Report Guidelines</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../assessments/Presentation_Guidelines.html" class="sidebar-item-text sidebar-link">Presentation Guidelines</a>
  </div>
</li>
      </ul>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">Resources</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/beginners_r.html" class="sidebar-item-text sidebar-link">Beginners in R</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/data_acquisition/data_sources.html" class="sidebar-item-text sidebar-link">Data Sources</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/data_acquisition/web_scraping_api.html" class="sidebar-item-text sidebar-link">Web Scraping</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources/cheatsheets.html" class="sidebar-item-text sidebar-link">Coding Cheatsheets</a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">On this page</h2>
   
  <ul>
<li>
<a href="#classification-tree" id="toc-classification-tree" class="nav-link active" data-scroll-target="#classification-tree">Classification tree</a>
  <ul class="collapse">
<li><a href="#data-preparation" id="toc-data-preparation" class="nav-link" data-scroll-target="#data-preparation">Data preparation</a></li>
  <li><a href="#fit-plot" id="toc-fit-plot" class="nav-link" data-scroll-target="#fit-plot">Fit &amp; plot</a></li>
  <li><a href="#pruning" id="toc-pruning" class="nav-link" data-scroll-target="#pruning">Pruning</a></li>
  <li><a href="#predictions" id="toc-predictions" class="nav-link" data-scroll-target="#predictions">Predictions</a></li>
  <li><a href="#interpretation" id="toc-interpretation" class="nav-link" data-scroll-target="#interpretation">Interpretation</a></li>
  </ul>
</li>
  <li><a href="#regression-tree" id="toc-regression-tree" class="nav-link" data-scroll-target="#regression-tree">Regression tree</a></li>
  <li><a href="#you-turn" id="toc-you-turn" class="nav-link" data-scroll-target="#you-turn">You turn</a></li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/do-unil/mlba/blob/main/labs/03_Models/032_Trees/Ex_ML_Tree.qmd" class="toc-action">View source</a></p><p><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><script type="application/javascript">
// Description: Change image src depending on body class (quarto-light or quarto-dark)
function updateImageSrc() {
  var bodyClass = window.document.body.classList;
  var images = window.document.getElementsByTagName('img');
  for (var i = 0; i < images.length; i++) {
    var image = images[i];
    var src = image.src;
    var newSrc = src;
    if (bodyClass.contains('quarto-light') && src.includes('.dark')) {
      newSrc = src.replace('.dark', '.light');
    } else if (bodyClass.contains('quarto-dark') && src.includes('.light')) {
      newSrc = src.replace('.light', '.dark');
    }
    if (newSrc !== src) {
      image.src = newSrc;
    }
  }
}

var observer = new MutationObserver(function(mutations) {
  mutations.forEach(function(mutation) {
    if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
      updateImageSrc();
    }
  });
});

observer.observe(window.document.body, {
  attributes: true
});

updateImageSrc();
</script><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title d-none d-lg-block">Models: CART</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><section id="classification-tree" class="level1"><h1>Classification tree</h1>
<p>In this exercise, the classification tree method is used to analyze the data set <code>Carseats</code> from the package <code>ISLR</code>. The exercise took some inspiration from <a href="https://www.youtube.com/watch?v=GOJN9SKl_OE">this video</a>.</p>
<section id="data-preparation" class="level2"><h2 class="anchored" data-anchor-id="data-preparation">Data preparation</h2>
<p>First, install the package <code>ISLR</code> in order to access the data set <code>Carseats</code>. Use <code><a href="https://rdrr.io/pkg/ISLR/man/Carseats.html">?Carseats</a></code> to read its description. To apply a classification of the sales, we first create a categorical outcome <code>SaleHigh</code> which equals “Yes” if <code>Sales</code> &gt; 7.5 and “No” otherwise. Then we create a data frame <code>MyCarseats</code> containing <code>SaleHigh</code> and all the features of <code>Carseats</code> except <code>Sales</code>. Finally, split <code>MyCarseats</code> into a training and a test set (2/3 vs 1/3). Below we call them <code>df_tr</code> and <code>df_te</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.statlearning.com">ISLR</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="va">MyCarseats</span> <span class="op">&lt;-</span> <span class="va">Carseats</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>SaleHigh<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">Sales</span> <span class="op">&gt;</span> <span class="fl">7.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">MyCarseats</span> <span class="op">&lt;-</span> <span class="va">MyCarseats</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Sales</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> <span class="co"># for reproducibility </span></span>
<span><span class="va">index_tr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span>x<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">MyCarseats</span><span class="op">)</span>, size<span class="op">=</span><span class="fl">2</span><span class="op">/</span><span class="fl">3</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">MyCarseats</span><span class="op">)</span>, replace<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">df_tr</span> <span class="op">&lt;-</span> <span class="va">MyCarseats</span><span class="op">[</span><span class="va">index_tr</span>,<span class="op">]</span></span>
<span><span class="va">df_te</span> <span class="op">&lt;-</span> <span class="va">MyCarseats</span><span class="op">[</span><span class="op">-</span><span class="va">index_tr</span>,<span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note: this is not the point of this exercise but remember that in a real situation the first step of the data analysis would be an EDA.</p>
</section><section id="fit-plot" class="level2"><h2 class="anchored" data-anchor-id="fit-plot">Fit &amp; plot</h2>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>The <code>rpart</code> function in the package <code>rpart</code> can be used to fit a classification tree with the same type of formulas as <code>naive_bayes</code>. It can then be plotted using the function <code>rpart.plot</code> of the package <code>rpart.plot</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/bethatkinson/rpart">rpart</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.milbo.org/rpart-plot/index.html">rpart.plot</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span><span class="va">carseats_tree</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart</a></span><span class="op">(</span><span class="va">SaleHigh</span> <span class="op">~</span> <span class="va">.</span>, data<span class="op">=</span><span class="va">df_tr</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/rpart.plot/man/rpart.plot.html">rpart.plot</a></span><span class="op">(</span><span class="va">carseats_tree</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load MLBA environment</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rstudio.github.io/reticulate/">reticulate</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/use_python.html">use_condaenv</a></span><span class="op">(</span><span class="st">"MLBA"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We use the <code>df_train</code> and <code>df_te</code> created in R to carry out our CART training. For this, we will use the <code>sklearn</code> library. First, we copy our dataset from the R variable to a python variable. Then we use any encoder (e.g.&nbsp;<code>OneHotEncoder</code>, <code>LabelEncoder</code>, <code>OrdinalEncoder</code>) from <code>sklearn.preprocessing</code> to convert categorical data into a numeric form, which many <code>sklearn</code> machine learning algorithms require. In this case, we use the <code>OneHoteEncoder</code> which is similar to making dummy variables and turn each level of the category into a column. Also, we standardize the data in the case of python for faster computations using <code>StandardScaler</code>, which also helps to bring numerical stability and improve the results. After this, we divide the training and test sets into predictors (e.g., <code>X_train</code>) and the outcome (e.g., <code>y_train</code>) and initialize our classification tree and fit the model to the data.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder, StandardScaler</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># We copy the training and testing datasets from R to Python.</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>carset_tr_py <span class="op">=</span> r.df_tr.copy()</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>carset_te_py<span class="op">=</span> r.df_te.copy()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># We encode categorical variables as numeric, which is necessary for CART.</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> OneHotEncoder()</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>cat_vars <span class="op">=</span> [<span class="st">"ShelveLoc"</span>, <span class="st">"Urban"</span>, <span class="st">"US"</span>, <span class="st">"SaleHigh"</span>]</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> var <span class="kw">in</span> cat_vars:</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the LabelEncoder to the training set and transform the training and testing sets</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We need to use the same encoder for both sets to ensure consistency</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    carset_tr_py_encoded <span class="op">=</span> le.fit_transform(carset_tr_py[[var]].values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    carset_te_py_encoded <span class="op">=</span> le.transform(carset_te_py[[var]].values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    carset_tr_py[var] <span class="op">=</span> carset_tr_py_encoded.toarray()</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    carset_te_py[var] <span class="op">=</span> carset_te_py_encoded.toarray()</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> carset_tr_py.drop(columns<span class="op">=</span>[<span class="st">"SaleHigh"</span>]), carset_tr_py[<span class="st">"SaleHigh"</span>]</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>X_test, y_test <span class="op">=</span> carset_te_py.drop(columns<span class="op">=</span>[<span class="st">"SaleHigh"</span>]), carset_te_py[<span class="st">"SaleHigh"</span>]</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize only the continuous variables</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>cont_vars <span class="op">=</span> [<span class="st">"CompPrice"</span>, <span class="st">"Income"</span>, <span class="st">"Advertising"</span>, <span class="st">"Population"</span>, <span class="st">"Price"</span>, <span class="st">"Age"</span>, <span class="st">"Education"</span>]</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>X_train[cont_vars] <span class="op">=</span> scaler.fit_transform(X_train[cont_vars])</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>X_test[cont_vars] <span class="op">=</span> scaler.transform(X_test[cont_vars])</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="co"># To speed up the operation you can also transform the inputs</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co"># X_train = X_train.to_numpy()</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co"># y_train = y_train.to_numpy()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now train and plot our decision tree using <code>DecisionTreeClassifier</code> and <code>plot_tree</code> functions.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># we clear any previous figures</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1234</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>carseats_tree <span class="op">=</span> DecisionTreeClassifier().fit(X_train, y_train)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">10</span>))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>plot_tree(carseats_tree,filled<span class="op">=</span><span class="va">True</span>, feature_names<span class="op">=</span>X_train.columns, label <span class="op">=</span> <span class="st">'root'</span>,fontsize<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'tree_high_dpi'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># for a better quality, save the image and load it again</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.show()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As the image dimensions are not always great for <code>matplotlib</code> plots in Rstudio, we saved the image and now load it again below using an R chunk.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/include_graphics.html">include_graphics</a></span><span class="op">(</span><span class="st">"tree_high_dpi.png"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section><section id="pruning" class="level2"><h2 class="anchored" data-anchor-id="pruning">Pruning</h2>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>The analysis of the tree complexity can be obtained using function <code>plotcp</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/rpart/man/plotcp.html">plotcp</a></span><span class="op">(</span><span class="va">carseats_tree</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>From the graph, we can identify that, according to the 1-SE rule, the tree with 8 nodes is equivalent to the tree with 12 nodes. This 8-nodes tree should be preferred.</p>
<p>To prune the tree (i.e., extract the tree with 8 nodes), we can use the function <code>prune</code> with argument <code>cp</code>. The <code>cp</code> of the tree can be read on the bottom x-axis of the <code>plotcp</code>. The argument in <code>prune</code> should be set to any value between the cp of 8-nodes tree (0.031) and the 11-node tree (0.019). Here 0.025 is OK.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">carseats_tree_prune</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/rpart/man/prune.rpart.html">prune</a></span><span class="op">(</span><span class="va">carseats_tree</span>, cp<span class="op">=</span><span class="fl">0.025</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/rpart.plot/man/rpart.plot.html">rpart.plot</a></span><span class="op">(</span><span class="va">carseats_tree_prune</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>Important note</code>: The CP evaluation relies on a cross-validation procedure, which uses random number generation. This is why we have set the seed to some value (1234). You may not find the same result with another seed or if you do not set it. In any case, just be coherent with your results and prune the tree accordingly.</p>
<p><strong>Let the computer do the work for you</strong>: Pruning using the 1-SE rule can be automatically obtained with the function <code>autoprune</code> in package <code>adabag</code>. Note that, because of the randomness involved in the CP evaluation, you may not find exactly the same result as the one obtained by hand. Use <code>set.seed</code> to make your result reproducible.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">adabag</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123455</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/rpart.plot/man/rpart.plot.html">rpart.plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/adabag/man/autoprune.html">autoprune</a></span><span class="op">(</span><span class="va">SaleHigh</span> <span class="op">~</span> <span class="va">.</span>, data<span class="op">=</span><span class="va">df_tr</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>The <code>rpart.plot</code> package in R provides a convenient <code><a href="https://rdrr.io/pkg/rpart/man/plotcp.html">plotcp()</a></code> function to plot the complexity parameter table for a decision tree fit with <code><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart()</a></code>. Unfortunately, <code>scikit-learn</code> doesn’t provide an equivalent function out of the box. However, you can still calculate the complexity parameter values for your decision tree and plot them using <code>matplotlib</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the paths of the leaf nodes for the Car Seats decision tree using cost complexity pruning</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> carseats_tree.cost_complexity_pruning_path(X_train, y_train)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the effective alphas and total impurities of the leaf nodes from the path object</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>ccp_alphas, impurities <span class="op">=</span> path.ccp_alphas, path.impurities</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a plot to visualize the relationship between effective alphas and total impurities</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>ax.plot(ccp_alphas, impurities, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">"-"</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Effective alpha"</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Total impurity of leaves"</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Total Impurity vs Effective alpha for Car Seats dataset"</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>ax.invert_xaxis()</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This plot only shows the training set results, which doesn’t tell us about over-fitting. A better approach is to compute accuracy (a different metric than <code>rpart</code>) on a second test set, called the <em>validation set</em> used solely for finding the ideal hyperparameters in machine learning. Once we choose the best hyperparameters, we re-train the model one final time with those parameters and compare everything on the test set (but we should no longer change our models based on the test set). We will learn more about this validation set during the upcoming lectures. Here we’ll use the two functions <code>cross_val_score</code> and <code>KFold</code> from the <code>sklearn.module_selection</code> sub-module. We will use ten folds to find the ideal <code>alpha</code> (equivalent to <code>cp</code> from <code><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart::rpart()</a></code>). This is not using the <code>1-SE</code> rule but proposes a good alternative.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score, KFold</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plotcp(X_train, y_train, random_state<span class="op">=</span><span class="dv">123</span>):</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a decision tree classifier</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    clf <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span>random_state)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the cross-validation scores for different values of alpha</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    path <span class="op">=</span> clf.cost_complexity_pruning_path(X_train, y_train)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    ccp_alphas, impurities <span class="op">=</span> path.ccp_alphas, path.impurities</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform cross-validation for each alpha</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    kfold <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">10</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span>random_state)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> []</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ccp_alpha <span class="kw">in</span> ccp_alphas:</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        clf <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span>random_state, ccp_alpha<span class="op">=</span>ccp_alpha)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> cross_val_score(clf, X_train, y_train, cv<span class="op">=</span>kfold, scoring<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>        scores.append(np.mean(score))</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the cross-validation scores vs alpha</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    ax.plot(ccp_alphas, scores, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">"-"</span>)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">"ccp_alpha"</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">"Cross-validation score (accuracy)"</span>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">"Pruning Complexity Parameter (ccp) vs Cross-validation Score"</span>)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    ax.invert_xaxis()</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>plotcp(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see that the best validation scores are obtained around a <code>ccp_alpha</code> of <code>0.008</code>. Similar to <code>cp</code> from <code>rpart</code>, in scikit-learn, the parameter controls the complexity of a classification tree by setting a penalty on the number of leaf nodes. A higher value of results in a simpler tree with fewer splits and more nodes being pruned. More specifically, <code>alpha</code> is the regularization parameter used for controlling the cost complexity of the tree. The cost complexity is the sum of the misclassification cost and the complexity cost of the tree. The complexity cost is proportional to the number of terminal nodes (leaves) in the tree. A higher value of <code>alpha</code> thus means that the model is less likely to overfit the training data and more likely to generalize better to new, unseen data. However, setting <code>alpha</code> too high can result in underfitting and poor model performance on both the training and test data. The optimal <code>alpha</code> value depends on the specific dataset and the problem being solved and can be determined through cross-validation or other model selection techniques, as demonstrated above.</p>
<p>Once you find the ideal alpha, you can specify it with the <code>ccp_alpha</code> argument in <code>DecisionTreeClassifier()</code>. Here we will take <code>ccp_alpha</code> as 0.008 for simplicity.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a decision tree classifier with a ccp_alpha of 0.025</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>carseats_tree_prune <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">123</span>, ccp_alpha<span class="op">=</span><span class="fl">0.008</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model to the data</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>carseats_tree_prune.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style>
<div id="sk-container-id-1" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>DecisionTreeClassifier(ccp_alpha=0.008, random_state=123)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>DecisionTreeClassifier</div></div>
<div>
<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html">?<span>Documentation for DecisionTreeClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>DecisionTreeClassifier(ccp_alpha=0.008, random_state=123)</pre></div> </div></div></div>
</div>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># You can again plot the figure with</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">10</span>))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>plot_tree(carseats_tree_prune,filled<span class="op">=</span><span class="va">True</span>, feature_names<span class="op">=</span>X_train.columns, label <span class="op">=</span> <span class="st">'root'</span>,fontsize<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'tree_pruned_high_dpi'</span>, dpi<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>plt.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/include_graphics.html">include_graphics</a></span><span class="op">(</span><span class="st">"tree_pruned_high_dpi.png"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This model is a lot simpler compared to the first tree made using python (where <code>ccp_alpha</code> was 0 by default).</p>
<p>For automatically pruning the tree, unlike the <code><a href="https://rdrr.io/pkg/adabag/man/autoprune.html">adabag::autoprune()</a></code> function in R’s adabag package, scikit-learn does not have a built-in function for automatic pruning of decision trees. Instead, you can use cross-validation to determine the optimal tree depth and use that to prune the tree.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the decision tree classifier</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>tree <span class="op">=</span> DecisionTreeClassifier()</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the grid search parameters</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'max_depth'</span>: <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>)}</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Run grid search cross-validation to find optimal tree depth</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(tree, param_grid<span class="op">=</span>param_grid, cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-2 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style>
<div id="sk-container-id-2" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),
             param_grid={'max_depth': range(1, 11)})</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped">
<div class="sk-label-container"><div class="sk-label fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>GridSearchCV</div></div>
<div>
<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),
             param_grid={'max_depth': range(1, 11)})</pre></div> </div></div>
<div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item">
<div class="sk-label-container"><div class="sk-label fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>best_estimator_: DecisionTreeClassifier</div></div></label><div class="sk-toggleable__content fitted"><pre>DecisionTreeClassifier(max_depth=3)</pre></div> </div></div>
<div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"><label for="sk-estimator-id-4" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>DecisionTreeClassifier</div></div>
<div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class="sk-toggleable__content fitted"><pre>DecisionTreeClassifier(max_depth=3)</pre></div> </div></div></div>
</div></div></div>
</div></div>
</div>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the best estimator to fit and prune the tree</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>pruned_tree <span class="op">=</span> grid_search.best_estimator_</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>plot_tree(pruned_tree, ax<span class="op">=</span>ax, feature_names<span class="op">=</span>X_train.columns)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># you can choose to re-train the model once again with this new parameter</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Python approach vs <code><a href="https://rdrr.io/pkg/adabag/man/autoprune.html">adabag::autoprune()</a></code>
</div>
</div>
<div class="callout-body-container callout-body">
<p>The technique above does not explicitly use the 1-SE rule for pruning the decision tree. Instead, it uses cross-validation to find the optimal tree depth based on the mean test score across all folds. According to the documentation of <code><a href="https://rdrr.io/pkg/adabag/man/autoprune.html">adabag::autoprune()</a></code>, <em>“The cross validation estimation of the error (xerror) has a random component. To avoid this randomness the 1-SE rule (or 1-SD rule) selects the simplest model with a xerror equal or less than the minimum xerror plus the standard deviation of the minimum xerror.”</em> If you’re interested in the 1-SE, see the adapted python code for it below.</p>
<details><summary><strong>Implementing GridSearchCV with 1-SE rule</strong>
</summary><div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the decision tree classifier</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>tree <span class="op">=</span> DecisionTreeClassifier()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the grid search parameters</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'max_depth'</span>: <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>)}</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Run grid search cross-validation to find optimal tree depth</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(tree, param_grid<span class="op">=</span>param_grid, cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-3 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style>
<div id="sk-container-id-3" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),
             param_grid={'max_depth': range(1, 11)})</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped">
<div class="sk-label-container"><div class="sk-label fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox"><label for="sk-estimator-id-5" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>GridSearchCV</div></div>
<div>
<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),
             param_grid={'max_depth': range(1, 11)})</pre></div> </div></div>
<div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item">
<div class="sk-label-container"><div class="sk-label fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox"><label for="sk-estimator-id-6" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>best_estimator_: DecisionTreeClassifier</div></div></label><div class="sk-toggleable__content fitted"><pre>DecisionTreeClassifier(max_depth=3)</pre></div> </div></div>
<div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox"><label for="sk-estimator-id-7" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>DecisionTreeClassifier</div></div>
<div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class="sk-toggleable__content fitted"><pre>DecisionTreeClassifier(max_depth=3)</pre></div> </div></div></div>
</div></div></div>
</div></div>
</div>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the mean and standard error of test scores for each tree depth</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>mean_scores <span class="op">=</span> grid_search.cv_results_[<span class="st">'mean_test_score'</span>]</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>std_scores <span class="op">=</span> grid_search.cv_results_[<span class="st">'std_test_score'</span>] <span class="op">/</span> np.sqrt(<span class="dv">10</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the optimal depth using the 1-SE rule</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>optimal_depth <span class="op">=</span> grid_search.best_params_[<span class="st">'max_depth'</span>]</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>optimal_score <span class="op">=</span> mean_scores[optimal_depth <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>se <span class="op">=</span> std_scores[optimal_depth <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>best_depth <span class="op">=</span> optimal_depth</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> depth <span class="kw">in</span> <span class="bu">range</span>(optimal_depth <span class="op">-</span> <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> mean_scores[depth]</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> score <span class="op">+</span> se <span class="op">&lt;</span> optimal_score:</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        best_depth <span class="op">=</span> depth <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the best estimator to fit and prune the tree</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>pruned_tree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span>best_depth)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>pruned_tree.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-4 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-4 {
  color: var(--sklearn-color-text);
}

#sk-container-id-4 pre {
  padding: 0;
}

#sk-container-id-4 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-4 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-4 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-4 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-4 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-4 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-4 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-4 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-4 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-4 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-4 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-4 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-4 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-4 div.sk-label label.sk-toggleable__label,
#sk-container-id-4 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-4 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-4 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-4 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-4 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-4 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-4 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-4 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-4 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style>
<div id="sk-container-id-4" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>DecisionTreeClassifier(max_depth=3)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" checked=""><label for="sk-estimator-id-8" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>DecisionTreeClassifier</div></div>
<div>
<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html">?<span>Documentation for DecisionTreeClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>DecisionTreeClassifier(max_depth=3)</pre></div> </div></div></div>
</div>
</div>
</div>
<p>The results are the same as not using 1-SE.</p>
</details>
</div>
</div>
</div>
</div>
</div>
</section><section id="predictions" class="level2"><h2 class="anchored" data-anchor-id="predictions">Predictions</h2>
<p>First, use the R plot to determine what is the prediction of the first instance of <code>MyCarseats</code>.</p>
<details><summary><strong>Answer</strong>
</summary><div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">MyCarseats</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Follow Left, Left, Left =&gt; The predicted answer is “No”.</p>
</details><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<p>The function <code>predict</code> can be used build the predictions of the test set (use option <code>type="class"</code>). This is similar to the previously seen models: the <code>predict</code> function used on an object of class <code>.rpart</code> (created by the function <code>rpart</code>), in fact, calls the function <code>predict.rpart</code> which is adapted to the model.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">carseats_tree_prune</span>, newdata<span class="op">=</span><span class="va">df_te</span>, type<span class="op">=</span><span class="st">"class"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span>Pred<span class="op">=</span><span class="va">pred</span>, Obs<span class="op">=</span><span class="va">df_te</span><span class="op">$</span><span class="va">SaleHigh</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that, like most categorical models, you may ask for the probabilities instead of the classes by setting <code>type="prob"</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">carseats_tree_prune</span>, newdata<span class="op">=</span><span class="va">df_te</span>, type<span class="op">=</span><span class="st">"prob"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>To print a confusion matrix of the predicted labels versus the true labels, we can use the <code>crosstab()</code> function from the <code>pandas</code> library. We pass the predicted and true labels as arguments to <code>crosstab()</code>, and use the <code>rownames</code> and <code>colnames</code> parameters to label the rows and columns of the table, respectively.</p>
<p>Finally, we use the <code>predict_proba()</code> method of the decision tree classifier to predict the class probabilities for the test data. The predicted probabilities are stored in the <code>y_probs</code> variable, which is a <code>NumPy</code> array with shape <code>(n_samples, n_classes)</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the class labels for the test data with the python implementation</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> carseats_tree_prune.predict(X_test)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print a confusion matrix of the predicted labels versus the true labels</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.crosstab(index<span class="op">=</span>y_pred, columns<span class="op">=</span>y_test, rownames<span class="op">=</span>[<span class="st">'Pred'</span>], colnames<span class="op">=</span>[<span class="st">'Obs'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This tree is worse than the R implementation, probably due to differences in other default values that we did not tune for.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the class probabilities for the test data</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>y_probs <span class="op">=</span> carseats_tree_prune.predict_proba(X_test)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.DataFrame(y_probs))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section><section id="interpretation" class="level2"><h2 class="anchored" data-anchor-id="interpretation">Interpretation</h2>
<p>By looking at the tree, interpret the most important features for the Sales: the highest in the tree.</p>
<p>Note that, for the level <em><code>Good</code></em> of the <code>ShelveLoc</code> variable, only the <code>Price</code> drives the <code>Sales</code> (according to the tree). Otherwise, it is a subtle mixture between <code>Price</code> and <code>CompPrice</code>.</p>
</section></section><section id="regression-tree" class="level1"><h1>Regression tree</h1>
<p>The regression tree concepts are the same as for classification tree. The (main) difference lies in the outcome being predicted as a value instead of a class.</p>
<p>To illustrate this we quickly build a tree on the Sales of the <code>Carseats</code> data (no training and test set here; it is simply to illustrate the numerical prediction).</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">carseats_reg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart</a></span><span class="op">(</span><span class="va">Sales</span> <span class="op">~</span> <span class="va">.</span>, data<span class="op">=</span><span class="va">Carseats</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/rpart.plot/man/rpart.plot.html">rpart.plot</a></span><span class="op">(</span><span class="va">carseats_reg</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see from the graph that the final nodes are associated to a numerical prediction. Use the plot to determine what is the prediction of the first instance of <code>Carseats</code>. Please note that here we are not dividing between training and test sets, and we only demonstrate how to do a regression tree, but in practice you should always do that.</p>
<details><summary><strong>Answer</strong>
</summary><div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Carseats</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Follow Left, Left, Left, Right =&gt; the predicted answer is 5.4.</p>
</details><p>Now make the prediction for all the data and check the quality.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">carseat_reg_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">carseats_reg</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">carseat_reg_pred</span> <span class="op">~</span> <span class="va">Carseats</span><span class="op">$</span><span class="va">Sales</span>,</span>
<span>     xlab<span class="op">=</span><span class="st">"Sales"</span>, ylab<span class="op">=</span><span class="st">"Predictions"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>, col<span class="op">=</span><span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<p>For the regression task, we need to select the Sales column with continuous values and then encode it via one of the available options. The default encoder for scikit-learn’s <code>DecisionTreeRegressor</code> is <code>OrdinalEncoder</code>. This means that the categorical variables are encoded during training using an ordinal mapping of the categories to integer values. Therefore, for demonstration purposes only (it doesn’t make as much sense as <code>OneHoteEncoder</code>), we encode them with <code>OrdinalEncoder</code>. To read more about this and why it may not make sense for this dataset, click on the blue box below.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
<code>OrdinalEncoder</code> vs <code>OneHotEncoder</code>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>If we use <code>OrdinalEncoder</code> to encode the categorical features, we would convert each category to a numerical value based on the order of the categories. For example, suppose the categories for <code>ShelveLoc</code> are “Bad”, “Good”, and “Medium”. If we use <code>OrdinalEncoder</code>, the encoding would be as follows: “Bad” = 1, “Good” = 2, “Medium” = 3. Similarly, for <code>Urban</code> and <code>US</code>, we might use “No” = 1 and “Yes” = 2. The resulting encoded features would be numerical, but the ordering might not be meaningful.</p>
<p>On the other hand, if we use <code>OneHotEncoder</code> to encode the categorical features, we would create a binary column for each category in each feature. For example, if we use <code>OneHotEncoder</code> to encode <code>ShelveLoc</code>, we would create three binary columns: <code>ShelveLoc_Bad</code>, <code>ShelveLoc_Good</code>, and <code>ShelveLoc_Medium</code>. For an instance where <code>ShelveLoc</code> is “Good”, the <code>ShelveLoc_Good</code> column would have a value of 1, and the other two columns would have a value of 0. This encoding ensures that each category is treated equally and that there is no implicit ordering between the categories.</p>
<p>In summary, <code>OrdinalEncoder</code> is appropriate when the categories have a meaningful order, such as in the case of “low”, “medium”, and “high” for a feature like <code>Price</code>. On the other hand, OneHotEncoder is appropriate when there is no meaningful ordering between the categories, such as in the case of <code>Urban</code>, <code>US</code>, and <code>ShelveLoc</code> for the CarSeats dataset.</p>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OrdinalEncoder</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Select different columns for the regression task from the original carsets data</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> r.Carseats.drop(columns<span class="op">=</span>[<span class="st">"Sales"</span>]), r.Carseats[<span class="st">"Sales"</span>]</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Once again select the categorical columns (this time without `SalesHigh`)</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>categorical_cols <span class="op">=</span> [<span class="st">'ShelveLoc'</span>, <span class="st">'Urban'</span>, <span class="st">'US'</span>]</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode categorical columns as integers</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OrdinalEncoder()</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>X[categorical_cols] <span class="op">=</span> encoder.fit_transform(X[categorical_cols])</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the regression tree model</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>carseats_reg <span class="op">=</span> DecisionTreeRegressor(random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>carseats_reg.fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-5 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-5 {
  color: var(--sklearn-color-text);
}

#sk-container-id-5 pre {
  padding: 0;
}

#sk-container-id-5 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-5 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-5 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-5 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-5 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-5 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-5 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-5 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-5 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-5 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-5 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-5 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-5 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-5 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-5 div.sk-label label.sk-toggleable__label,
#sk-container-id-5 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-5 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-5 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-5 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-5 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-5 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-5 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-5 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-5 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style>
<div id="sk-container-id-5" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>DecisionTreeRegressor(random_state=123)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox" checked=""><label for="sk-estimator-id-9" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>DecisionTreeRegressor</div></div>
<div>
<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeRegressor.html">?<span>Documentation for DecisionTreeRegressor</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>DecisionTreeRegressor(random_state=123)</pre></div> </div></div></div>
</div>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the tree (a bit messy)</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co"># fig, ax = plt.subplots(figsize=(12, 8))</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># plot_tree(carseats_reg, ax=ax, feature_names=X.columns)</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.show()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the training data</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>carseat_reg_pred <span class="op">=</span> carseats_reg.predict(X)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a scatter plot of predicted versus true values</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>ax.scatter(y, carseat_reg_pred, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Sales'</span>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Predictions'</span>)</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>ax.plot(ax.get_xlim(), ax.get_ylim(), ls<span class="op">=</span><span class="st">"--"</span>, c<span class="op">=</span><span class="st">".3"</span>)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This perfect line indicates that we (perfectly) over-fit the data, which is a significant danger (bias-variance trade-off). That’s why you need both training and test sets (and preferably a validation set)!</p>
</div>
</div>
</div>
</section><section id="you-turn" class="level1"><h1>You turn</h1>
<p>Use a regression tree to fit nursing data (outcome = <code>cost</code>). Fit the tree using a training set, prune the tree and make the scatterplot “obs vs pred” on the test set to analyze the quality.</p>


<!-- -->

</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Linear &amp; Logistic Regression</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../labs/03_Models/033_NeuralNetworks/EX_ML_NN.html" class="pagination-link">
        <span class="nav-page-text">Neural Networks</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb31" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Models: CART"</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r global_options, include = FALSE}</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">fig.align=</span><span class="st">"center"</span>, <span class="at">results =</span> <span class="st">'hide'</span>, <span class="at">fig.show =</span> <span class="st">'hide'</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="fu"># Classification tree</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>In this exercise, the classification tree method is used to analyze the data set <span class="in">`Carseats`</span> from the package <span class="in">`ISLR`</span>. The exercise took some inspiration from <span class="co">[</span><span class="ot">this video</span><span class="co">](https://www.youtube.com/watch?v=GOJN9SKl_OE)</span>.</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data preparation</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>First, install the package <span class="in">`ISLR`</span> in order to access the data set <span class="in">`Carseats`</span>. Use <span class="in">`?Carseats`</span> to read its description. To apply a classification of the sales, we first create a categorical outcome <span class="in">`SaleHigh`</span> which equals "Yes" if <span class="in">`Sales`</span> <span class="sc">\&gt;</span> 7.5 and "No" otherwise. Then we create a data frame <span class="in">`MyCarseats`</span> containing <span class="in">`SaleHigh`</span> and all the features of <span class="in">`Carseats`</span> except <span class="in">`Sales`</span>. Finally, split <span class="in">`MyCarseats`</span> into a training and a test set (2/3 vs 1/3). Below we call them <span class="in">`df_tr`</span> and <span class="in">`df_te`</span>.</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>MyCarseats <span class="ot">&lt;-</span> Carseats <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">SaleHigh=</span><span class="fu">ifelse</span>(Sales <span class="sc">&gt;</span> <span class="fl">7.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>))</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>MyCarseats <span class="ot">&lt;-</span> MyCarseats <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Sales)</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) <span class="co"># for reproducibility </span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>index_tr <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x=</span><span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(MyCarseats), <span class="at">size=</span><span class="dv">2</span><span class="sc">/</span><span class="dv">3</span><span class="sc">*</span><span class="fu">nrow</span>(MyCarseats), <span class="at">replace=</span><span class="cn">FALSE</span>)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>df_tr <span class="ot">&lt;-</span> MyCarseats[index_tr,]</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>df_te <span class="ot">&lt;-</span> MyCarseats[<span class="sc">-</span>index_tr,]</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>Note: this is not the point of this exercise but remember that in a real situation the first step of the data analysis would be an EDA.</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a><span class="fu">## Fit &amp; plot</span></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>The <span class="in">`rpart`</span> function in the package <span class="in">`rpart`</span> can be used to fit a classification tree with the same type of formulas as <span class="in">`naive_bayes`</span>. It can then be plotted using the function <span class="in">`rpart.plot`</span> of the package <span class="in">`rpart.plot`</span>.</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>carseats_tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(SaleHigh <span class="sc">~</span> ., <span class="at">data=</span>df_tr)</span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(carseats_tree)</span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Load MLBA environment</span></span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>)</span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a>We use the <span class="in">`df_train`</span> and <span class="in">`df_te`</span> created in R to carry out our CART training. For this, we will use the <span class="in">`sklearn`</span> library. First, we copy our dataset from the R variable to a python variable. Then we use any encoder (e.g. <span class="in">`OneHotEncoder`</span>, <span class="in">`LabelEncoder`</span>, <span class="in">`OrdinalEncoder`</span>) from <span class="in">`sklearn.preprocessing`</span> to convert categorical data into a numeric form, which many <span class="in">`sklearn`</span> machine learning algorithms require. In this case, we use the <span class="in">`OneHoteEncoder`</span> which is similar to making dummy variables and turn each level of the category into a column. Also, we standardize the data in the case of python for faster computations using <span class="in">`StandardScaler`</span>, which also helps to bring numerical stability and improve the results. After this, we divide the training and test sets into predictors (e.g., <span class="in">`X_train`</span>) and the outcome (e.g., <span class="in">`y_train`</span>) and initialize our classification tree and fit the model to the data.</span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder, StandardScaler</span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a><span class="co"># We copy the training and testing datasets from R to Python.</span></span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a>carset_tr_py <span class="op">=</span> r.df_tr.copy()</span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a>carset_te_py<span class="op">=</span> r.df_te.copy()</span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a><span class="co"># We encode categorical variables as numeric, which is necessary for CART.</span></span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> OneHotEncoder()</span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a>cat_vars <span class="op">=</span> [<span class="st">"ShelveLoc"</span>, <span class="st">"Urban"</span>, <span class="st">"US"</span>, <span class="st">"SaleHigh"</span>]</span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> var <span class="kw">in</span> cat_vars:</span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the LabelEncoder to the training set and transform the training and testing sets</span></span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We need to use the same encoder for both sets to ensure consistency</span></span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a>    carset_tr_py_encoded <span class="op">=</span> le.fit_transform(carset_tr_py[[var]].values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a>    carset_te_py_encoded <span class="op">=</span> le.transform(carset_te_py[[var]].values.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a>    carset_tr_py[var] <span class="op">=</span> carset_tr_py_encoded.toarray()</span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a>    carset_te_py[var] <span class="op">=</span> carset_te_py_encoded.toarray()</span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> carset_tr_py.drop(columns<span class="op">=</span>[<span class="st">"SaleHigh"</span>]), carset_tr_py[<span class="st">"SaleHigh"</span>]</span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a>X_test, y_test <span class="op">=</span> carset_te_py.drop(columns<span class="op">=</span>[<span class="st">"SaleHigh"</span>]), carset_te_py[<span class="st">"SaleHigh"</span>]</span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize only the continuous variables</span></span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a>cont_vars <span class="op">=</span> [<span class="st">"CompPrice"</span>, <span class="st">"Income"</span>, <span class="st">"Advertising"</span>, <span class="st">"Population"</span>, <span class="st">"Price"</span>, <span class="st">"Age"</span>, <span class="st">"Education"</span>]</span>
<span id="cb31-90"><a href="#cb31-90" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb31-91"><a href="#cb31-91" aria-hidden="true" tabindex="-1"></a>X_train[cont_vars] <span class="op">=</span> scaler.fit_transform(X_train[cont_vars])</span>
<span id="cb31-92"><a href="#cb31-92" aria-hidden="true" tabindex="-1"></a>X_test[cont_vars] <span class="op">=</span> scaler.transform(X_test[cont_vars])</span>
<span id="cb31-93"><a href="#cb31-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-94"><a href="#cb31-94" aria-hidden="true" tabindex="-1"></a><span class="co"># To speed up the operation you can also transform the inputs</span></span>
<span id="cb31-95"><a href="#cb31-95" aria-hidden="true" tabindex="-1"></a><span class="co"># X_train = X_train.to_numpy()</span></span>
<span id="cb31-96"><a href="#cb31-96" aria-hidden="true" tabindex="-1"></a><span class="co"># y_train = y_train.to_numpy()</span></span>
<span id="cb31-97"><a href="#cb31-97" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-98"><a href="#cb31-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-99"><a href="#cb31-99" aria-hidden="true" tabindex="-1"></a>We can now train and plot our decision tree using <span class="in">`DecisionTreeClassifier`</span> and <span class="in">`plot_tree`</span> functions.</span>
<span id="cb31-100"><a href="#cb31-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-103"><a href="#cb31-103" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb31-104"><a href="#cb31-104" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb31-105"><a href="#cb31-105" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-106"><a href="#cb31-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-107"><a href="#cb31-107" aria-hidden="true" tabindex="-1"></a><span class="co"># we clear any previous figures</span></span>
<span id="cb31-108"><a href="#cb31-108" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb31-109"><a href="#cb31-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-110"><a href="#cb31-110" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1234</span>)</span>
<span id="cb31-111"><a href="#cb31-111" aria-hidden="true" tabindex="-1"></a>carseats_tree <span class="op">=</span> DecisionTreeClassifier().fit(X_train, y_train)</span>
<span id="cb31-112"><a href="#cb31-112" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">10</span>))</span>
<span id="cb31-113"><a href="#cb31-113" aria-hidden="true" tabindex="-1"></a>plot_tree(carseats_tree,filled<span class="op">=</span><span class="va">True</span>, feature_names<span class="op">=</span>X_train.columns, label <span class="op">=</span> <span class="st">'root'</span>,fontsize<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb31-114"><a href="#cb31-114" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'tree_high_dpi'</span>, dpi<span class="op">=</span><span class="dv">300</span>)</span>
<span id="cb31-115"><a href="#cb31-115" aria-hidden="true" tabindex="-1"></a><span class="co"># for a better quality, save the image and load it again</span></span>
<span id="cb31-116"><a href="#cb31-116" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.show()</span></span>
<span id="cb31-117"><a href="#cb31-117" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-118"><a href="#cb31-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-119"><a href="#cb31-119" aria-hidden="true" tabindex="-1"></a>As the image dimensions are not always great for <span class="in">`matplotlib`</span> plots in Rstudio, we saved the image and now load it again below using an R chunk.</span>
<span id="cb31-120"><a href="#cb31-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-123"><a href="#cb31-123" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-124"><a href="#cb31-124" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"tree_high_dpi.png"</span>)</span>
<span id="cb31-125"><a href="#cb31-125" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-126"><a href="#cb31-126" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb31-127"><a href="#cb31-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-128"><a href="#cb31-128" aria-hidden="true" tabindex="-1"></a><span class="fu">## Pruning</span></span>
<span id="cb31-129"><a href="#cb31-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-130"><a href="#cb31-130" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb31-131"><a href="#cb31-131" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb31-132"><a href="#cb31-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-133"><a href="#cb31-133" aria-hidden="true" tabindex="-1"></a>The analysis of the tree complexity can be obtained using function <span class="in">`plotcp`</span>.</span>
<span id="cb31-134"><a href="#cb31-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-137"><a href="#cb31-137" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-138"><a href="#cb31-138" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(carseats_tree)</span>
<span id="cb31-139"><a href="#cb31-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-140"><a href="#cb31-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-141"><a href="#cb31-141" aria-hidden="true" tabindex="-1"></a>From the graph, we can identify that, according to the 1-SE rule, the tree with 8 nodes is equivalent to the tree with 12 nodes. This 8-nodes tree should be preferred.</span>
<span id="cb31-142"><a href="#cb31-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-143"><a href="#cb31-143" aria-hidden="true" tabindex="-1"></a>To prune the tree (i.e., extract the tree with 8 nodes), we can use the function <span class="in">`prune`</span> with argument <span class="in">`cp`</span>. The <span class="in">`cp`</span> of the tree can be read on the bottom x-axis of the <span class="in">`plotcp`</span>. The argument in <span class="in">`prune`</span> should be set to any value between the cp of 8-nodes tree (0.031) and the 11-node tree (0.019). Here 0.025 is OK.</span>
<span id="cb31-144"><a href="#cb31-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-147"><a href="#cb31-147" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-148"><a href="#cb31-148" aria-hidden="true" tabindex="-1"></a>carseats_tree_prune <span class="ot">&lt;-</span> <span class="fu">prune</span>(carseats_tree, <span class="at">cp=</span><span class="fl">0.025</span>)</span>
<span id="cb31-149"><a href="#cb31-149" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(carseats_tree_prune)</span>
<span id="cb31-150"><a href="#cb31-150" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-151"><a href="#cb31-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-152"><a href="#cb31-152" aria-hidden="true" tabindex="-1"></a><span class="in">`Important note`</span>: The CP evaluation relies on a cross-validation procedure, which uses random number generation. This is why we have set the seed to some value (1234). You may not find the same result with another seed or if you do not set it. In any case, just be coherent with your results and prune the tree accordingly.</span>
<span id="cb31-153"><a href="#cb31-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-154"><a href="#cb31-154" aria-hidden="true" tabindex="-1"></a>**Let the computer do the work for you**: Pruning using the 1-SE rule can be automatically obtained with the function <span class="in">`autoprune`</span> in package <span class="in">`adabag`</span>. Note that, because of the randomness involved in the CP evaluation, you may not find exactly the same result as the one obtained by hand. Use <span class="in">`set.seed`</span> to make your result reproducible.</span>
<span id="cb31-155"><a href="#cb31-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-158"><a href="#cb31-158" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-159"><a href="#cb31-159" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(adabag)</span>
<span id="cb31-160"><a href="#cb31-160" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123455</span>)</span>
<span id="cb31-161"><a href="#cb31-161" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(<span class="fu">autoprune</span>(SaleHigh <span class="sc">~</span> ., <span class="at">data=</span>df_tr))</span>
<span id="cb31-162"><a href="#cb31-162" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-163"><a href="#cb31-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-164"><a href="#cb31-164" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb31-165"><a href="#cb31-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-166"><a href="#cb31-166" aria-hidden="true" tabindex="-1"></a>The <span class="in">`rpart.plot`</span> package in R provides a convenient <span class="in">`plotcp()`</span> function to plot the complexity parameter table for a decision tree fit with <span class="in">`rpart()`</span>. Unfortunately, <span class="in">`scikit-learn`</span> doesn't provide an equivalent function out of the box. However, you can still calculate the complexity parameter values for your decision tree and plot them using <span class="in">`matplotlib`</span>.</span>
<span id="cb31-167"><a href="#cb31-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-170"><a href="#cb31-170" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb31-171"><a href="#cb31-171" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the paths of the leaf nodes for the Car Seats decision tree using cost complexity pruning</span></span>
<span id="cb31-172"><a href="#cb31-172" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> carseats_tree.cost_complexity_pruning_path(X_train, y_train)</span>
<span id="cb31-173"><a href="#cb31-173" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the effective alphas and total impurities of the leaf nodes from the path object</span></span>
<span id="cb31-174"><a href="#cb31-174" aria-hidden="true" tabindex="-1"></a>ccp_alphas, impurities <span class="op">=</span> path.ccp_alphas, path.impurities</span>
<span id="cb31-175"><a href="#cb31-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-176"><a href="#cb31-176" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a plot to visualize the relationship between effective alphas and total impurities</span></span>
<span id="cb31-177"><a href="#cb31-177" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb31-178"><a href="#cb31-178" aria-hidden="true" tabindex="-1"></a>ax.plot(ccp_alphas, impurities, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">"-"</span>)</span>
<span id="cb31-179"><a href="#cb31-179" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Effective alpha"</span>)</span>
<span id="cb31-180"><a href="#cb31-180" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Total impurity of leaves"</span>)</span>
<span id="cb31-181"><a href="#cb31-181" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Total Impurity vs Effective alpha for Car Seats dataset"</span>)</span>
<span id="cb31-182"><a href="#cb31-182" aria-hidden="true" tabindex="-1"></a>ax.invert_xaxis()</span>
<span id="cb31-183"><a href="#cb31-183" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb31-184"><a href="#cb31-184" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-185"><a href="#cb31-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-186"><a href="#cb31-186" aria-hidden="true" tabindex="-1"></a>This plot only shows the training set results, which doesn't tell us about over-fitting. A better approach is to compute accuracy (a different metric than <span class="in">`rpart`</span>) on a second test set, called the *validation set* used solely for finding the ideal hyperparameters in machine learning. Once we choose the best hyperparameters, we re-train the model one final time with those parameters and compare everything on the test set (but we should no longer change our models based on the test set). We will learn more about this validation set during the upcoming lectures. Here we'll use the two functions <span class="in">`cross_val_score`</span> and <span class="in">`KFold`</span> from the <span class="in">`sklearn.module_selection`</span> sub-module. We will use ten folds to find the ideal <span class="in">`alpha`</span> (equivalent to <span class="in">`cp`</span> from <span class="in">`rpart::rpart()`</span>). This is not using the <span class="in">`1-SE`</span> rule but proposes a good alternative.</span>
<span id="cb31-187"><a href="#cb31-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-190"><a href="#cb31-190" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb31-191"><a href="#cb31-191" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score, KFold</span>
<span id="cb31-192"><a href="#cb31-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-193"><a href="#cb31-193" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plotcp(X_train, y_train, random_state<span class="op">=</span><span class="dv">123</span>):</span>
<span id="cb31-194"><a href="#cb31-194" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a decision tree classifier</span></span>
<span id="cb31-195"><a href="#cb31-195" aria-hidden="true" tabindex="-1"></a>    clf <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span>random_state)</span>
<span id="cb31-196"><a href="#cb31-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-197"><a href="#cb31-197" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the cross-validation scores for different values of alpha</span></span>
<span id="cb31-198"><a href="#cb31-198" aria-hidden="true" tabindex="-1"></a>    path <span class="op">=</span> clf.cost_complexity_pruning_path(X_train, y_train)</span>
<span id="cb31-199"><a href="#cb31-199" aria-hidden="true" tabindex="-1"></a>    ccp_alphas, impurities <span class="op">=</span> path.ccp_alphas, path.impurities</span>
<span id="cb31-200"><a href="#cb31-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-201"><a href="#cb31-201" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform cross-validation for each alpha</span></span>
<span id="cb31-202"><a href="#cb31-202" aria-hidden="true" tabindex="-1"></a>    kfold <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">10</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span>random_state)</span>
<span id="cb31-203"><a href="#cb31-203" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> []</span>
<span id="cb31-204"><a href="#cb31-204" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ccp_alpha <span class="kw">in</span> ccp_alphas:</span>
<span id="cb31-205"><a href="#cb31-205" aria-hidden="true" tabindex="-1"></a>        clf <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span>random_state, ccp_alpha<span class="op">=</span>ccp_alpha)</span>
<span id="cb31-206"><a href="#cb31-206" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> cross_val_score(clf, X_train, y_train, cv<span class="op">=</span>kfold, scoring<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb31-207"><a href="#cb31-207" aria-hidden="true" tabindex="-1"></a>        scores.append(np.mean(score))</span>
<span id="cb31-208"><a href="#cb31-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-209"><a href="#cb31-209" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the cross-validation scores vs alpha</span></span>
<span id="cb31-210"><a href="#cb31-210" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb31-211"><a href="#cb31-211" aria-hidden="true" tabindex="-1"></a>    ax.plot(ccp_alphas, scores, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">"-"</span>)</span>
<span id="cb31-212"><a href="#cb31-212" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">"ccp_alpha"</span>)</span>
<span id="cb31-213"><a href="#cb31-213" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">"Cross-validation score (accuracy)"</span>)</span>
<span id="cb31-214"><a href="#cb31-214" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">"Pruning Complexity Parameter (ccp) vs Cross-validation Score"</span>)</span>
<span id="cb31-215"><a href="#cb31-215" aria-hidden="true" tabindex="-1"></a>    ax.invert_xaxis()</span>
<span id="cb31-216"><a href="#cb31-216" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb31-217"><a href="#cb31-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-218"><a href="#cb31-218" aria-hidden="true" tabindex="-1"></a>plotcp(X_train, y_train)</span>
<span id="cb31-219"><a href="#cb31-219" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-220"><a href="#cb31-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-221"><a href="#cb31-221" aria-hidden="true" tabindex="-1"></a>We can see that the best validation scores are obtained around a <span class="in">`ccp_alpha`</span> of <span class="in">`0.008`</span>. Similar to <span class="in">`cp`</span> from <span class="in">`rpart`</span>, in scikit-learn, the parameter controls the complexity of a classification tree by setting a penalty on the number of leaf nodes. A higher value of results in a simpler tree with fewer splits and more nodes being pruned. More specifically, <span class="in">`alpha`</span> is the regularization parameter used for controlling the cost complexity of the tree. The cost complexity is the sum of the misclassification cost and the complexity cost of the tree. The complexity cost is proportional to the number of terminal nodes (leaves) in the tree. A higher value of <span class="in">`alpha`</span> thus means that the model is less likely to overfit the training data and more likely to generalize better to new, unseen data. However, setting <span class="in">`alpha`</span> too high can result in underfitting and poor model performance on both the training and test data. The optimal <span class="in">`alpha`</span> value depends on the specific dataset and the problem being solved and can be determined through cross-validation or other model selection techniques, as demonstrated above.</span>
<span id="cb31-222"><a href="#cb31-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-223"><a href="#cb31-223" aria-hidden="true" tabindex="-1"></a>Once you find the ideal alpha, you can specify it with the <span class="in">`ccp_alpha`</span> argument in <span class="in">`DecisionTreeClassifier()`</span>. Here we will take <span class="in">`ccp_alpha`</span> as 0.008 for simplicity.</span>
<span id="cb31-224"><a href="#cb31-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-227"><a href="#cb31-227" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb31-228"><a href="#cb31-228" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a decision tree classifier with a ccp_alpha of 0.025</span></span>
<span id="cb31-229"><a href="#cb31-229" aria-hidden="true" tabindex="-1"></a>carseats_tree_prune <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">123</span>, ccp_alpha<span class="op">=</span><span class="fl">0.008</span>)</span>
<span id="cb31-230"><a href="#cb31-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-231"><a href="#cb31-231" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model to the data</span></span>
<span id="cb31-232"><a href="#cb31-232" aria-hidden="true" tabindex="-1"></a>carseats_tree_prune.fit(X_train, y_train)</span>
<span id="cb31-233"><a href="#cb31-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-234"><a href="#cb31-234" aria-hidden="true" tabindex="-1"></a><span class="co"># You can again plot the figure with</span></span>
<span id="cb31-235"><a href="#cb31-235" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb31-236"><a href="#cb31-236" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">10</span>))</span>
<span id="cb31-237"><a href="#cb31-237" aria-hidden="true" tabindex="-1"></a>plot_tree(carseats_tree_prune,filled<span class="op">=</span><span class="va">True</span>, feature_names<span class="op">=</span>X_train.columns, label <span class="op">=</span> <span class="st">'root'</span>,fontsize<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb31-238"><a href="#cb31-238" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'tree_pruned_high_dpi'</span>, dpi<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb31-239"><a href="#cb31-239" aria-hidden="true" tabindex="-1"></a>plt.close()</span>
<span id="cb31-240"><a href="#cb31-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-241"><a href="#cb31-241" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-242"><a href="#cb31-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-245"><a href="#cb31-245" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-246"><a href="#cb31-246" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"tree_pruned_high_dpi.png"</span>)</span>
<span id="cb31-247"><a href="#cb31-247" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-248"><a href="#cb31-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-249"><a href="#cb31-249" aria-hidden="true" tabindex="-1"></a>This model is a lot simpler compared to the first tree made using python (where <span class="in">`ccp_alpha`</span> was 0 by default).</span>
<span id="cb31-250"><a href="#cb31-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-251"><a href="#cb31-251" aria-hidden="true" tabindex="-1"></a>For automatically pruning the tree, unlike the <span class="in">`adabag::autoprune()`</span> function in R's adabag package, scikit-learn does not have a built-in function for automatic pruning of decision trees. Instead, you can use cross-validation to determine the optimal tree depth and use that to prune the tree.</span>
<span id="cb31-252"><a href="#cb31-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-255"><a href="#cb31-255" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb31-256"><a href="#cb31-256" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb31-257"><a href="#cb31-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-258"><a href="#cb31-258" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the decision tree classifier</span></span>
<span id="cb31-259"><a href="#cb31-259" aria-hidden="true" tabindex="-1"></a>tree <span class="op">=</span> DecisionTreeClassifier()</span>
<span id="cb31-260"><a href="#cb31-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-261"><a href="#cb31-261" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the grid search parameters</span></span>
<span id="cb31-262"><a href="#cb31-262" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'max_depth'</span>: <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>)}</span>
<span id="cb31-263"><a href="#cb31-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-264"><a href="#cb31-264" aria-hidden="true" tabindex="-1"></a><span class="co"># Run grid search cross-validation to find optimal tree depth</span></span>
<span id="cb31-265"><a href="#cb31-265" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(tree, param_grid<span class="op">=</span>param_grid, cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb31-266"><a href="#cb31-266" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span>
<span id="cb31-267"><a href="#cb31-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-268"><a href="#cb31-268" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the best estimator to fit and prune the tree</span></span>
<span id="cb31-269"><a href="#cb31-269" aria-hidden="true" tabindex="-1"></a>pruned_tree <span class="op">=</span> grid_search.best_estimator_</span>
<span id="cb31-270"><a href="#cb31-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-271"><a href="#cb31-271" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb31-272"><a href="#cb31-272" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb31-273"><a href="#cb31-273" aria-hidden="true" tabindex="-1"></a>plot_tree(pruned_tree, ax<span class="op">=</span>ax, feature_names<span class="op">=</span>X_train.columns)</span>
<span id="cb31-274"><a href="#cb31-274" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb31-275"><a href="#cb31-275" aria-hidden="true" tabindex="-1"></a><span class="co"># you can choose to re-train the model once again with this new parameter</span></span>
<span id="cb31-276"><a href="#cb31-276" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-277"><a href="#cb31-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-278"><a href="#cb31-278" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb31-279"><a href="#cb31-279" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python approach vs `adabag::autoprune()`</span></span>
<span id="cb31-280"><a href="#cb31-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-281"><a href="#cb31-281" aria-hidden="true" tabindex="-1"></a>The technique above does not explicitly use the 1-SE rule for pruning the decision tree. Instead, it uses cross-validation to find the optimal tree depth based on the mean test score across all folds. According to the documentation of <span class="in">`adabag::autoprune()`</span>, *"The cross validation estimation of the error (xerror) has a random component. To avoid this randomness the 1-SE rule (or 1-SD rule) selects the simplest model with a xerror equal or less than the minimum xerror plus the standard deviation of the minimum xerror."* If you're interested in the 1-SE, see the adapted python code for it below.</span>
<span id="cb31-282"><a href="#cb31-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-283"><a href="#cb31-283" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb31-284"><a href="#cb31-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-285"><a href="#cb31-285" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>**Implementing GridSearchCV with 1-SE rule**<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb31-286"><a href="#cb31-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-289"><a href="#cb31-289" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb31-290"><a href="#cb31-290" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the decision tree classifier</span></span>
<span id="cb31-291"><a href="#cb31-291" aria-hidden="true" tabindex="-1"></a>tree <span class="op">=</span> DecisionTreeClassifier()</span>
<span id="cb31-292"><a href="#cb31-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-293"><a href="#cb31-293" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the grid search parameters</span></span>
<span id="cb31-294"><a href="#cb31-294" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'max_depth'</span>: <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>)}</span>
<span id="cb31-295"><a href="#cb31-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-296"><a href="#cb31-296" aria-hidden="true" tabindex="-1"></a><span class="co"># Run grid search cross-validation to find optimal tree depth</span></span>
<span id="cb31-297"><a href="#cb31-297" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(tree, param_grid<span class="op">=</span>param_grid, cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb31-298"><a href="#cb31-298" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span>
<span id="cb31-299"><a href="#cb31-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-300"><a href="#cb31-300" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the mean and standard error of test scores for each tree depth</span></span>
<span id="cb31-301"><a href="#cb31-301" aria-hidden="true" tabindex="-1"></a>mean_scores <span class="op">=</span> grid_search.cv_results_[<span class="st">'mean_test_score'</span>]</span>
<span id="cb31-302"><a href="#cb31-302" aria-hidden="true" tabindex="-1"></a>std_scores <span class="op">=</span> grid_search.cv_results_[<span class="st">'std_test_score'</span>] <span class="op">/</span> np.sqrt(<span class="dv">10</span>)</span>
<span id="cb31-303"><a href="#cb31-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-304"><a href="#cb31-304" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the optimal depth using the 1-SE rule</span></span>
<span id="cb31-305"><a href="#cb31-305" aria-hidden="true" tabindex="-1"></a>optimal_depth <span class="op">=</span> grid_search.best_params_[<span class="st">'max_depth'</span>]</span>
<span id="cb31-306"><a href="#cb31-306" aria-hidden="true" tabindex="-1"></a>optimal_score <span class="op">=</span> mean_scores[optimal_depth <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb31-307"><a href="#cb31-307" aria-hidden="true" tabindex="-1"></a>se <span class="op">=</span> std_scores[optimal_depth <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb31-308"><a href="#cb31-308" aria-hidden="true" tabindex="-1"></a>best_depth <span class="op">=</span> optimal_depth</span>
<span id="cb31-309"><a href="#cb31-309" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> depth <span class="kw">in</span> <span class="bu">range</span>(optimal_depth <span class="op">-</span> <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb31-310"><a href="#cb31-310" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> mean_scores[depth]</span>
<span id="cb31-311"><a href="#cb31-311" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> score <span class="op">+</span> se <span class="op">&lt;</span> optimal_score:</span>
<span id="cb31-312"><a href="#cb31-312" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb31-313"><a href="#cb31-313" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb31-314"><a href="#cb31-314" aria-hidden="true" tabindex="-1"></a>        best_depth <span class="op">=</span> depth <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb31-315"><a href="#cb31-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-316"><a href="#cb31-316" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the best estimator to fit and prune the tree</span></span>
<span id="cb31-317"><a href="#cb31-317" aria-hidden="true" tabindex="-1"></a>pruned_tree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span>best_depth)</span>
<span id="cb31-318"><a href="#cb31-318" aria-hidden="true" tabindex="-1"></a>pruned_tree.fit(X_train, y_train)</span>
<span id="cb31-319"><a href="#cb31-319" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-320"><a href="#cb31-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-321"><a href="#cb31-321" aria-hidden="true" tabindex="-1"></a>The results are the same as not using 1-SE.</span>
<span id="cb31-322"><a href="#cb31-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-323"><a href="#cb31-323" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb31-324"><a href="#cb31-324" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb31-325"><a href="#cb31-325" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb31-326"><a href="#cb31-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-327"><a href="#cb31-327" aria-hidden="true" tabindex="-1"></a><span class="fu">## Predictions</span></span>
<span id="cb31-328"><a href="#cb31-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-329"><a href="#cb31-329" aria-hidden="true" tabindex="-1"></a>First, use the R plot to determine what is the prediction of the first instance of <span class="in">`MyCarseats`</span>.</span>
<span id="cb31-330"><a href="#cb31-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-331"><a href="#cb31-331" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb31-332"><a href="#cb31-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-333"><a href="#cb31-333" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>**Answer**<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb31-334"><a href="#cb31-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-337"><a href="#cb31-337" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-338"><a href="#cb31-338" aria-hidden="true" tabindex="-1"></a>MyCarseats[<span class="dv">1</span>,]</span>
<span id="cb31-339"><a href="#cb31-339" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-340"><a href="#cb31-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-341"><a href="#cb31-341" aria-hidden="true" tabindex="-1"></a>Follow Left, Left, Left =<span class="sc">\&gt;</span> The predicted answer is "No".</span>
<span id="cb31-342"><a href="#cb31-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-343"><a href="#cb31-343" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb31-344"><a href="#cb31-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-345"><a href="#cb31-345" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb31-346"><a href="#cb31-346" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb31-347"><a href="#cb31-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-348"><a href="#cb31-348" aria-hidden="true" tabindex="-1"></a>The function <span class="in">`predict`</span> can be used build the predictions of the test set (use option <span class="in">`type="class"`</span>). This is similar to the previously seen models: the <span class="in">`predict`</span> function used on an object of class <span class="in">`.rpart`</span> (created by the function <span class="in">`rpart`</span>), in fact, calls the function <span class="in">`predict.rpart`</span> which is adapted to the model.</span>
<span id="cb31-349"><a href="#cb31-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-352"><a href="#cb31-352" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-353"><a href="#cb31-353" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(carseats_tree_prune, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"class"</span>)</span>
<span id="cb31-354"><a href="#cb31-354" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="at">Pred=</span>pred, <span class="at">Obs=</span>df_te<span class="sc">$</span>SaleHigh)</span>
<span id="cb31-355"><a href="#cb31-355" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-356"><a href="#cb31-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-357"><a href="#cb31-357" aria-hidden="true" tabindex="-1"></a>Note that, like most categorical models, you may ask for the probabilities instead of the classes by setting <span class="in">`type="prob"`</span>.</span>
<span id="cb31-358"><a href="#cb31-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-361"><a href="#cb31-361" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-362"><a href="#cb31-362" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(carseats_tree_prune, <span class="at">newdata=</span>df_te, <span class="at">type=</span><span class="st">"prob"</span>)</span>
<span id="cb31-363"><a href="#cb31-363" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-364"><a href="#cb31-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-365"><a href="#cb31-365" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb31-366"><a href="#cb31-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-367"><a href="#cb31-367" aria-hidden="true" tabindex="-1"></a>To print a confusion matrix of the predicted labels versus the true labels, we can use the <span class="in">`crosstab()`</span> function from the <span class="in">`pandas`</span> library. We pass the predicted and true labels as arguments to <span class="in">`crosstab()`</span>, and use the <span class="in">`rownames`</span> and <span class="in">`colnames`</span> parameters to label the rows and columns of the table, respectively.</span>
<span id="cb31-368"><a href="#cb31-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-369"><a href="#cb31-369" aria-hidden="true" tabindex="-1"></a>Finally, we use the <span class="in">`predict_proba()`</span> method of the decision tree classifier to predict the class probabilities for the test data. The predicted probabilities are stored in the <span class="in">`y_probs`</span> variable, which is a <span class="in">`NumPy`</span> array with shape <span class="in">`(n_samples, n_classes)`</span>.</span>
<span id="cb31-370"><a href="#cb31-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-373"><a href="#cb31-373" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb31-374"><a href="#cb31-374" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the class labels for the test data with the python implementation</span></span>
<span id="cb31-375"><a href="#cb31-375" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> carseats_tree_prune.predict(X_test)</span>
<span id="cb31-376"><a href="#cb31-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-377"><a href="#cb31-377" aria-hidden="true" tabindex="-1"></a><span class="co"># Print a confusion matrix of the predicted labels versus the true labels</span></span>
<span id="cb31-378"><a href="#cb31-378" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.crosstab(index<span class="op">=</span>y_pred, columns<span class="op">=</span>y_test, rownames<span class="op">=</span>[<span class="st">'Pred'</span>], colnames<span class="op">=</span>[<span class="st">'Obs'</span>]))</span>
<span id="cb31-379"><a href="#cb31-379" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-380"><a href="#cb31-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-381"><a href="#cb31-381" aria-hidden="true" tabindex="-1"></a>This tree is worse than the R implementation, probably due to differences in other default values that we did not tune for.</span>
<span id="cb31-382"><a href="#cb31-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-385"><a href="#cb31-385" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb31-386"><a href="#cb31-386" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the class probabilities for the test data</span></span>
<span id="cb31-387"><a href="#cb31-387" aria-hidden="true" tabindex="-1"></a>y_probs <span class="op">=</span> carseats_tree_prune.predict_proba(X_test)</span>
<span id="cb31-388"><a href="#cb31-388" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.DataFrame(y_probs))</span>
<span id="cb31-389"><a href="#cb31-389" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-390"><a href="#cb31-390" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb31-391"><a href="#cb31-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-392"><a href="#cb31-392" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interpretation</span></span>
<span id="cb31-393"><a href="#cb31-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-394"><a href="#cb31-394" aria-hidden="true" tabindex="-1"></a>By looking at the tree, interpret the most important features for the Sales: the highest in the tree.</span>
<span id="cb31-395"><a href="#cb31-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-396"><a href="#cb31-396" aria-hidden="true" tabindex="-1"></a>Note that, for the level *`Good`* of the <span class="in">`ShelveLoc`</span> variable, only the <span class="in">`Price`</span> drives the <span class="in">`Sales`</span> (according to the tree). Otherwise, it is a subtle mixture between <span class="in">`Price`</span> and <span class="in">`CompPrice`</span>.</span>
<span id="cb31-397"><a href="#cb31-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-398"><a href="#cb31-398" aria-hidden="true" tabindex="-1"></a><span class="fu"># Regression tree</span></span>
<span id="cb31-399"><a href="#cb31-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-400"><a href="#cb31-400" aria-hidden="true" tabindex="-1"></a>The regression tree concepts are the same as for classification tree. The (main) difference lies in the outcome being predicted as a value instead of a class.</span>
<span id="cb31-401"><a href="#cb31-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-402"><a href="#cb31-402" aria-hidden="true" tabindex="-1"></a>To illustrate this we quickly build a tree on the Sales of the <span class="in">`Carseats`</span> data (no training and test set here; it is simply to illustrate the numerical prediction).</span>
<span id="cb31-403"><a href="#cb31-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-404"><a href="#cb31-404" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb31-405"><a href="#cb31-405" aria-hidden="true" tabindex="-1"></a><span class="fu">## R</span></span>
<span id="cb31-406"><a href="#cb31-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-409"><a href="#cb31-409" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-410"><a href="#cb31-410" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb31-411"><a href="#cb31-411" aria-hidden="true" tabindex="-1"></a>carseats_reg <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Sales <span class="sc">~</span> ., <span class="at">data=</span>Carseats)</span>
<span id="cb31-412"><a href="#cb31-412" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(carseats_reg)</span>
<span id="cb31-413"><a href="#cb31-413" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-414"><a href="#cb31-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-415"><a href="#cb31-415" aria-hidden="true" tabindex="-1"></a>We can see from the graph that the final nodes are associated to a numerical prediction. Use the plot to determine what is the prediction of the first instance of <span class="in">`Carseats`</span>. Please note that here we are not dividing between training and test sets, and we only demonstrate how to do a regression tree, but in practice you should always do that.</span>
<span id="cb31-416"><a href="#cb31-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-417"><a href="#cb31-417" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;</span></span>
<span id="cb31-418"><a href="#cb31-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-419"><a href="#cb31-419" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;summary&gt;</span>**Answer**<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb31-420"><a href="#cb31-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-423"><a href="#cb31-423" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-424"><a href="#cb31-424" aria-hidden="true" tabindex="-1"></a>Carseats[<span class="dv">1</span>,]</span>
<span id="cb31-425"><a href="#cb31-425" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-426"><a href="#cb31-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-427"><a href="#cb31-427" aria-hidden="true" tabindex="-1"></a>Follow Left, Left, Left, Right =<span class="sc">\&gt;</span> the predicted answer is 5.4.</span>
<span id="cb31-428"><a href="#cb31-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-429"><a href="#cb31-429" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb31-430"><a href="#cb31-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-431"><a href="#cb31-431" aria-hidden="true" tabindex="-1"></a>Now make the prediction for all the data and check the quality.</span>
<span id="cb31-432"><a href="#cb31-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-435"><a href="#cb31-435" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb31-436"><a href="#cb31-436" aria-hidden="true" tabindex="-1"></a>carseat_reg_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(carseats_reg)</span>
<span id="cb31-437"><a href="#cb31-437" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(carseat_reg_pred <span class="sc">~</span> Carseats<span class="sc">$</span>Sales,</span>
<span id="cb31-438"><a href="#cb31-438" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"Sales"</span>, <span class="at">ylab=</span><span class="st">"Predictions"</span>)</span>
<span id="cb31-439"><a href="#cb31-439" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="at">col=</span><span class="st">"red"</span>)</span>
<span id="cb31-440"><a href="#cb31-440" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-441"><a href="#cb31-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-442"><a href="#cb31-442" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python</span></span>
<span id="cb31-443"><a href="#cb31-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-444"><a href="#cb31-444" aria-hidden="true" tabindex="-1"></a>For the regression task, we need to select the Sales column with continuous values and then encode it via one of the available options. The default encoder for scikit-learn's <span class="in">`DecisionTreeRegressor`</span> is <span class="in">`OrdinalEncoder`</span>. This means that the categorical variables are encoded during training using an ordinal mapping of the categories to integer values. Therefore, for demonstration purposes only (it doesn't make as much sense as <span class="in">`OneHoteEncoder`</span>), we encode them with <span class="in">`OrdinalEncoder`</span>. To read more about this and why it may not make sense for this dataset, click on the blue box below.</span>
<span id="cb31-445"><a href="#cb31-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-446"><a href="#cb31-446" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb31-447"><a href="#cb31-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-448"><a href="#cb31-448" aria-hidden="true" tabindex="-1"></a><span class="fu">### `OrdinalEncoder` vs `OneHotEncoder`</span></span>
<span id="cb31-449"><a href="#cb31-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-450"><a href="#cb31-450" aria-hidden="true" tabindex="-1"></a>If we use <span class="in">`OrdinalEncoder`</span> to encode the categorical features, we would convert each category to a numerical value based on the order of the categories. For example, suppose the categories for <span class="in">`ShelveLoc`</span> are "Bad", "Good", and "Medium". If we use <span class="in">`OrdinalEncoder`</span>, the encoding would be as follows: "Bad" = 1, "Good" = 2, "Medium" = 3. Similarly, for <span class="in">`Urban`</span> and <span class="in">`US`</span>, we might use "No" = 1 and "Yes" = 2. The resulting encoded features would be numerical, but the ordering might not be meaningful.</span>
<span id="cb31-451"><a href="#cb31-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-452"><a href="#cb31-452" aria-hidden="true" tabindex="-1"></a>On the other hand, if we use <span class="in">`OneHotEncoder`</span> to encode the categorical features, we would create a binary column for each category in each feature. For example, if we use <span class="in">`OneHotEncoder`</span> to encode <span class="in">`ShelveLoc`</span>, we would create three binary columns: <span class="in">`ShelveLoc_Bad`</span>, <span class="in">`ShelveLoc_Good`</span>, and <span class="in">`ShelveLoc_Medium`</span>. For an instance where <span class="in">`ShelveLoc`</span> is "Good", the <span class="in">`ShelveLoc_Good`</span> column would have a value of 1, and the other two columns would have a value of 0. This encoding ensures that each category is treated equally and that there is no implicit ordering between the categories.</span>
<span id="cb31-453"><a href="#cb31-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-454"><a href="#cb31-454" aria-hidden="true" tabindex="-1"></a>In summary, <span class="in">`OrdinalEncoder`</span> is appropriate when the categories have a meaningful order, such as in the case of "low", "medium", and "high" for a feature like <span class="in">`Price`</span>. On the other hand, OneHotEncoder is appropriate when there is no meaningful ordering between the categories, such as in the case of <span class="in">`Urban`</span>, <span class="in">`US`</span>, and <span class="in">`ShelveLoc`</span> for the CarSeats dataset.</span>
<span id="cb31-455"><a href="#cb31-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-456"><a href="#cb31-456" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb31-457"><a href="#cb31-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-460"><a href="#cb31-460" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb31-461"><a href="#cb31-461" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb31-462"><a href="#cb31-462" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OrdinalEncoder</span>
<span id="cb31-463"><a href="#cb31-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-464"><a href="#cb31-464" aria-hidden="true" tabindex="-1"></a><span class="co"># Select different columns for the regression task from the original carsets data</span></span>
<span id="cb31-465"><a href="#cb31-465" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> r.Carseats.drop(columns<span class="op">=</span>[<span class="st">"Sales"</span>]), r.Carseats[<span class="st">"Sales"</span>]</span>
<span id="cb31-466"><a href="#cb31-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-467"><a href="#cb31-467" aria-hidden="true" tabindex="-1"></a><span class="co"># Once again select the categorical columns (this time without `SalesHigh`)</span></span>
<span id="cb31-468"><a href="#cb31-468" aria-hidden="true" tabindex="-1"></a>categorical_cols <span class="op">=</span> [<span class="st">'ShelveLoc'</span>, <span class="st">'Urban'</span>, <span class="st">'US'</span>]</span>
<span id="cb31-469"><a href="#cb31-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-470"><a href="#cb31-470" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode categorical columns as integers</span></span>
<span id="cb31-471"><a href="#cb31-471" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OrdinalEncoder()</span>
<span id="cb31-472"><a href="#cb31-472" aria-hidden="true" tabindex="-1"></a>X[categorical_cols] <span class="op">=</span> encoder.fit_transform(X[categorical_cols])</span>
<span id="cb31-473"><a href="#cb31-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-474"><a href="#cb31-474" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the regression tree model</span></span>
<span id="cb31-475"><a href="#cb31-475" aria-hidden="true" tabindex="-1"></a>carseats_reg <span class="op">=</span> DecisionTreeRegressor(random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb31-476"><a href="#cb31-476" aria-hidden="true" tabindex="-1"></a>carseats_reg.fit(X, y)</span>
<span id="cb31-477"><a href="#cb31-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-478"><a href="#cb31-478" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the tree (a bit messy)</span></span>
<span id="cb31-479"><a href="#cb31-479" aria-hidden="true" tabindex="-1"></a><span class="co"># fig, ax = plt.subplots(figsize=(12, 8))</span></span>
<span id="cb31-480"><a href="#cb31-480" aria-hidden="true" tabindex="-1"></a><span class="co"># plot_tree(carseats_reg, ax=ax, feature_names=X.columns)</span></span>
<span id="cb31-481"><a href="#cb31-481" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.show()</span></span>
<span id="cb31-482"><a href="#cb31-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-483"><a href="#cb31-483" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-484"><a href="#cb31-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-487"><a href="#cb31-487" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb31-488"><a href="#cb31-488" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the training data</span></span>
<span id="cb31-489"><a href="#cb31-489" aria-hidden="true" tabindex="-1"></a>carseat_reg_pred <span class="op">=</span> carseats_reg.predict(X)</span>
<span id="cb31-490"><a href="#cb31-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-491"><a href="#cb31-491" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a scatter plot of predicted versus true values</span></span>
<span id="cb31-492"><a href="#cb31-492" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb31-493"><a href="#cb31-493" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb31-494"><a href="#cb31-494" aria-hidden="true" tabindex="-1"></a>ax.scatter(y, carseat_reg_pred, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb31-495"><a href="#cb31-495" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Sales'</span>)</span>
<span id="cb31-496"><a href="#cb31-496" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Predictions'</span>)</span>
<span id="cb31-497"><a href="#cb31-497" aria-hidden="true" tabindex="-1"></a>ax.plot(ax.get_xlim(), ax.get_ylim(), ls<span class="op">=</span><span class="st">"--"</span>, c<span class="op">=</span><span class="st">".3"</span>)</span>
<span id="cb31-498"><a href="#cb31-498" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb31-499"><a href="#cb31-499" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb31-500"><a href="#cb31-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-501"><a href="#cb31-501" aria-hidden="true" tabindex="-1"></a>This perfect line indicates that we (perfectly) over-fit the data, which is a significant danger (bias-variance trade-off). That's why you need both training and test sets (and preferably a validation set)!</span>
<span id="cb31-502"><a href="#cb31-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-503"><a href="#cb31-503" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb31-504"><a href="#cb31-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-505"><a href="#cb31-505" aria-hidden="true" tabindex="-1"></a><span class="fu"># You turn</span></span>
<span id="cb31-506"><a href="#cb31-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-507"><a href="#cb31-507" aria-hidden="true" tabindex="-1"></a>Use a regression tree to fit nursing data (outcome = <span class="in">`cost`</span>). Fit the tree using a training set, prune the tree and make the scatterplot "obs vs pred" on the test set to analyze the quality.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">© Copyright 2024, <a href="https://iliaazizi.com/">Ilia Azizi &amp; Marc-Olivier Boldi</a></div>   
    <div class="nav-footer-right">This page is built with 🤍 and <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>


</body></html>