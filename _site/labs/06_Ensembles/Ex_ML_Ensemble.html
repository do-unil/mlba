<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>MLBA - S24 - Ensemble Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../labs/07_InterpretableML/Ex_ML_VarImp.html" rel="next">
<link href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" rel="prev">
<link href="../../images/logo.dark.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script><script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="../labs.css">
<meta property="og:title" content="MLBA - S24 - Ensemble Methods">
<meta property="og:description" content="Homepage for Machine Learning in Business Analytics at HEC Lausanne, Spring 2024.">
<meta property="og:site_name" content="MLBA - S24 ">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../labs/06_Ensembles/Ex_ML_Ensemble.html">Ensemble Methods</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../images/logo.light.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
      <div class="sidebar-tools-main tools-wide">
    <a href="http://moodle2.unil.ch/course/view.php?id=8715" title="Moodle" class="quarto-navigation-tool px-1" aria-label="Moodle"><i class="bi bi-person-rolodex"></i></a>
    <a href="https://github.com/do-unil/mlba" title="GitHub Repo" class="quarto-navigation-tool px-1" aria-label="GitHub Repo"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">Course information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../schedule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../links.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Useful links</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../faq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FAQ</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Lectures</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/00_lab/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Structure &amp; Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/031_LinearLogisticRegression/Ex_ML_LinLogReg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear &amp; Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/032_Trees/Ex_ML_Tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/033_NeuralNetworks/EX_ML_NN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/034_SupportVectorMachine/Ex_ML_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/03_Models/035_KNN/Ex_ML_KNN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">K-Nearest Neighbors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/04_Metrics/Ex_ML_Scoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Splitting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/06_Ensembles/Ex_ML_Ensemble.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Ensemble Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/07_InterpretableML/Ex_ML_VarImp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretable ML</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/081_Clustering/Ex_ML_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/082_DimensionReduction/Ex_ML_PCA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../labs/08_UnsupervisedLearning/083_AutoEncoders/Ex_ML_Autoencoder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Autoencoders</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
 <span class="menu-text">Assessments</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/exam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exam</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../assessments/project.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Resources</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">On this page</h2>
   
  <ul>
<li>
<a href="#random-forest" id="toc-random-forest" class="nav-link active" data-scroll-target="#random-forest">Random Forest</a>
  <ul class="collapse">
<li>
<a href="#classification" id="toc-classification" class="nav-link" data-scroll-target="#classification">Classification</a>
  <ul class="collapse">
<li><a href="#data-preparation-for-random-forest" id="toc-data-preparation-for-random-forest" class="nav-link" data-scroll-target="#data-preparation-for-random-forest">Data preparation for Random Forest</a></li>
  <li><a href="#training-and-testing-the-model" id="toc-training-and-testing-the-model" class="nav-link" data-scroll-target="#training-and-testing-the-model">Training and testing the model</a></li>
  <li><a href="#variable-importance" id="toc-variable-importance" class="nav-link" data-scroll-target="#variable-importance">Variable importance</a></li>
  </ul>
</li>
  <li><a href="#regression" id="toc-regression" class="nav-link" data-scroll-target="#regression">Regression</a></li>
  </ul>
</li>
  <li>
<a href="#gradient-boosting-machines-gbm" id="toc-gradient-boosting-machines-gbm" class="nav-link" data-scroll-target="#gradient-boosting-machines-gbm">Gradient Boosting Machines (GBM)</a>
  <ul class="collapse">
<li>
<a href="#classification-1" id="toc-classification-1" class="nav-link" data-scroll-target="#classification-1">Classification</a>
  <ul class="collapse">
<li><a href="#training-and-testing-the-model-1" id="toc-training-and-testing-the-model-1" class="nav-link" data-scroll-target="#training-and-testing-the-model-1">Training and testing the model</a></li>
  </ul>
</li>
  <li><a href="#regression-1" id="toc-regression-1" class="nav-link" data-scroll-target="#regression-1">Regression</a></li>
  </ul>
</li>
  <li>
<a href="#bonus-xgboost" id="toc-bonus-xgboost" class="nav-link" data-scroll-target="#bonus-xgboost">Bonus: XGBoost</a>
  <ul class="collapse">
<li><a href="#what-is-xgboost" id="toc-what-is-xgboost" class="nav-link" data-scroll-target="#what-is-xgboost">What is XGBoost?</a></li>
  <li><a href="#modelling-with-xgboost" id="toc-modelling-with-xgboost" class="nav-link" data-scroll-target="#modelling-with-xgboost">Modelling with XGBoost</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/06_Ensembles/Ex_ML_Ensemble.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../labs/00_lab/setup.html">Labs</a></li><li class="breadcrumb-item"><a href="../../labs/06_Ensembles/Ex_ML_Ensemble.html">Ensemble Methods</a></li></ol></nav><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Ensemble Methods</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><section id="random-forest" class="level1"><h1>Random Forest</h1>
<p>In this part of the lab, we will look at how the <code>randomForest</code> library (alternative to <code>ranger</code>) can be applied for classification and regression tasks. At the very end, please feel free to apply these techniques to one of your favorite datasets seen in class (classification or regression).</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hyperparameters of RF
</div>
</div>
<div class="callout-body-container callout-body">
<p>R (using the <code>randomForest</code> library):</p>
<ol type="1">
<li>
<code>ntree</code>: The number of trees in the forest (equivalent to <code>n_estimators</code> in python).</li>
<li>
<code>mtry</code>: The number of features to consider when looking for the best split. (similar to <code>max_features</code> in python)</li>
<li>
<code>max.depth</code>: The maximum depth of each tree.</li>
<li>
<code>nodesize</code>: The minimum number of samples required to split an internal node (equivalent to <code>min_samples_split</code> in python).</li>
</ol>
<p>Python (using the <code>sklearn</code> library):</p>
<ol type="1">
<li>
<code>n_estimators</code>: The number of trees in the forest.</li>
<li>
<code>max_features</code>: The number of features to consider when looking for the best split.</li>
<li>
<code>max_depth</code>: The maximum depth of each tree.</li>
<li>
<code>min_samples_split</code>: The minimum number of samples required to split an internal node.</li>
<li>
<code>min_samples_leaf</code>: The minimum number of samples required to be at a leaf node.</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Few tips on RF hyperparameters
</div>
</div>
<div class="callout-body-container callout-body">
<p>A few (among many) tips for finding the ideal hyperparameters for RF:</p>
<ol type="1">
<li>
<code>ntree</code> (R) / <code>n_estimators</code> (python): Use a large number of trees in the forest to improve model performance, but be aware of the increased computation time. The default value is usually a good starting point.</li>
<li>
<code>mtry</code> (R) / <code>max_features</code> (python): Experiment with different values, usually starting with the default (square root of the number of features for classification or one-third of the number of features for regression). Increasing this value may improve model performance but can also increase computation time.</li>
<li>
<code>max.depth</code>: Control the depth of each tree to manage overfitting. Deeper trees capture more complex patterns but can lead to overfitting. Experiment with different values, keeping in mind that a shallower tree can be more interpretable and less prone to overfitting.</li>
<li>
<code>nodesize</code> (R) / <code>min_samples_split</code> (python): Increasing this value can help reduce overfitting, but setting it too high might lead to underfitting. Experiment with different values to find the optimal balance.</li>
</ol>
</div>
</div>
<section id="classification" class="level2"><h2 class="anchored" data-anchor-id="classification">Classification</h2>
<section id="data-preparation-for-random-forest" class="level3"><h3 class="anchored" data-anchor-id="data-preparation-for-random-forest">Data preparation for Random Forest</h3>
<p>Load the library <code>randomForest</code> in R. Then, load the <code>wine</code> data set. This dataset is about white wine quality (in fact Portuguese vinho verde). The data contains 11 numerical features and 1 factor variable:</p>
<ul>
<li><code>fixed.acidity</code></li>
<li><code>volatile.acidity</code></li>
<li><code>citric.acid</code></li>
<li><code>residual.sugar</code></li>
<li><code>chlorides</code></li>
<li><code>free.sulfur.dioxide</code></li>
<li><code>total.sulfur.dioxide</code></li>
<li><code>density</code></li>
<li><code>pH</code></li>
<li><code>sulphates</code></li>
<li><code>alcohol</code></li>
<li><code>quality: Good/Bad</code></li>
</ul>
<p>All the numerical features have units. The data source can be found <a href="https://archive.ics.uci.edu/ml/datasets/wine+quality">here</a>. For simplicity, only an extraction of 200 wines are used in this exercise. Note that in the original data set, the <code>quality</code> is a score (0 to 10) that was turned as factor here for the exercise (Bad: 0 to 5, Good: 6 to 10). Also, note that in the data source, the objective is to predict the quality from the other features (supervised learning).</p>
<p>As mentioned, the outcome variable used for this dataset is the wine <code>quality</code>. We should first coerce the classes as factors. Then, we make the training/test set random split with a 75/25 scheme.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.stat.berkeley.edu/~breiman/RandomForests/">randomForest</a></span><span class="op">)</span></span>
<span><span class="va">wine</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org//reference/here.html">here</a></span><span class="op">(</span><span class="st">"data/Wine.csv"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">wine</span><span class="op">$</span><span class="va">quality</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">wine</span><span class="op">$</span><span class="va">quality</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># define a function to get the splitting index (training and testing) of a given dataset</span></span>
<span><span class="va">get_split_index</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">dataset</span>, <span class="va">train_proportion</span> <span class="op">=</span> <span class="fl">0.75</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span>  <span class="va">index</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span></span>
<span>      x <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,</span>
<span>      size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">dataset</span><span class="op">)</span>,</span>
<span>      replace <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>      prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">train_proportion</span>, <span class="fl">1</span> <span class="op">-</span> <span class="va">train_proportion</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">index</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">wine_index</span> <span class="op">&lt;-</span> <span class="fu">get_split_index</span><span class="op">(</span><span class="va">wine</span><span class="op">)</span></span>
<span><span class="va">wine_tr</span> <span class="op">&lt;-</span> <span class="va">wine</span><span class="op">[</span><span class="va">wine_index</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span></span>
<span><span class="va">wine_te</span> <span class="op">&lt;-</span> <span class="va">wine</span><span class="op">[</span><span class="va">wine_index</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load the course python environment as usual with a r code chunks.</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rstudio.github.io/reticulate/">reticulate</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/use_python.html">use_condaenv</a></span><span class="op">(</span><span class="st">"MLBA"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Similar to the previous labs, in python, we can use the usual <code>sklearn</code> library to do all our modelling. Please note that we will load the data again in python to make the demo easier. Additionally, weâ€™ll load all the necessary libraries for this lab in this code chunk.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, RandomForestRegressor</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score, mean_squared_error</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># we first move up one directory to achieve relative paths</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>wine <span class="op">=</span> pd.read_csv(<span class="st">'../data/Wine.csv'</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>wine[<span class="st">'quality'</span>] <span class="op">=</span> wine[<span class="st">'quality'</span>].astype(<span class="st">'category'</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Split wine dataset into train and test</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>train_wine, test_wine <span class="op">=</span> train_test_split(wine, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p><strong>Note:</strong> Here, we have written a function to make the split as we will also need to apply it also for another dataset in the regression part.</p>
</section><section id="training-and-testing-the-model" class="level3"><h3 class="anchored" data-anchor-id="training-and-testing-the-model">Training and testing the model</h3>
<p>Fit a random forest on the train set. The target is the <code>taste</code> variable that we want to predict. Specify for the number of trees <code>ntree=1000</code> (by default, the function selects <span class="math inline">500</span> trees). Remember to exclude <code>quality</code> in the predictors of the formula. Also, use the option <code>importance=TRUE</code>, we will need it afterward. Then test the model by computing the accuracy on the test set. You may use <code>confusionMatrix</code> from <code>caret</code>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">wine_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest</a></span><span class="op">(</span><span class="va">quality</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">wine_tr</span>, ntree<span class="op">=</span><span class="fl">1000</span>, importance<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">wine.pred_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">wine_rf</span>, newdata<span class="op">=</span><span class="va">wine_te</span><span class="op">)</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/caret/">caret</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span>data<span class="op">=</span><span class="va">wine.pred_rf</span>, reference <span class="op">=</span> <span class="va">wine_te</span><span class="op">$</span><span class="va">quality</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Random Forest classifier on the train set</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>wine_rf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>wine_rf.fit(train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_wine[<span class="st">'quality'</span>])</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the accuracy</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>wine_pred_rf <span class="op">=</span> wine_rf.predict(test_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(test_wine[<span class="st">'quality'</span>], wine_pred_rf))</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(test_wine[<span class="st">'quality'</span>], wine_pred_rf))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This model is worse than the R version mostly because of the different defaults.</p>
</div>
</div>
</div>
</section><section id="variable-importance" class="level3"><h3 class="anchored" data-anchor-id="variable-importance">Variable importance</h3>
<p>Extract the model-specific variable importance using the functions <code>varImpPlot</code> (plots) and <code>importance</code> (values) on the model. Observe well that the mean decrease in accuracy of each variable is also computed for each specific class. In particular, what makes <code>density</code> special for predicting <code>Good</code> compare to another variable (like for example <code>citric.acid</code>)?</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/varImpPlot.html">varImpPlot</a></span><span class="op">(</span><span class="va">wine_rf</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/importance.html">importance</a></span><span class="op">(</span><span class="va">wine_rf</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable importance</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>wine_importances <span class="op">=</span> pd.Series(wine_rf.feature_importances_, index<span class="op">=</span>train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>).columns)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>wine_importances.sort_values(ascending<span class="op">=</span><span class="va">False</span>).plot(kind<span class="op">=</span><span class="st">'bar'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p><code>density</code> is important for predicting the <code>Good</code> since their predictions is much less accurate if we do not use it. <code>citric.acid</code> is both overall less important than <code>density</code> but especially for prediction of <code>Good</code>.</p>
</section></section><section id="regression" class="level2"><h2 class="anchored" data-anchor-id="regression">Regression</h2>
<p>In this part, we will be using the <code>real_estate_data.csv</code> once again. After reading the data, apply a random forest to predict <code>price</code> using all the other variables except <code>No</code>, <code>Month</code> and <code>Year</code>. Compute the RMSE and inspect the prediction quality with a graph. Note that the importance is not specific to any class here.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://magrittr.tidyverse.org">magrittr</a></span><span class="op">)</span></span>
<span><span class="va">real_estate_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org//reference/here.html">here</a></span><span class="op">(</span><span class="st">"labs/data/real_estate_data.csv"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># select the columns of interest</span></span>
<span><span class="va">real_estate_data</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">real_estate_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">No</span>, <span class="va">Month</span>, <span class="va">Year</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># once again, divide the data into training and testing sets using the function created earlier</span></span>
<span><span class="va">restate_index</span> <span class="op">&lt;-</span> <span class="fu">get_split_index</span><span class="op">(</span><span class="va">real_estate_data</span><span class="op">)</span></span>
<span><span class="va">restate_tr</span> <span class="op">&lt;-</span> <span class="va">real_estate_data</span><span class="op">[</span><span class="va">restate_index</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span></span>
<span><span class="va">restate_te</span> <span class="op">&lt;-</span> <span class="va">real_estate_data</span><span class="op">[</span><span class="va">restate_index</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span></span>
<span></span>
<span><span class="co"># apply the RF model as a regression</span></span>
<span><span class="va">restate_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest</a></span><span class="op">(</span><span class="va">Price</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">restate_tr</span>, ntree<span class="op">=</span><span class="fl">1000</span>, importance<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">restate.pred_rf</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">restate_rf</span>, newdata<span class="op">=</span><span class="va">restate_te</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute rmse and plot the results as well the VarImp</span></span>
<span><span class="op">(</span><span class="va">rmse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">-</span> <span class="va">restate.pred_rf</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">~</span> <span class="va">restate.pred_rf</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/varImpPlot.html">varImpPlot</a></span><span class="op">(</span><span class="va">restate_rf</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/importance.html">importance</a></span><span class="op">(</span><span class="va">restate_rf</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load real estate dataset</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="op">=</span> pd.read_csv(<span class="st">"../data/real_estate_data.csv"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="op">=</span> real_estate_data.drop([<span class="st">'No'</span>, <span class="st">'Month'</span>, <span class="st">'Year'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Split real estate dataset into train and test</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>train_restate, test_restate <span class="op">=</span> train_test_split(real_estate_data, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Random Forest regressor on the train set</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>restate_rf <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>restate_rf.fit(train_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_restate[<span class="st">'Price'</span>])</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>restate_pred_rf <span class="op">=</span> restate_rf.predict(test_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> np.sqrt(mean_squared_error(test_restate[<span class="st">'Price'</span>], restate_pred_rf))</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RMSE:"</span>, rmse)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the prediction quality</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>plt.scatter(test_restate[<span class="st">'Price'</span>], restate_pred_rf)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Actual Price'</span>)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted Price'</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], [<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable importance</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>restate_importances <span class="op">=</span> pd.Series(restate_rf.feature_importances_, index<span class="op">=</span>train_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>).columns)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>restate_importances.sort_values(ascending<span class="op">=</span><span class="va">False</span>).plot(kind<span class="op">=</span><span class="st">'bar'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>Compare this model with the one you came up with in <code>Ex_ML_LinLogReg</code> . Which one would you go for?</p>
</section></section><section id="gradient-boosting-machines-gbm" class="level1"><h1>Gradient Boosting Machines (GBM)</h1>
<p>In this part of the lab, we will look at how the <code>gbm</code> library in R and the <code>GradientBoostingClassifier</code> and <code>GradientBoostingRegressor</code> in Python can be applied for classification and regression tasks. We will continue using the <code>wine</code> dataset for classification and <code>real_estate_data</code> for regression.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hyperparameters of GBM
</div>
</div>
<div class="callout-body-container callout-body">
<p>R (using the <code>gbm</code> library):</p>
<ol type="1">
<li>
<code>n.trees</code>: The number of boosting stages to perform (equivalent to <code>n_estimators</code> in python).</li>
<li>
<code>interaction.depth</code>: The maximum depth of each tree (equivalent to <code>max_depth</code> in python).</li>
<li>
<code>shrinkage</code>: The learning rate.</li>
<li>
<code>n.minobsinnode</code>: The minimum number of samples required to split an internal node (equivalent to <code>min_samples_split</code> in python).</li>
<li>
<code>bag.fraction</code>: The fraction of samples to be used for fitting individual base learners (equivalent to <code>subsample</code> in python).</li>
</ol>
<p>Python (using the <code>sklearn</code> library):</p>
<ol type="1">
<li>
<code>n_estimators</code>: The number of boosting stages to perform. Similar to Random Forest, increasing the number of estimators can improve the modelâ€™s performance but may also increase the computational complexity and training time.</li>
<li>
<code>learning_rate</code>: The learning rate shrinks the contribution of each tree. A smaller learning rate requires more boosting stages to achieve the same performance as a larger learning rate, but it can also result in a more robust model.</li>
<li>
<code>max_depth</code>: The maximum depth of each tree. Similar to Random Forest, a higher depth can capture more complex patterns in the data, but it may also lead to overfitting.</li>
<li>
<code>min_samples_split</code>: The minimum number of samples required to split an internal node. Similar to Random Forest, a smaller value allows the model to capture finer details in the data, while a larger value can help prevent overfitting.</li>
<li>
<code>min_samples_leaf</code>: The minimum number of samples required to be at a leaf node. Similar to Random Forest, a smaller value allows the model to capture finer details, while a larger value can help prevent overfitting.</li>
<li>
<code>subsample</code>: The fraction of samples to be used for fitting individual base learners. A value smaller than 1.0 can lead to a reduction in variance and an increase in bias, resulting in a more robust model.</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Few tips on GBM hyperparameters
</div>
</div>
<div class="callout-body-container callout-body">
<p>Similar to R, here are some tips for finding the best combination of the hyperparameters:</p>
<ol type="1">
<li>
<code>n.trees</code> (R) / <code>n_estimators</code> (python): Start with a lower number of trees and increase it until no further improvement in performance is observed. Be aware of the increased computation time with a larger number of trees.</li>
<li>
<code>interaction.depth</code> (R) / <code>max_depth</code> (python): Keep the depth of each tree relatively shallow (3-5 levels) to prevent overfitting. Deeper trees can capture more complex patterns but may lead to overfitting.</li>
<li>
<code>shrinkage</code> (R) / <code>learning_rate</code> (python): Use a smaller learning rate for better model performance, but be prepared for slower convergence and increased computation time. Typically, values range between 0.01 and 0.1.</li>
<li>
<code>n.minobsinnode</code> (R) / <code>min_samples_split</code> (python): Similar to Random Forest, experiment with different values to find the optimal balance between overfitting and underfitting.</li>
<li>
<code>bag.fraction</code> (R) / <code>subsample</code> (python): Using a subsample of the data (e.g., 0.5-0.8) can help reduce overfitting and speed up the training process. Experiment with different values to find the best trade-off between performance and computation time.</li>
</ol>
</div>
</div>
<section id="classification-1" class="level2"><h2 class="anchored" data-anchor-id="classification-1">Classification</h2>
<section id="training-and-testing-the-model-1" class="level3"><h3 class="anchored" data-anchor-id="training-and-testing-the-model-1">Training and testing the model</h3>
<p>We now fit a GBM model on the <code>wine</code> training set and apply it to the same target variable <code>quality</code>. We can train the model and add</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/gbm-developers/gbm">gbm</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">wine_gbm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gbm/man/gbm.html">gbm</a></span><span class="op">(</span><span class="va">quality</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">wine_tr</span>, distribution<span class="op">=</span><span class="st">"multinomial"</span>, n.trees<span class="op">=</span><span class="fl">1000</span>, interaction.depth<span class="op">=</span><span class="fl">4</span>, shrinkage<span class="op">=</span><span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="va">wine.pred_gbm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">wine_gbm</span>, newdata<span class="op">=</span><span class="va">wine_te</span>, n.trees<span class="op">=</span><span class="fl">1000</span>, type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span></span>
<span><span class="va">wine.pred_gbm_class</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">wine.pred_gbm</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">wine_te</span><span class="op">$</span><span class="va">quality</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">wine_te</span><span class="op">$</span><span class="va">quality</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">wine.pred_gbm_class</span><span class="op">)</span>, <span class="va">wine_te</span><span class="op">$</span><span class="va">quality</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingClassifier</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Gradient Boosting classifier on the train set</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>wine_gbm <span class="op">=</span> GradientBoostingClassifier(n_estimators<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.01</span>, max_depth<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>wine_gbm.fit(train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_wine[<span class="st">'quality'</span>])</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the accuracy</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>wine_pred_gbm <span class="op">=</span> wine_gbm.predict(test_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(test_wine[<span class="st">'quality'</span>], wine_pred_gbm))</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(test_wine[<span class="st">'quality'</span>], wine_pred_gbm))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section></section><section id="regression-1" class="level2"><h2 class="anchored" data-anchor-id="regression-1">Regression</h2>
<p>In this part, we will continue using the <code>real_estate_data.csv</code>. Fit a GBM model on the real estate training set to predict <code>price</code> using all the other variables except <code>No</code>, <code>Month</code>, and <code>Year</code>. Then compute the metrics and plot the predictions.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">restate_gbm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/gbm/man/gbm.html">gbm</a></span><span class="op">(</span><span class="va">Price</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">restate_tr</span>, distribution<span class="op">=</span><span class="st">"gaussian"</span>, n.trees<span class="op">=</span><span class="fl">1000</span>, interaction.depth<span class="op">=</span><span class="fl">4</span>, shrinkage<span class="op">=</span><span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="va">restate.pred_gbm</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">restate_gbm</span>, newdata<span class="op">=</span><span class="va">restate_te</span>, n.trees<span class="op">=</span><span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute rmse and plot the results</span></span>
<span><span class="op">(</span><span class="va">rmse_gbm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">-</span> <span class="va">restate.pred_gbm</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">~</span> <span class="va">restate.pred_gbm</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run the code below if you have not cleared the plot yet</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Gradient Boosting regressor on the train set</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>restate_gbm <span class="op">=</span> GradientBoostingRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.01</span>, max_depth<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>restate_gbm.fit(train_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_restate[<span class="st">'Price'</span>])</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>restate_pred_gbm <span class="op">=</span> restate_gbm.predict(test_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>rmse_gbm <span class="op">=</span> np.sqrt(mean_squared_error(test_restate[<span class="st">'Price'</span>], restate_pred_gbm))</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RMSE:"</span>, rmse_gbm)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the prediction quality</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(test_restate[<span class="st">'Price'</span>], restate_pred_gbm)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Actual Price'</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted Price'</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], [<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>Compare the GBM model with the Random Forest model you came up with earlier. Which one would you go for?</p>
</section></section><section id="bonus-xgboost" class="level1"><h1>Bonus: XGBoost</h1>
<section id="what-is-xgboost" class="level2"><h2 class="anchored" data-anchor-id="what-is-xgboost">What is XGBoost?</h2>
<p>XGBoost (Extreme Gradient Boosting) is an optimized implementation of the gradient boosting algorithm. It is designed for high performance and efficient memory usage. XGBoost improves upon the base Gradient Boosting Machine (GBM) by incorporating regularization to prevent overfitting and implementing parallel processing techniques for faster training. The algorithm also offers built-in cross-validation and early stopping to save time and resources during model training.</p>
</section><section id="modelling-with-xgboost" class="level2"><h2 class="anchored" data-anchor-id="modelling-with-xgboost">Modelling with XGBoost</h2>
<p>Weâ€™ll use the <a href="https://xgboost.readthedocs.io/en/stable/index.html"><code>xgboost</code></a> library in both R and python. You can see some of the hyperparameters below:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hyperparameters of XGBoost
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>
<code>eta</code>: Controls the learning rate, which determines the step size at each iteration while updating the model weights. Smaller values make the model more robust to overfitting but require more iterations to converge. Typical values range from 0.01 to 0.3.</li>
<li>
<code>max_depth</code>: Controls the maximum depth of each tree. Deeper trees can model more complex relationships but are more prone to overfitting. Experiment with different values, keeping in mind that a shallower tree can be more interpretable and less prone to overfitting.</li>
<li>
<code>min_child_weight</code>: Controls the minimum sum of instance weights needed in a child node. Increasing this value helps to prevent overfitting by making the model more conservative.</li>
</ol>
</div>
</div>
<p>You can read more about the package in its documentation.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">R</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Python</a></li>
</ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Install and load the package</span></span>
<span><span class="co"># install.packages("xgboost")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dmlc/xgboost">xgboost</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prepare data for XGBoost</span></span>
<span><span class="va">dtrain</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.DMatrix.html">xgb.DMatrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">restate_tr</span><span class="op">[</span>, <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">restate_tr</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>, label <span class="op">=</span> <span class="va">restate_tr</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span>
<span><span class="va">dtest</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.DMatrix.html">xgb.DMatrix</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">restate_te</span><span class="op">[</span>, <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">restate_te</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>, label <span class="op">=</span> <span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Set hyperparameters</span></span>
<span><span class="va">params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  objective <span class="op">=</span> <span class="st">"reg:squarederror"</span>,</span>
<span>  eta <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  max_depth <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  min_child_weight <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  subsample <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  colsample_bytree <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Train the model</span></span>
<span><span class="va">xgb_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html">xgb.train</a></span><span class="op">(</span><span class="va">params</span>, <span class="va">dtrain</span>, nrounds <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Test the model and compute the RMSE</span></span>
<span><span class="va">restate_pred_xgb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">xgb_model</span>, <span class="va">dtest</span><span class="op">)</span></span>
<span><span class="va">rmse_xgb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">restate_te</span><span class="op">$</span><span class="va">Price</span> <span class="op">-</span> <span class="va">restate_pred_xgb</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"RMSE:"</span>, <span class="va">rmse_xgb</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<p>We will first install the <code>xgboost</code> with a R code chunk:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">reticulate</span><span class="fu">::</span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/py_install.html">py_install</a></span><span class="op">(</span><span class="st">"xgboost"</span>, pip<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then we can run the XGBoost model with <code>xgboost</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install and load the package</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for XGBoost</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>dtrain <span class="op">=</span> xgb.DMatrix(train_restate.drop(<span class="st">"Price"</span>, axis<span class="op">=</span><span class="dv">1</span>), label<span class="op">=</span>train_restate[<span class="st">"Price"</span>])</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>dtest <span class="op">=</span> xgb.DMatrix(test_restate.drop(<span class="st">"Price"</span>, axis<span class="op">=</span><span class="dv">1</span>), label<span class="op">=</span>test_restate[<span class="st">"Price"</span>])</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Set hyperparameters</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"objective"</span>: <span class="st">"reg:squarederror"</span>,</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eta"</span>: <span class="fl">0.1</span>,</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"max_depth"</span>: <span class="dv">3</span>,</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"min_child_weight"</span>: <span class="dv">1</span>,</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subsample"</span>: <span class="dv">1</span>,</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"colsample_bytree"</span>: <span class="dv">1</span>,</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> xgb.train(params, dtrain, num_boost_round<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>restate_pred_xgb <span class="op">=</span> xgb_model.predict(dtest)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>rmse_xgb <span class="op">=</span> np.sqrt(mean_squared_error(test_restate[<span class="st">"Price"</span>], restate_pred_xgb))</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RMSE:"</span>, rmse_xgb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Although initially our GBM suffered compared to the RF, we can see that XGBoost can help improve the result (the case for the python implementation). However, random forest still outperforms all the other models.</p>
</div>
</div>
</div>
<p>Feel free to apply XGBoost to the dataset of your choice.</p>


<!-- -->

</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../labs/05_DataSplitting/Ex_ML_Data_Splitting.html" class="pagination-link  aria-label=" data="" splitting="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Data Splitting</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../labs/07_InterpretableML/Ex_ML_VarImp.html" class="pagination-link" aria-label="Interpretable ML">
        <span class="nav-page-text">Interpretable ML</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb17" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Ensemble Methods"</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r global_options, include = FALSE}</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::opts_chunk$set(eval = F, fig.align="center", results = 'hide', fig.show = 'hide')</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="fu"># Random Forest</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>In this part of the lab, we will look at how the <span class="in">`randomForest`</span> library (alternative to <span class="in">`ranger`</span>) can be applied for classification and regression tasks. At the very end, please feel free to apply these techniques to one of your favorite datasets seen in class (classification or regression).</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hyperparameters of RF </span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>R (using the <span class="in">`randomForest`</span> library): </span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`ntree`</span>: The number of trees in the forest (equivalent to <span class="in">`n_estimators`</span> in python). </span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`mtry`</span>: The number of features to consider when looking for the best split. (similar to <span class="in">`max_features`</span> in python)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`max.depth`</span>: The maximum depth of each tree. </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`nodesize`</span>: The minimum number of samples required to split an internal node (equivalent to <span class="in">`min_samples_split`</span> in python).</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>Python (using the <span class="in">`sklearn`</span> library): </span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`n_estimators`</span>: The number of trees in the forest. </span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`max_features`</span>: The number of features to consider when looking for the best split. </span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`max_depth`</span>: The maximum depth of each tree. </span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`min_samples_split`</span>: The minimum number of samples required to split an internal node. </span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span><span class="in">`min_samples_leaf`</span>: The minimum number of samples required to be at a leaf node.</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="fu">## Few tips on RF hyperparameters</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>A few (among many) tips for finding the ideal hyperparameters for RF:</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`ntree`</span> (R) / <span class="in">`n_estimators`</span> (python): Use a large number of trees in the forest to improve model performance, but be aware of the increased computation time. The default value is usually a good starting point. </span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`mtry`</span> (R) / <span class="in">`max_features`</span> (python): Experiment with different values, usually starting with the default (square root of the number of features for classification or one-third of the number of features for regression). Increasing this value may improve model performance but can also increase computation time. </span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`max.depth`</span>: Control the depth of each tree to manage overfitting. Deeper trees capture more complex patterns but can lead to overfitting. Experiment with different values, keeping in mind that a shallower tree can be more interpretable and less prone to overfitting. </span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`nodesize`</span> (R) / <span class="in">`min_samples_split`</span> (python): Increasing this value can help reduce overfitting, but setting it too high might lead to underfitting. Experiment with different values to find the optimal balance.</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classification</span></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data preparation for Random Forest</span></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>Load the library <span class="in">`randomForest`</span> in R. Then, load the <span class="in">`wine`</span> data set. This dataset is about white wine quality (in fact Portuguese vinho verde). The data contains 11 numerical features and 1 factor variable:</span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`fixed.acidity`</span></span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`volatile.acidity`</span></span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`citric.acid`</span></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`residual.sugar`</span></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`chlorides`</span></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`free.sulfur.dioxide`</span></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`total.sulfur.dioxide`</span></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`density`</span></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`pH`</span></span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`sulphates`</span></span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`alcohol`</span></span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`quality: Good/Bad`</span></span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a>All the numerical features have units. The data source can be found <span class="co">[</span><span class="ot">here</span><span class="co">](https://archive.ics.uci.edu/ml/datasets/wine+quality)</span>. For simplicity, only an extraction of 200 wines are used in this exercise. Note that in the original data set, the <span class="in">`quality`</span> is a score (0 to 10) that was turned as factor here for the exercise (Bad: 0 to 5, Good: 6 to 10). Also, note that in the data source, the objective is to predict the quality from the other features (supervised learning).</span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a>As mentioned, the outcome variable used for this dataset is the wine <span class="in">`quality`</span>. We should first coerce the classes as factors. Then, we make the training/test set random split with a 75/25 scheme.</span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a>wine <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"data/Wine.csv"</span>))</span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a>wine<span class="sc">$</span>quality <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(wine<span class="sc">$</span>quality)</span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a><span class="co"># define a function to get the splitting index (training and testing) of a given dataset</span></span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a>get_split_index <span class="ot">&lt;-</span> <span class="cf">function</span>(dataset, <span class="at">train_proportion =</span> <span class="fl">0.75</span>) {</span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a>  index <span class="ot">&lt;-</span></span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sample</span>(</span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,</span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a>      <span class="at">size =</span> <span class="fu">nrow</span>(dataset),</span>
<span id="cb17-82"><a href="#cb17-82" aria-hidden="true" tabindex="-1"></a>      <span class="at">replace =</span> <span class="cn">TRUE</span>,</span>
<span id="cb17-83"><a href="#cb17-83" aria-hidden="true" tabindex="-1"></a>      <span class="at">prob =</span> <span class="fu">c</span>(train_proportion, <span class="dv">1</span> <span class="sc">-</span> train_proportion)</span>
<span id="cb17-84"><a href="#cb17-84" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-85"><a href="#cb17-85" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(index)</span>
<span id="cb17-86"><a href="#cb17-86" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-87"><a href="#cb17-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-88"><a href="#cb17-88" aria-hidden="true" tabindex="-1"></a>wine_index <span class="ot">&lt;-</span> <span class="fu">get_split_index</span>(wine)</span>
<span id="cb17-89"><a href="#cb17-89" aria-hidden="true" tabindex="-1"></a>wine_tr <span class="ot">&lt;-</span> wine[wine_index <span class="sc">==</span> <span class="dv">1</span>, ]</span>
<span id="cb17-90"><a href="#cb17-90" aria-hidden="true" tabindex="-1"></a>wine_te <span class="ot">&lt;-</span> wine[wine_index <span class="sc">==</span> <span class="dv">2</span>, ]</span>
<span id="cb17-91"><a href="#cb17-91" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-92"><a href="#cb17-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-93"><a href="#cb17-93" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb17-96"><a href="#cb17-96" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb17-97"><a href="#cb17-97" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the course python environment as usual with a r code chunks.</span></span>
<span id="cb17-98"><a href="#cb17-98" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb17-99"><a href="#cb17-99" aria-hidden="true" tabindex="-1"></a><span class="fu">use_condaenv</span>(<span class="st">"MLBA"</span>)</span>
<span id="cb17-100"><a href="#cb17-100" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-101"><a href="#cb17-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-102"><a href="#cb17-102" aria-hidden="true" tabindex="-1"></a>Similar to the previous labs, in python, we can use the usual <span class="in">`sklearn`</span> library to do all our modelling. Please note that we will load the data again in python to make the demo easier. Additionally, we'll load all the necessary libraries for this lab in this code chunk.</span>
<span id="cb17-103"><a href="#cb17-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-106"><a href="#cb17-106" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb17-107"><a href="#cb17-107" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-108"><a href="#cb17-108" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-109"><a href="#cb17-109" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb17-110"><a href="#cb17-110" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, RandomForestRegressor</span>
<span id="cb17-111"><a href="#cb17-111" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score, mean_squared_error</span>
<span id="cb17-112"><a href="#cb17-112" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-113"><a href="#cb17-113" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb17-114"><a href="#cb17-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-115"><a href="#cb17-115" aria-hidden="true" tabindex="-1"></a><span class="co"># we first move up one directory to achieve relative paths</span></span>
<span id="cb17-116"><a href="#cb17-116" aria-hidden="true" tabindex="-1"></a>wine <span class="op">=</span> pd.read_csv(<span class="st">'../data/Wine.csv'</span>)</span>
<span id="cb17-117"><a href="#cb17-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-118"><a href="#cb17-118" aria-hidden="true" tabindex="-1"></a>wine[<span class="st">'quality'</span>] <span class="op">=</span> wine[<span class="st">'quality'</span>].astype(<span class="st">'category'</span>)</span>
<span id="cb17-119"><a href="#cb17-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-120"><a href="#cb17-120" aria-hidden="true" tabindex="-1"></a><span class="co"># Split wine dataset into train and test</span></span>
<span id="cb17-121"><a href="#cb17-121" aria-hidden="true" tabindex="-1"></a>train_wine, test_wine <span class="op">=</span> train_test_split(wine, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb17-122"><a href="#cb17-122" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-123"><a href="#cb17-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-124"><a href="#cb17-124" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-125"><a href="#cb17-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-126"><a href="#cb17-126" aria-hidden="true" tabindex="-1"></a>**Note:** Here, we have written a function to make the split as we will also need to apply it also for another dataset in the regression part.</span>
<span id="cb17-127"><a href="#cb17-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-128"><a href="#cb17-128" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training and testing the model</span></span>
<span id="cb17-129"><a href="#cb17-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-130"><a href="#cb17-130" aria-hidden="true" tabindex="-1"></a>Fit a random forest on the train set. The target is the <span class="in">`taste`</span> variable that we want to predict. Specify for the number of trees <span class="in">`ntree=1000`</span> (by default, the function selects $500$ trees). Remember to exclude <span class="in">`quality`</span> in the predictors of the formula. Also, use the option <span class="in">`importance=TRUE`</span>, we will need it afterward. Then test the model by computing the accuracy on the test set. You may use <span class="in">`confusionMatrix`</span> from <span class="in">`caret`</span>.</span>
<span id="cb17-131"><a href="#cb17-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-132"><a href="#cb17-132" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb17-133"><a href="#cb17-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-134"><a href="#cb17-134" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb17-137"><a href="#cb17-137" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb17-138"><a href="#cb17-138" aria-hidden="true" tabindex="-1"></a>wine_rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(quality<span class="sc">~</span>., <span class="at">data=</span>wine_tr, <span class="at">ntree=</span><span class="dv">1000</span>, <span class="at">importance=</span><span class="cn">TRUE</span>)</span>
<span id="cb17-139"><a href="#cb17-139" aria-hidden="true" tabindex="-1"></a>wine.pred_rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(wine_rf, <span class="at">newdata=</span>wine_te)</span>
<span id="cb17-140"><a href="#cb17-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-141"><a href="#cb17-141" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb17-142"><a href="#cb17-142" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>wine.pred_rf, <span class="at">reference =</span> wine_te<span class="sc">$</span>quality)</span>
<span id="cb17-143"><a href="#cb17-143" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-144"><a href="#cb17-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-145"><a href="#cb17-145" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb17-146"><a href="#cb17-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-149"><a href="#cb17-149" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb17-150"><a href="#cb17-150" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Random Forest classifier on the train set</span></span>
<span id="cb17-151"><a href="#cb17-151" aria-hidden="true" tabindex="-1"></a>wine_rf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb17-152"><a href="#cb17-152" aria-hidden="true" tabindex="-1"></a>wine_rf.fit(train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_wine[<span class="st">'quality'</span>])</span>
<span id="cb17-153"><a href="#cb17-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-154"><a href="#cb17-154" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the accuracy</span></span>
<span id="cb17-155"><a href="#cb17-155" aria-hidden="true" tabindex="-1"></a>wine_pred_rf <span class="op">=</span> wine_rf.predict(test_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb17-156"><a href="#cb17-156" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(test_wine[<span class="st">'quality'</span>], wine_pred_rf))</span>
<span id="cb17-157"><a href="#cb17-157" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(test_wine[<span class="st">'quality'</span>], wine_pred_rf))</span>
<span id="cb17-158"><a href="#cb17-158" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-159"><a href="#cb17-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-160"><a href="#cb17-160" aria-hidden="true" tabindex="-1"></a>This model is worse than the R version mostly because of the different defaults.</span>
<span id="cb17-161"><a href="#cb17-161" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-162"><a href="#cb17-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-163"><a href="#cb17-163" aria-hidden="true" tabindex="-1"></a><span class="fu">### Variable importance</span></span>
<span id="cb17-164"><a href="#cb17-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-165"><a href="#cb17-165" aria-hidden="true" tabindex="-1"></a>Extract the model-specific variable importance using the functions <span class="in">`varImpPlot`</span> (plots) and <span class="in">`importance`</span> (values) on the model. Observe well that the mean decrease in accuracy of each variable is also computed for each specific class. In particular, what makes <span class="in">`density`</span> special for predicting <span class="in">`Good`</span> compare to another variable (like for example <span class="in">`citric.acid`</span>)?</span>
<span id="cb17-166"><a href="#cb17-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-167"><a href="#cb17-167" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb17-168"><a href="#cb17-168" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb17-171"><a href="#cb17-171" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb17-172"><a href="#cb17-172" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(wine_rf)</span>
<span id="cb17-173"><a href="#cb17-173" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(wine_rf)</span>
<span id="cb17-174"><a href="#cb17-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-175"><a href="#cb17-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-176"><a href="#cb17-176" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb17-177"><a href="#cb17-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-180"><a href="#cb17-180" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb17-181"><a href="#cb17-181" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable importance</span></span>
<span id="cb17-182"><a href="#cb17-182" aria-hidden="true" tabindex="-1"></a>wine_importances <span class="op">=</span> pd.Series(wine_rf.feature_importances_, index<span class="op">=</span>train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>).columns)</span>
<span id="cb17-183"><a href="#cb17-183" aria-hidden="true" tabindex="-1"></a>wine_importances.sort_values(ascending<span class="op">=</span><span class="va">False</span>).plot(kind<span class="op">=</span><span class="st">'bar'</span>)</span>
<span id="cb17-184"><a href="#cb17-184" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-185"><a href="#cb17-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-186"><a href="#cb17-186" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-187"><a href="#cb17-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-188"><a href="#cb17-188" aria-hidden="true" tabindex="-1"></a><span class="in">`density`</span> is important for predicting the <span class="in">`Good`</span> since their predictions is much less accurate if we do not use it. <span class="in">`citric.acid`</span> is both overall less important than <span class="in">`density`</span> but especially for prediction of <span class="in">`Good`</span>.</span>
<span id="cb17-189"><a href="#cb17-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-190"><a href="#cb17-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-191"><a href="#cb17-191" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression</span></span>
<span id="cb17-192"><a href="#cb17-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-193"><a href="#cb17-193" aria-hidden="true" tabindex="-1"></a>In this part, we will be using the <span class="in">`real_estate_data.csv`</span> once again. After reading the data, apply a random forest to predict <span class="in">`price`</span> using all the other variables except <span class="in">`No`</span>, <span class="in">`Month`</span> and <span class="in">`Year`</span>. Compute the RMSE and inspect the prediction quality with a graph. Note that the importance is not specific to any class here.</span>
<span id="cb17-194"><a href="#cb17-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-195"><a href="#cb17-195" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb17-196"><a href="#cb17-196" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb17-197"><a href="#cb17-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-200"><a href="#cb17-200" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb17-201"><a href="#cb17-201" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb17-202"><a href="#cb17-202" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr)</span>
<span id="cb17-203"><a href="#cb17-203" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"labs/data/real_estate_data.csv"</span>))</span>
<span id="cb17-204"><a href="#cb17-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-205"><a href="#cb17-205" aria-hidden="true" tabindex="-1"></a><span class="co"># select the columns of interest</span></span>
<span id="cb17-206"><a href="#cb17-206" aria-hidden="true" tabindex="-1"></a>real_estate_data <span class="ot">&lt;-</span> </span>
<span id="cb17-207"><a href="#cb17-207" aria-hidden="true" tabindex="-1"></a>  real_estate_data <span class="sc">%&gt;%</span> </span>
<span id="cb17-208"><a href="#cb17-208" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(No, Month, Year))</span>
<span id="cb17-209"><a href="#cb17-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-210"><a href="#cb17-210" aria-hidden="true" tabindex="-1"></a><span class="co"># once again, divide the data into training and testing sets using the function created earlier</span></span>
<span id="cb17-211"><a href="#cb17-211" aria-hidden="true" tabindex="-1"></a>restate_index <span class="ot">&lt;-</span> <span class="fu">get_split_index</span>(real_estate_data)</span>
<span id="cb17-212"><a href="#cb17-212" aria-hidden="true" tabindex="-1"></a>restate_tr <span class="ot">&lt;-</span> real_estate_data[restate_index <span class="sc">==</span> <span class="dv">1</span>, ]</span>
<span id="cb17-213"><a href="#cb17-213" aria-hidden="true" tabindex="-1"></a>restate_te <span class="ot">&lt;-</span> real_estate_data[restate_index <span class="sc">==</span> <span class="dv">2</span>, ]</span>
<span id="cb17-214"><a href="#cb17-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-215"><a href="#cb17-215" aria-hidden="true" tabindex="-1"></a><span class="co"># apply the RF model as a regression</span></span>
<span id="cb17-216"><a href="#cb17-216" aria-hidden="true" tabindex="-1"></a>restate_rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(Price<span class="sc">~</span>., <span class="at">data=</span>restate_tr, <span class="at">ntree=</span><span class="dv">1000</span>, <span class="at">importance=</span><span class="cn">TRUE</span>)</span>
<span id="cb17-217"><a href="#cb17-217" aria-hidden="true" tabindex="-1"></a>restate.pred_rf<span class="ot">&lt;-</span><span class="fu">predict</span>(restate_rf, <span class="at">newdata=</span>restate_te)</span>
<span id="cb17-218"><a href="#cb17-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-219"><a href="#cb17-219" aria-hidden="true" tabindex="-1"></a><span class="co"># compute rmse and plot the results as well the VarImp</span></span>
<span id="cb17-220"><a href="#cb17-220" aria-hidden="true" tabindex="-1"></a>(rmse <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((restate_te<span class="sc">$</span>Price <span class="sc">-</span> restate.pred_rf)<span class="sc">^</span><span class="dv">2</span>)))</span>
<span id="cb17-221"><a href="#cb17-221" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(restate_te<span class="sc">$</span>Price <span class="sc">~</span> restate.pred_rf)</span>
<span id="cb17-222"><a href="#cb17-222" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb17-223"><a href="#cb17-223" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(restate_rf)</span>
<span id="cb17-224"><a href="#cb17-224" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(restate_rf)</span>
<span id="cb17-225"><a href="#cb17-225" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-226"><a href="#cb17-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-227"><a href="#cb17-227" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb17-228"><a href="#cb17-228" aria-hidden="true" tabindex="-1"></a><span class="in">```{python a}</span></span>
<span id="cb17-229"><a href="#cb17-229" aria-hidden="true" tabindex="-1"></a><span class="in"># Load real estate dataset</span></span>
<span id="cb17-230"><a href="#cb17-230" aria-hidden="true" tabindex="-1"></a><span class="in">real_estate_data = pd.read_csv("../data/real_estate_data.csv")</span></span>
<span id="cb17-231"><a href="#cb17-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-232"><a href="#cb17-232" aria-hidden="true" tabindex="-1"></a><span class="in">real_estate_data = real_estate_data.drop(['No', 'Month', 'Year'], axis=1)</span></span>
<span id="cb17-233"><a href="#cb17-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-234"><a href="#cb17-234" aria-hidden="true" tabindex="-1"></a><span class="in"># Split real estate dataset into train and test</span></span>
<span id="cb17-235"><a href="#cb17-235" aria-hidden="true" tabindex="-1"></a><span class="in">train_restate, test_restate = train_test_split(real_estate_data, test_size=0.25, random_state=123)</span></span>
<span id="cb17-236"><a href="#cb17-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-237"><a href="#cb17-237" aria-hidden="true" tabindex="-1"></a><span class="in"># Fit a Random Forest regressor on the train set</span></span>
<span id="cb17-238"><a href="#cb17-238" aria-hidden="true" tabindex="-1"></a><span class="in">restate_rf = RandomForestRegressor(n_estimators=1000, random_state=123)</span></span>
<span id="cb17-239"><a href="#cb17-239" aria-hidden="true" tabindex="-1"></a><span class="in">restate_rf.fit(train_restate.drop('Price', axis=1), train_restate['Price'])</span></span>
<span id="cb17-240"><a href="#cb17-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-241"><a href="#cb17-241" aria-hidden="true" tabindex="-1"></a><span class="in"># Test the model and compute the RMSE</span></span>
<span id="cb17-242"><a href="#cb17-242" aria-hidden="true" tabindex="-1"></a><span class="in">restate_pred_rf = restate_rf.predict(test_restate.drop('Price', axis=1))</span></span>
<span id="cb17-243"><a href="#cb17-243" aria-hidden="true" tabindex="-1"></a><span class="in">rmse = np.sqrt(mean_squared_error(test_restate['Price'], restate_pred_rf))</span></span>
<span id="cb17-244"><a href="#cb17-244" aria-hidden="true" tabindex="-1"></a><span class="in">print("RMSE:", rmse)</span></span>
<span id="cb17-245"><a href="#cb17-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-246"><a href="#cb17-246" aria-hidden="true" tabindex="-1"></a><span class="in"># Plot the prediction quality</span></span>
<span id="cb17-247"><a href="#cb17-247" aria-hidden="true" tabindex="-1"></a><span class="in">plt.scatter(test_restate['Price'], restate_pred_rf)</span></span>
<span id="cb17-248"><a href="#cb17-248" aria-hidden="true" tabindex="-1"></a><span class="in">plt.xlabel('Actual Price')</span></span>
<span id="cb17-249"><a href="#cb17-249" aria-hidden="true" tabindex="-1"></a><span class="in">plt.ylabel('Predicted Price')</span></span>
<span id="cb17-250"><a href="#cb17-250" aria-hidden="true" tabindex="-1"></a><span class="in">plt.plot([min(test_restate['Price']), max(test_restate['Price'])], [min(test_restate['Price']), max(test_restate['Price'])], color='red')</span></span>
<span id="cb17-251"><a href="#cb17-251" aria-hidden="true" tabindex="-1"></a><span class="in">plt.show()</span></span>
<span id="cb17-252"><a href="#cb17-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-253"><a href="#cb17-253" aria-hidden="true" tabindex="-1"></a><span class="in"># Variable importance</span></span>
<span id="cb17-254"><a href="#cb17-254" aria-hidden="true" tabindex="-1"></a><span class="in">restate_importances = pd.Series(restate_rf.feature_importances_, index=train_restate.drop('Price', axis=1).columns)</span></span>
<span id="cb17-255"><a href="#cb17-255" aria-hidden="true" tabindex="-1"></a><span class="in">restate_importances.sort_values(ascending=False).plot(kind='bar')</span></span>
<span id="cb17-256"><a href="#cb17-256" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-257"><a href="#cb17-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-258"><a href="#cb17-258" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-259"><a href="#cb17-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-260"><a href="#cb17-260" aria-hidden="true" tabindex="-1"></a>Compare this model with the one you came up with in <span class="in">`Ex_ML_LinLogReg`</span> . Which one would you go for?</span>
<span id="cb17-261"><a href="#cb17-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-262"><a href="#cb17-262" aria-hidden="true" tabindex="-1"></a><span class="fu"># Gradient Boosting Machines (GBM)</span></span>
<span id="cb17-263"><a href="#cb17-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-264"><a href="#cb17-264" aria-hidden="true" tabindex="-1"></a>In this part of the lab, we will look at how the <span class="in">`gbm`</span> library in R and the <span class="in">`GradientBoostingClassifier`</span> and <span class="in">`GradientBoostingRegressor`</span> in Python can be applied for classification and regression tasks. We will continue using the <span class="in">`wine`</span> dataset for classification and <span class="in">`real_estate_data`</span> for regression.</span>
<span id="cb17-265"><a href="#cb17-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-266"><a href="#cb17-266" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb17-267"><a href="#cb17-267" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hyperparameters of GBM </span></span>
<span id="cb17-268"><a href="#cb17-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-269"><a href="#cb17-269" aria-hidden="true" tabindex="-1"></a>R (using the <span class="in">`gbm`</span> library): </span>
<span id="cb17-270"><a href="#cb17-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-271"><a href="#cb17-271" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`n.trees`</span>: The number of boosting stages to perform (equivalent to <span class="in">`n_estimators`</span> in python). </span>
<span id="cb17-272"><a href="#cb17-272" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`interaction.depth`</span>: The maximum depth of each tree (equivalent to <span class="in">`max_depth`</span> in python). </span>
<span id="cb17-273"><a href="#cb17-273" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`shrinkage`</span>: The learning rate. </span>
<span id="cb17-274"><a href="#cb17-274" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`n.minobsinnode`</span>: The minimum number of samples required to split an internal node (equivalent to <span class="in">`min_samples_split`</span> in python). </span>
<span id="cb17-275"><a href="#cb17-275" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span><span class="in">`bag.fraction`</span>: The fraction of samples to be used for fitting individual base learners (equivalent to <span class="in">`subsample`</span> in python).</span>
<span id="cb17-276"><a href="#cb17-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-277"><a href="#cb17-277" aria-hidden="true" tabindex="-1"></a>Python (using the <span class="in">`sklearn`</span> library):</span>
<span id="cb17-278"><a href="#cb17-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-279"><a href="#cb17-279" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`n_estimators`</span>: The number of boosting stages to perform. Similar to Random Forest, increasing the number of estimators can improve the model's performance but may also increase the computational complexity and training time. </span>
<span id="cb17-280"><a href="#cb17-280" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`learning_rate`</span>: The learning rate shrinks the contribution of each tree. A smaller learning rate requires more boosting stages to achieve the same performance as a larger learning rate, but it can also result in a more robust model. </span>
<span id="cb17-281"><a href="#cb17-281" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`max_depth`</span>: The maximum depth of each tree. Similar to Random Forest, a higher depth can capture more complex patterns in the data, but it may also lead to overfitting. </span>
<span id="cb17-282"><a href="#cb17-282" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`min_samples_split`</span>: The minimum number of samples required to split an internal node. Similar to Random Forest, a smaller value allows the model to capture finer details in the data, while a larger value can help prevent overfitting. </span>
<span id="cb17-283"><a href="#cb17-283" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span><span class="in">`min_samples_leaf`</span>: The minimum number of samples required to be at a leaf node. Similar to Random Forest, a smaller value allows the model to capture finer details, while a larger value can help prevent overfitting.</span>
<span id="cb17-284"><a href="#cb17-284" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span><span class="in">`subsample`</span>: The fraction of samples to be used for fitting individual base learners. A value smaller than 1.0 can lead to a reduction in variance and an increase in bias, resulting in a more robust model.</span>
<span id="cb17-285"><a href="#cb17-285" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-286"><a href="#cb17-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-287"><a href="#cb17-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-288"><a href="#cb17-288" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb17-289"><a href="#cb17-289" aria-hidden="true" tabindex="-1"></a><span class="fu">## Few tips on GBM hyperparameters</span></span>
<span id="cb17-290"><a href="#cb17-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-291"><a href="#cb17-291" aria-hidden="true" tabindex="-1"></a>Similar to R, here are some tips for finding the best combination of the hyperparameters:</span>
<span id="cb17-292"><a href="#cb17-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-293"><a href="#cb17-293" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`n.trees`</span> (R) / <span class="in">`n_estimators`</span> (python): Start with a lower number of trees and increase it until no further improvement in performance is observed. Be aware of the increased computation time with a larger number of trees. </span>
<span id="cb17-294"><a href="#cb17-294" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`interaction.depth`</span> (R) / <span class="in">`max_depth`</span> (python): Keep the depth of each tree relatively shallow (3-5 levels) to prevent overfitting. Deeper trees can capture more complex patterns but may lead to overfitting. </span>
<span id="cb17-295"><a href="#cb17-295" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`shrinkage`</span> (R) / <span class="in">`learning_rate`</span> (python): Use a smaller learning rate for better model performance, but be prepared for slower convergence and increased computation time. Typically, values range between 0.01 and 0.1. </span>
<span id="cb17-296"><a href="#cb17-296" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="in">`n.minobsinnode`</span> (R) / <span class="in">`min_samples_split`</span> (python): Similar to Random Forest, experiment with different values to find the optimal balance between overfitting and underfitting. </span>
<span id="cb17-297"><a href="#cb17-297" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span><span class="in">`bag.fraction`</span> (R) / <span class="in">`subsample`</span> (python): Using a subsample of the data (e.g., 0.5-0.8) can help reduce overfitting and speed up the training process. Experiment with different values to find the best trade-off between performance and computation time.</span>
<span id="cb17-298"><a href="#cb17-298" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-299"><a href="#cb17-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-300"><a href="#cb17-300" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classification</span></span>
<span id="cb17-301"><a href="#cb17-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-302"><a href="#cb17-302" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training and testing the model</span></span>
<span id="cb17-303"><a href="#cb17-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-304"><a href="#cb17-304" aria-hidden="true" tabindex="-1"></a>We now fit a GBM model on the <span class="in">`wine`</span> training set and apply it to the same target variable <span class="in">`quality`</span>. We can train the model and add</span>
<span id="cb17-305"><a href="#cb17-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-306"><a href="#cb17-306" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb17-307"><a href="#cb17-307" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb17-310"><a href="#cb17-310" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb17-311"><a href="#cb17-311" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gbm)</span>
<span id="cb17-312"><a href="#cb17-312" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb17-313"><a href="#cb17-313" aria-hidden="true" tabindex="-1"></a>wine_gbm <span class="ot">&lt;-</span> <span class="fu">gbm</span>(quality<span class="sc">~</span>., <span class="at">data=</span>wine_tr, <span class="at">distribution=</span><span class="st">"multinomial"</span>, <span class="at">n.trees=</span><span class="dv">1000</span>, <span class="at">interaction.depth=</span><span class="dv">4</span>, <span class="at">shrinkage=</span><span class="fl">0.01</span>)</span>
<span id="cb17-314"><a href="#cb17-314" aria-hidden="true" tabindex="-1"></a>wine.pred_gbm <span class="ot">&lt;-</span> <span class="fu">predict</span>(wine_gbm, <span class="at">newdata=</span>wine_te, <span class="at">n.trees=</span><span class="dv">1000</span>, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb17-315"><a href="#cb17-315" aria-hidden="true" tabindex="-1"></a>wine.pred_gbm_class <span class="ot">&lt;-</span> <span class="fu">apply</span>(wine.pred_gbm, <span class="dv">1</span>, which.max)</span>
<span id="cb17-316"><a href="#cb17-316" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(wine_te<span class="sc">$</span>quality) <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(<span class="fu">levels</span>(wine_te<span class="sc">$</span>quality))</span>
<span id="cb17-317"><a href="#cb17-317" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="fu">factor</span>(wine.pred_gbm_class), wine_te<span class="sc">$</span>quality)</span>
<span id="cb17-318"><a href="#cb17-318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-319"><a href="#cb17-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-320"><a href="#cb17-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-321"><a href="#cb17-321" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb17-322"><a href="#cb17-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-325"><a href="#cb17-325" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb17-326"><a href="#cb17-326" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingClassifier</span>
<span id="cb17-327"><a href="#cb17-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-328"><a href="#cb17-328" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Gradient Boosting classifier on the train set</span></span>
<span id="cb17-329"><a href="#cb17-329" aria-hidden="true" tabindex="-1"></a>wine_gbm <span class="op">=</span> GradientBoostingClassifier(n_estimators<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.01</span>, max_depth<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb17-330"><a href="#cb17-330" aria-hidden="true" tabindex="-1"></a>wine_gbm.fit(train_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_wine[<span class="st">'quality'</span>])</span>
<span id="cb17-331"><a href="#cb17-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-332"><a href="#cb17-332" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the accuracy</span></span>
<span id="cb17-333"><a href="#cb17-333" aria-hidden="true" tabindex="-1"></a>wine_pred_gbm <span class="op">=</span> wine_gbm.predict(test_wine.drop(<span class="st">'quality'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb17-334"><a href="#cb17-334" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(test_wine[<span class="st">'quality'</span>], wine_pred_gbm))</span>
<span id="cb17-335"><a href="#cb17-335" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(test_wine[<span class="st">'quality'</span>], wine_pred_gbm))</span>
<span id="cb17-336"><a href="#cb17-336" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-337"><a href="#cb17-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-338"><a href="#cb17-338" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-339"><a href="#cb17-339" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regression</span></span>
<span id="cb17-340"><a href="#cb17-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-341"><a href="#cb17-341" aria-hidden="true" tabindex="-1"></a>In this part, we will continue using the <span class="in">`real_estate_data.csv`</span>. Fit a GBM model on the real estate training set to predict <span class="in">`price`</span> using all the other variables except <span class="in">`No`</span>, <span class="in">`Month`</span>, and <span class="in">`Year`</span>. Then compute the metrics and plot the predictions.</span>
<span id="cb17-342"><a href="#cb17-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-343"><a href="#cb17-343" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb17-344"><a href="#cb17-344" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R</span></span>
<span id="cb17-345"><a href="#cb17-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-348"><a href="#cb17-348" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb17-349"><a href="#cb17-349" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb17-350"><a href="#cb17-350" aria-hidden="true" tabindex="-1"></a>restate_gbm <span class="ot">&lt;-</span> <span class="fu">gbm</span>(Price<span class="sc">~</span>., <span class="at">data=</span>restate_tr, <span class="at">distribution=</span><span class="st">"gaussian"</span>, <span class="at">n.trees=</span><span class="dv">1000</span>, <span class="at">interaction.depth=</span><span class="dv">4</span>, <span class="at">shrinkage=</span><span class="fl">0.01</span>)</span>
<span id="cb17-351"><a href="#cb17-351" aria-hidden="true" tabindex="-1"></a>restate.pred_gbm<span class="ot">&lt;-</span><span class="fu">predict</span>(restate_gbm, <span class="at">newdata=</span>restate_te, <span class="at">n.trees=</span><span class="dv">1000</span>)</span>
<span id="cb17-352"><a href="#cb17-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-353"><a href="#cb17-353" aria-hidden="true" tabindex="-1"></a><span class="co"># compute rmse and plot the results</span></span>
<span id="cb17-354"><a href="#cb17-354" aria-hidden="true" tabindex="-1"></a>(rmse_gbm <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((restate_te<span class="sc">$</span>Price <span class="sc">-</span> restate.pred_gbm)<span class="sc">^</span><span class="dv">2</span>)))</span>
<span id="cb17-355"><a href="#cb17-355" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(restate_te<span class="sc">$</span>Price <span class="sc">~</span> restate.pred_gbm)</span>
<span id="cb17-356"><a href="#cb17-356" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb17-357"><a href="#cb17-357" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-358"><a href="#cb17-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-359"><a href="#cb17-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-360"><a href="#cb17-360" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Python</span></span>
<span id="cb17-361"><a href="#cb17-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-364"><a href="#cb17-364" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb17-365"><a href="#cb17-365" aria-hidden="true" tabindex="-1"></a><span class="co"># run the code below if you have not cleared the plot yet</span></span>
<span id="cb17-366"><a href="#cb17-366" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb17-367"><a href="#cb17-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-368"><a href="#cb17-368" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb17-369"><a href="#cb17-369" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a Gradient Boosting regressor on the train set</span></span>
<span id="cb17-370"><a href="#cb17-370" aria-hidden="true" tabindex="-1"></a>restate_gbm <span class="op">=</span> GradientBoostingRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>, learning_rate<span class="op">=</span><span class="fl">0.01</span>, max_depth<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb17-371"><a href="#cb17-371" aria-hidden="true" tabindex="-1"></a>restate_gbm.fit(train_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>), train_restate[<span class="st">'Price'</span>])</span>
<span id="cb17-372"><a href="#cb17-372" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb17-373"><a href="#cb17-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-374"><a href="#cb17-374" aria-hidden="true" tabindex="-1"></a>restate_pred_gbm <span class="op">=</span> restate_gbm.predict(test_restate.drop(<span class="st">'Price'</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb17-375"><a href="#cb17-375" aria-hidden="true" tabindex="-1"></a>rmse_gbm <span class="op">=</span> np.sqrt(mean_squared_error(test_restate[<span class="st">'Price'</span>], restate_pred_gbm))</span>
<span id="cb17-376"><a href="#cb17-376" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RMSE:"</span>, rmse_gbm)</span>
<span id="cb17-377"><a href="#cb17-377" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the prediction quality</span></span>
<span id="cb17-378"><a href="#cb17-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-379"><a href="#cb17-379" aria-hidden="true" tabindex="-1"></a>plt.scatter(test_restate[<span class="st">'Price'</span>], restate_pred_gbm)</span>
<span id="cb17-380"><a href="#cb17-380" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Actual Price'</span>)</span>
<span id="cb17-381"><a href="#cb17-381" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted Price'</span>)</span>
<span id="cb17-382"><a href="#cb17-382" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], [<span class="bu">min</span>(test_restate[<span class="st">'Price'</span>]), <span class="bu">max</span>(test_restate[<span class="st">'Price'</span>])], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb17-383"><a href="#cb17-383" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-384"><a href="#cb17-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-385"><a href="#cb17-385" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-386"><a href="#cb17-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-387"><a href="#cb17-387" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-388"><a href="#cb17-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-389"><a href="#cb17-389" aria-hidden="true" tabindex="-1"></a>Compare the GBM model with the Random Forest model you came up with earlier. Which one would you go for?</span>
<span id="cb17-390"><a href="#cb17-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-391"><a href="#cb17-391" aria-hidden="true" tabindex="-1"></a><span class="fu"># Bonus: XGBoost</span></span>
<span id="cb17-392"><a href="#cb17-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-393"><a href="#cb17-393" aria-hidden="true" tabindex="-1"></a><span class="fu">## What is XGBoost?</span></span>
<span id="cb17-394"><a href="#cb17-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-395"><a href="#cb17-395" aria-hidden="true" tabindex="-1"></a>XGBoost (Extreme Gradient Boosting) is an optimized implementation of the gradient boosting algorithm. It is designed for high performance and efficient memory usage. XGBoost improves upon the base Gradient Boosting Machine (GBM) by incorporating regularization to prevent overfitting and implementing parallel processing techniques for faster training. The algorithm also offers built-in cross-validation and early stopping to save time and resources during model training.</span>
<span id="cb17-396"><a href="#cb17-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-397"><a href="#cb17-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-398"><a href="#cb17-398" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modelling with XGBoost</span></span>
<span id="cb17-399"><a href="#cb17-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-400"><a href="#cb17-400" aria-hidden="true" tabindex="-1"></a>We'll use the <span class="co">[</span><span class="ot">`xgboost`</span><span class="co">](https://xgboost.readthedocs.io/en/stable/index.html)</span> library in both R and python. You can see some of the hyperparameters below:</span>
<span id="cb17-401"><a href="#cb17-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-402"><a href="#cb17-402" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb17-403"><a href="#cb17-403" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hyperparameters of XGBoost</span></span>
<span id="cb17-404"><a href="#cb17-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-405"><a href="#cb17-405" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`eta`</span>: Controls the learning rate, which determines the step size at each iteration while updating the model weights. Smaller values make the model more robust to overfitting but require more iterations to converge. Typical values range from 0.01 to 0.3. </span>
<span id="cb17-406"><a href="#cb17-406" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`max_depth`</span>: Controls the maximum depth of each tree. Deeper trees can model more complex relationships but are more prone to overfitting. Experiment with different values, keeping in mind that a shallower tree can be more interpretable and less prone to overfitting. </span>
<span id="cb17-407"><a href="#cb17-407" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`min_child_weight`</span>: Controls the minimum sum of instance weights needed in a child node. Increasing this value helps to prevent overfitting by making the model more conservative.</span>
<span id="cb17-408"><a href="#cb17-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-409"><a href="#cb17-409" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-410"><a href="#cb17-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-411"><a href="#cb17-411" aria-hidden="true" tabindex="-1"></a>You can read more about the package in its documentation.</span>
<span id="cb17-412"><a href="#cb17-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-413"><a href="#cb17-413" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb17-414"><a href="#cb17-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-415"><a href="#cb17-415" aria-hidden="true" tabindex="-1"></a><span class="fu">### R</span></span>
<span id="cb17-416"><a href="#cb17-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-419"><a href="#cb17-419" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb17-420"><a href="#cb17-420" aria-hidden="true" tabindex="-1"></a><span class="co"># Install and load the package</span></span>
<span id="cb17-421"><a href="#cb17-421" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("xgboost")</span></span>
<span id="cb17-422"><a href="#cb17-422" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb17-423"><a href="#cb17-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-424"><a href="#cb17-424" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for XGBoost</span></span>
<span id="cb17-425"><a href="#cb17-425" aria-hidden="true" tabindex="-1"></a>dtrain <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(restate_tr[, <span class="sc">-</span><span class="fu">ncol</span>(restate_tr)]), <span class="at">label =</span> restate_tr<span class="sc">$</span>Price)</span>
<span id="cb17-426"><a href="#cb17-426" aria-hidden="true" tabindex="-1"></a>dtest <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(restate_te[, <span class="sc">-</span><span class="fu">ncol</span>(restate_te)]), <span class="at">label =</span> restate_te<span class="sc">$</span>Price)</span>
<span id="cb17-427"><a href="#cb17-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-428"><a href="#cb17-428" aria-hidden="true" tabindex="-1"></a><span class="co"># Set hyperparameters</span></span>
<span id="cb17-429"><a href="#cb17-429" aria-hidden="true" tabindex="-1"></a>params <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb17-430"><a href="#cb17-430" aria-hidden="true" tabindex="-1"></a>  <span class="at">objective =</span> <span class="st">"reg:squarederror"</span>,</span>
<span id="cb17-431"><a href="#cb17-431" aria-hidden="true" tabindex="-1"></a>  <span class="at">eta =</span> <span class="fl">0.1</span>,</span>
<span id="cb17-432"><a href="#cb17-432" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_depth =</span> <span class="dv">5</span>,</span>
<span id="cb17-433"><a href="#cb17-433" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_child_weight =</span> <span class="dv">1</span>,</span>
<span id="cb17-434"><a href="#cb17-434" aria-hidden="true" tabindex="-1"></a>  <span class="at">subsample =</span> <span class="dv">1</span>,</span>
<span id="cb17-435"><a href="#cb17-435" aria-hidden="true" tabindex="-1"></a>  <span class="at">colsample_bytree =</span> <span class="dv">1</span></span>
<span id="cb17-436"><a href="#cb17-436" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-437"><a href="#cb17-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-438"><a href="#cb17-438" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb17-439"><a href="#cb17-439" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="ot">&lt;-</span> <span class="fu">xgb.train</span>(params, dtrain, <span class="at">nrounds =</span> <span class="dv">1000</span>)</span>
<span id="cb17-440"><a href="#cb17-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-441"><a href="#cb17-441" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb17-442"><a href="#cb17-442" aria-hidden="true" tabindex="-1"></a>restate_pred_xgb <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb_model, dtest)</span>
<span id="cb17-443"><a href="#cb17-443" aria-hidden="true" tabindex="-1"></a>rmse_xgb <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((restate_te<span class="sc">$</span>Price <span class="sc">-</span> restate_pred_xgb)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb17-444"><a href="#cb17-444" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"RMSE:"</span>, rmse_xgb))</span>
<span id="cb17-445"><a href="#cb17-445" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-446"><a href="#cb17-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-447"><a href="#cb17-447" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python</span></span>
<span id="cb17-448"><a href="#cb17-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-449"><a href="#cb17-449" aria-hidden="true" tabindex="-1"></a>We will first install the <span class="in">`xgboost`</span> with a R code chunk:</span>
<span id="cb17-450"><a href="#cb17-450" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, eval = F}</span></span>
<span id="cb17-451"><a href="#cb17-451" aria-hidden="true" tabindex="-1"></a><span class="in">reticulate::py_install("xgboost", pip=TRUE)</span></span>
<span id="cb17-452"><a href="#cb17-452" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-453"><a href="#cb17-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-454"><a href="#cb17-454" aria-hidden="true" tabindex="-1"></a>Then we can run the XGBoost model with <span class="in">`xgboost`</span>.</span>
<span id="cb17-455"><a href="#cb17-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-458"><a href="#cb17-458" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb17-459"><a href="#cb17-459" aria-hidden="true" tabindex="-1"></a><span class="co"># Install and load the package</span></span>
<span id="cb17-460"><a href="#cb17-460" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb17-461"><a href="#cb17-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-462"><a href="#cb17-462" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for XGBoost</span></span>
<span id="cb17-463"><a href="#cb17-463" aria-hidden="true" tabindex="-1"></a>dtrain <span class="op">=</span> xgb.DMatrix(train_restate.drop(<span class="st">"Price"</span>, axis<span class="op">=</span><span class="dv">1</span>), label<span class="op">=</span>train_restate[<span class="st">"Price"</span>])</span>
<span id="cb17-464"><a href="#cb17-464" aria-hidden="true" tabindex="-1"></a>dtest <span class="op">=</span> xgb.DMatrix(test_restate.drop(<span class="st">"Price"</span>, axis<span class="op">=</span><span class="dv">1</span>), label<span class="op">=</span>test_restate[<span class="st">"Price"</span>])</span>
<span id="cb17-465"><a href="#cb17-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-466"><a href="#cb17-466" aria-hidden="true" tabindex="-1"></a><span class="co"># Set hyperparameters</span></span>
<span id="cb17-467"><a href="#cb17-467" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb17-468"><a href="#cb17-468" aria-hidden="true" tabindex="-1"></a>    <span class="st">"objective"</span>: <span class="st">"reg:squarederror"</span>,</span>
<span id="cb17-469"><a href="#cb17-469" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eta"</span>: <span class="fl">0.1</span>,</span>
<span id="cb17-470"><a href="#cb17-470" aria-hidden="true" tabindex="-1"></a>    <span class="st">"max_depth"</span>: <span class="dv">3</span>,</span>
<span id="cb17-471"><a href="#cb17-471" aria-hidden="true" tabindex="-1"></a>    <span class="st">"min_child_weight"</span>: <span class="dv">1</span>,</span>
<span id="cb17-472"><a href="#cb17-472" aria-hidden="true" tabindex="-1"></a>    <span class="st">"subsample"</span>: <span class="dv">1</span>,</span>
<span id="cb17-473"><a href="#cb17-473" aria-hidden="true" tabindex="-1"></a>    <span class="st">"colsample_bytree"</span>: <span class="dv">1</span>,</span>
<span id="cb17-474"><a href="#cb17-474" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-475"><a href="#cb17-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-476"><a href="#cb17-476" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb17-477"><a href="#cb17-477" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> xgb.train(params, dtrain, num_boost_round<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb17-478"><a href="#cb17-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-479"><a href="#cb17-479" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model and compute the RMSE</span></span>
<span id="cb17-480"><a href="#cb17-480" aria-hidden="true" tabindex="-1"></a>restate_pred_xgb <span class="op">=</span> xgb_model.predict(dtest)</span>
<span id="cb17-481"><a href="#cb17-481" aria-hidden="true" tabindex="-1"></a>rmse_xgb <span class="op">=</span> np.sqrt(mean_squared_error(test_restate[<span class="st">"Price"</span>], restate_pred_xgb))</span>
<span id="cb17-482"><a href="#cb17-482" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RMSE:"</span>, rmse_xgb)</span>
<span id="cb17-483"><a href="#cb17-483" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-484"><a href="#cb17-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-485"><a href="#cb17-485" aria-hidden="true" tabindex="-1"></a>Although initially our GBM suffered compared to the RF, we can see that XGBoost can help improve the result (the case for the python implementation). However, random forest still outperforms all the other models. </span>
<span id="cb17-486"><a href="#cb17-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-487"><a href="#cb17-487" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-488"><a href="#cb17-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-489"><a href="#cb17-489" aria-hidden="true" tabindex="-1"></a>Feel free to apply XGBoost to the dataset of your choice.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Â© Copyright 2024, <a href="https://iliaazizi.com/">Ilia Azizi &amp; Marc-Olivier Boldi</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/do-unil/mlba/blob/main/labs/06_Ensembles/Ex_ML_Ensemble.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/do-unil/mlba/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with ðŸ¤ and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer><script type="application/javascript">
// Description: Change image src depending on body class (quarto-light or quarto-dark)
function updateImageSrc() {
  var bodyClass = window.document.body.classList;
  var images = window.document.getElementsByTagName('img');
  for (var i = 0; i < images.length; i++) {
    var image = images[i];
    var src = image.src;
    var newSrc = src;
    if (bodyClass.contains('quarto-light') && src.includes('.dark')) {
      newSrc = src.replace('.dark', '.light');
    } else if (bodyClass.contains('quarto-dark') && src.includes('.light')) {
      newSrc = src.replace('.light', '.dark');
    }
    if (newSrc !== src) {
      image.src = newSrc;
    }
  }
}

var observer = new MutationObserver(function(mutations) {
  mutations.forEach(function(mutation) {
    if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
      updateImageSrc();
    }
  });
});

observer.observe(window.document.body, {
  attributes: true
});

updateImageSrc();
</script>


</body></html>