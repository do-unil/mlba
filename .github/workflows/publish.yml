on:
  push:
    branches: main
  pull_request:
    branches: main
  workflow_dispatch:

name: Build Site

permissions:
  contents: write
  pages: write

jobs:
  build-website:
    runs-on: windows-latest
    concurrency:
      group:  ${{ github.workflow }}
      cancel-in-progress: true
    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
      # Configure R to use more memory
      R_MAX_MEM_SIZE: 16000M
      R_MAX_VSIZE: 16000M
    steps:
      - uses: actions/checkout@v3

      - name: Install Quarto CLI
        uses: quarto-dev/quarto-actions/setup@v2
        with:
          tinytex: true
          # version: 1.4.330

      - name: Set up Miniconda
        uses: conda-incubator/setup-miniconda@v2
        with:
          auto-update-conda: true
          python-version: 3.9
          activate-environment: mlba
          miniconda-version: "latest"
          
      - name: Set up R
        uses: r-lib/actions/setup-r@v2
        with:
          use-public-rspm: true
          windows-path-include-mingw: true

      # See here for more info https://github.com/r-lib/actions/tree/v2-branch/setup-renv
      - name: Set up renv
        uses: r-lib/actions/setup-renv@v2
        with:
          cache-version: 3
      
      # Configure memory settings for R on Windows
      - name: Configure R memory settings
        run: |
          echo "R_MAX_MEM_SIZE=16000M" | Out-File -FilePath $env:GITHUB_ENV -Append
          echo "R_MAX_VSIZE=16000M" | Out-File -FilePath $env:GITHUB_ENV -Append
          # Display memory information
          Get-CimInstance Win32_OperatingSystem | Select-Object TotalVisibleMemorySize,FreePhysicalMemory
      
      - name: Publish Quarto Project
        run: |
          quarto publish gh-pages --no-prompt
        shell: bash -el {0}

      - name: Deploy ðŸš€
        if: github.event_name != 'pull_request'
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          branch: gh-pages # The branch the action should deploy to.
          folder: _site # The folder the action should deploy.