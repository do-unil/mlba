{
  "hash": "32cda24379d7eb8f4f1e868f1bf78175",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Model scoring\"\n---\n\n\n\n\n# Regression task\n\n## Data\n\nThe data set is the one used in the series on linear regressions.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(readr)\nreal_estate_data <- read.csv(here::here(\"labs/data/real_estate_data.csv\"))\n```\n:::\n\n\nThen we split the data in a training and a test set (0.8/0.2). For this, we use the `createDataPartition` function of the `caret` package.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(caret)\nset.seed(234)\nindex_tr <- createDataPartition(y = real_estate_data$Price, p= 0.8, list = FALSE)\ndf_tr <- real_estate_data[index_tr,]\ndf_te <- real_estate_data[-index_tr,]\n```\n:::\n\n\n## Models\n\nWe will compare a linear regression, a regression tree and a 3-NN (KNN).\n\n::: panel-tabset\n### R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(rpart)\nest_lm <- lm(Price~TransDate+HouseAge+Dist+\n               NumStores+Lat+Long, data=df_tr)\nest_rt <- rpart(Price~TransDate+HouseAge+Dist+\n                      NumStores+Lat+Long, data=df_tr)\nest_knn <- knnreg(Price~TransDate+HouseAge+Dist+\n                      NumStores+Lat+Long, data=df_tr, k = 3)\n```\n:::\n\n\n### Python\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the course python environment as usual with a r code chunks.\nlibrary(reticulate)\nuse_condaenv(\"MLBA\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\n# Fit the models: linear regression, regression tree, and KNN\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\n\n# Define predictors and target variable\npredictors = ['TransDate', 'HouseAge', 'Dist', 'NumStores', 'Lat', 'Long']\ntarget = 'Price'\n\n# Fit models\nest_lm = LinearRegression().fit(r.df_tr[predictors], r.df_tr[target])\nest_rt = DecisionTreeRegressor(random_state=234).fit(r.df_tr[predictors], r.df_tr[target])\nest_knn = KNeighborsRegressor(n_neighbors=3).fit(r.df_tr[predictors], r.df_tr[target])\n```\n:::\n\n\n:::\n\n## R-squared\n\n::: panel-tabset\n### R\nWe now compute the R2 for each model using the `R2` function (in `caret`).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nR2(predict(est_lm, newdata = df_te), df_te$Price)\nR2(predict(est_rt, newdata = df_te), df_te$Price)\nR2(predict(est_knn, newdata = df_te), df_te$Price)\n```\n:::\n\n\nJust for the exercise, we can compute it by hand (square of the correlation)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor(predict(est_lm, newdata = df_te), df_te$Price)^2\n```\n:::\n\n\n### Python\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\n# Same thing as the R code\nfrom sklearn.metrics import r2_score\nimport numpy as np\n\n# Only to demonostrate which argument goes where (different from `caret::R2`)\nprint(r2_score(y_true = r.df_te[target], y_pred = est_lm.predict(r.df_te[predictors])))\n```\n\n```{.python .cell-code}\nprint(r2_score(r.df_te[target], est_rt.predict(r.df_te[predictors])))\n```\n\n```{.python .cell-code}\nprint(r2_score(r.df_te[target], est_knn.predict(r.df_te[predictors])))\n```\n\n```{.python .cell-code}\n# Computing it by hand gives us the same result as R\nnp.corrcoef(est_lm.predict(r.df_te[predictors]), r.df_te[target])[0][1]**2\n```\n:::\n\n\nTo understand why the results are different in `caret::R2()` vs. `sklearn.metrics.r2_score()`, \nsee [this post on stackoverflow](https://stats.stackexchange.com/questions/586821/what-is-the-interpretation-of-the-traditional-r2). If you want to get the same results in both, you can set the argument `form = 'corr'` to `form = \"traditional\"` in `caret::R2()` so that for instance `R2(predict(est_lm, newdata = df_te), df_te$Price, form = \"traditional\")`, produces the same result of 0.642401.\n\nAdditionally, please note that the performance of the tree is highly dependent on the seed, so setting a different seed can lead to different results.\n\n:::\n\n## RMSE\n\nNow, we compute the RMSE.\n\n::: panel-tabset\n### R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nRMSE(predict(est_lm, newdata = df_te), df_te$Price)\nRMSE(predict(est_rt, newdata = df_te), df_te$Price)\nRMSE(predict(est_knn, newdata = df_te), df_te$Price)\n```\n:::\n\n\nThe formula would be:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsqrt(mean((predict(est_lm, newdata = df_te)-df_te$Price)^2))\n```\n:::\n\n\n### Python\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\nprint(mean_squared_error(r.df_te[target], est_lm.predict(r.df_te[predictors]), squared = False))\n```\n\n```{.python .cell-code}\n# alternatively in the older version of `sklearn`, you had to run the code below\n# print(np.sqrt(mean_squared_error(r.df_te[target], est_lm.predict(r.df_te[predictors]))))\nprint(mean_squared_error(r.df_te[target], est_rt.predict(r.df_te[predictors]), squared = False))\n```\n\n```{.python .cell-code}\nprint(mean_squared_error(r.df_te[target], est_knn.predict(r.df_te[predictors]), squared = False))\n```\n:::\n\n\n:::\n\n## MAE\n\nNow, we compute the MAE.\n\n::: panel-tabset\n### R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nMAE(predict(est_lm, newdata = df_te), df_te$Price)\nMAE(predict(est_rt, newdata = df_te), df_te$Price)\nMAE(predict(est_knn, newdata = df_te), df_te$Price)\n```\n:::\n\nThe formula would be:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(abs(predict(est_lm, newdata = df_te)-df_te$Price))\n```\n:::\n\n\n\n### Python\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\n# Compute MAE for each model\nfrom sklearn.metrics import mean_absolute_error\n\nprint(mean_absolute_error(r.df_te[target], est_lm.predict(r.df_te[predictors])))\n```\n\n```{.python .cell-code}\nprint(mean_absolute_error(r.df_te[target], est_rt.predict(r.df_te[predictors])))\n```\n\n```{.python .cell-code}\nprint(mean_absolute_error(r.df_te[target], est_knn.predict(r.df_te[predictors])))\n```\n:::\n\n\n:::\n\n## Best model\n\nThese three measures agree on the fact that the regression tree is the best model. To inspect further the predictions, we use scatterplots:\n\n::: panel-tabset\n### R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(df_te$Price ~ predict(est_lm, newdata = df_te), xlab=\"Prediction\", \n     ylab=\"Observed prices\", main=\"Lin. Reg.\")\nabline(0,1)\nplot(df_te$Price ~ predict(est_rt, newdata = df_te), xlab=\"Prediction\", \n     ylab=\"Observed prices\", main=\"Lin. Reg.\")\nabline(0,1)\nplot(df_te$Price ~ predict(est_knn, newdata = df_te), xlab=\"Prediction\", \n     ylab=\"Observed prices\", main=\"Lin. Reg.\")\nabline(0,1)\npar(mfrow=c(1,1))\n```\n:::\n\n\n### Python\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\n# visualize also in Python\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 6))\n\nplt.subplot(221)\nplt.scatter(est_lm.predict(r.df_te[predictors]), r.df_te[target], alpha=0.5)\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"Observed prices\")\nplt.title(\"Lin. Reg.\")\nplt.plot(r.df_te[target], r.df_te[target], color='red')\n\nplt.subplot(222)\nplt.scatter(est_rt.predict(r.df_te[predictors]), r.df_te[target], alpha=0.5)\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"Observed prices\")\nplt.title(\"Regression Tree\")\nplt.plot(r.df_te[target], r.df_te[target], color='red')\n\nplt.subplot(223)\nplt.scatter(est_knn.predict(r.df_te[predictors]), r.df_te[target], alpha=0.5)\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"Observed prices\")\nplt.title(\"KNN\")\nplt.plot(r.df_te[target], r.df_te[target], color='red')\n\nplt.tight_layout()\nplt.show()\n```\n:::\n\n:::\n\nThe scatterplots are in line with the conclusion that KNN is the best, even though it is not easy to declare from a plot. We can in addition see that the regression tree (RT) has made more error on the larger prices.\n\n# Classification task\n\n## Data\n\nThe data set is the visit data (already used in previous exercises). For simplicity, we turn the outcome (`visits`) into factor. Like before, that are also split into a training and a test set.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nDocVis <- read.csv(here::here(\"labs/data/DocVis.csv\"))\nDocVis$visits <- as.factor(DocVis$visits)\n\nlibrary(caret)\nset.seed(346)\nindex_tr <- createDataPartition(y = DocVis$visits, p= 0.8, list = FALSE)\ndf_tr <- DocVis[index_tr,]\ndf_te <- DocVis[-index_tr,]\n```\n:::\n\n\n## Models\n\nWe will compare a logistic regression, a classification tree (pruned) and a SVM with radial basis (cost and gamma tuned).\n\n:::panel-tabset\n### R\nNote that the *code for tuning the SVM* is provided below in comments because of the time it takes to run. The final parameters have been selected accordingly. Also, the SVM fit includes the argument `probability=TRUE` to allow the calculations of predicted probabilities later.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(e1071)\nlibrary(adabag)\n\n## Logistic regression\nDoc_lr <- glm(visits~., data=df_tr, family=\"binomial\")\nDoc_lr <- step(Doc_lr)\n\n## Classification tree \nDoc_ct <- autoprune(visits~., data=df_tr)\n\n## SVM radial basis\n# grid_radial <- expand.grid(sigma = c(0.0001, 0.001, 0.01, 0.1),\n#                           C = c(0.1, 1, 10, 100, 1000))\n# trctrl <- trainControl(method = \"cv\", number=10)\n# set.seed(143)\n# Doc_svm <- train(visits ~., data = df_tr, method = \"svmRadial\",\n#                          trControl=trctrl,\n#                          tuneGrid = grid_radial)\nDoc_svm <- svm(visits~., data=df_tr, gamma=0.001, cost=1000, probability=TRUE)\n```\n:::\n\n\n### Python\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\n\n# We first put the data in a nice format by one-hot encoding the categorical variables\nX_train = pd.get_dummies(r.df_tr.drop('visits', axis=1))\ny_train = r.df_tr['visits']\nX_test = pd.get_dummies(r.df_te.drop('visits', axis=1))\ny_test = r.df_te['visits']\n\n## Logistic regression\ndoc_lr = LogisticRegression()\ndoc_lr.fit(X_train, y_train)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>\n```\n\n:::\n\n```{.python .cell-code}\n## Classification tree\ndoc_ct = DecisionTreeClassifier(random_state=123)\ndoc_ct.fit(X_train, y_train)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<style>#sk-container-id-2 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-2 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-2 pre {\n  padding: 0;\n}\n\n#sk-container-id-2 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-2 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-2 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-2 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-2 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-2 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-2 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-2 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-2 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-2 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n#sk-container-id-2 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-2 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-2 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-2 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-2 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-2 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-2 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(random_state=123)</pre></div> </div></div></div></div>\n```\n\n:::\n\n```{.python .cell-code}\n## SVM radial basis\ndoc_svm = SVC(kernel='rbf', gamma=0.001, C=1000, probability=True, random_state=123)\ndoc_svm.fit(X_train, y_train)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<style>#sk-container-id-3 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-3 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-3 pre {\n  padding: 0;\n}\n\n#sk-container-id-3 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-3 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-3 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-3 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-3 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-3 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-3 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-3 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-3 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-3 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n#sk-container-id-3 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-3 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-3 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-3 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-3 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-3 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-3 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1000, gamma=0.001, probability=True, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=1000, gamma=0.001, probability=True, random_state=123)</pre></div> </div></div></div></div>\n```\n\n:::\n:::\n\n:::\n\n## Predictions\n\nWe now compute the predicted probabilities and the predictions of all the models.\n\n::: panel-tabset\n## R\nNote that, for SVM, we need to extract the *attribute* \"probabilities\" from the predicted object. This can be done with the `attr` function.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Logistic regression\nDoc_lr_prob <- predict(Doc_lr, newdata=df_te, type=\"response\")\nDoc_lr_pred <- ifelse(Doc_lr_prob>0.5,\"Yes\",\"No\")\n\n## Classification tree \nDoc_ct_prob <- predict(Doc_ct, newdata=df_te, type=\"prob\")\nDoc_ct_pred <- predict(Doc_ct, newdata=df_te, type=\"class\")\n\n## SVM radial basis\nlibrary(dplyr)\nDoc_svm_prob <- predict(Doc_svm, newdata=df_te, probability=TRUE) %>% attr(\"probabilities\")\nDoc_svm_pred <- predict(Doc_svm, newdata=df_te, type=\"class\")\n```\n:::\n\n\n## Python\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\n## Logistic regression\n## the second column represents the `no` values, to make sure of that, you can run `doc_lr.classes_`\ndoc_lr_prob = doc_lr.predict_proba(X_test)[:,1]\ndoc_lr_pred = np.where(doc_lr_prob>0.5, \"Yes\", \"No\")\n\n## Classification tree\ndoc_ct_prob = doc_ct.predict_proba(X_test)[:,1]\ndoc_ct_pred = doc_ct.predict(X_test)\n\n## SVM radial basis\ndoc_svm_prob = doc_svm.predict_proba(X_test)[:,1]\ndoc_svm_pred = doc_svm.predict(X_test)\n```\n:::\n\n:::\n\n## Confusion matrices & prediction-based measures\n\n::: panel-tabset\n### R\nThe `confusionMatrix` function provides all the accuracy measures that we want.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconfusionMatrix(data=as.factor(Doc_lr_pred), reference = df_te$visits)\nconfusionMatrix(data=as.factor(Doc_ct_pred), reference = df_te$visits)\nconfusionMatrix(data=as.factor(Doc_svm_pred), reference = df_te$visits)\n```\n:::\n\n\n### Python\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\nfrom sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, cohen_kappa_score\n\n## Logistic regression\nprint(confusion_matrix(y_test, doc_lr_pred))\n```\n\n```{.python .cell-code}\nprint(f\"Accuracy: {accuracy_score(y_test, doc_lr_pred):.3f}\")\n```\n\n```{.python .cell-code}\nprint(f\"Kappa: {cohen_kappa_score(y_test, doc_lr_pred):.3f}\")\n```\n\n```{.python .cell-code}\nprint(f\"Balanced accuracy: {balanced_accuracy_score(y_test, doc_lr_pred):.3f}\")\n```\n\n```{.python .cell-code}\n## Classification tree\nprint(confusion_matrix(y_test, doc_ct_pred))\n```\n\n```{.python .cell-code}\nprint(f\"Accuracy: {accuracy_score(y_test, doc_ct_pred):.3f}\")\n```\n\n```{.python .cell-code}\nprint(f\"Kappa: {cohen_kappa_score(y_test, doc_ct_pred):.3f}\")\n```\n\n```{.python .cell-code}\nprint(f\"Balanced accuracy: {balanced_accuracy_score(y_test, doc_ct_pred):.3f}\")\n```\n\n```{.python .cell-code}\n## SVM radial basis\nprint(confusion_matrix(y_test, doc_svm_pred))\n```\n\n```{.python .cell-code}\nprint(f\"Accuracy: {accuracy_score(y_test, doc_svm_pred):.3f}\")\n```\n\n```{.python .cell-code}\nprint(f\"Kappa: {cohen_kappa_score(y_test, doc_svm_pred):.3f}\")\n```\n\n```{.python .cell-code}\nprint(f\"Balanced accuracy: {balanced_accuracy_score(y_test, doc_svm_pred):.3f}\")\n```\n:::\n\nDifferent results for the tree and CSV due to randomness, but even with that, SVM remains the best model in terms of accuracy.\n\n:::\n\nThe conclusion may be different from one measure to another\n\n-   Accuracy: the SVM reaches the highest accuracy\n-   Kappa: the CT is the highest.\n-   Balanced accuracy: the CT is the highest.\n-   etc.\n\nLooking at the confusion matrix, we see that the data is highly unbalanced (many more \"No\" than \"Yes\"). Therefore, measures like balanced accuracy and kappa are interesting because they take this characteristics into account. This shows that the CT is probably better than the SVM because it reaches a better balance between predicting \"Yes\" and \"No\".\n\nBy looking at the sensitivity and specificity ([!! here the positive class is \"No\"]{.underline}), we see that the best model to recover the \"No\" is the logistic regression (largest sensitivity) and the best model to recover the \"Yes\" is the classification tree (largest specificity).\n\n## Probability-based measures\n\n::: panel-tabset\n### R\nTo compute the AUC (area under the ROC curve) we can use the `caret::twoClassSummary` function. The use of this function can be tricky. Its argument should be a data frame with columns (names are fixed):\n\n-   \"obs\": the observed classes\n-   \"pred\": the predicted classes\n-   two columns with names being the levels of the classes, here \"Yes\" and \"No\", containing the predicted probabilities.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_pred_lr <- data.frame(obs=df_te$visits,\n                         Yes=Doc_lr_prob,\n                         No=1-Doc_lr_prob,\n                         pred=as.factor(Doc_lr_pred))\nhead(df_pred_lr)\n\ndf_pred_ct <- data.frame(obs=df_te$visits,\n                         Doc_ct_prob,\n                         pred=as.factor(Doc_ct_pred))\nhead(df_pred_ct)\ndf_pred_svm <- data.frame(obs=df_te$visits,\n                          Doc_svm_prob,\n                          pred=as.factor(Doc_svm_pred))\nhead(df_pred_svm)\n```\n:::\n\n\nThen we pass these objects to the function, and levels of the classes to be predicted (for the function to be able to recover them in the data frame). The function compute the AUC by default (under the name ROC_.. not very wise) as well as sensitivity and specificity (that we already have).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntwoClassSummary(df_pred_lr, lev = levels(df_pred_lr$obs))\ntwoClassSummary(df_pred_ct, lev = levels(df_pred_lr$obs))\ntwoClassSummary(df_pred_svm, lev = levels(df_pred_lr$obs))\n```\n:::\n\n\nThis brings us another view: the logistic regression has the highest AUC. This shows that varying the prediction threshold provides a good potential of improving the specificity and the sensitivity (in fine, the balanced accuracy).\n\nNow we compute the entropy using the `mnLogLoss` function (entropy is also called *log-loss*).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmnLogLoss(df_pred_lr, lev = levels(df_pred_lr$obs))\nmnLogLoss(df_pred_ct, lev = levels(df_pred_lr$obs))\nmnLogLoss(df_pred_svm, lev = levels(df_pred_lr$obs))\n```\n:::\n\n\nHere again, the entropy selects the logistic regression as the best model, though close to classification tree and SVM.\n\n### Python\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\n## Logistic regression\nprint(f\"AUC: {roc_auc_score(y_test, doc_lr_prob):.3f}\")\n```\n\n```{.python .cell-code}\n## Classification tree\nprint(f\"AUC: {roc_auc_score(y_test, doc_ct_prob):.3f}\")\n```\n\n```{.python .cell-code}\n## SVM radial basis\nprint(f\"AUC: {roc_auc_score(y_test, doc_svm_prob):.3f}\")\n```\n\n```{.python .cell-code}\n# Now we compute the entropy using the `log_loss` function (entropy is also called *log-loss*).\n\nfrom sklearn.metrics import log_loss\n\n## Logistic regression\nprint(f\"Log-loss: {log_loss(y_test, doc_lr_prob):.3f}\")\n```\n\n```{.python .cell-code}\n## Classification tree\nprint(f\"Log-loss: {log_loss(y_test, doc_ct_prob):.3f}\")\n```\n\n```{.python .cell-code}\n## SVM radial basis\nprint(f\"Log-loss: {log_loss(y_test, doc_svm_prob):.3f}\")\n```\n:::\n\n\n:::\n\n## ROC curve & prob threshold tuning\n\n::: panel-tabset\n### R\nTo go deeper in the analysis, we now produce the ROC curve of each model using the `roc` function of the `proc` package.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(pROC)\nROC_lr <- roc(obs ~ Yes, data=df_pred_lr)\nROC_ct <- roc(obs ~ Yes, data=df_pred_ct)\nROC_svm <- roc(obs ~ Yes, data=df_pred_svm)\n\nplot(ROC_lr, print.thres=\"best\")\nplot(ROC_ct, print.thres=\"best\", add=TRUE)\nplot(ROC_svm, print.thres=\"best\", add=TRUE)\n```\n:::\n\n\nThe plotting function provides an \"optimal\" threshold that reaches the best trade-off between sensitivity and specificity (according to some criterion). We see that there is room to improve this trade-off.\n\nNow, to tune this threshold, we need to do it *on the training set* to avoid overfitting. To do this, we just repeat the previous calculations (predictions) on the training set. To simplify, we only do this on the logistic regression (note that you can try on the other models; you may find that logistic regression is the best one).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nDoc_lr_prob_tr <- predict(Doc_lr, newdata=df_tr, type=\"response\")\ndf_pred_lr_tr <- data.frame(obs=df_tr$visits,\n                            Yes=Doc_lr_prob_tr)\nROC_lr_tr <- roc(obs ~ Yes, data=df_pred_lr_tr)\nplot(ROC_lr_tr, print.thres=\"best\")\n```\n:::\n\n\nThe best threshold is 0.193. Now let us compute the confusion table with this threshold.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nDoc_lr_pred_opt <- ifelse(Doc_lr_prob>0.193,\"Yes\",\"No\")\nconfusionMatrix(data=as.factor(Doc_lr_pred_opt), reference = df_te$visits)\n```\n:::\n\n\nWe now have a model with an accuracy of circa $70\\%$ but with a balanced accuracy of $67\\%$. Far from perfect, this is still an interesting improvement compare to the CT $62\\%$. The specificity and sensitivity are now respectively $62\\%$ and $72\\%$. The specificity in particular made a huge improvement (from around $29\\%$ at best - by CT - to $62\\%$ - by log. reg).\n\nIf the aim is to predict both \"Yes\" and \"No\", this last model (log. reg. with tuned threshold) is the best one to use.\n\n### Python\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\n## Logistic regression\n## We need to turn back our results into binary values to be plotted\ndoc_lr_prob_dict = {'Yes': 1, 'No': 0}\ny_test_binary = np.array([doc_lr_prob_dict[x] for x in y_test])\nfpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test_binary, doc_lr_prob)\nplt.plot(fpr_lr, tpr_lr, label=\"Logistic Regression\")\n\n## Classification tree\ndoc_ct_prob_dict = {'Yes': 1, 'No': 0}\ny_test_binary = np.array([doc_ct_prob_dict[x] for x in y_test])\nfpr_ct, tpr_ct, thresholds_ct = roc_curve(y_test_binary, doc_ct_prob)\nplt.plot(fpr_ct, tpr_ct, label=\"Classification Tree\")\n\n## SVM radial basis\ndoc_svm_prob_dict = {'Yes': 1, 'No': 0}\ny_test_binary = np.array([doc_svm_prob_dict[x] for x in y_test])\nfpr_svm, tpr_svm, thresholds_svm = roc_curve(y_test_binary, doc_svm_prob)\n\n# Clear the last plot (if any)\n# plt.clf()\n\nplt.plot(fpr_svm, tpr_svm, label=\"SVM Radial Basis\")\n# Plot the ROC curve\nplt.plot([0, 1], [0, 1], 'k--', label=\"Random Classifier\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nplt.legend()\nplt.show()\n```\n:::\n\n\nWe can then plot the results in the similar way to R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\ndoc_lr_prob_tr = doc_lr.predict_proba(X_train)[:,1]\ndoc_lr_prob_tr_dict = {'Yes': 1, 'No': 0}\ny_train_binary = np.array([doc_lr_prob_tr_dict[x] for x in y_train])\nfpr_lr_tr, tpr_lr_tr, thresholds_lr_tr = roc_curve(y_train_binary, doc_lr_prob_tr)\noptimal_idx = np.argmax(tpr_lr_tr - fpr_lr_tr)\noptimal_threshold = thresholds_lr_tr[optimal_idx]\nprint(f\"Optimal threshold: {optimal_threshold:.3f}\")\n```\n:::\n\n\nFinally, we print the confusion matrix again:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.python .cell-code}\ndoc_lr_pred_opt = np.where(doc_lr_prob > optimal_threshold, \"Yes\", \"No\")\nprint(confusion_matrix(y_test, doc_lr_pred_opt))\n```\n:::\n\nThe logistic regression produced with R was better.\n\n:::\n\n# Your turn\n\n## Classification\n\nRepeat the analysis on the German credit data. Put several models in competition. Tune them and try to optimize their threshold. Select the best one and analyze its performance.\n\n## Regression\n\nRepeat the analysis on the nursing cost data. Put several models in competition. Tune them and select the best one. Analyze its performance using a scatterplot.\n",
    "supporting": [
      "Ex_ML_Scoring_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}